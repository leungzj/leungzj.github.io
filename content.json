{"meta":{"title":"Jim's Blog","subtitle":null,"description":null,"author":"Jim","url":"http://yoursite.com"},"pages":[{"title":"","date":"2018-11-23T02:53:13.907Z","updated":"2018-11-23T02:53:13.907Z","comments":true,"path":"google6067bd16d98499cd.html","permalink":"http://yoursite.com/google6067bd16d98499cd.html","excerpt":"","text":"google-site-verification: google6067bd16d98499cd.html"},{"title":"","date":"2018-10-30T03:17:12.022Z","updated":"2018-10-30T03:17:12.022Z","comments":true,"path":"baidu_verify_HCnRC8FAR2.html","permalink":"http://yoursite.com/baidu_verify_HCnRC8FAR2.html","excerpt":"","text":"HCnRC8FAR2"},{"title":"","date":"2018-10-17T02:15:56.847Z","updated":"2018-10-17T02:15:56.843Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":"关于运维工程师，熟悉网络、运维、数据库、自学前端、python，志向于全栈认证：CCNA,SAA,PMP,中级网络工程师，目前在考高级项目管理师 { name: ‘jim’ age: ‘28’ gender: ‘男’ profession: ‘Operation’ experience: ‘3年’ address: ‘广东省广州市’ education: ‘本科’ github: ‘https://github.com/leungzj&#39; email: &#39;18826400669@163.com‘ blog: ‘leungzj.github.io’ description: ‘技术改变世界’ skills: [ 网络、运维、SQL、python...(持续更新中) ] }"},{"title":"categories","date":"2018-09-19T09:02:45.000Z","updated":"2018-09-19T09:06:58.378Z","comments":true,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""},{"title":"","date":"2018-12-17T02:52:24.170Z","updated":"2018-12-17T02:52:24.170Z","comments":true,"path":"books/index.html","permalink":"http://yoursite.com/books/index.html","excerpt":"","text":"docker:《第一本docker书》 python:《python编程:从入门到实践》 mongodb:《MongoDB权威指南》 shell:《linux与Unix_shell编程指南》 puppet:《puppet权威指南》 jenkins:《jenkins权威指南》"},{"title":"标签","date":"2018-10-17T02:54:58.153Z","updated":"2018-10-17T02:54:58.153Z","comments":false,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2018-10-17T03:21:43.737Z","updated":"2018-10-17T03:21:43.733Z","comments":false,"path":"links/index.html","permalink":"http://yoursite.com/links/index.html","excerpt":"","text":""}],"posts":[{"title":"nginx（缓存）","slug":"nginx（缓存）","date":"2019-03-01T08:00:00.000Z","updated":"2019-03-01T09:53:44.995Z","comments":true,"path":"2019/03/01/nginx（缓存）/","link":"","permalink":"http://yoursite.com/2019/03/01/nginx（缓存）/","excerpt":"","text":"1、缓存的优点nginx缓存，可以在一定程度上减少源服务器的处理请求压力。因为静态文件（比如css、js、图片）中，很多都是不经常更新的。nginx使用proxy_cache将用户的请求缓存到本地一个目录，下一个相同的请求可以直接调取缓存文件，就不用去请求服务器了。 2、配置说明开启简单的缓存配置，只需要两个指令：proxy_cache_path和proxy_cache。proxy_cache_path：配置缓存的存放地址和其他的一些常用配置proxy_cache：启动缓存 3、proxy_cache_path配置例子：proxy_cache_path /path/to/cache levels=1:2 keys_zone=mycache:10m max_size=10g inactive=60m use_temp_path=off;相关配置说明如下：1）/path/to/cache，本地路径，用来设置nginx缓存资源的存放路径2）levels，默认所有的缓存文件都放在同一个/path/to/cache下，但是会影响缓存的性能，因此通常会在/path/to/cache下面建立子目录用来分别存放不同的文件。假设levels=1:2，nginx为将要缓存的资源生成的key是f4cd0fbc769e94925ec5540b6a4136d0，那么key的最后一位0，以及倒数第2-3位6d作为二级的子目录，也就是该资源最终会被缓存到/path/to/cache/0/6d目录中3）key_zone，在共享内存中设置一块存储区域来存放缓存的key和metadata（类似使用次数），这样nginx可以快速判断一个request是否命中或者未命中缓存。1m可以存储8000个key，10m可以存储80000个key。4）max_size：最大cache空间，如果不指定，会使用掉所有的disk space，当达到配额后，会删除最少使用的cache文件。5）inactive：未被访问文件在缓存中保留时间。本配置中如果60分钟未被访问则不论状态是否为expired，缓存控制程序会删掉文件。inactive默认是10分钟，需要注意的是，inactive和expired配置项的含义是不同的，expired只是缓存过期，但不会被删除，inactive是删除指定时间内未被访问的缓存文件。6）use_temp_path：如果为off，则nginx会将配置文件直接写入到指定的cache文件中，而不是用temp_path存储，官方建议为off，避免文件在不同文件系统中不必要的拷贝。 4、proxy_cache配置proxy_cache on启用proxy_cache，并指定key_zone。如果proxy_cache off表示关掉缓存功能。","categories":[{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/categories/nginx/"}],"tags":[]},{"title":"nginx（负载均衡调度状态）","slug":"nginx（负载均衡调度状态）","date":"2019-03-01T06:50:00.000Z","updated":"2019-03-01T06:54:50.036Z","comments":true,"path":"2019/03/01/nginx（负载均衡调度状态）/","link":"","permalink":"http://yoursite.com/2019/03/01/nginx（负载均衡调度状态）/","excerpt":"","text":"在nginx upstream模块中，可以设定每台后端服务器在负载均衡调度中的状态，常见的状态有：1）down：表示当前的server暂时不参与负载均衡2）backup：预留的备份机器。当其他所有的非backup机器出现故障或者忙的时候，才会请求backup机器，因此这台机器的访问压力最小3）max_fails：允许请求失败的最大次数，默认为1。当超过最大次数时，返回proxy_next_upstream模块定义的错误4）fail_timeout：请求失败超时时间，在经历了max_fails次失败之后，暂停服务的时间。max_fails和fail_timeout可以一起使用","categories":[{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/categories/nginx/"}],"tags":[]},{"title":"nginx（负载均衡算法实例）","slug":"nginx（负载均衡算法实例）","date":"2019-03-01T06:13:00.000Z","updated":"2019-03-01T06:22:00.142Z","comments":true,"path":"2019/03/01/nginx（负载均衡算法实例）/","link":"","permalink":"http://yoursite.com/2019/03/01/nginx（负载均衡算法实例）/","excerpt":"","text":"1、轮询（默认）每个请求按照时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。 2、weight指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。代码如下：upstream backend{ server 192.168.0.14 weight=10; server 192.168.0.15 weight=10;} 3、ip_hash每个请求按照访问ip的hash结果分配，这样每个访客固定访问一台后端服务器，可以解决session的问题。代码如下：upstream backend{ ip_hash; server 192.168.0.14:88; server 192.168.0.15:80;} 4、fair（第三方）按照后端服务器的响应时间来分配请求，响应时间短的优先分配。代码如下：upstream backend{ fair; server server1; server server2;} 5、url_hash（第三方）按照访问url的hash结果来分配请求，使同一个url定向到同一个后端服务器，后端服务器为缓存时比较有效。upstream backend { server squid1:3128; server squid2:3128; hash $request_uri; hash_method crc32;}备注：在upstream中加入hash语句，server语句中不能写入weight等其他的参数，hash_method是使用的hash算法","categories":[{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/categories/nginx/"}],"tags":[]},{"title":"nginx（负载均衡算法）","slug":"nginx（负载均衡算法）","date":"2019-03-01T06:01:31.000Z","updated":"2019-03-01T06:10:43.884Z","comments":true,"path":"2019/03/01/nginx（负载均衡算法）/","link":"","permalink":"http://yoursite.com/2019/03/01/nginx（负载均衡算法）/","excerpt":"","text":"1、nginx负载均衡算法1）轮询（默认）每个请求按照时间顺序逐一分配到不同的后端服务，如果后端某台服务器宕机，自动剔除故障主机，使用户访问不受影响。2）weight（轮询权值）weight的值越大，访问概率越高，主要用于后端每台服务器性能不均衡的情况下。或者仅仅为在主从的情况下设置不同的权值，达到合理有效的利用主机资源。3）ip_hash每个请求按照访问IP的哈希结果分配，使来自同一个IP的访客固定访问一台后端服务器，并且可以有效解决动态网页存在的session共享问题。4）fair比weight、ip_hash更加智能的负载均衡算法，fair算法可以根据页面大小和加载时间长短智能地进行负载均衡，也就是根据后端服务器的响应时间来分配请求，响应时间短的优先分配。nginx本身不支持fair，如果需要这种调度算法，则必须安装upstream_fair模块。 5）url_hash按照访问url的哈希结果来分配请求，使每个url定向到一台后端服务器，可以进一步提高后端缓存服务器的效率。nginx本身不支持url_hash，如果需要这种调度算法，则必须安装nginx的hash软件包。","categories":[],"tags":[]},{"title":"nginx（负载均衡配置）","slug":"nginx（负载均衡）","date":"2019-03-01T03:34:00.000Z","updated":"2019-03-01T06:11:16.184Z","comments":true,"path":"2019/03/01/nginx（负载均衡）/","link":"","permalink":"http://yoursite.com/2019/03/01/nginx（负载均衡）/","excerpt":"","text":"upstream模块：实现负载均衡，nginx把客户端请求加权论调到后端多个服务器。需要注意的是，upstream模块需要定义在server之外 语法格式：upstream websrvs{ server 172.16.100.1 weight=1 max_fails=2 fail_timeout=2; server 172.16.100.2 weight=2 max_fails=2 fail_timeout=2; server 127.0.0.1:8080 backup;}备注：1）172.16.100.1和172.16.100.2不能加http协议，直接指定服务器ip2）backup指定当前面定义的httpd服务down掉的时候，这时候会启用这个页面3）使用google浏览器验证负载均衡的时候，需要先清掉缓存；可以用IE浏览器验证 location / { proxy_pass http://websvrs/; 这里需要改成websvrs}","categories":[{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/categories/nginx/"}],"tags":[]},{"title":"nginx（反向代理）","slug":"nginx（反向代理）","date":"2019-03-01T03:16:00.000Z","updated":"2019-03-01T07:35:10.471Z","comments":true,"path":"2019/03/01/nginx（反向代理）/","link":"","permalink":"http://yoursite.com/2019/03/01/nginx（反向代理）/","excerpt":"","text":"1、什么是代理服务器代理服务器：客户端在发送请求时，不会直接发送给目的主机，而是先发送给代理服务器，代理服务器接受客户端请求之后，再向目的主机发出，并接收目的主机返回的数据，转发回给客户端。简单来说，就是一个”跳板”的作用。 2、为什么要使用代理服务器1）提高访问速度由于目的主机返回的数据会存放在代理服务器的硬盘中，因此下一次客户再访问相同的站点数据时，会直接从代理服务器的硬盘中读取，起到了缓存的作用，尤其是对于热门站点能够明显提高请求速度。2）防火墙作用由于所有客户端请求都必须通过代理服务器访问远程站点，因此可在代理服务器上设限，过滤不安全信息。 3、正向代理和反向代理正向代理：代理内部网络对Internet的连接请求，客户机必须指定代理服务器,并将本来要直接发送到Web服务器上的http请求发送到代理服务器中。正向代理的作用：1）访问原来无法访问的资源，比如google2）可以做缓存，加速访问资源3）对客户端访问授权，上网进行认证4）代理可以记录用户访问记录（上网行为管理），对外隐藏用户信息 反向代理：当一个代理服务器能够代理外部网络上的主机，访问内部网络时，这种代理服务的方式称为反向代理服务。反向代理的作用：1）保证内网的安全，阻止web攻击（大型网站，通常将反向代理作为公网访问地址，web服务器是内网）2）负载均衡，通过反向代理来优化网站的负载 server语法：server { listen 80; server_name www.magedu.com location / { 后端服务器; }} 1）location /forum/ { proxy_pass http://172.16.100.1:8080/bbs/; proxy_pass，反向代理}意味着用户访问http://www.magedu.com/forum/，这个访问请求会被转发至http://172.16.100.1:8080/bbs/备注：forum后面的斜线必须跟下面的bbs后面的斜线保持一致，意味着上面有斜线下面也必须有，上面没有斜线下面也必须没有 2）location ~* /forum/ { proxy_pass http://172.16.100.1:8080/;}意味着用户访问http://www.magedu.com/forum，这个访问请求会被转发至http://172.16.100.1:8080/forum/(如果是模式匹配正则表达式的形式，下面只要指定服务器即可，否则会报错) 3）proxy_set_header:location ~* /forum/ { proxy_pass http://172.16.100.1:8080/; proxy_set_header X-Real-IP $remote_addr;}说明：这可以使得传递给后端的ip是真正的客户端的ip地址，但是在记录日志的时候还不是真正客户端的地址，而是代理服务器的ip地址。如果向记录日志的时候记录的是真正客户端的ip地址，还需要编辑/etc/httpd/conf/httpd.conf配置文件：LogFormat “%h…” ==&gt; LogFormat “%{X-Real-IP}i…” ,后面加i表示的是引用这个变量的值，然后重启服务","categories":[{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/categories/nginx/"}],"tags":[]},{"title":"nginx（整合nginx和php）","slug":"nginx（整合nginx和php）","date":"2019-03-01T02:48:00.000Z","updated":"2019-03-01T02:57:40.683Z","comments":true,"path":"2019/03/01/nginx（整合nginx和php）/","link":"","permalink":"http://yoursite.com/2019/03/01/nginx（整合nginx和php）/","excerpt":"","text":"1、编辑/etc/nginx/nginx.conf，启动如下选项：location ~ .php${ root html;改为/web/htdocs，改为html主页所在目录 fastcgi_pass 127.0.0.1:9000; 127.0.0.1表示nginx和php是在同一台主机上，如果是不同主机，要改为部署php的主机 fastcgi_index index.php; fast_cgi_param SCRIPT_FILENAME; include fastcgi_params;} 2、编辑/etc/nginx/fastcgi_params，将其内容更改为如下内容：fastcgi_param GATEWAY_INTERFACE CGI/1.1;fastcgi_param SERVER_SOFTWARE nginx;fastcgi_param QUERY_STRING $query_string;fastcgi_param REQUEST_METHOD $request_methodfastcgi_param CONTENT_TYPE $content_type;fastcgi_param CONTENT_LENGTH $content_length;fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;fastcgi_param SCRIPT_NAME $fast_script_namefastcgi_param REQUEST_URI $request_uri;fastcgi_param DOCUMENT_URI $document_urifastcgi_param DOCUMENT_ROOT $document_rootfastcgi_param SERVER_PROTOCOL $server_protocolfastcgi_param REMOTE_ADDR $remote_addrfastcgi_param REMOTE_PORT $remote_portfastcgi_param SERVER_ADDR $server_addrfastcgi_param SERVER_PORT $server_portfastcgi_param SERVER_NAME $server_name 并在所支持的主页面格式中添加php格式的主页，类似如下:location / { root html; index index.php index.html index.htm;} 3、重新载入nginx配置文件:service nginx reload","categories":[{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/categories/nginx/"}],"tags":[]},{"title":"nginx（php安装）","slug":"nginx（php安装）","date":"2019-03-01T02:06:00.000Z","updated":"2019-03-01T02:47:15.625Z","comments":true,"path":"2019/03/01/nginx（php安装）/","link":"","permalink":"http://yoursite.com/2019/03/01/nginx（php安装）/","excerpt":"","text":"编译安装php解决依赖关系：yum -y groupinstall “X Software Development”如果要让编译的php支持mcrypt，mhash扩展和libevent，此处还需要下载几个rpm包:libmcrypt-2.5.8.4.e15.centos.i386.rpmlibmcrypt-devel-2.5.8.4.e15.centos.i386.rpmmhash-0.9.9-1.el5.centos.i386.rpmmhash-devel-0.9.9-1.el5.centos.i386.rpmmcrypt-2.6.8-1.e15.i386.rpm最好使用升级的方式安装上面的rpm包，命令格式如下：rpm -Uvh 另外，也可以根据需要安装libevent，系统一般会自带libevent，但版本有些低，因此可以升级安装。它包含以下两个rpm包：libevent-2.0.17-2.i386.rpmlibevent-devel-2.0.1702.i386.rpm备注：libevent是一个异步时间通知库文件，其API提供了在某文件描述上发生某事件时或其超时执行回调函数的机制，它主要是用来替换事件驱动的网络服务器上的event loop机制。目前来说，libevent支持/dev/poll,kqueue,select,poll,epoll以及solaris的event ports 1）tax xf php-5.4.13.tar.bz2）cd php-5.4.133）./configure –prefix=/usr/local/php –with-mysql=/usr/local/mysql –with-openssl –enable-sockets –enable-sysvshm –with-mysqli=/usr/local/mysql/bin/mysql_config –enable-mbstring –with-freetype-dir –with-jpeg-dir–with-png-dir –with-zlib-dir –with-libxml-dir=/usr –enable-xml –with-mhash –with-mcrrypt –with-config-file-path=/etc –with-config-file-scan-dir=/etc/php.d –with-bz2 –with-curl 说明：如果前面解决依赖关系时安装了mcrypt相关的两个rpm包，此处的./configure命令还可以带上–with-mcrypt选项让php支持mcrypt扩展，–with-snmp选项则用于实现php的snmp扩展，但此snmp功能要求提前安装net-snmp相关软件包 备注：./configure的时候如果提示某些安装包没有装，使用命令yum list all|grep 包名 可以查看哪些包没装，然后直接yum -y install 没安装的包的包名即可（直接是包名，不需要加上版本号之类。yum list all 的时候如果状态是bash表示没有安装） 4）make5）make install6）为php提供配置文件：cp php.ini-production /etc/php.ini7）为php-fpm提供Sysv init脚本，并将其添加到服务列表：cp sapi/fpm/init.d/php-fpm /etc/rc.d/init.d/php-fpmchmod +x /etc/rc.d/init.d/php-fpm8）chkconfig –add php-fpm9）chkconfig php-fpm on10）为php-fpm提供配置文件：cp /usr/local/php/etc/php-fpm.conf.default /usr/local/php/etc/php-fpm.conf11）编译php-fpm配置文件：vi /usr/local/php/etc/php-fpm.conf配置fpm相关选项为你所需要的值，并启用pid文件（如下最后一行）：pm.max_children = 50pm.start_servers = 5pm.min_spare_servers = 2pm.max_spare_servers = 8pid = /usr/local/php/var/run/php-fpm.pid12）接下来就可以启动php-fpm：service php-fpm start13）验证：使用如下命令，如果命令输出有几个fpm-php进程说明启动成功ps aux|grep php-fpm","categories":[{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/categories/nginx/"}],"tags":[]},{"title":"nginx配置（虚拟主机）","slug":"nginx配置（虚拟主机）","date":"2019-02-26T08:14:00.000Z","updated":"2019-02-26T08:49:22.317Z","comments":true,"path":"2019/02/26/nginx配置（虚拟主机）/","link":"","permalink":"http://yoursite.com/2019/02/26/nginx配置（虚拟主机）/","excerpt":"","text":"server { listen 80 server_name localhost location / { root /web/htdocs; 网页配置文件在/web/htdocs下，访问时直接输入ip index index.html } location /bbs { root /web; 网页配置文件在/web/bbs下，访问时输入ip/bbs index index.html; allow xx.xx.xx.xx; 只允许特定地址访问 deny all; auth_basic “Restricted”; 指定名称 auth_basic_user_file htpasswd; 指定文件路径，通过auth_basic和auth_basic_user_file这两个选项可以实现基于用户认证的访问 } 备注: 1)要建立配置htpasswd文件，要借用httpd的htpasswd命令。 2)安装httpd,yum install -y httpd,chkconfig –list httpd(查看httpd是否开机启动，必须确保httpd和nginx不会争用同一个套接字)，htpasswd –hep可以查看命令用法，htpasswd第二次不能使用-c选项 location /status { stub_status on; 显示状态信息，注意状态信息一般不会开放给所有人访问 allow xx.xx.xx.xx; deny all; } 备注: 1)显示的信息： active connection：活动连接数 server accept handled requests：服务器已经处理过的请求数 reading：nginx正在读首部的请求个数 writing：nginx正在读主体的请求个数或正处理着其请求内容的请求个数或者正在向客户端发送响应的个数 waiting：reading+writing} server里面的选项：location：1)location uri {}:花括号中的属性对当前路径及子路径下的所有对象都生效2)location = uri {}：花括号中的属性对当前路径生效（精确匹配指定路径，不包括子路径）3)location ~ uri {}：模式匹配uri，此处的uri可以使用正则表达式（区分字符大小写）4)location ~* uri {}：模式匹配uri，此处的uri可以使用正则表达式（不区分字符大小写）5)location ~~ uri {}：不使用正则表达式 备注：nginx语法检查：nginx -t","categories":[{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/categories/nginx/"}],"tags":[]},{"title":"nginx配置","slug":"nginx配置","date":"2019-02-22T09:19:00.000Z","updated":"2019-02-26T08:11:57.427Z","comments":true,"path":"2019/02/22/nginx配置/","link":"","permalink":"http://yoursite.com/2019/02/22/nginx配置/","excerpt":"","text":"nginx的配置文件:/etc/nginx1、大体配置:分为几个上下文（意思就是分段）:mainhttpserver（http子段）upstream（http子段，定义反向代理）location（相当于虚拟主机的DocumentRoot）mail（实现邮件的反向代理） 2、详细配置1）worker process 1（work进程数，与cpu个数相关）备注:如果负载是cpu密集型应用为主，如ssl或者压缩应用，则work个数与cpu个数相同；如果负载是io密集型为主，如响应大量内容给客户端，则worker的个数应该是cpu个数的1.5倍或2倍2）error_log logs/error.log（错误日志路径，如果是被注释掉，说明我们编译时候指定的错误日志路径已经生效）3）pid logs/nginx.pid（pid路径，如果是被注释掉，说明我们编译的时候指定的路径已经生效）4）event{ worker_connections 1024; keeplive_timeout 65; 使用长连接并指定超时时间 gzip on; 先压缩再发送，可以节省带宽 }备注:worker_connection指定的是连接数","categories":[{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/categories/nginx/"}],"tags":[]},{"title":"nginx安装","slug":"nginx安装","date":"2019-02-22T07:29:00.000Z","updated":"2019-02-22T09:17:30.739Z","comments":true,"path":"2019/02/22/nginx安装/","link":"","permalink":"http://yoursite.com/2019/02/22/nginx安装/","excerpt":"","text":"编译安装nginx（如果将来需要批量部署安装nginx，可以自己做成rpm包。官方也有提供rpm包）1、安装前准备1）yum grouplist（查看安装了哪些yum包组）2）yum -y groupinstall “Development Tools” “Server Platform Libraries”（安装包组）3）yum install -y pcre-devel openssl-devel gd（安装依赖，pcre是perl扩展的正则表达式） 2、解压缩1）tar xf nginx-1.4.1.tar.gz（安装软件之前需要确认下时间，如果系统时间比软件包时间靠前的话，会认为软件包是来自未来的，因此软件包是无法使用的）2）groupadd -r -g 108 nginx3）useradd -r -g 108 -u 108 nginx（nginx应该要以普通用户的身份运行）备注:-r:创建系统账户-g:指定gid-u:指定uid 3、编译安装1）cd nginx-1.4.12）./configure –help|less（查看configure的帮助文档） 3）./configure \\–prefix=/usr \\–sbin-path=/usr/sbin/nginx \\–conf-path=/etc/nginx/nginx.conf \\–error-log-path=/var/log/nginx/error.log \\–htp-log-path=/var/log/nginx/access.log \\–pid-path=/var/run/nginx/nginx/pid \\–lock-path=/var/lock/nginx.lock \\–user=nginx \\–group=nginx \\–with-http_ssl-module \\–with-http_flv_module \\–with-http_stub_status_module \\–with-http_gzip_static_module \\–http-client-body-temp-path=/var/tmp/nginx/client/ \\–with-proxy-temp-path=/var/tmp/nginx/proxy/ \\–with-fastcgi-temp-path=/var/tmp/nginx/fcgi/ \\–withuwsgi-temp-path=/var/tmp/nginx/uwsgi/ \\–with-scgi-temp-path=/var/tmp/nginx/scgi/ \\–with-pcre\\–with-file-aio4）make5）make install备注:如果编译出错需要重新编译，要先make clean一下再configure 4、将nginx加入到服务列表chkconfig –add nginx（加到服务列表中去）chkconfig –list nginx（检查是否已经加入到服务列表） 5、启动nginx要想启用nginx，需要编辑一个启动脚本:/etc/rc.d/init.d/nginx #需要自己写，可以参考httpd的启动停止脚本(就是可以通过脚本来实现start|stop|reload等功能)。然后通过service nginx start来启动nginx 备注:会在默认安装目录下创建一个html目录，里面放的就是网页文件。如果是按照上面方法提供的路径来安装nginx的话，网页文件就放在/usr/html目录中.","categories":[{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/categories/nginx/"}],"tags":[]},{"title":"nginx功能","slug":"nginx功能","date":"2019-02-22T07:03:00.000Z","updated":"2019-02-22T07:20:34.623Z","comments":true,"path":"2019/02/22/nginx功能/","link":"","permalink":"http://yoursite.com/2019/02/22/nginx功能/","excerpt":"","text":"1、nginx官网:www.nginx.org 2、nginx功能:1）web服务器（具有基本web服务器所需要具备的绝大多数功能，除非需要apache提供的某些功能，否则nginx是我们选择web服务器的首选）2）反向代理（反向代理web和mail，反向代理mail一般很少用） 3、nginx进程:nginx会按需同时运行多个进程，一个主进程（master）和几个工作进程（worker），配置了缓存时还会有缓存加载器进程（cache loader）和缓存管理器（cache manager）等。所有进程均是只含有一个线程，并主要通过共享内存机制来实现进程间通信。主进程以root用户身份运行，而worker、cache loader、cache manager均以非特权用户身份运行。 4、进程详细作用1）主进程主要完成以下工作:a、读取并验证配置信息b、创建、绑定和关闭套接字c、启动、终止和维护worker进程的个数d、热部署、平滑升级，也就是重新加载配置以及在线升级时，不需要中断正在处理的请求e、重新打开日志文件，实现日志滚动f、编译嵌入式perl脚本 2）worker进程主要完成的任务包括:a、接收、传入并处理来自客户端的连接b、提供反向代理及过滤功能c、nginx任何能完成的其他任务 3）cache loader进程主要完成的任务包括:a、检查缓存存储中的缓存对象b、使用缓存元数据建立内存数据库 4）cache manager进程的主要任务包括:a、缓存的失效及过期检验","categories":[{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/categories/nginx/"}],"tags":[]},{"title":"httpd虚拟主机配置（Session 3）","slug":"httpd虚拟主机配置（Session-3）","date":"2019-02-22T06:29:00.000Z","updated":"2019-02-22T06:55:38.735Z","comments":true,"path":"2019/02/22/httpd虚拟主机配置（Session-3）/","link":"","permalink":"http://yoursite.com/2019/02/22/httpd虚拟主机配置（Session-3）/","excerpt":"","text":"虚拟主机:一个apache服务服务于多个不同的站点1）定义: 备注:要使用虚拟主机，首先要取消中心主机。取消方法，注释DocumentRoot 2）新建虚拟主机:两种方法第一种:在/etc/httpd/conf/httpd.conf里面定义虚拟主机第二种:新建虚拟主机定义文件/etc/httpd/conf.d/virtual.conf，在里面定义虚拟主机 3）示例:a、基于IP的虚拟主机 备注:httpd -t（可以检查httpd的配置或者语法是否正确） b、基于端口的虚拟主机如果是基于端口的虚拟主机，还需要在httpd.conf主配置文件中定义监听端口(默认是只监听了80端口) c、基于域名的虚拟主机 备注:默认所有的主机日志都在/var/log/httpd/access.log|error_log","categories":[{"name":"http","slug":"http","permalink":"http://yoursite.com/categories/http/"}],"tags":[]},{"title":"httpd属性配置（Session 2）","slug":"httpd属性配置（Session-2）","date":"2019-02-22T03:38:00.000Z","updated":"2019-02-22T06:53:39.582Z","comments":true,"path":"2019/02/22/httpd属性配置（Session-2）/","link":"","permalink":"http://yoursite.com/2019/02/22/httpd属性配置（Session-2）/","excerpt":"","text":"1、配置文件内容:1）ServerAdmin root@localhost（服务器管理员邮箱地址）2）ServerName www.example.com:80（主机名称，除了在定义虚拟主机这个选项必须开启之外，其他模式下可以注释）3）UserCanonicalName Off（正式名称，很少用，一般注释掉）4）DocumentRoot “/var/www/html”（文档根目录，就是网页文件存放的位置） 备注:Directory里面的内容是一个容器，这里面定义的是如何访问/var/www/html这个路径 2、容器里面的内容:1）options（定义访问属性，如果存在多个值，值与值之间用空格隔开）访问属性值:none:不支持任何选项indexes:允许索引目录，在生产环境中通常不允许（有一种情况例外，就是提供下载文件）FollowSymLinks:允许访问符号链接指向的源文件（通常不允许）ExecCGI:允许执行cgi脚本All:支持所有选项（在生产环境中一般没有人这样玩）2）AllowOverride支持的值:none:不支持任何选项Authconfig:需要提供账号密码才能访问站点3）AuthType Basic4）AuthName “Restricted Site”5）AuthUserFile “/etc/httpd/conf/htpasswd”（允许哪些用户访问）6）AuthGroupFile “/etc/httpd/conf/htgroup”（允许哪些组访问）7）Require user user_name（只允许某个用户登录）8）Require group group_name（只允许某个组登录）9）Require valid-user（允许/etc/httpd/conf/htpasswd中的所有用户登录） 3、htpasswd1）作用:创建htpasswd文件2）示例:第一次创建:htpasswd -c -m /etc/httpd/conf/htpasswd user_name第二次创建:htpasswd -m /etc/httpd/conf/htpasswd user_name备注:a、只在第一次创建的时候使用-c创建/etc/httpd/conf/htpasswd文件，第二次创建的时候不要使用-c，否则会覆盖原来的文件b、htpasswd -h 可以查看帮助","categories":[{"name":"http","slug":"http","permalink":"http://yoursite.com/categories/http/"}],"tags":[]},{"title":"httpd cgi","slug":"httpd-cgi","date":"2019-02-22T03:17:00.000Z","updated":"2019-02-22T06:18:52.956Z","comments":true,"path":"2019/02/22/httpd-cgi/","link":"","permalink":"http://yoursite.com/2019/02/22/httpd-cgi/","excerpt":"","text":"1、cgi由来httpd或者web服务器本身不处理动态内容，而是通过某种协议调用额外的应用程序来运行，并将处理后的结果响应给客户端。而cgi，全称是common gateway interface，翻译为通用网关接口，就是使web服务器能够跟其他应用程序通讯的一种机制（或者协议），能够调用额外的应用程序来处理动态内容。例如web服务器调用php解释器来解释php脚本。 2、fastcgiweb服务器与动态进程服务器通讯，动态进程不再归web服务器管理，而是统一由动态进程服务器进程管理。这个动态进程服务器进程同时生成了很多子进程，等待响应请求。也就是说，静态内容和动态内容分别由不同的主机处理（web服务器处理静态内容，动态进程服务器处理动态内容，然后返回html页面给web服务器） 3、动态网站分两种类型:1）客户端动态过程:用户过来请求，把服务器端的源码下载到本地，在本地执行程序安全性:如果有人恶意的在服务器端放了一个恶意脚本，用户下载到本地会对本地主机造成一定的危害适应性:如果服务器端的脚本是java写的，要运行这段脚本，就必须要求用户本地主机必须安装有java的执行环境，否则脚本无法执行2）服务器端动态过程:脚本放在服务器端，通过cgi协议调用相关的解释器来执行脚本，并把执行后的结果返回给客户端 4、php每一种程序开发语言都有其最适用的场景。比如，C,C++非常底层，执行效率很高，不适合开发那些多媒体，表现形式很丰富的程序，而适用于那些直接驱动硬件的程序。php是一种脚本语言，天生就是用来开发web页面的。 5、小于1024端口1）httpd:root,root(master process) – 这个主导进程是root用户，root组 #并不会处理用户请求，而是用来创建进程或者销毁多余的进程2）httpd:apache,apache(worker process) – 其他进程都是apache用户，apache组备注:a、在linux上，小于1024的端口只有管理员有权限使用，所以启动httpd的master进程的用户只有是管理员(httpd:80端口;如果是基于SSL:443端口)b、在/etc/rc.d/init.d下有一个脚本叫做httpd，因此httpd也可以通过service httpd start|stop来启动或者停止httpd进程","categories":[{"name":"http","slug":"http","permalink":"http://yoursite.com/categories/http/"}],"tags":[]},{"title":"httpd全局配置（Session 1）","slug":"httpd配置","date":"2019-02-22T01:22:00.000Z","updated":"2019-02-22T06:25:54.390Z","comments":true,"path":"2019/02/22/httpd配置/","link":"","permalink":"http://yoursite.com/2019/02/22/httpd配置/","excerpt":"","text":"1、httpd相关目录（1）/etc/httpd:工作的根目录（2）/etc/httpd/conf:配置文件目录（3）/etc/httpd/conf/httpd.conf:主配置文件（配置文件很大，在/etc/httpd/conf.d/*.conf的文件都属于httpd的配置文件的一部分，主配置文件通过include将这些配置文件包含进来）（4）/etc/httpd/modules:模块链接，指向/usr/lib/httpd/modules下的库文件（5）/etc/httpd/logs:目录文件，是一个链接文件，指向/var/log/httpd备注:a、httpd的日志分两类:访问日志:access_log错误日志:err_logb、/var/www/:（请求的资源所在的目录，一般包含两个目录）html:静态页面所在路径cgi-bin:动态内容所在路径 2、httpd主配置文件/etc/httpd/conf/httpd.conf（1）总体配置grep “Section” /etc/httpd/conf/httpd.conf，可以看到主配置文件分为3段:Section 1:Global Environment（全局环境）Section 2:Main server configuration（主服务器配置）Section 3:Virtual Hosts（虚拟主机）备注：a、第二段和第三段的配置不能同时生效，只能有一个生效b、第一段全局配置指的是如果你使用的是虚拟主机，就对全部的虚拟主机都生效（2）详细配置a、ServerTokens OS – 输出操作系统版本信息:当网页报错时，最底下的显示（示例:Apache/2.2.3 RedHat Server at 172.16.100.1 port 80）备注:ServerTokens的值除了OS，还有其他的值，比如Major|Minor|Min[imal]|Prod[uctonly]|Fullb、ServerRoot “/etc/httpd” – 服务器的根目录（不到万不得已不要修改这个配置）c、PidFile run/httpd.pid – run是相对路径，相对于/etc/httpd路径d、timeout 120 – 超时时间（跟tcp协议相关的超时时间）e、KeepAlive Off – 是否使用长连接f、KeepAliveRequest 100 –使用长连接的请求达到100个之后，就断开长连接g、KeepAliveTimeout 15 – 长连接耗时超过15s，就断开长连接 1)StartServer 8 – 定义web服务器启动时启动空闲进程的数量2)MinSpareServers 5 – 定义web服务器随时要保证的空闲进程的数量（至少要有的空间进程的个数）3)MaxSpareServers 20 – 定义的最大空闲进程数量（过多的空闲进程会浪费系统资源）4)ServerLimit 256 – MaxClinet的上限值，MaxClient的值不能超过ServerLimit定义的值。要修改该值，需要kill原进程，修改值之后再重启服务5)MaxClient 256 – 允许请求的最大客户端数量6)MaxRequestPerchild 4000 – 定义一个进程最多只能服务多少个用户请求（一旦超过该设定值，就会kill掉该进程） 1)StartServer 2 – 生成进程数2)MaxClient 1503)MinSpareThread 25 – 最小空闲线程（所有的进程加起来的线程数）4)MaxSpareThread 75 – 最大空闲线程（所有的进程加起来的线程数）5)ThreadPerChild 25 – 每个进程最多生成多少个线程6)MaxRequestPerChild 0 – 每个进程最多服务多少个用户请求。因为用户请求是由线程响应的，所以这里设置为0表示不做限定j、Listen 80（指定监听地址和端口，如果不带ip地址，表示监听当前主机上的所有地址）示例:监听多个地址:Listen 80Listen 8080监听某个地址上的某个端口:Listen 172.16.10.1:80k、LoadModule mod_name（装载模块）l、include conf.d/*.confm、User apachen、Group apache 3、本地查看httpd帮助文档yum install -y httpd-manual（这时候会在httpd的主配置目录里面生成一个manual的文件，重启httpd服务后只需要在你的主机ip后面加上/manual，就可以在浏览器中显示帮助文档）","categories":[{"name":"http","slug":"http","permalink":"http://yoursite.com/categories/http/"}],"tags":[]},{"title":"httpd安装","slug":"httpd安装","date":"2019-02-21T15:27:00.000Z","updated":"2019-02-22T07:23:17.455Z","comments":true,"path":"2019/02/21/httpd安装/","link":"","permalink":"http://yoursite.com/2019/02/21/httpd安装/","excerpt":"","text":"1、安装方式:（1）使用系统自带的rpm包（2）源码编译安装 2、通过rpm包的方式安装（1）缺点:有些功能可能不需要但是已经编译进来，或者是有些功能需要但是没有编译进来（2）安装步骤:（以红帽系统的rpm包安装为例）a、yum list all |grep httpd（查看系统自带的rpm包）输出内容:httpd.i386（服务器端的包）httpd-devel-i386（除非是针对httpd做二次开发，否则这个包用不上）httpd.manual-i386（帮助手册）备注:一般来说，系统自带的版本比较落后，或者是有漏洞，或者是某些特定的功能rpm包没有提供，所以很多时候我们是需要通过源码安装的方式来安装httpdb、getenforce（查看selinux状态）setenforce 0（设置selinux为permissive状态，临时生效）备注:因为红帽系统上httpd是受selinux控制的，所以需要先停止掉selinux。如果要使selinux关闭永久生效，需要编辑/etc/sysconfig/selinux或/etc/selinux/config(这两个文件是同一个文件)，设置SELINUX=permissivec、yum -y install httpd（安装httpd）d、rpm -ql httpd|less（查看httpd安装生成哪些文件）e、service httpd start（启动httpd）f、chkconfig httpd on（开机启动httpd）g、在浏览器输入服务器的ip地址即可访问httpdh、配置欢迎页面，编辑/etc/httpd/conf.d/welcome.conf，配置完成后通过service httpd restart重启服务使得配置生效。如果没有欢迎页面，默认页面在/var/www/html目录下定义:新建文件a.html, 不需要重启服务，刷新浏览器即可","categories":[{"name":"http","slug":"http","permalink":"http://yoursite.com/categories/http/"}],"tags":[]},{"title":"httpd","slug":"httpd","date":"2019-02-21T14:51:00.000Z","updated":"2019-02-22T03:37:01.693Z","comments":true,"path":"2019/02/21/httpd/","link":"","permalink":"http://yoursite.com/2019/02/21/httpd/","excerpt":"","text":"1、httpd由来httpd最初是由NCSA研发和维护的，后来这个机构解散之后，很多原来维护httpd的工程师觉得httpd这个软件很好用，所以就自愿通过互联网的方式继续维护httpd这个软件，其实也是打打补丁之类的工作。所以之后httpd被戏称为a patchy server(打满补丁的软件)，简称为apache。后来apache发展为一个软件基金会ASF(apache software foundation),ASF底下维护了很多著名的项目，比如httpd、tomcat、hadoop等备注:a、早期的httpd就叫做apache，但是其实apache是一个软件基金会，这个基金会维护着很多著名的软件，httpd只是其中的一种b、apache官方网站 www.apache.org，httpd官方网站 http://httpd.apache.org(apache的子网页) 2、httpd特性（1）事先创建进程（在用户请求之前已经创建好进程作为空闲进程，一旦有用户请求进来，就可以立刻把空闲进程分配给请求予以响应）（2）按需维持适当的进程（一旦空闲进程太多，会把空闲进程销毁）（3）模块化设计，核心比较小，各种功能模块化添加。支持运行时配置，单独编译模块即可。也可以在运行时启用，即装载响应的模块即可。（4）支持多种方式的虚拟主机配置（5）支持url重写（假如用户访问/a.jpg，可以通过转换使得用户去访问/b.jpg，这个过程对用户来说是不可见的）（6）支持https（通过模块mod_ssl实现）（7）支持用户认证（认证方式:简单认证、摘要认证、表单认证等）（8）支持基于ip或主机名的acl（acl:访问控制列表）（9）支持某目录的访问控制（访问网站不需要密码，但是访问特定目录的时候需要输入账号密码） 3、虚拟主机（1）定义:web物理服务器和web程序都只有一个，但可以服务不同的站点（2）种类:a、基于ip的虚拟主机（ipv4地址资源比较紧缺，使用互联网ip来定义基于ip的虚拟主机不太现实）b、基于端口的虚拟主机（在互联网上使用端口也不太现实，因为如果不使用标准端口的话，在互联网上很难知道web服务器到底是使用哪一个端口来提供web服务）c、基于域名的虚拟主机（常用） 4、httpd与nginx比较nginx是多进程响应n个用户请求的模型，使用有限的资源响应比httpd更多的用户请求，但是替代不了httpd原因是:（1）从提供众多特性这点来说，nginx是无法与httpd比较的（2）稳定性也无法跟httpd比较（3）一般nginx是用来做反向代理的，而httpd仍然是web服务的老大","categories":[{"name":"http","slug":"http","permalink":"http://yoursite.com/categories/http/"}],"tags":[]},{"title":"web server模型","slug":"web-server模型","date":"2019-02-21T08:14:00.000Z","updated":"2019-02-22T03:10:42.372Z","comments":true,"path":"2019/02/21/web-server模型/","link":"","permalink":"http://yoursite.com/2019/02/21/web-server模型/","excerpt":"","text":"1、web server主要操作:（不会处理动态内容，也就是不会执行脚本）（1）建立连接:接收或者拒绝客户端的连接请求（2）接收请求:通过网络读取http请求报文（3）处理请求:解析请求报文并做出相应的动作（4）访问资源:访问请求报文中的相关资源（5）构建响应:使用正确的首部生成http响应报文（6）发送响应:向客户端发送生成的响应报文（7）记录日志:已经完成http事务记录进日志 2、web server模型:mpm模型，也叫多道处理模块，定义apache服务器在响应多个用户请求时所采用的的模型。分三种:（1）prefork:在apache启动之初，就会预派生一些子进程，然后等待连接。每个子进程只有一个线程，可以兼容新老模块，也不需要担心线程安全问题。但是一个进程相对的占用更多的资源，消耗大量内存，不擅长处理高并发的场景。备注:a、查看当前使用的mpm:/usr/local/apache24/bin/httpd -V 或者apachectl -Vb、MaxClients的设置值:设定Apache可同时处理的请求数量，默认的150远远不能满足一般站点，超过这个数量的请求需要排队，直到前面的请求处理完毕。如果我们发现系统资源还剩很多，但是HTTP访问却很缓慢，大多数时候增加这个值可以得到缓解。c、MaxRequestsPerChild的设置值:设定处理多少个请求后该进程自动销毁，默认值为0表示永不销毁。当负载较高时，为了使每个进程处理更多的请求，避免销毁、创建进程的开销，一般建议设置为0或者较大的数字。但是也要注意可能会造成进程占用的内存不能得到释放，所以这个值不能设置得太大，也不能太小，大了会影响资源的释放，小了会导致apache不断fork进程。（2）worker:与prefork的工作模式相比，worker使用了多进程和多线程的混合模式，worker模式也会预派生一些子进程，然后每个子进程创建一些线程，同时包括一个监听线程，每个请求过来会被分配到一个线程来服务。线程比进程更加轻量级，因为线程通常会共享父进程的内存地址，因此内存占用会减少一些。缺点是必须考虑线程安全性，因为多个子进程是共享父进程的内存地址的，如果使用keep-alive的长连接方式，某个线程会被一直占据，需要等到超时才会被释放。如果过多的线程被这样占据，也会导致在高并发下的无服务线程可用。（3）event:和worker的工作模式很像，最大的区别是解决了在keep-alive场景下，长期线程被占用导致的资源浪费问题。在event模式下，会有一个专门的线程来管理keep-alive线程，当有真实请求过来的时候，将请求传递给服务进程，执行完毕后，又允许它释放，这样增强了在高并发场景下的请求处理能力。通过事件驱动机制和通知机制，大大加速响应请求的过程，请求所占用的服务器资源也大大减少。备注:a、httpd -l（可以查看当前所使用的工作模型）b、rpm -ql httpd|grep bin（可以查看httpd也支持worker模型和event模型，默认是prefork模型）c、prefork、worker、event模型分别对应的二进制程序是:/usr/sbin/httpd/usr/sbin/httpd.worker/usr/sbin/httpd.event如果要启用worker模型或者event模型，就通过httpd.worker或者httpd.event相对应的程序来启动httpd。或者修改/etc/sysconfig/httpd文件中的httpd = /usr/sbin/httpd.worker|httpd.event 3、web server架构:C/S架构C:client agent，客户端代理，就是常见的浏览器，包括ie、firefox、chrome、opera、sarafi（其他的诸如360浏览器、遨游等，都是假的浏览器，里面是ie的内核，只是外观不同而已）S:server，能够提供web服务的，包括httpd、iis、nginx、lightted、tomcat、jboss（tomcat的二次封装）、websphere、weblogic（最后两个是商业化产品）备注:www.netcraft.com #可以查看web服务器各种产品的市场占有率","categories":[{"name":"http","slug":"http","permalink":"http://yoursite.com/categories/http/"}],"tags":[]},{"title":"http报文","slug":"http报文","date":"2019-02-21T07:45:00.000Z","updated":"2019-02-21T08:06:25.434Z","comments":true,"path":"2019/02/21/http报文/","link":"","permalink":"http://yoursite.com/2019/02/21/http报文/","excerpt":"","text":"1、ip首部:主要是ip地址，包括源ip和目的ip2、tcp首部:主要是端口号，包括源端口和目的端口备注:ip和tcp主要是负责将报文传输到目标主机上，但是对应是目标主机的哪一个页面，tcp/ip协议并没有指定。因此，要正确访问一个web页面，还需要http首部。 3、http首部:GET /2.html #直接指定要访问的资源文件host:www.magedu.com #已经通过tcp/ip协议来确定了主机，为什么还需要通过host来指定主机呢？答:这是为虚拟主机准备的备注:一个http页面，通常包含多个资源。也就是说，客户端访问一个页面，要向服务端发起多个请求。http首部属于http报文的一部分。 4、http报文种类:请求报文和响应报文http报文组成:起始行、报文首部、主体(报文首部和主体之间需要空一行)(1)请求报文: 请求报文实例: (2)响应报文: 响应报文实例: 5、状态码(1)1xx:纯信息(用的很少)(2)2xx:成功类信息(请求资源获取正确的响应，200,201,202)(3)3xx:重定向信息(301:永久重定向，302:临时重定向，304:服务端告诉客户端所请求的内容没有发生任何改变，告知客户端用自己的缓存内容即可)备注:重定向:请求的资源已经挪到另外的位置，并返回对应位置的信息给客户端让客户端去访问新的资源地址(4)4xx:客户端错误类信息(例如请求的是一个不存在的内容，404 not found)(5)5xx:服务端错误信息","categories":[{"name":"http","slug":"http","permalink":"http://yoursite.com/categories/http/"}],"tags":[]},{"title":"web服务","slug":"web服务","date":"2019-02-20T14:49:00.000Z","updated":"2019-02-20T15:51:02.821Z","comments":true,"path":"2019/02/20/web服务/","link":"","permalink":"http://yoursite.com/2019/02/20/web服务/","excerpt":"","text":"1、http定义http:hypertext transfer protocol，超文本传输协议超文本:带有超级链接的文本，基于这些链接，能够使得文档之间相互跳转 2、http版本:（1）http 0.9版本:仅支持纯文本，仅支持GET方法（2）http 1.0版本:除了GET方法，还支持PUT、POST、DELETEGET:从远程服务器上直接获取文件到本地之后以浏览器的方式展示PUT:从远程服务器直接获取文件到本地POST:提交数据或表单到服务器上DELETE:从远程服务器上删除文件备注:http method有8种，分别是GET、PUT、POST、DELETE、HEAD（只返回首部，不返回主体内容）、TRACE、OPTIONS、CONNECTION，最常用的是前面4种 最大的改进是引进了MIMEMIME:Multipurpose Internet Mail Extension，多用途互联网邮件扩展，就是将非文本数据在传输前重新编码成文本格式，接收方能够用相反的将其还原成原来的格式，还能够调用相应的程序来打开此文件备注:a、通过协议首部告知接收方（也就是浏览器）自己的类型，然后浏览器在收到之后就会调用相关的插件来展示b、早期的传输邮件是通过SMTP协议来传输的，只能传输纯文本，所以叫做简单文件传输协议。后来SMTP引进了MIME，所以现在邮件可以传输的不仅仅是纯文本，还有图片、mp3等 还引进了缓存的机制缓存的意义:因为http是基于tcp传输的，tcp连接包含了3次握手、4次挥手，所以传输的时间会很久。此时缓存就可以加速你访问网页的速度，加速系统资源访问，还可以节省带宽。其实页面刷新就是清除缓存，也就是无论本地缓存是否存在，都重新去服务端下载一次文件（3）http 1.1版本:增强了缓存的功能，引进了长连接的功能长连接：连接不断开，直到超时好处:同一客户端发起第二个请求的时候，尽可能的缩短时间并降低服务端的资源利用率坏处:服务器并发量巨大的时候，后面来的请求就很难建立连接。但是绝大多数情况下，如果你的连接请求不是大到一定请求的时候，使用长连接的方式可以显著的提高服务器的性能 3、http概念（1）html:hypertext mark language，超文本标记语言（开发超文本的语言）（2）URI:Uniform Resource Indentifier，统一资源标识符（3）URL:Uniform Resource Locator，统一资源定位符（URI的子集）（4）web资源:多个资源很可能会被整合为一个html文档，也叫web对象（5）动态网页:服务端存储的文档非html格式，而是编程语言开发的脚本。客户端访问服务端的时候，会将自身浏览器的属性数据（比如ip、浏览器类型等）作为参数传给服务端的脚本，脚本接受参数之后在服务端执行一次。就动态语言来说，是什么类型的语言编写的脚本就调用相对应的解析器来解析。脚本执行完之后会生成html格式的文档发给客户端。不同的客户端获取的结果可能不一样。备注：a、动态网页不同于flash、java的applet所展示的动态效果（动态网页和动态效果不是同一个概念）b、动态网页包括:静态内容（不需要通过脚本执行，直接是一个文档或者是一张图片等等）；动态内容（需要脚本执行生成html文档之后返回客户端）web监听方式（web服务器怎么知道有客户端来访问资源）:以去饭馆吃饭举例a、阻塞:阻塞的方式就是一直盯着饭菜有没有做好，不能去干别的事b、非阻塞:非阻塞的方式就是在等菜的时候可以出去玩或者干别的事，过一段时间再回来看饭菜有没有做好，这种方式也叫轮询","categories":[{"name":"http","slug":"http","permalink":"http://yoursite.com/categories/http/"}],"tags":[]},{"title":"mysql管理视图","slug":"mysql管理视图","date":"2019-01-31T06:28:00.000Z","updated":"2019-01-31T06:35:36.366Z","comments":true,"path":"2019/01/31/mysql管理视图/","link":"","permalink":"http://yoursite.com/2019/01/31/mysql管理视图/","excerpt":"","text":"1、定义视图就是存储下来的select语句，基于基表的查询结果 2、管理视图（1）查看创建视图的帮助：help create view;（2）创建视图：create view view_name as select * from tb_name;说明：view_name的结果来自于select语句（3）删除视图：drop view view_name; 备注：1、视图一般在限定某个用户在查询数据表的时候，只能查看特定的字段的时候使用。其他情况下一般不建议使用视图。2、一种特殊的视图：物化视图，可以将select的结果，也就是select生成的视图缓存下来。好处：节省资源坏处：基表更新和虚表不一致因此，对于更新不频繁的数据表，可以使用物化视图。但是，mysql不支持物化视图，也不支持在视图上创建索引。3、查看之前的某个对象是怎样创建的：SHOW CREATE TABLE tb_name;4、mysql -e “SHOW DATABASES”;说明：在命令行中执行sql语句，并返回sql语句执行的结果","categories":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/categories/mysql/"}],"tags":[]},{"title":"mysql管理数据库、数据表和索引","slug":"mysql管理数据库、数据表和索引","date":"2019-01-30T14:16:00.000Z","updated":"2019-01-30T14:45:48.152Z","comments":true,"path":"2019/01/30/mysql管理数据库、数据表和索引/","link":"","permalink":"http://yoursite.com/2019/01/30/mysql管理数据库、数据表和索引/","excerpt":"","text":"1、数据库操作（1）查看创建数据库的帮助：help create database（2）创建数据库：CREATE SCHEMA students CHARACTER SET ‘gbk’ COLLATE ‘gbk_chinese_ci’说明：CHARACTER定义字符集，COLLATE定义排序规则，SCHEMA跟DATABASE意思一样。在mysql的students数据库目录中会生成db.opt文件，里面保存着字符集和排序规则的相关信息。 （3）修改数据库：针对数据库修改的就只有两项，字符集和排序规则alter schema character set=’xxx’alter schema collate=’xxx’（4）删除数据库：drop schema db_name 2、数据表操作（1）查看创建数据表的帮助：help create table（2）创建数据表：（有三种方法）方法一、直接定义一张空表：CREATE TABLE tb1(id INT UNSIGNED NOT NULL AUTO_INCREMENT PRIMARY KEY,name CHAR(20),age TINYINT NOT NULL)说明：使用AUTO_INCREMENT的字段必须使用定义为主键类似于下面这种写法：CREATE TABLE tb2(id INT UNSIGNED NOT NULL AUTO_INCREMENT,name CHAR(20),age TINYINT NOT NULL,PRIMARY KEY(id))说明：PRIMARY_KEY可以单独定义，然后在括号中指明是作用在哪个字段上即可。如果是多个字段定义为键的话必须使用这种方法方法二、从其他表中查询出数据，并以之创建新表CREATE TABLE tb3 SELECT * FROM tb1 WHERE id &lt;=2;方法三、以其他表为模板创建一个空表CREATE TABLE tb4 LIKE tb1;（3）修改数据表：alter table添加、删除、修改字段 说明：修改是modify、change添加、删除、修改索引例子：ALTER TABLE tb1 ADD PRIMARY KEY(id) REFERENCE tb2(id);说明：外键约束只能用于支持事务的存储引擎上，也就是InodeDB上，Myisam不支持事务，因此不支持外键的使用。外键约束可以防止误删，但是外键约束在一定程度上也会消耗系统资源修改表引擎：ALTER TABLE tb1 ENGINE=InnodeDB;（4）删除数据表DROP TABLE tb_name [RESTRICT|CASCADE];说明：restrict：如果想要删除父表的记录时，而在子表中有关联该父表的记录，则不允许删除父表中的记录cascade：表示级联，会同时删除与之有外键约束关系的表 3、索引操作（1）查看创建索引的帮助：HELP CREATE INDEX;（2）创建索引：CREATE INDEX index_name ON tb_name(col_name); #用于哪张表的哪个字段CREATE INDEX index_name ON tb_name(col_name(#num));用于哪张表的哪个字段的前num个字符上（3）查看索引：SHOW INDEXES FROM tb_name;（4）删除索引：DROP INDEX index_name ON tb_name(col_name);说明：索引不能修改，要修改只能先删除再创建即可 备注：1、键和索引的区别：键也称作约束，可用作索引，属于特殊索引2、主键和唯一键的区别：主键和唯一键都是唯一标识字段的；每张表只能有一个主键，但是每张表可以有多个唯一键；主键不能为空，唯一键可以为空；","categories":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/categories/mysql/"}],"tags":[]},{"title":"mysql单表查询、多表查询和子查询","slug":"mysql单表查询、多表查询和子查询","date":"2019-01-30T09:41:00.000Z","updated":"2019-01-30T09:42:18.447Z","comments":true,"path":"2019/01/30/mysql单表查询、多表查询和子查询/","link":"","permalink":"http://yoursite.com/2019/01/30/mysql单表查询、多表查询和子查询/","excerpt":"","text":"1、单表查询例子：SELECT FROM tb_name;SELECT field1,field2 FROM tb_nmae； –投影SELECT [DISTINCT] FROM tb_name WHERE condition; –选择,WHERE子句后面接的字段不一定是SELECT接的字段 where子句：（1）符号匹配=，!=，&gt;,&gt;=,&lt;,&lt;=说明：等号也可以用来比较字符串，字符串需要加引号（2）组合条件&amp;&amp;：and||：or!：not（3）模糊匹配使用通配符百分号(%)：匹配任意长度的任意字符下划线：匹配任意单个字符（4）正则表达式regexp ‘正则表达式’（5）离散取值和连续取值离散取值：in连续取值：between..and..（6）比较空值is null、is not null select扩展：（1）order by filed_name {asc|desc}说明：排序，asc是正序，默认也是正序，desc是逆序（2）as取别名，as可以省略，后面可以直接引用别名（3）limit：只显示某些行例子：limit 2：最终结果只显示2个limit 2，3：最终结果偏移2个，然后显示接下来的3个（4）聚合计算sum()，求总和avg()，求平均值min()，求最小值max()，求最大值count()，求数量（5）group by分组，主要是做聚合计算（一般来说，不是求聚合函数的就不要分组）（6）having对分组后的结果过滤，也就是说，对group by后的结果进行过滤必须用having，不能用where 2、多表查询（1）交叉连接select * from tb1,tb2说明：tb1和tb2做笛卡尔乘积（2）自然连接：对应字段必须保持等值关系select tb1.xxx,tb2.xxx from tb1,tb2 where tb1.xxx=tb2.xxx说明：可以加别名（3）外连接左外连接：（左表）left join （右表）on (条件)右外连接：（右表）right join (左表) on (条件)例子：比如说，左表是课程表，右表是学生信息如果以课程表为标准，如果课程表有学生选择，就显示出来，课程没人选就显示为null。这就叫做左外连接；如果以学生为标准，如果学生有选课，就显示出来，没选课就显示为null。这就叫做右外连接。（4）自连接要连接的两个数据表在同一张表中，from tb1 as name1,tb1 as name2同一张表，起两个别名 3、子查询一个查询中嵌套另一个查询（1）在where子句中使用SELECT NAME FROM student WHERE Age &gt; (SELECT AVG(age) FROM student);说明：查询出大于平均年龄的学生不能这样写：SELECT NAME FROM student WHERE Age &gt; AVG(Age)SELECT NAME FROM student WHERE Age IN (SELECT age FROM tutor)说明：in的使用（2）在from子句中使用这种情况下一般可以使用联合查询(UNION)例子：(SELECT col1,col2 FROM tb1) UNION (SELECT col1,col2 FROM tb2)","categories":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/categories/mysql/"}],"tags":[]},{"title":"MySQL数据类型和sqlmode","slug":"sqlmode","date":"2019-01-30T03:25:00.000Z","updated":"2019-01-30T03:42:30.029Z","comments":true,"path":"2019/01/30/sqlmode/","link":"","permalink":"http://yoursite.com/2019/01/30/sqlmode/","excerpt":"","text":"一些比较特殊的数据类型：float（m,n） #整数占m位，小数点后占n位enum和set:enum：枚举列出的值set：可以随意组合列出的值例子：ENUM(‘A’,’B’) #’A’,’B’SET(‘A’,’B’) #’A’,’B’,’AA’,’BB’,’AB’,’BA’备注：set存储的方式比较特殊，不是存储字符，而是存储每个字符的索引下标 查看sql模式：show global variables like ‘sql_mode’;或者：select @@global.sql_mode;备注：1、@@变量名：表示显示服务器变量2、如果是一个@，表示显示自定义变量3、如果是设置变量，set global|session sql_mode=’xxx’ MYSQL的服务器变量：按作用域区分，分为两类：1.全局变量(对所有用户生效) #SHOW GLOBAL VARIABLES2.会话变量(只对会话生效) #SHOW [SESSION] VARIABLES AUTO_INCREMENT:(自动加1)修饰的字段必须满足以下几个条件：整型、无符号、非空、主键或者唯一键例子：CREATE TABLE test(ID INT UNSIGNED AUTO_INCREATEMENT NOT NULL PRIMARY KEY,name CHAR(20)) 存储引擎：1、mysql默认的是myisam和innodeDB两种存储引擎(通用引擎，除这两种之外的其他都是辅助的存储引擎)；2、存储引擎是表类型，是表级别的概念，不是数据库级的概念，一个数据库中的不同表可以使用不同的存储引擎。3、显示当前数据库所支持的所有存储引擎：show engines4、显示当前表所用的存储引擎：SHOW TABLE STATUS LIKE ‘TABLE_NAME’\\G;（显示一个表的属性信息）","categories":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/categories/mysql/"}],"tags":[]},{"title":"docker存储篇","slug":"docker存储篇","date":"2019-01-29T07:33:00.000Z","updated":"2019-01-29T08:45:45.448Z","comments":true,"path":"2019/01/29/docker存储篇/","link":"","permalink":"http://yoursite.com/2019/01/29/docker存储篇/","excerpt":"","text":"主题一、存储数据（1）storage driver定义：docker支持多种storage driver，有AUFS、Device Mapper、Btrfs、OverlayFS、VFS和ZFS。它们都能实现分层的架构，同时又有各自的特性。优选：对于选择哪种storage driver，docker官方给出了一个简单的答案，就是优先使用linux发行版默认的storage driver。查看：可以通过docker info查看driver 由上图可以看出，Centos用的是overlay2，底层文件系统是extfs，各层数据存放在/var/lib/docker优缺点：优点是对于某些容器，直接将数据放在由 storage driver 维护的层中是很好的选择，比如那些无状态的应用。无状态意味着容器没有需要持久化的数据，随时可以从镜像直接创建。比如 busybox，它是一个工具箱，我们启动 busybox 是为了执行诸如 wget，ping 之类的命令，不需要保存数据供以后使用，使用完直接退出，容器删除时存放在容器层中的工作数据也一起被删除；缺点是对于有持久化数据的需求，容器启动时需要加载已有的数据，容器销毁时希望保留产生的新数据，也就是说，这类容器是有状态的。这就要用到 Docker 的另一种存储机制：Data Volume。 （2）data volume定义：Data Volume 本质上是 Docker Host 文件系统中的目录或文件，能够直接被 mount 到容器的文件系统中。特点：Data Volume 是目录或文件，而非没有格式化的磁盘（块设备）；容器可以读写 volume 中的数据；volume 数据可以被永久的保存，即使使用它的容器已经销毁。类型：bind mount：定义：将host上已存在的目录或文件mount到容器例子：1、docker host上有目录$HOME/htdocs： 2、通过-v将其 mount 到 httpd 容器： -v的格式为:。/usr/local/apache2/htdocs 就是 apache server 存放静态文件的地方。由于 /usr/local/apache2/htdocs 已经存在，原有数据会被隐藏起来，取而代之的是 host $HOME/htdocs/ 中的数据，这与 linux mount命令的行为是一致的。3、查看httpd容器的ip： 4、在docker host上用curl验证： curl 显示当前主页确实是 $HOME/htdocs/index.html 中的内容5、更新一下，看是否能生效： 6、将容器删除，验证对bind mount的影响： 结论：数据依然存在。说明bind mount是docker host系统中的数据，只是借给容器使用7、设置权限： ro设置了只读权限，在容器中是无法对bind mount数据进行修改的。只有host有权修改数据，提高了安全性。8、除了mount目录，bind mount还可以单独指定一个文件： 使用 bind mount 单个文件的场景是：只需要向容器添加文件，不希望覆盖整个目录。在上面的例子中，我们将 html 文件加到 apache 中，同时也保留了容器原有的数据。使用单一文件有一点要注意：host 中的源文件必须要存在。 docker managed volume：定义：使用bind mount指定的时候有一个缺点，就是bind mount 需要指定 host 文件系统的特定路径，这就限制了容器的可移植性，当需要将容器迁移到其他 host，而该 host 没有要 mount 的数据或者数据不在相同的路径时，操作会失败。因此引出来docker managed volume，移植性更好的方式是 docker managed volume。例子：1、docker managed volume 与 bind mount 在使用上的最大区别是不需要指定 mount 源，指明 mount point 就行了： 通过 -v 告诉 docker 需要一个 data volume，并将其 mount 到 /usr/local/apache2/htdocs。2、查看data volume的位置：docker inspect 28534a2a1452ce(这是容器的短ID)，主要关心mount部分： 这里会显示容器当前使用的所有 data volume，Source 就是该 volume 在 host 上的目录3、查看volume里面的内容： volume 的内容跟容器原有 /usr/local/apache2/htdocs 完全一样。这是因为如果 mount point 指向的是已有目录，原有数据会被复制到 volume 中。我们可以像 bind mount 一样对数据进行操作，例如更新数据。4、通过docker volume查看volume： 备注：总结docker managed volume 的创建过程1、容器启动时，简单的告诉 docker “我需要一个 volume 存放数据，帮我 mount 到目录 /abc”。2、docker 在 /var/lib/docker/volumes 中生成一个随机目录作为 mount 源。 两种类型的比较：相同点：两者都是host文件系统中的某个路径不同点： 两种类型的使用场景：数据层，或者说镜像层和容器层（storage driver）和volume（data volume）都可以用来存放数据，各自的使用场景：1、Database软件vs Database数据2、web应用 vs web应用产生的日志3、数据分析软件 vs input/output数据4、Apache server vs 静态html文件结论：1、这四种场景中，前者都应该放在数据层，因为这部分内容是无状态的，应该作为镜像的一部分；2、后者放在data volume。因为这是需要持久化的数据，并且应该与镜像分开存放。 主题二：共享数据（1）容器与host共享数据我们有两种类型的 data volume，它们均可实现在容器与 host 之间共享数据，但方式有所区别。bind mount：直接将要共享的目录 mount 到容器。docker managed volume：由于 volume 位于 host 中的目录，是在容器启动时才生成，所以需要将共享数据拷贝到 volume 中。 备注：docker cp 可以在容器和 host 之间拷贝数据，当然我们也可以直接通过 Linux 的 cp 命令复制到 /var/lib/docker/volumes/xxx（2）容器与容器共享数据方法一：原理：将共享数据放在 bind mount 中，然后将其 mount 到多个容器。例子：1、我们要创建由三个 httpd 容器组成的 web server 集群，它们使用相同的 html 文件： 2、修改 volume 中的主页文件，再次查看并确认所有容器都使用了新的主页： 方法二：原理：用 volume container 共享数据特点：1、与 bind mount 相比，不必为每一个容器指定 host path，所有 path 都在 volume container 中定义好了，容器只需与 volume container 关联，实现了容器与 host 的解耦。2、使用 volume container 的容器其 mount point 是一致的，有利于配置的规范和标准化，但也带来一定的局限，使用时需要综合考虑。 例子：1、volume container 是专门为其他容器提供 volume 的容器。它提供的卷可以是 bind mount，也可以是 docker managed volume 我们将容器命名为 vc_data（vc 是 volume container 的缩写）。注意这里执行的是 docker create 命令，这是因为 volume container 的作用只是提供数据，它本身不需要处于运行状态。容器 mount 了两个 volume：（1）bind mount，存放 web server 的静态文件。（2）docker managed volume，存放一些实用工具。2、通过docker inspect vc_data可以查看到这两个volume： 3、其他容器通过 –volumes-from 使用 vc_data 这个 volume container 4、以webapp4为例 webapp4 容器使用的就是 vc_data 的 volume，而且连 mount point 都是一样的。5、验证数据共享 结论：三个容器已经成功共享了volume container中的volume。 方法三：原理：使用data-packed volume container。其原理是将数据打包到镜像中，然后通过 docker managed volume 共享。例子：1、通过Dockerfile创建镜像 ADD将静态文件添加到容器目录 /usr/local/apache2/htdocs。VOLUME的作用与-v等效，用来创建docker managed volume，mount point 为/usr/local/apache2/htdocs，因为这个目录就是ADD添加的目录，所以会将已有数据拷贝到volume中。2、build 新镜像 datapacked 备注：htdocs要在当前目录下事先存在3、用新镜像创建 data-packed volume container 4、因为在 Dockerfile 中已经使用了 VOLUME 指令，这里就不需要指定 volume 的 mount point 了。启动 httpd 容器并使用 data-packed volume container data-packed volume container 和 volume container 的区别是：前者共享的数据是在image中的，不需要修改，任何host上的容器都能用；后者共享的是某个特定host上的数据，只有同一个host上的容器才能用。也就是说， data-packed volume 可以在任何host中使用，这就是区别。这样的方式迁移起来相当方便，但是如果数据有变动的话，只能通过重新构建image的方式来修改。用来做data-packed volume container的base image是越小越好，比如busybox 主题三、volume生命周期管理1、备份定义：因为 volume 实际上是 host 文件系统中的目录和文件，所以 volume 的备份实际上是对文件系统的备份。操作：搭建本地registry 所有的本地镜像都存在 host 的 /myregistry 目录中，我们要做的就是定期备份这个目录。2、恢复定义：volume 的恢复也很简单，如果数据损坏了，直接用之前备份的数据拷贝到 /myregistry 就可以了。3、迁移如果我们想使用更新版本的 Registry，这就涉及到数据迁移，方法是：（1）docker stop 当前 Registry 容器。（2）启动新版本容器并 mount 原有 volumedocker run -d -p 5000:5000 -v /myregistry:/var/lib/registry registry:latest4、销毁对于bind mount，docker 不会销毁 bind mount，删除数据的工作只能由 host 负责。对于 docker managed volume，在执行 docker rm 删除容器时可以带上 -v 参数，docker 会将容器使用到的 volume 一并删除，但前提是没有其他容器 mount 该 volume，目的是保护数据。如果没有带上-v参数，这样会产生孤立volume。例子：（1）使用docker managed volume 可以创建一个容器bbox （2）删除bbox （3）因为没有使用 -v，volume 遗留了下来。对于这样的孤儿 volume，可以用 docker volume rm 删除 （4）也可以这样删除孤儿 volume： docker volume prune如果想批量删除孤儿 volume，可以执行：docker volume rm $(docker volume ls -q) 最后总结：1、docker 为容器提供了两种存储资源：数据层和 Data Volume。2、数据层包括镜像层和容器层，由 storage driver 管理。3、Data Volume 有两种类型：bind mount 和 docker managed volume。4、bind mount 可实现容器与 host 之间，容器与容器之间共享数据。5、volume container 是一种具有更好移植性的容器间数据共享方案，特别是 data-packed volume container。6、备份、恢复、迁移和销毁 Data Volume。","categories":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/categories/docker/"}],"tags":[]},{"title":"docker网络篇","slug":"docker网络篇","date":"2019-01-29T01:36:00.000Z","updated":"2019-01-29T02:56:27.454Z","comments":true,"path":"2019/01/29/docker网络篇/","link":"","permalink":"http://yoursite.com/2019/01/29/docker网络篇/","excerpt":"","text":"1、四个网络定义：docker安装时会自动在host上创建三个网络，可以通过docker network ls命令查看 （1）none网络定义：顾名思义，none网络就是什么都没有的网络。挂在这个网络下的容器除了lo，没有其他任何网卡。容器创建时，可以通过–network=none指定使用none网络。 应用场景：封闭意味着隔离，一些对安全性要求高并且不需要联网的应用可以使用none网络。比如某个容器的唯一用途就是生成随机密码，就可以放到none网络中避免密码被窃取。 命令：指定使用none网络 （2）host网络定义：连接到host网络的容器共享docker host的网络栈，容器的网络配置与host完全一样。可以通过–network=host来指定使用host网络。 应用场景：直接使用docker host网络的最大好处就是性能，如果容器对网络传输效率有较高要求，则可以选择host网络。当然不便之处就是牺牲一些灵活性，比如要考虑端口冲突问题，docker host上已经使用的端口就不能再使用了。 命令：指定使用host网络 容器的hostname也跟宿主机一样 （3）bridge网络（默认）定义：docker安装时会创建一个命名为docker0的linux bridge。如果不指定–network，创建的容器默认都会挂到docker0上。 命令：一个新的网络接口vethad723e1被挂到了docker0上，vethad723e1就是新创建容器的虚拟网卡。 查看容器的网络配置 对比docker0和容器的interface，实际上vethad723e1和eth0@if109是一对veth pair。veth pair是一种成对出现的特殊网络设备，可以把它们想象成由一根虚拟网线连接起来的一对网卡，网卡的一头（eth0@if109）在容器中，另一头（vethad723e1）挂在网桥docker0上，其效果就是将eth0@if109 也挂在了 docker0 上。其中，eth0@if109的ip地址是172.17.0.3/16，这个网段的ip是由bridge网络的配置决定的。查看bridge网络的配置信息 （4）自定义网络定义：除了none、host、bridge这三个自动创建的网络，用户也可以根据业务需要创建user-defined网络。docker提供了三种user-defined网络驱动：bridge、overlay和macvlan。 命令：新增了一个网桥br-30ff061f03ca 查看my_net的配置信息 除了可以自动分配，还可以自定义ip网段 容器使用新的网络，使用自动分配的ip 除了可以自动分配，还可以指定ip地址 备注：只有使用–subnet创建的网络才能指定静态ip。如果容器使用不是–subnet创建的网络，指定ip地址时会返回错误。 2、容器与容器的相互访问同一网络之间的容器通信：有三种通信方式（1）IP两个容器要能通信，必须要有属于同一网络的网卡。具体做法是在创建容器时通过–network指定相应的网络，或者通过docker network connect将现有网络加入到指定网络。参考之前的章节。（2）docker dns server通过ip访问会有一个问题：我们在部署应用之前有可能无法确定ip，部署之后再指定要访问的ip会比较麻烦。针对这个问题，可以通过docker自带的dns服务来解决。原理：从docker1.10版本开始，docker daemon实现了一个内嵌的dns server，使容器可以直接通过容器名通信。方法很简单，只要在启动时使用–name为容器命名就可以了。实验一：启动两个容器：docker run -it –network=my_net2 –name=bbox1 busyboxdocker run -it –network=my_net2 –name=bbox2 busybox验证ping测试： 结论：可以ping通。 实验二：创建两个bridge网络下的容器：docker run -it –name=bbox3 busyboxdocker run -it –name=bbox4 busybox验证ping测试： 结论：使用dns有限制，只能在自定义网络（my_net2就是自定义网络）中使用。也就是说，默认的bridge网络是无法使用dns的。（3）joined原理：可以使两个或多个容器共享一个网络栈、网卡和配置信息，joined容器之间可以通过127.0.0.1直接通信适用场景：不同容器中的程序希望通过loopback高效快速的通信，比如web server与app server；希望监控其他容器的网络流量，比如运行在独立容器中的网络监控程序。验证：先创建一个httpd容器，名字为web1：docker run -d -it –name=web1 httpd然后创建busybox容器并通过–network=container:web1指定joined容器为web1 查看web1容器的网络配置信息： 结论：busybox与web1的网卡mac地址与ip地址完全一样，它们共享了相同的网络栈。 不同网络之间的容器通信：首先，由常识可知，同一网络中的容器、网关之间都是可以相互通信的。也可以通过实验验证。但是，自定义网络（my_net2）与默认bridge网络之间默认不能相互通信。针对这个问题，我们可以通过添加路由来达到不同网络之间的同期也能相互通信的目的。也就是说，如果host上针对每个网络都有一条路由，同时操作系统上打开了ip forwarding，host就成了一个路由器，挂接在不同网桥上的网络就能够相互通信。验证：首先，定义172.17.0.0/16和172.22.16.0/24两个网络的路由： 确认打开了ip转发功能：sysctl net.ipv4.ip_forward或者cat /proc/sys/net/ipv4/ip_forward，值为1表示打开了ip转发功能为httpd容器（位于bridge网络）添加一块my_net2的网卡，添加命令： 在httpd容器中查看网络配置（红框中为新加的网卡，ip地址是my_net2端随机分配的ip，这时候就可以在位于my_net2的容器ping通httpd容器）： 容器与外部的相互访问：（1）容器访问外部定义：容器默认就能访问外网（外网指的是容器网络以外的网络环境，并非特指Internet）原理：最关键的就是NAT技术验证首先，查看一下host的iptables规则： 这条iptables规则的含义：如果网桥 docker0 收到来自 172.17.0.0/16 网段的外出包，把它交给 MASQUERADE 处理。而 MASQUERADE 的处理方式是将包的源地址替换成 host 的地址发送出去，即做了一次网络地址转换（NAT）。通过tcpdump查看地址转换：首先，查看host的路由表：默认路由通过eth0发送出去，所以我们可以通过tcpdump来监控docker0和eth0上的icmp数据包 然后，在busybox容器上ping外网（比如www.bing.com），tcpdump输出如图：docker0 收到 busybox 的 ping 包，源地址为容器 IP 172.17.0.4，然后交给 MASQUERADE 处理。 这时在eth0上查（发现ping包的源地址变成了144.34.204.150） （2）外部访问容器原理：端口映射验证首先，docker可以将容器对外提供服务的端口映射到host的某个端口，外网通过该端口访问容器。 容器启动后，可以通过docker ps或者docker port查看到host映射的端口。在上面的例子中，httpd容器的80端口被映射到host 32769上，这样就可以通过 : 访问容器的 web 服务了。也可以指定映射到host的某个特定端口： 每一个映射的端口，host都会启动一个docker-proxy进程来处理访问容器的流量： 最后，过程总结：docke-proxy监听host的32769端口；当访问宿主机的web服务的时候（宿主机的ip:port），docker-proxy 转发给容器(容器ip:容器port）；httpd 容器响应请求并返回结果。","categories":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/categories/docker/"}],"tags":[]},{"title":"广域网技术","slug":"广域网技术","date":"2019-01-25T08:06:00.000Z","updated":"2019-01-25T08:28:37.989Z","comments":true,"path":"2019/01/25/广域网技术/","link":"","permalink":"http://yoursite.com/2019/01/25/广域网技术/","excerpt":"","text":"1、基础概述（1）定义WAN–广义网，大范围网络，常常是一个国家或者一个州（2）设备路由器–支持不同类型的网络接口，实现不同网络类型互联 2、基础术语（1）上行/下行 （2）同步/异步 （3）串行/并行 3、连接类型（1）专线连接 E1：2MT1：1.544M优点：线缆专用，带宽恒定缺点：价格昂贵（2）电路连接 （3）分组交换 （4）信元交换固定长度的分组就是信元 4、WAN协议（1）HDLC定义：高级数据链路控制协议–Cisco私有 概念：DTE：数据终端设备DCE：数据通信设备配置：第一步，首先确定DTE与DCE的时钟频率一致：查看时钟频率 配置时钟频率 第二步，进行协议配置：配置端口协议 查看端口协议 （2）PPP定义：point-to-point协议 配置： 认证：PAP认证（明文）：PAP认证过程： PAP认证配置： CHAP认证（密文）：分为双向CHAP和单向CHAP双向CHAP认证过程： 双向CHAP认证配置： 单向CHAP认证过程： 单向CHAP认证配置： 链路捆绑：定义： 配置： 查看： （3）frame-relayWHYframe-relay出现之前:拓扑复杂： 查询复杂： frame-relay出现之后：拓扑简洁： 查询简单： WHAT术语：DLCI：数字链路连接标识符标签：tag接口类型：DTE、DCE、NNI信令类型：cisco、q933a、ansi(同一线缆上信令类型必须一致)电路类型：VC(虚拟电路)、PVC(永久虚电路)、SVC(短暂虚电路)HOW拓扑图： 静态配置： R1： R2： R3： 动态配置： 查看配置：","categories":[{"name":"网络基础","slug":"网络基础","permalink":"http://yoursite.com/categories/网络基础/"}],"tags":[]},{"title":"NAT技术","slug":"NAT技术","date":"2019-01-25T07:56:00.000Z","updated":"2019-01-25T08:04:28.457Z","comments":true,"path":"2019/01/25/NAT技术/","link":"","permalink":"http://yoursite.com/2019/01/25/NAT技术/","excerpt":"","text":"1、WHY为什么需要NAT？私网设备与公网设备不会运行任何路由协议上网流量：默认路由出去，精细路由回来 2、WHATNAT类型：（1）静态NAT：一对一映射 （2）动态NAT：多对多映射 （3）PAT：端口复用 3、HOW配置：（1）静态NAT （2）动态NAT （3）PAT","categories":[{"name":"网络基础","slug":"网络基础","permalink":"http://yoursite.com/categories/网络基础/"}],"tags":[]},{"title":"ACL技术","slug":"ACL技术","date":"2019-01-25T07:35:00.000Z","updated":"2019-01-25T07:53:51.736Z","comments":true,"path":"2019/01/25/ACL技术/","link":"","permalink":"http://yoursite.com/2019/01/25/ACL技术/","excerpt":"","text":"1、ACL定义访问控制列表–定义感兴趣流量 2、ACL规则（1）编号：条目编号默认以10递增，方便ACL后期修改（2）查看：从上到下查看，一旦匹配规则，立即执行，后面规则不再查看（3）特性：条目最后隐藏一条拒绝所有语句；本地流量不过滤 3、ACL分类按编号分类：（1）标准ACL：编号1到99，只能定义源IP （2）扩展ACL：编号100到199，能定义源IP、目的IP、协议、端口号 按功能分类：（1）时间ACL概念：绝对时间（absolute）–即这个时间只生效一次，比如 2010年1 月1 月15:00周期时间（periodic）–即这个时间是会多次重复的，比如每周一需求： 配置： 查看： （2）自反ACL需求： 过程： 配置： （3）lock&amp;key ACL需求： 过程： 配置： 4、ACL命令（1）调用 （2）命名 （3）插入 （4）删除 （5）查看","categories":[{"name":"网络基础","slug":"网络基础","permalink":"http://yoursite.com/categories/网络基础/"}],"tags":[]},{"title":"Centos7安装mongoDB","slug":"Centos7安装mongoDB","date":"2019-01-24T09:04:00.000Z","updated":"2019-01-24T09:06:44.414Z","comments":true,"path":"2019/01/24/Centos7安装mongoDB/","link":"","permalink":"http://yoursite.com/2019/01/24/Centos7安装mongoDB/","excerpt":"","text":"1、配置mongoDB的yum源vim /etc/yum.repos.d/mongodb-org-3.4.repo #添加以下内容：[mongodb-org-3.4]name=MongoDB Repositorybaseurl=https://repo.mongodb.org/yum/redhat/$releasever/mongodb-org/3.4/x86_64/gpgcheck=1enabled=1gpgkey=https://www.mongodb.org/static/pgp/server-3.4.asc #这里可以修改 gpgcheck=0, 省去gpg验证[root@localhost ~]# yum makecache 2、安装MongoDB安装命令：yum -y install mongodb-org 3、查看mongo安装位置whereis mongod 4、启动mongoDBsystemctl start mongod.service","categories":[{"name":"安装篇","slug":"安装篇","permalink":"http://yoursite.com/categories/安装篇/"}],"tags":[]},{"title":"mongoDB的图形化软件","slug":"mongoDB的图形化软件","date":"2019-01-23T02:18:00.000Z","updated":"2019-01-23T02:18:53.104Z","comments":true,"path":"2019/01/23/mongoDB的图形化软件/","link":"","permalink":"http://yoursite.com/2019/01/23/mongoDB的图形化软件/","excerpt":"","text":"nosqlbooster for mongodb:","categories":[{"name":"QA","slug":"QA","permalink":"http://yoursite.com/categories/QA/"}],"tags":[]},{"title":"telnet mongod端口连接失败","slug":"telnet-mongod端口连接失败","date":"2019-01-23T01:34:00.000Z","updated":"2019-01-23T01:40:26.902Z","comments":true,"path":"2019/01/23/telnet-mongod端口连接失败/","link":"","permalink":"http://yoursite.com/2019/01/23/telnet-mongod端口连接失败/","excerpt":"","text":"mongodDB端口号27017，已在防火墙上放行27017端口，但是在本地telnet端口提示连接失败，如图： 解决方法：在mongoDB的配置文件有一个bind_ip的配置，默认值为127.0.0.1，默认只有本机可以连接。此时，需要将bind_ip配置为0.0.0.0，表示接受任何IP的连接。 然后重启mongoDB:service mongod restart这时候再telnet 27017就可以了","categories":[{"name":"QA","slug":"QA","permalink":"http://yoursite.com/categories/QA/"}],"tags":[]},{"title":"ECS（容器代理、安全性）","slug":"ECS（容器代理、安全性）","date":"2019-01-14T06:18:00.000Z","updated":"2019-01-14T06:18:32.237Z","comments":true,"path":"2019/01/14/ECS（容器代理、安全性）/","link":"","permalink":"http://yoursite.com/2019/01/14/ECS（容器代理、安全性）/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[]},{"title":"ECS（调度、集群）","slug":"ECS（调度、集群）","date":"2019-01-14T06:17:00.000Z","updated":"2019-01-14T06:17:22.956Z","comments":true,"path":"2019/01/14/ECS（调度、集群）/","link":"","permalink":"http://yoursite.com/2019/01/14/ECS（调度、集群）/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[]},{"title":"ECS（fargate、两种模式）","slug":"ECS（fargate、两种模式）","date":"2019-01-14T06:15:00.000Z","updated":"2019-01-14T06:15:55.492Z","comments":true,"path":"2019/01/14/ECS（fargate、两种模式）/","link":"","permalink":"http://yoursite.com/2019/01/14/ECS（fargate、两种模式）/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[]},{"title":"ECS（任务定义）","slug":"ECS（任务定义）","date":"2019-01-14T06:13:00.000Z","updated":"2019-01-14T06:14:18.488Z","comments":true,"path":"2019/01/14/ECS（任务定义）/","link":"","permalink":"http://yoursite.com/2019/01/14/ECS（任务定义）/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[]},{"title":"ECS（定义、特点）","slug":"ECS（定义、特点）","date":"2019-01-14T06:12:00.000Z","updated":"2019-01-14T06:12:29.260Z","comments":true,"path":"2019/01/14/ECS（定义、特点）/","link":"","permalink":"http://yoursite.com/2019/01/14/ECS（定义、特点）/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[]},{"title":"docker（容器与虚拟化的区别）","slug":"docker（容器与虚拟化的区别）","date":"2019-01-14T03:17:00.000Z","updated":"2019-01-14T03:18:06.343Z","comments":true,"path":"2019/01/14/docker（容器与虚拟化的区别）/","link":"","permalink":"http://yoursite.com/2019/01/14/docker（容器与虚拟化的区别）/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[]},{"title":"docker（特点、优点）","slug":"docker（特点、优点）","date":"2019-01-14T03:15:00.000Z","updated":"2019-01-14T03:16:08.327Z","comments":true,"path":"2019/01/14/docker（特点、优点）/","link":"","permalink":"http://yoursite.com/2019/01/14/docker（特点、优点）/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[]},{"title":"docker（组件）","slug":"docker（组件）","date":"2019-01-14T03:14:00.000Z","updated":"2019-01-14T03:15:03.354Z","comments":true,"path":"2019/01/14/docker（组件）/","link":"","permalink":"http://yoursite.com/2019/01/14/docker（组件）/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[]},{"title":"docker（起源、定义）","slug":"docker（起源、定义）","date":"2019-01-14T03:13:00.000Z","updated":"2019-01-14T03:13:47.242Z","comments":true,"path":"2019/01/14/docker（起源、定义）/","link":"","permalink":"http://yoursite.com/2019/01/14/docker（起源、定义）/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[]},{"title":"EC2置放群组（特点）","slug":"EC2置放群组（特点）","date":"2019-01-14T02:58:03.000Z","updated":"2019-01-14T02:58:10.336Z","comments":true,"path":"2019/01/14/EC2置放群组（特点）/","link":"","permalink":"http://yoursite.com/2019/01/14/EC2置放群组（特点）/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"EC2置放群组（定义、最佳实践）","slug":"EC2置放群组（定义、最佳实践）","date":"2019-01-14T02:56:00.000Z","updated":"2019-01-14T02:57:05.256Z","comments":true,"path":"2019/01/14/EC2置放群组（定义、最佳实践）/","link":"","permalink":"http://yoursite.com/2019/01/14/EC2置放群组（定义、最佳实践）/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[]},{"title":"弹性伸缩（扩展选项、默认的实例终止策略、与ELB搭配使用）","slug":"弹性伸缩（扩展选项、默认的实例终止策略、与ELB搭配使用）","date":"2019-01-11T09:10:00.000Z","updated":"2019-01-11T09:12:22.268Z","comments":true,"path":"2019/01/11/弹性伸缩（扩展选项、默认的实例终止策略、与ELB搭配使用）/","link":"","permalink":"http://yoursite.com/2019/01/11/弹性伸缩（扩展选项、默认的实例终止策略、与ELB搭配使用）/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[]},{"title":"弹性伸缩（启动配置、弹性伸缩组）","slug":"弹性伸缩（启动配置、弹性伸缩组）","date":"2019-01-11T09:08:00.000Z","updated":"2019-01-11T09:08:57.803Z","comments":true,"path":"2019/01/11/弹性伸缩（启动配置、弹性伸缩组）/","link":"","permalink":"http://yoursite.com/2019/01/11/弹性伸缩（启动配置、弹性伸缩组）/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[]},{"title":"弹性伸缩（定义、功能、参数）","slug":"弹性伸缩（定义、功能、参数）","date":"2019-01-11T09:04:00.000Z","updated":"2019-01-11T09:05:16.106Z","comments":true,"path":"2019/01/11/弹性伸缩（定义、功能、参数）/","link":"","permalink":"http://yoursite.com/2019/01/11/弹性伸缩（定义、功能、参数）/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[]},{"title":"bootstrap开机脚本","slug":"bootstrap开机脚本","date":"2019-01-11T08:19:00.000Z","updated":"2019-01-11T08:20:21.507Z","comments":true,"path":"2019/01/11/bootstrap开机脚本/","link":"","permalink":"http://yoursite.com/2019/01/11/bootstrap开机脚本/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[]},{"title":"EC2实例（数据类型）","slug":"EC2实例（数据类型）","date":"2019-01-11T08:11:00.000Z","updated":"2019-01-11T08:12:04.902Z","comments":true,"path":"2019/01/11/EC2实例（数据类型）/","link":"","permalink":"http://yoursite.com/2019/01/11/EC2实例（数据类型）/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[]},{"title":"vmware虚拟机：Exception 0xc000001d  has occurred.","slug":"vmware虚拟机：Exception-0xc000001d-has-occurred","date":"2019-01-11T07:39:00.000Z","updated":"2019-01-11T07:41:17.320Z","comments":true,"path":"2019/01/11/vmware虚拟机：Exception-0xc000001d-has-occurred/","link":"","permalink":"http://yoursite.com/2019/01/11/vmware虚拟机：Exception-0xc000001d-has-occurred/","excerpt":"","text":"解决方案：虚拟机设置，点击显示器，加速3D图形前面的打勾去掉即可。","categories":[{"name":"QA","slug":"QA","permalink":"http://yoursite.com/categories/QA/"}],"tags":[]},{"title":"docker容器篇","slug":"docker容器","date":"2019-01-10T07:10:00.000Z","updated":"2019-01-10T08:58:21.178Z","comments":true,"path":"2019/01/10/docker容器/","link":"","permalink":"http://yoursite.com/2019/01/10/docker容器/","excerpt":"","text":"1、运行容器指定容器启动时执行的命令的三种方法：（1）CMD命令（2）ENTRYPOINT命令（3）在docker run命令行中指定举例：（1）在容器启动时执行pwd，返回的/是容器中的当前目录 （2）执行docker ps或者docker container ls查看当前运行的容器 （3）执行docker ps -a或者docker container ls -a查看所有容器（-a会显示所有状态的容器） 可以看到容器已经退出，状态为exited 让容器保持运行状态的两种方法：（1）通过执行一个长期运行的命令来保持容器的运行状态（例如循环） 打开另外一个终端查看容器的状态缺点是：这种方法始终会占用一个终端（2）加上参数-d以后台方式启动容器 通过docker ps看到的container id是短id，短id是长id的前12个字符 停止容器：docker stop “短id” 指定容器名称：docker run –name “my_httpd_server” -d httpd docker ps可以看到容器运行的命令是httpd-foreground docker history可以知道这个命令是通过CMD指定的 2、进入容器两种进入容器的方法：（1）docker attach 通过id attach到容器的启动命令终端，然后可以看到echo每隔1秒打印hello-world（2）docker exec -it就是以交互模式打开，执行bash，其结果就是打开一个bash终端，就可以像在普通的linux中一样执行命令了。执行exit会退出容器，回到docker host（3）两者的区别attach直接进入容器启动命令的终端，不会启动新的进程；exec则是在容器中打开新的终端，并且可以启动新的进程；如果想直接在终端中查看启动命令的输出，用attach。其他情况用exec。通过docker log -f也可以查看启动命令的输出（-f与tail -f类似，能够持续打印输出） 指定容器的三种方法：（1）短ID（2）长ID（3）容器名称（通过–name为容器命名。重命名容器可以执行docker rename） 3、常用命令create：创建容器run：运行容器pause：暂停容器unpause：取消暂停stop：发送SIGTERM停止容器kill：发送SIGKILL快速停止容器start：启动容器restart：重新启动容器attach：attach到容器启动进程的终端exec：在容器中启动新进程，通常使用”-it”参数logs：显示容器启动进程的控制台输出，用”-f”持续打印rm：从磁盘中删除容器 4、资源限额内存限额：（1）内存定义：内存包含两部分，物理内存和swap（2）设置命令：-m或–memory：设置内存的使用限额，例如100M，2G–memory-swap：设置内存+swap的使用限额（备注：不单单是指swap，而是内存和swap的总和）（3）举例：例子1docker run -m 200M –memory-swap=300M ubuntu这条指令的意思是该容器最多允许使用200M的内存和100M的swap。默认上面两组参数的值为1，即对该容器内存和swap的使用没有限制 例子2docker run -it -m 200M –memory-swap=300M progrium/stress –vm 1 –vm-bytes 280M备注：–vm 1是指启动一个内存工作线程；–vm-bytes 280M是指每个线程分配280M内存运行结果： 结论：可以正常工作工作过程：分配 280M 内存。释放 280M 内存。再分配 280M 内存。再释放 280M 内存。一直循环…… 例子3docker run -it -m 200M –memory-swap=300M progrium/stress –vm 1 –vm-bytes 310M运行结果： 结论：不能正常工作工作过程：分配的内存超过限额，stress 线程报错，容器退出 备注：如果在启动容器时只指定 -m 而不指定 –memory-swap，那么 –memory-swap 默认为 -m 的两倍，比如：docker run -it -m 200M ubuntu容器最多使用 200M 物理内存和 200M swap。 CPU限额：设置命令：-c或者–cpu-shares：设置容器使用cpu的权重备注：（1）与内存限额不同，通过 -c 设置的 cpu share 并不是 CPU 资源的绝对数量，而是一个相对的权重值。也就是说，某个容器最终能分配到的 CPU 资源取决于它的 cpu share 占所有容器 cpu share 总和的比例。（2）比如说，在docker host中启动了两个容器docker run –name “container_A” -c 1024 ubuntudocker run –name “container_A” -c 512 ubuntucontainer_A 的 cpu share 1024，是 container_B 的两倍。当两个容器都需要 CPU 资源时，container_A 可以得到的 CPU 是 container_B 的两倍。（3）这种按权重分配cpu只会发生在cpu资源紧张的时候。如果 container_A 处于空闲状态，这时，为了充分利用 CPU 资源，container_B 也可以分配到全部可用的 CPU。 举例：（1）启动container_a 备注：–cpu是用来设置工作线程的数量。因为当前host只有一颗cpu，所以一个工作线程就能将cpu压满。如果host有多颗cpu，则需要相应增加–cpu的数量。（2）打开另一个终端，启动container_b （3）再打开一个终端，执行top命令 结论：container_a消耗的cpu是container_d的2倍（4）暂停container_a （5）container_b在container_a空闲的情况下可以用满整颗CPU IO限额：（1）IO定义：block io指的是磁盘的读写，docker可以通过设置权重、限制bps和iops的方式控制容器读写磁盘的带宽（2）限制IO的两种方式：设置权重：通过设置–blkio-weight参数来修改权重，默认值是500举例：container_a读写磁盘的带宽是container_b的两倍docker run -it –name container_a –blkio-weight 600 ubuntudocker run -it –name container_b –blkio-weight 300 ubuntu 限制bps和iops：（1）定义：bps：byte per second，每秒读写的数据量iops：io per second，每秒io的次数（2）可以通过以下参数控制容器的bps和iops：–device-read-bps：限制读某个设备的bps；–device-write-bps：限制写某个设备的bps；–device-read-iops：限制读某个设备的iops；–device-write-iops：限制写某个设备的iops。（3）举例：限制容器写/dev/sda的速率为30MB/sdocker run -it –device-write-bps /dev/sda:30MB ubuntu限速情况下的运行结果： 对比不限速情况下的运行结果： 备注：oflag=direct 指定用 direct IO 方式写文件，这样 –device-write-bps 才能生效 5、底层技术cgroup（1）作用：实现资源限额（2）定义：全称control group。Linux 操作系统通过 cgroup 可以设置进程使用 CPU、内存 和 IO 资源的限额。之前设置的–cpu-shares、-m、–device-write-bps 实际上就是在配置 cgroup（3）举例：启动一个容器： 查看容器ID： 查看cgroup目录： 在 /sys/fs/cgroup/cpu/docker 目录中，Linux 会为每个容器创建一个 cgroup 目录，以容器长ID 命名备注：目录中包含所有与 cpu 相关的 cgroup 配置，文件 cpu.shares 保存的就是 –cpu-shares 的配置，值为 512；同样的，/sys/fs/cgroup/memory/docker 和 /sys/fs/cgroup/blkio/docker 中保存的是内存以及 Block IO 的 cgroup 配置。 namespace（1）作用：实现资源隔离（2）定义：在每个容器中，我们都可以看到文件系统，网卡等资源，这些资源看上去是容器自己的。拿网卡来说，每个容器都会认为自己有一块独立的网卡，即使 host 上只有一块物理网卡。这种方式非常好，它使得容器更像一个独立的计算机。Linux 实现这种方式的技术是 namespace。namespace 管理着 host 中全局唯一的资源，并可以让每个容器都觉得只有自己在使用它。（3）六种namespace：六种namespace分别对应六种资源：Mount、UTS、IPC、PID、Network和User（4）六种资源：Mount namespace：Mount namespace 让容器看上去拥有整个文件系统。容器有自己的 / 目录，可以执行 mount 和 umount 命令。当然我们知道这些操作只在当前容器中生效，不会影响到 host 和其他容器； UTS namespace：UTS namespace 让容器有自己的 hostname。 默认情况下，容器的 hostname 是它的短ID，可以通过 -h 或 –hostname 参数设置； IPC namespace：IPC namespace 让容器拥有自己的共享内存和信号量（semaphore）来实现进程间通信，而不会与 host 和其他容器的 IPC 混在一起； PID namespace：容器在 host 中以进程的形式运行。例如当前 host 中运行了两个容器； Network namespace：Network namespace 让容器拥有自己独立的网卡、IP、路由等资源； User namespace：User namespace 让容器能够管理自己的用户，host 不能看到容器中创建的用户。","categories":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/categories/docker/"}],"tags":[]},{"title":"mysql基本使用","slug":"mysql数据库基础","date":"2019-01-09T07:12:00.000Z","updated":"2019-01-09T09:50:49.070Z","comments":true,"path":"2019/01/09/mysql数据库基础/","link":"","permalink":"http://yoursite.com/2019/01/09/mysql数据库基础/","excerpt":"","text":"1、mysql安装（1）专用软件包管理器：deb（ubuntu系统）和rpm(Redhat、centos、Fedora、suse系统)备注：rpm包可以由两种组织制作，一种是操作系统发行商（Redhat）制作，一种是mysql官方制作（2）通用二进制格式包gcc:x86（32位），x64（64位）（3）源代码包5.5、5.6之后的mysql不再用make编译，而是改用cmake（跨平台）；5.5、5.6本身没有提供cmake，需要自定义安装；mysql 6之后就已经集成了cmake备注：源代码方式和二进制包方式的区分（1）二进制包里面包括了已经经过编译,可以马上运行的程序。你只需要下载和解包(安装)它们以后,就马上可以使用；源代码包里面包括了程序原始的程序代码,需要在你的计算机上进行编译以后才可以产生可以运行程序，所以从源代码安装的时间会比较长。（2）二进制格式的包名字很长,都带有版本号、适应平台、适应的硬件类型等,而源码格式仅仅就是一个版本号的tar包：mysql-5.0.45.tar.gz 是源码包mysql-5.0.45-linux-x86_64-glibc23.tar.gz 是二进制包（3）源代码包里的文件往往会含有种种源代码文件,头文件.h、c代码源文件.c、C++代码源文件.cc/.cpp等;而二进制包里的文件则会有可执行文件(与软件同名的往往是主执行文件),标志是其所在路径含有名为bin的目录(仅有少数例外) 2、mysql版本alpha：内测版beta：公测版rc：发行候选版ga：通用发行版 3、进程间通信对于mysql客户端和服务端在同一主机的，不同进程间通过mysql.sock进行通信；对于mysql客户端和服务端不在同一主机的，不同进程间基于TCP/IP协议栈进行通信 4、mysql工具客户端工具（1）mysql：交互式输入SQL语句或从文件以批处理模式执行它们的命令行工具（2）mysqlaccess：检查访问主机名、用户名和数据库组合的权限的脚本（3）mysqladmin：管理工具，执行管理操作的客户程序，例如创建或删除数据库，重载授权表，将表刷新到硬盘上，以及重新打开日志文件。mysqladmin还可以用来检索版本、进程，以及服务器的状态信息。（4）mysqlbinlog：从二进制日志读取语句的工具。在二进制日志文件中包含执行过的语句，可用来帮助系统从崩溃中恢复（5）mysqlcheck：检查工具，检查、修复、分析以及优化表的表维护客户程序（6）mysqldump：备份工具，将mysql数据库转储到一个文件（7）mysqlhotcopy：当服务器在运行时，快速备份的工具（8）mysql import：导入工具，使用load data infile将文本文件导入相关表的客户程序（9）mysqlshow：显示数据库、表、列以及索引相关信息的客户程序 （1）\\d:定义语句结束符（2）\\c:提前终止语句执行(直接在后面加上\\c即可，但是加在结束符后面语句依然会执行)（3）\\r:重新连接到服务器（4）\\g:无论语句结束符是什么，直接将此语句送至服务端去执行（5）\\G:无论语句结束符是什么，直接将此语句送至服务端去执行，而且是以竖排的方式来显示(纵向显示，这对于横排显示不下一张表的时候，\\G是一种非常好的显示手段)（6）\\p:print,显示正在执行的命令（7）! COMMAND:执行shell命令(或者用system)（8）\\W:大写W表示语句执行之后显示警告信息（9）\\w:小写w表示语句执行之后不显示警告信息 服务端工具（1）mysqld：SQL后台程序（即mysql服务器进程）。该程序必须运行之后，客户端才能通过连接服务来访问数据库（2）mysqld_safe：服务器启动脚本。在Unix中推荐使用mysqld_safe来启动mysqld服务器。mysqld_safe增加了一些安全特性，例如当出现错误时重启服务器并向错误日志写入运行时间信息（3）mysql.server：服务器启动脚本。它调用mysqld_safe来启动mysql服务（4）mysql_multi：服务器启动脚本。用于启动或者停止系统上安装的多个mysql服务（5）myisampack：压缩myisam表以产生更小的只读表的一个工具（6）myisamchk：用来描述、检查、优化和维护myisam表的实用工具（7）mysql_install_db：该脚本用默认权限创建mysql授权表。通常只是在系统上首次安装mysql时执行一次备注：mysqld工具可能不在bin目录下，可能在{mysql安装目录}/mysql/libexec下 图形化工具mysql官方提供的图形化管理工具MySQL WorkbenchMySQL Workbenck也有两个版本：（1）MySQL Workbench Community Edition，也就是社区版本。（2）MySQL Workbench Standard Edition，也就是商业版本，是按年收取费用的。 其他工具mysql_configmysql在安装完后，一般在${MYSQL_HOME}/bin目录下有mysql_config工具，它不是一个二进制文件，是一个脚本工具。当我们在编译自己的mysql客户端时，可用通过mysql_config工具获取很多的有用的编译参数，例如使用mysql_config –include可以获取mysql的mysql在安装时的一些头文件位置，或者mysql_config–libs可以获取mysql的头文件及共享库等编译参数。例如：mysql_config–include #得到-I/usr/include/mysqlmysql_config –libs #得到-L/usr/lib/mysql-lmysqlclient -lz -lcrypt -lnsl -lm -L/usr/lib -lssl -lcrypto 备注：（1）修改用户密码：mysqladmin -u username -h hostname password ‘new_password’ -p ‘old_password’也可以这样修改：set password for ‘username‘@’host’=password(‘new_password’)（2）SELECT DATABASE();#查看当前使用的默认数据库连入数据库的时候，还可以通过–database db_name(或者-D db_name)来指定默认的数据库 5、mysqladmin工具mysqladmin create hellodb #不用连上数据库直接在linux命令行下创建(会读取my.cnf下的数据库的定义)mysqladmin -uroot -p password -h host_name create hellodb还有其他一些子命令，比如：mysqladmin drop db_name:删除dbmysqladmin ping:测试对方mysql服务器是否在线：mysqladmin -uroot -p -hhostname(或主机ip) pingmysqladmin processlist:显示正在执行的进程(线程列表)(相当于连上mysql之后执行的SHOW PROCESSES)mysqladmin status:显示mysql服务器的状态status的高级用法：mysqladmin status –sleep 2 #定义多久显示一次mysqladmin status –count 2 #定义显示次数mysqladmin extended-status:显示状态变量(状态变量对于查询mysql服务器状态和排除故障至关重要)mysqladmin variables:显示服务器变量(跟状态变量区分)mysqladmin flush-privileges(等同于reload):让mysql重读授权表mysqladmin flush-status:重置大多数的服务器状态变量mysqladmin flush-threads:重置线程缓存mysqladmin flush-logs:中继日志滚动mysqladmin flush-hosts:重置连接的hostmysqladmin refresh:相当于mysqladmin flush-logs和mysqladmin flush-hostsmysqladmin shutdown:关闭mysql服务器mysqladmin version:显示当前服务器版本及状态信息mysqladmin start-slave:启动复制，启动从服务器复制线程mysqladmin stop-slave:关闭复制 6、表文件（1）对于myisam存储引擎来说.frm：表结构.MYD：表空间.MYI：表索引 （2）对于innodeDB存储引擎来说（默认所有表共享一个表空间文件，建议每个表单独一个表空间文件）.frm：表结构.ibd：表空间（表数据和表索引）.opt：定义字符集和排列规则（是一个文本文件，排列规则collation）","categories":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/categories/mysql/"}],"tags":[]},{"title":"关系型数据库基础理论","slug":"关系型数据库基础理论","date":"2019-01-09T06:20:00.000Z","updated":"2019-01-09T07:04:13.452Z","comments":true,"path":"2019/01/09/关系型数据库基础理论/","link":"","permalink":"http://yoursite.com/2019/01/09/关系型数据库基础理论/","excerpt":"","text":"1、关系模型和关系型数据库之间的联系关系模型：也叫结构化数据模型关系模型分类：（1）关系模型：最基本的（2）关系-实体模型：将数据拆分为多个不同实体（数据表），通过实体之间建立关联关系，也叫E-R模型（3）对象关系模型：基于对象的数据模型（比如图片）（4）半结构化数据模型：比如XML（扩展标记语言），存储数据的同时也存储数据的属性 关系型数据库能够处理以上的4种关系型数据模型 2、SQL语句分类（1）DML：数据操作语言（增删改查）insertdeleteupdateselect（2）DDL：数据定义语言（针对操作对象）createdropalter（3）DCL：数据控制语言（针对访问权限）grantrevoke 关系型数据库的对象有：库、表、索引、视图、用户、约束、存储过程、存储函数、触发器、事件调度器（类似于cron） 3、约束分类（1）域约束：数据类型约束（2）外键约束：引用完整性约束（使本表与另外的表关联起来的字段）（3）主键约束：某字段能唯一标识此字段所属的实体，并且不能为空（唯一标识本表）（4）唯一约束：跟主键约束类似，但是唯一约束可以为空，主键约束不能为空，而且一张表可以有多个唯一约束，但是只能有一个主键约束（5）检查性约束：除了用域约束来规定数据的类型之外，检查性约束可以规定数据不违反常理（比如规定一个人的年龄不超过150岁） 4、关系型数据分层表示层：表逻辑层：存储引擎物理层：数据文件 5、关键组件（1）查询管理器DDL解释器、DML解释器、查询执行引擎（2）存储管理器缓冲区管理器、文件管理器、事务管理器、权限和完整性管理器备注：因为对数据操作都是需要把数据从磁盘中读到内存，而内存往往比硬盘小得多，因此需要缓冲区管理器提供一种缓冲置换策略，将不常用的或者是已过期很久的一些操作置换出去，以此来腾出内存空间 6、进程与线程mysql是属于单进程多线程。线程分为守护线程和用户线程两种。守护线程：mysql内部的线程用户线程：比如连进来的用户（每一个用户连进来都建立一个线程，一个线程不能同时为多个用户服务，因为这涉及到权限交叉的问题）备注：在32位系统中，mysql只能使用到2.7G的内存（因此在生产环境中应该上64位的系统） 7、mysql与Oracle的区别最大的区别在于mysql支持插件式的存储引擎（也就是用户可以自行选择使用哪个存储引擎）备注：5.5.8之前，mysql默认的存储引擎是myisam，myisam不支持事务（myisam适用于查询比较多而修改比较少的场景，特别适用于数据仓库）；5.5.8之后，也就是mysql被Oracle收购之后，mysql的默认存储引擎变为innodeDB（innodeDB适用于在线事务管理系统，比如在线论坛等等） 8、SQL语句执行过程连接管理器–&gt;线程管理器–&gt;用户模块（验证身份）–&gt;命令分发模块–&gt;解析器–&gt;优化器（select）、表定义模块（update、delete、insert）、表维护模块（repair，检查、修改、备份、修复、优化等）、复制模块、状态报告模块–&gt;访问控制模块（检查用户是否有权限操作相关数据表）–&gt;表管理器（完成SQL操作，负责创建、读取或修改表结构定义文件，维护表描述符高速缓存，管理表锁）–&gt;存储引擎（数据库跟磁盘上的数据打交道的接口） 9、定长和变长对于定长的数据来说，查询的效率高，但是很容易造成空间浪费；对于变长的数据来说，查询效率慢，但是可以节省存储空间备注：在选择使用定长还是变长的时候，应该选择折中的方案 10、数据字典定义：存储元数据的表（在mysql初始化的时候，默认会生成一个叫做mysql的数据表，这个数据表就是用来存储数据库的相关元数据的，也就是数据字典）","categories":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/categories/mysql/"}],"tags":[]},{"title":"bash: ifconfig: command not found","slug":"bash-ifconfig-command-not-found","date":"2019-01-08T02:34:00.000Z","updated":"2019-01-08T02:37:08.948Z","comments":true,"path":"2019/01/08/bash-ifconfig-command-not-found/","link":"","permalink":"http://yoursite.com/2019/01/08/bash-ifconfig-command-not-found/","excerpt":"","text":"root@37e20725f95d:/usr/local/apache2# ifconfigbash: ifconfig: command not found 备注：debian默认没有安装ifconfig查看redhat（Centos）版本：cat /etc/redhat-release查看debian（ubuntu）版本：cat /etc/issue Debian系统：apt-get install net-tools","categories":[{"name":"QA","slug":"QA","permalink":"http://yoursite.com/categories/QA/"}],"tags":[{"name":"ifconfig","slug":"ifconfig","permalink":"http://yoursite.com/tags/ifconfig/"}]},{"title":" bash: ip: command not found","slug":"bash-ip-command-not-found","date":"2019-01-08T02:31:00.000Z","updated":"2019-01-08T02:32:05.155Z","comments":true,"path":"2019/01/08/bash-ip-command-not-found/","link":"","permalink":"http://yoursite.com/2019/01/08/bash-ip-command-not-found/","excerpt":"","text":"Centos安装:yum install iproute iproute-doc Ubuntu安装:apt-get install iproute iproute-doc","categories":[{"name":"QA","slug":"QA","permalink":"http://yoursite.com/categories/QA/"}],"tags":[{"name":"ip","slug":"ip","permalink":"http://yoursite.com/tags/ip/"}]},{"title":"Centos:brctl command not found","slug":"linux-brctl-command-not-found","date":"2019-01-08T02:27:00.000Z","updated":"2019-01-08T02:28:53.007Z","comments":true,"path":"2019/01/08/linux-brctl-command-not-found/","link":"","permalink":"http://yoursite.com/2019/01/08/linux-brctl-command-not-found/","excerpt":"","text":"[root@localhost ~]# brctl-bash: brctl: command not found 解决方法： [root@localhost ~]# yum install bridge-utils","categories":[{"name":"QA","slug":"QA","permalink":"http://yoursite.com/categories/QA/"}],"tags":[{"name":"brctl","slug":"brctl","permalink":"http://yoursite.com/tags/brctl/"}]},{"title":"docker镜像篇","slug":"docker镜像篇","date":"2019-01-07T01:28:00.000Z","updated":"2019-01-10T06:17:00.284Z","comments":true,"path":"2019/01/07/docker镜像篇/","link":"","permalink":"http://yoursite.com/2019/01/07/docker镜像篇/","excerpt":"","text":"1、最小镜像（1）定义hello-world是Docker官方提供的一个镜像，通常用来验证Docker是否安装成功（2）Dockerfile查看地址：https://github.com/docker-library/hello-world/blob/master/Dockerfile-linux.template 解释指令：FROM scratch：此镜像是从白手起家，从0开始构建的COPY hello /：将文件”hello”复制到镜像的根目录CMD [“/hello”]：容器启动时，执行/hello 2、base镜像（1）定义base镜像提供的是最小安装的linux发行版。能称作base镜像的通常都是各种linux发行版的Docker镜像，比如Ubuntu、Debian、Centos等（2）Dockerfile查看地址：https://github.com/CentOS/sig-cloud-instance-images/blob/a77b36c6c55559b0db5bf9e74e61d32ea709a179/docker/Dockerfile 解释指令：FROM、COPY、CMD这几个指令的作用跟hello-world镜像中的作用是一样的；ADD指令添加到镜像的tar包就是Centos7的rootfs。在制作镜像时，这个tar包会自动解压到/目录下，生成/dev、/proc、/bin等目录（3）含义不依赖其他镜像，从scratch构建；其他镜像可以以之为基础进行扩展（4）以Cenots为例下载镜像：docker pull centos查看镜像信息：docker images centos（备注：平时我们安装一个Centos至少都有几个GB，这里只有200MB。这是因为内核空间kernel的文件系统是bootfs，linux刚启动时会加载bootfs文件系统，之后bootfs会被卸载掉。而用户空间的文件系统是rootfs，包含我们熟悉的/dev、/proc、/bin等目录。对于base镜像来说，底层用host的kernel，自己只需要提供rootfs就行。对于一个精简的OS，rootfs可以很小，只需要包括最基本的命令、工具和程序库等）支持多种操作系统类型（备注：除Centos之外，base镜像可以模拟出多种操作系统环境。base镜像只是用户空间与发行版一致，kernel版本与发行版是不同的。因为所有容器共用host的kernel，因此在容器中无法对kernel升级。如果容器对kernel的版本有要求，比如说应用只能在某个kernel版本下运行，则不建议用容器，这种场景虚拟机可能更合适） 3、分层结构（1）定义通过扩展现有镜像，创建新的镜像（实际上，Docker Hub中99%的镜像都是通过在base镜像中安装和配置需要的软件构建出来的）（2）Dockerfile 解释指令：新镜像不再是从scratch开始，而是直接在Debian base镜像上构建；安装emacs编辑器；安装Apache2；容器启动时运行bash（3）好处：共享资源比如，有多个镜像都从相同的base镜像构建而来，那么Docker Hub只需要在磁盘上保存一份base镜像即可；同时内存中也只需要加载一份base镜像，就可以为所有容器服务了（4）copy-on-write特性定义：当需要修改时，才复制一份数据原理：当容器启动时，一个新的可写层被加载到镜像的顶部，这一层通常被称作”容器层”，”容器层”之下都叫”镜像层”；所有对容器的改动（无论是添加、删除或者是修改文件）都只会发生在容器层中；只有容器层是可写的，容器层下面的所有镜像层都是只读的，不会被容器修改，所以镜像可以被多个容器共享。（5）查看分层结构docker history：会显示镜像的构建历史，也就是Dockerfile的执行过程。ubuntu-with-vi-dockerfile与ubuntu镜像相比，确实只是多了顶部的一层 备注：docker history输出中IMAGE列出现，表示无法获取IMAGE ID，通常从Docker Hub下载的镜像会有这个问题 4、构建镜像（1）docker commit步骤：a、运行容器 -it参数的作用是以交互模式进入容器，并打开终端b、确认vim确实没有安装 c、安装vim（如果没有找到vim软件包，先apt-get update一下） d、打开一个新的窗口，查看当前运行的容器 silly_goldberg 是 Docker 为我们的容器随机分配的名字e、执行docker commit命令将容器保存为镜像 新镜像命名为ubuntu-with-vif、查看新镜像属性 从size上看到镜像因为安装了软件而变大了g、从新镜像启动容器，验证vi已经可以使用 总结：Docker并不建议用户通过这种方式构建镜像原因：这是一种手工创建镜像的方式，容易出错，效率低且可重复性弱；使用者并不知道镜像是如何创建出来的，里面是否有恶意程序。也就是说无法对镜像进行审计，存在安全隐患。（2）Dockerfile构建文件步骤：a、新建一个Dockerfile文件，内容如下：FROM ubuntuRUN apt-get update &amp;&amp; apt-get install -y vimb、运行docker build命令docker build -t ubuntu-with-vi-dockerfile .命令解释：-t将新镜像命名为ubuntu-with-vi-dockerfile；命令末尾的点号(.)，指明了build context为当前目录。目录下的所有文件和子目录都会被发送给Docker daemon。所以，不要将多余文件放到build context，特别不要把/、/usr作为build context，否则构建过程会相当缓慢甚至失败；我们也可以通过-f参数指定Dockerfile的位置。c、构建完成后，通过docker images查看镜像信息 5、缓存特性（1）定义缓存已有镜像的镜像层，构建新镜像时，如果某镜像层已经存在，就直接使用，无需重新创建（2）举例在前面的Dockerfile中添加一点新内容，往镜像中复制一个文件 （3）不使用缓存如果我们希望在构建镜像的时候不使用缓存，可以在docker build命令上加上–no-cache参数（4）缓存失效Dockerfile中每一个指令都会创建一个镜像层，上层是依赖下层的。无论什么时候，只要某一层发生变化，其上面所有层的缓存都会失效。也就是说，如果我们改变Dockerfile指令的执行顺序，或者修改或添加指令，都会使缓存失效。比如，交换前面的RUN和COPY的顺序，也会导致缓存失效。（5）使用场景构建镜像 &amp;&amp; 下载镜像 6、调试Dockerfile（1）定义如果Dockerfile由于某种原因执行到某个指令失败了，我们能够得到前一个指令成功执行构建出的镜像，这对调试Dockerfile非常有帮助（2）举例 运行在第三步的时候报错，我们可以利用第二部创建的镜像ba6402b1298d进行调试，方式是通过 docker run -it 启动镜像的一个容器。手工执行 RUN 指令很容易定位失败的原因是 busybox 镜像中没有 bash。 7、Dockerfile常用指令（1）FROM指定base镜像（2）MAINTAINER设置镜像的作者，可以是任意字符串（3）COPY将文件从build context复制到镜像（build context默认是当前目录，也可以通过-f来指定）COPY支持两种形式：COPY src destCOPY [“src”,”dest”]备注：src只能指定build context中的文件或目录（4）ADD与COPY类似，从build context复制文件到镜像。不同的是，如果src是归档文件（tar、zip、tgz、xz等），文件会被自动解压到dest（5）ENV设置环境变量，环境变量可以被后面的指令使用举例：…ENV MY_VERSION 1.3RUN apt-get install -y mypackage=$MY_VERSION…（6）EXPOSE指定容器中的进程会监听某个端口（7）VOLUME将文件或目录声明为volume（8）WORKDIR设置镜像中的当前工作目录（9）RUN在容器中运行指定的命令。通常用于安装应用和软件包两种格式：shell格式：RUN apt-get install python3Exec格式：RUN [“apt-get”,”install”,”python3”]举例：RUN apt-get update &amp;&amp; apt-get install -y \\bzr \\cvs \\git \\mercurial \\subversion备注：apt-get update和apt-get install被放在一个RUN指令中执行，这样能够保证每次安装的是最新的包。如果apt-get install在单独的RUN中执行，则会使用apt-get update创建的镜像层，而这一层可能是很久以前缓存的。（10）CMD设置容器启动时运行指定的指令，此命令会在容器启动且docker run没有指定其他指令时运行备注：如果docker run指定了其他命令，CMD指定的默认命令将会被忽略；如果Dockerfile中有多个CMD指令，只有最后一个CMD有效三种格式：shell格式：CMD echo “hello world”Exec格式：CMD [“/bin/echo”,”hello world”]与ENTRYPOINT搭配使用：CMD [“param1”,”param2”] ,此时ENTRYPOINT必须使用Exec格式，其用途是为ENTRYPOINT设置默认的参数举例：Dockerfile 片段如下：CMD echo “Hello world”运行容器 docker run -it [image] 将输出：Hello world但当后面加上一个命令，比如 docker run -it [image] /bin/bash，CMD 会被忽略掉，命令 bash 将被执行（11）ENTRYPOINT设置容器启动时运行的指令，看上去与CMD很像备注：与CMD不同的地方在于，ENTRYPOINT不会被忽略，一定会被执行，即使运行docker run时指定了其他指令；Dockerfile中有多个ENTRYPOINT命令，但是只有最后一个生效两种格式：shell格式：ENTRYPOINT echo “hello world”Exec格式：ENTRYPOINT [“/bin/echo”,”hello world”]举例：Dockerfile 片段如下：ENTRYPOINT [“/bin/echo”, “Hello”]CMD [“world”]当容器通过 docker run -it [image] 启动时，输出为：Hello world而如果通过 docker run -it [image] CloudMan 启动，则输出为：Hello CloudMan 8、镜像命名（1）组成实际上一个特定镜像的名字由两部分组成：repository和tag。格式为：[imagename]=[reposity]:[tag]默认如果docker build没有指定tag，会使用默认值latesttag的作用：常用于描述镜像的版本信息，比如httpd镜像 也可以是任意字符串，比如ubuntu镜像 打tag：docker tag myimage-v1.9.2 myimage:1docker tag myimage-v1.9.2 myimage:1.9docker tag myimage-v1.9.2 myimage:1.9.2docker tag myimage-v1.9.2 myimage:latest 9、搭建Registry（1）搭建公共Registry步骤：a、首先在docker hub上面注册一个账号b、命令行登录（用户名密码是你注册时提供的用户名和密码） c、修改镜像的repository使之与docker hub账号匹配 d、通过docker push将镜像上传到Docker Hub 备注：Docker 会上传镜像的每一层。如果是在官方镜像的基础上做了一点修改而得到新的镜像，Docker Hub 上已经有了全部的镜像层，所以真正上传的数据很少。同样的，如果我们的镜像是基于 base 镜像的，也只有新增加的镜像层会被上传。如果想上传同一 repository 中所有镜像，省略 tag 部分就可以了，例如：docker push liangzj/ubuntu-with-vi-dockerfilee、登录 https://hub.docker.com，在repository就可以看到上传的镜像 f、这个镜像就可以被下载使用了docker pull liangzj/ubuntu-with-vi-dockerfile:v1（2）搭建本地Registrywhy：Docker Hub虽然非常方便，但还是有些限制，比如，需要Internet连接，而且上传和下载的速度慢；上传到Docker Hub的镜像任何人都能够访问，虽然可以用私有repository，但不是免费的；安全原因很多组织不允许将镜像放到外网；解决方案就是搭建本地的Registry。步骤：a、启动registry容器 备注：使用的镜像是 registry:2-d是后台启动容器；-p是将容器的5000端口映射到host的5000端口。5000 是 registry 服务端口。-v是将容器的/var/lib/registry目录映射到host的/myregistry，用于存放镜像数据b、通过docker tag重命名镜像，使之与registry匹配 备注：localhost是文件/etc/hosts里面定义的主机名我们在镜像的前面加上了运行 registry 的主机名称和端口。c、通过docker push上传镜像 d、通过docker pull从本地registry下载镜像 10、常用操作子命令（1）images：显示镜像列表（2）history：显示镜像构建历史（3）commit：从容器创建新镜像（4）build：从Dockerfile构建镜像（5）tag：给镜像打tag（6）pull：从registry下载镜像（7）push：将镜像上传到registry（8）rmi：删除镜像（如果一个镜像对应了多个 tag，只有当最后一个 tag 被删除时，镜像才被真正删除）（9）search：搜索docker hub中的镜像（search 让我们无需打开浏览器，在命令行中就可以搜索 Docker Hub 中的镜像）","categories":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/categories/docker/"}],"tags":[]},{"title":"docker配置允许远程服务器的连接请求","slug":"docker配置允许远程服务器的连接请求","date":"2019-01-02T02:20:00.000Z","updated":"2019-01-02T02:23:42.864Z","comments":true,"path":"2019/01/02/docker配置允许远程服务器的连接请求/","link":"","permalink":"http://yoursite.com/2019/01/02/docker配置允许远程服务器的连接请求/","excerpt":"","text":"默认配置下，docker daemon只能响应来自本地host的客户端请求。如果要允许远程服务端请求，需要在配置文件中打开TCP监听。步骤如下：1、在环境变量 ExecStart 后面添加 -H tcp://0.0.0.0，允许来自任意 IP 的客户端连接（服务端） 2、重启 Docker daemon（服务端） 3、服务器 IP 为 120.79.244.203，客户端在命令行里加上 -H 参数，即可与远程服务器通信（客户端） 备注：info 子命令用于查看 Docker 服务器的信息。","categories":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/categories/docker/"}],"tags":[]},{"title":"docker架构与组件","slug":"docker架构与组件","date":"2019-01-02T02:01:00.000Z","updated":"2019-01-02T02:16:21.247Z","comments":true,"path":"2019/01/02/docker架构与组件/","link":"","permalink":"http://yoursite.com/2019/01/02/docker架构与组件/","excerpt":"","text":"1、why–为什么需要容器（1）背景今天，开发人员通常使用多种服务（比如 MQ，Cache，DB）构建和组装应用，而且应用很可能会部署到不同的环境，比如虚拟服务器，私有云和公有云。一方面应用包含多种服务，这些服务有自己所依赖的库和软件包；另一方面存在多种部署环境，服务在运行时可能需要动态迁移到不同的环境中。这就产生了一个问题：如何让每种服务能够在所有的部署环境中顺利运行？（2）引入docker的理由简要的答案是：容器使软件具备了超强的可移植能力。（3）docker的优势对于开发人员来说–Build Once, Run Anywhere容器意味着环境隔离和可重复性。开发人员只需为应用创建一次运行环境，然后打包成容器便可在其他机器上运行。另外，容器环境与所在的 Host 环境是隔离的，就像虚拟机一样，但更快更简单。 对于运维人员来说–Configure Once, Run Anything只需要配置好标准的 runtime 环境，服务器就可以运行任何容器。这使得运维人员的工作变得更高效，一致和可重复。容器消除了开发、测试、生产环境的不一致性。 2、what–什么是容器（1）定义容器是一种轻量级、可移植、自包含的软件打包技术，使应用程序可以在几乎任何地方以相同的方式运行。开发人员在自己笔记本上创建并测试好的容器，无需任何修改就能够在生产系统的虚拟机、物理服务器或公有云主机上运行。（2）组成应用程序本身；依赖：比如应用程序所需要的库或者其他软件（3）对比容器与虚拟机相同点：两者都是为应用提供封装何隔离不同点：a、容器在Host操作系统的用户空间中运行，与操作系统的其他进程隔离。这一点显著区别于虚拟机。b、由于所有的容器共享同一个Host OS，这使得容器在体积上要比虚拟机小很多。另外，启动容器不需要启动整个操作系统，所以容器部署和启动速度更快，开销更小，也更容易迁移。 3、how–容器是如何工作的（1）docker架构docker采用的是Client/Server架构。客户端向服务端发送请求，服务端负责构建、运行和分发容器。客户端和服务端可以运行在同一个Host上，客户端也可以通过socket或REST API与远程的服务器通信 （2）核心组件a、docker客户端定义：通过docker客户端我们可以方便地在Host上构建和运行容器。相关命令：最常用的Docker客户端是docker命令；直接输入docker可以查看docker支持的子命令。 b、docker服务端定义：Docker daemon以后台服务的方式运行在Docker host上，负责创建、运行、监控容器，构建、存储镜像。默认配置：默认配置下，Docker daemon只能响应来自本地Host的客户端请求。（也可以配置允许远程客户端请求） c、docker镜像定义：可将Docker镜像看着只读模板，通过它可以创建Docker容器。例如某个镜像可能包含一个Ubuntu操作系统、一个Apache HTTP Server以及用户开发的Web应用。生成镜像：可以从无到有开始创建镜像（可以将镜像的内容和创建步骤描述在一个文本文件中，这个文件被称作 Dockerfile，通过执行 docker build 命令可以构建出 Docker 镜像）；也可以下载并使用别人创建好的现成的镜像；还可以在现有镜像上创建新的镜像。 d、docker容器定义：Docker容器就是Docker镜像的运行实例。通俗理解：可以这么认为，对于应用软件，镜像是软件生命周期的构建和打包阶段，而容器则是启动和运行阶段。 e、registry定义：Registry 是存放 Docker 镜像的仓库。分类：公有：Docker Hub（https://hub.docker.com/） 是默认的 Registry，由 Docker 公司维护，上面有数以万计的镜像，用户可以自由下载和使用；私有：出于对速度或安全的考虑，用户也可以创建自己的私有 Registry。相关命令：docker pull：命令可以从 Registry 下载镜像。docker run：命令则是先下载镜像（如果本地没有），然后再启动容器。","categories":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/categories/docker/"}],"tags":[]},{"title":"docker基本安装","slug":"docker基本安装","date":"2018-12-29T03:16:00.000Z","updated":"2018-12-29T07:19:13.330Z","comments":true,"path":"2018/12/29/docker基本安装/","link":"","permalink":"http://yoursite.com/2018/12/29/docker基本安装/","excerpt":"","text":"1、docker安装在ubuntu下安装：（1）允许apt命令HTTPS访问docker源$ sudo apt-get install \\ apt-transport-https \\ ca-certificates \\ curl \\ software-properties-common （2）添加docker官方的GPGcurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - （3）将docker的源添加到/etc/apt/sources.list$ sudo add-apt-repository \\“deb [arch=amd64] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) \\ stable” （4）安装docker$ sudo apt-get update$ sudo apt-get install docker-ce 在centos7下安装：（1）更新yum源yum update（2）脚本安装curl -sSL https://get.docker.com/ | sh（3）启动dockerservice docker start 2、docker加速背景：由于 Docker Hub 的服务器在国外，下载镜像会比较慢。幸好 DaoCloud 为我们提供了免费的国内镜像服务。步骤：（1）在 daocloud.io 免费注册一个用户。登录后，点击顶部菜单“加速器”。 （2）点击之后，复制”配置Docker加速器”框中给出的命令，在你的服务器上执行我的是curl -sSL https://get.daocloud.io/daotools/set_mirror.sh | sh -s http://f1361db2.m.daocloud.io （3）重启docker$sudo systemctl restart docker.service 3、docker启动（1）容器启动过程（httpd为例）a、Docker daemon 发现本地没有 httpd 镜像b、daemon 从 Docker Hub 下载镜像c、下载完成，镜像 httpd 被保存到本地d、Docker daemon 启动容器（2）容器基本命令docker images：查看镜像docker ps：查看容器","categories":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/categories/docker/"}],"tags":[]},{"title":"apt-get update报错","slug":"apt-get-update报错","date":"2018-12-28T08:57:00.000Z","updated":"2018-12-28T09:05:09.096Z","comments":true,"path":"2018/12/28/apt-get-update报错/","link":"","permalink":"http://yoursite.com/2018/12/28/apt-get-update报错/","excerpt":"","text":"apt安装docker的时候，遇到apt-get update报错：下列签名无效：KEYEXPIRED 1544811256 处理步骤：1、用apt-key list 命令看一下，发现是mongoDB的gpg过期了，所以无法update 2、试着把mongoDB的gpg删除，用apt-key del 91FA4AD5，再次apt-get update，还是报错 3、这时候重新导入一个新的MongoDB public GPG Keyapt-key adv –keyserver hkp://keyserver.ubuntu.com:80 –recv 2930ADAE8CAF5059EE73BB4B58712A2291FA4AD5然后再执行apt-get update,这是update终于不会报错了这时候就可以安装docker了：$sudo apt-get install docker-ce","categories":[{"name":"QA","slug":"QA","permalink":"http://yoursite.com/categories/QA/"}],"tags":[]},{"title":"容器生态系统（容器支持技术）","slug":"容器生态系统（容器支持技术）","date":"2018-12-28T07:44:00.000Z","updated":"2018-12-28T07:52:46.504Z","comments":true,"path":"2018/12/28/容器生态系统（容器支持技术）/","link":"","permalink":"http://yoursite.com/2018/12/28/容器生态系统（容器支持技术）/","excerpt":"","text":"1、容器网络定义：容器的出现使网络拓扑变得更加动态和复杂。用户需要专门的解决方案来管理容器与容器，容器与其他实体之间的连通性和隔离性。分类：（1）docker原生：docker network（2）第三方开源：fannelweavecalico 2、服务发现定义：动态变化是微服务应用的一大特点。当负载增加时，集群会自动创建新的容器；负载减小，多余的容器会被销毁。容器也会根据 host 的资源使用情况在不同 host 中迁移，容器的 IP 和端口也会随之发生变化。因此需要提供服务发现这种机制，来保存容器集群中所有微服务最新的信息，比如 IP 和端口，并对外提供 API，提供服务查询功能。分类（典型方案）：（1）etcd（2）consul（3）zookeeper 3、监控定义：监控对于基础架构非常重要，而容器的动态特征对监控提出更多挑战。分类：（1）docker原生：docker ps/top/stats：docker ps/top/stats 是Docker 原生的命令行监控工具。docker stats API：用户可以通过 HTTP 请求获取容器的状态信息。（2）第三方开源：sysdigcAdvisor/HeapsterWeave Scope 4、数据管理定义：容器经常会在不同的 host 之间迁移，如何保证持久化数据也能够动态迁移，是数据管理的重要内容。分类：flocker（提供数据管理的相关能力） 5、日志管理定义：日志为问题排查和事件管理提供了重要依据。分类：（1）docker logs：docker logs是docker原生工具（2）logspout：logspout对日志提供了路由功能，它可以收集不同容器的日志并转发给其他工具进行后处理 6、安全性定义：对于年轻的容器，安全性一直是业界争论的焦点。分类：OpenSCAP（OpenSCAP能够对容器镜像进行扫描，发现潜在的漏洞。）","categories":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/categories/docker/"}],"tags":[]},{"title":"容器生态系统（容器平台技术）","slug":"容器生态系统（容器平台技术）","date":"2018-12-28T07:39:00.000Z","updated":"2018-12-28T07:43:01.371Z","comments":true,"path":"2018/12/28/容器生态系统（容器平台技术）/","link":"","permalink":"http://yoursite.com/2018/12/28/容器生态系统（容器平台技术）/","excerpt":"","text":"1、容器编排引擎定义：基于容器的应用一般会被划分为不同的组件，并以服务的形式运行在各自的容器中，通过 API 对外提供服务。为了保证应用的高可用，每个组件都可能会运行多个相同的容器。这些容器会组成集群，这时候我们就需要通过容器编排引擎来管理容器集群，包括容器管理、调度、集群定义和服务发现等。通过容器编排引擎，容器被有机的组合成微服务应用，实现业务需求。分类（当前主流）：（1）docker swarm：docker swarm 是 Docker 开发的容器编排引擎。（2）kubernetes：kubernetes 是 Google 领导开发的开源容器编排引擎，同时支持 Docker 和 CoreOS 容器。（3）mesos：mesos 是一个通用的集群资源调度平台，mesos 与 marathon 一起提供容器编排引擎功能。 2、容器管理平台定义：容器管理平台是架构在容器编排引擎之上的一个更为通用的平台。通常容器管理平台能够支持多种编排引擎，抽象了编排引擎的底层实现细节，为用户提供更方便的功能分类（典型代表）：（1）Rancher（2）ContainerShip 3、基于容器的PaaS定义：基于容器的 PaaS 为微服务应用开发人员和公司提供了开发、部署和管理应用的平台，使用户不必关心底层基础设施而专注于应用的开发。分类（典型代表）：（1）Deis（2）Flynn（3）Dokku","categories":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/categories/docker/"}],"tags":[]},{"title":"容器生态系统（容器核心技术）","slug":"容器生态系统（容器核心技术）","date":"2018-12-28T06:49:00.000Z","updated":"2018-12-28T07:25:18.320Z","comments":true,"path":"2018/12/28/容器生态系统（容器核心技术）/","link":"","permalink":"http://yoursite.com/2018/12/28/容器生态系统（容器核心技术）/","excerpt":"","text":"1、容器规范定义：容器不光是 Docker，还有其他容器，比如 CoreOS 的 rkt。为了保证容器生态的健康发展，保证不同容器之间能够兼容，包含 Docker、CoreOS、Google在内的若干公司共同成立了一个叫 Open Container Initiative（OCI） 的组织，其目是制定开放的容器规范。分类：目前 OCI 发布了两个规范：runtime spec 和 image format spec。有了这两个规范，不同组织和厂商开发的容器能够在不同的 runtime 上运行。这样就保证了容器的可移植性和互操作性。 2、容器runtime定义：runtime 是容器真正运行的地方。runtime 需要跟操作系统 kernel 紧密协作，为容器提供运行环境。类似于java与JVM的关系：Java 程序就好比是容器，JVM 则好比是 runtime。JVM 为 Java 程序提供运行环境。同样的道理，容器只有在 runtime 中才能运行。分类（目前主流）：（1）lxc：lxc 是 Linux 上老牌的容器 runtime。Docker 最初也是用 lxc 作为 runtime。（2）runc：runc 是 Docker 自己开发的容器 runtime，符合 oci 规范，也是现在 Docker 的默认 runtime。（3）rkt：rkt 是 CoreOS 开发的容器 runtime，符合 oci 规范，因而能够运行 Docker 的容器。 3、容器管理工具定义：容器管理工具对内与 runtime 交互，对外为用户提供 interface，比如 CLI。这就好比除了 JVM，还得提供 java 命令让用户能够启停应用分类：（1）lxd：lxc的管理工具lxd（2）docker engine：runc 的管理工具是 docker engine。可以理解为docker engine=docker daemon。docker engine 包含后台 deamon 和 cli 两个部分。我们通常提到 Docker，一般就是指的 docker engine（3）rkt cli：rkt 的管理工具是 rkt cli 4、容器定义工具定义：允许用户定义容器的内容和属性，这样容器就能够被保存，共享和重建。分类：（1）docker image：docker image 是 docker 容器的模板，runtime 依据 docker image 创建容器。（2）dockerfile：dockerfile是包含若干命令的文本文件，可以通过这些命令创建出 docker image。（3）ACI：ACI (App Container Image) 与 docker image 类似，只不过它是由 CoreOS 开发的 rkt 容器的 image 格式。 5、registries定义：容器是通过 image 创建的，需要有一个仓库来统一存放 image，这个仓库就叫做 Registry。分类：（1）docker registry：企业可以用 Docker Registry 构建私有的 Registry。（2）docker hub：Docker Hub（https://hub.docker.com） 是 Docker 为公众提供的托管 Registry，上面有很多现成的 image，为 Docker 用户提供了极大的便利。（3）Quay.io：Quay.io（https://quay.io/）是另一个公共托管 Registry，提供与 Docker Hub 类似的服务。 6、容器OS定义：容器 OS 是专门运行容器的操作系统。与常规 OS 相比，容器 OS 通常体积更小，启动更快。因为是为容器定制的 OS，通常它们运行容器的效率会更高。分类（杰出代表）：（1）CoreOS（2）atomic（3）ubuntu core","categories":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/categories/docker/"}],"tags":[]},{"title":"路由技术（动态路由之OSPF）","slug":"路由技术（动态路由之OSPF）","date":"2018-12-28T02:06:00.000Z","updated":"2018-12-28T02:20:15.382Z","comments":true,"path":"2018/12/28/路由技术（动态路由之OSPF）/","link":"","permalink":"http://yoursite.com/2018/12/28/路由技术（动态路由之OSPF）/","excerpt":"","text":"1、基本概述定义：开放性最短路径优先（用于替代有缺陷的RIP）2、基本特征（1）OSI层次：传输层，基于协议号89（2）协议类型：链路状态路由协议（3）有类/无类：无类（4）IGP/EGP：IGP（5）管理距离：110（6）度量值：cost=100/带宽（M）（7）路由更新：组播如果是Dother，组播地址224.0.0.5如果是DR/BDR，组播地址224.0.0.63、基本运行 4、路由表更新 5、运行环境决定因素：网络类型默认由介质类型决定环境分类：（1）广播多路访问（BMA）（2）非广播多路访问（NBMA）（3）点到点（P2P）（4）点到多点（P2MP）（5）点到多点非广播多路访问（P2MP-NBMA）–思科私有相关命令： 6、特殊概念（1）router-id定义：路由器的身份id，唯一代表一台ospf路由器（默认以最大物理接口ip作为router-id）功能：防止路由抖动选举规则：a、手动指定；b、最大环回接口IP；c、最大物理接口IP清除router-id： （2）DR/BDR定义：指定路由器/备份指定路由器，类似于班集体当中的班长/副班长的位置功能：设定DR和BDR可以避免报文重复发送而导致的链路资源浪费选举规则：a、最大ospf接口优先级，默认为1（优先级为0代表不参与DR/BDR的选举）b、最大物理接口IP（3）邻居/邻接邻居关系：Dother–Dother邻接关系：Dother–DR/BDR两者区别：邻接关系建立在邻居关系基础之上，就好像男女朋友关系是建立在男女性朋友关系之上（4）区域骨干区域：骨干区域是area 0非骨干区域：所有不是area 0的都是非骨干区域两者关系：a、流量中转：非骨干区域间数据通信，必须要经过骨干区域 area 0 中转b、拓扑规划：所有非骨干区域要挂载在骨干区域 area 0 上","categories":[{"name":"网络基础","slug":"网络基础","permalink":"http://yoursite.com/categories/网络基础/"}],"tags":[]},{"title":"路由技术（动态路由之EIGRP）","slug":"路由技术（动态路由之EIGRP）","date":"2018-12-28T01:53:00.000Z","updated":"2018-12-28T02:22:52.082Z","comments":true,"path":"2018/12/28/路由技术（动态路由之EIGRP）/","link":"","permalink":"http://yoursite.com/2018/12/28/路由技术（动态路由之EIGRP）/","excerpt":"","text":"1、基本概述定义：增强型内部网关路由协议（号称”收敛之王”），属于混合型路由协议（距离矢量+链路状态）2、基本特征（1）OSI层次：传输层，基于协议号88（2）协议类型：混合型（3）有类/无类：无类（4）IGP/EGP：IGP（5）管理距离：内部90，外部170（6）度量值：复合型度量值a、5个标准：带宽、负载、延迟、可靠性、MTUb、度量值计算：针对路由条目接收端口（7）路由更新：224.0.0.103、基本运行 4、路由表同步 5、特殊术语（1）通告距离（AD）：邻居告诉你他自己到达目的地的距离 （2）可行距离（FD）：本地到达目的地的距离 （3）可行条件（FC）：AD&lt;FD，用于防环（4）后继路由：最优路由（5）可行后继路由：次优路由（6）后继站：最优路由的下一跳（7）可行后继站：次优路由的下一跳","categories":[{"name":"网络基础","slug":"网络基础","permalink":"http://yoursite.com/categories/网络基础/"}],"tags":[]},{"title":"路由技术（动态路由之RIP）","slug":"路由技术（动态路由之RIP）","date":"2018-12-28T01:31:00.000Z","updated":"2019-01-25T07:32:50.636Z","comments":true,"path":"2018/12/28/路由技术（动态路由之RIP）/","link":"","permalink":"http://yoursite.com/2018/12/28/路由技术（动态路由之RIP）/","excerpt":"","text":"1、基本概述定义：路由信息协议版本：（1）RIPv1：有类，传递路由条目时，不携带掩码，默认开启主类汇总，不能关闭主类汇总（不能关闭主要是为了减少链路带宽消耗）（2）RIPv2：无类，传递路由条目时，携带掩码，默认开启主类汇总，可以关闭主类汇总（到目前带宽已经不是问题，而更加追求网络的真实性）2、基本特征（1）OSI层次：应用层，基于UDP520（2）协议类型：距离矢量路由协议（3）有类/无类：RIPv1–有类，RIPv2–无类（4）IGP/EGP：IGP（5）管理距离：120（6）度量值：最大跳数15跳，16跳为不可达（7）路由更新：RIPv1–广播RIPv2–组播224.0.0.93、基本运行 4、路由表同步 5、时间机制 （1）更新计时器–30s在RIP启动之后,平均每30秒（实际上为25.5~30秒间的随机数时间，之所以这样也是为了错峰发送更新，以防止所有路由器同时发送路由更新造成太大流量） 启用了RIP的接口会发送自己的除了被水平分割（split horizon）抑制的路由选择表的完整副本给所有相邻路由器的时间间隔，并且update的目标地址为255.255.255.255。（2）失效计时器–180s如果 180 秒（默认值）后还未收到可刷新现有路由的更新，则将该路由的度量设置为 16，路由表项将被标记为“x.x.x.x is possibly down”。在清除计时器超时以前，该路由仍将保留在路由表中。（此时RIP路由仍然用来转发数据包）（3）刷新计时器–240s默认情况下，清除计时器设置为 240 秒，比无效计时器长 60 秒。当清除计时器超时后，该路由将从路由表中删除。（4）抑制计时器–180s该计时器用于稳定路由信息，并有助于在拓扑结构根据新信息收敛的过程中防止路由环路。在某条路由被标记为不可达后，它处于抑制状态的时间必须足够长，以便拓扑结构中所有路由器能在此期间获知该不可达网络。默认情况下，抑制计时器设置为180 秒。失效计时器到时，立马进入180s的抑制计时器。6、防环机制（1）最大条数：最大跳数15跳，16跳为不可达（2）水平分割：我发给你的，不要发给我（3）路由毒化：故障点设备主动发送16跳路由，主动干掉故障路由（4）毒性逆转：转发16跳毒化路由（违背水平分割原则）（5）抑制计时器：防止路由表频繁翻动，增加了网络的稳定性（6）触发更新：一旦检测到路由崩溃，立即广播路由刷新报文，而不等到下一个刷新周期","categories":[{"name":"网络基础","slug":"网络基础","permalink":"http://yoursite.com/categories/网络基础/"}],"tags":[]},{"title":"路由技术（静态路由）","slug":"路由技术（静态路由）","date":"2018-12-27T08:44:00.000Z","updated":"2018-12-28T01:27:56.902Z","comments":true,"path":"2018/12/27/路由技术（静态路由）/","link":"","permalink":"http://yoursite.com/2018/12/27/路由技术（静态路由）/","excerpt":"","text":"1、定义管理员手动静态写入路由表2、配置：Config# ip route 目标网络号 目标网络掩码 下一跳/逃出接口3、特殊的静态路由（1）默认路由定义：路由器网关配置：ip route 0.0.0.0 0.0.0.0 下一跳/逃出接口（2）浮动默认路由定义：主备冗余配置：","categories":[{"name":"网络基础","slug":"网络基础","permalink":"http://yoursite.com/categories/网络基础/"}],"tags":[]},{"title":"路由基础","slug":"路由基础","date":"2018-12-27T08:36:00.000Z","updated":"2018-12-27T08:43:32.801Z","comments":true,"path":"2018/12/27/路由基础/","link":"","permalink":"http://yoursite.com/2018/12/27/路由基础/","excerpt":"","text":"1、路由功能依据路由表进行数据转发的功能2、路由最优选举原则：（1）最小管理距离（管理距离越小越可靠、安全）（2）最小度量值（度量值越小，本地到达目的网络的花销就越小）3、路由查询查询原则：（1）最长匹配原则（最长是指网络位最长）（2）递归查询 4、路由分类（1）静态路由定义：管理员手工静态写入路由表优点：安全性高，度量值为0缺点：配置繁琐，不能动态适应拓扑变化（2）动态路由定义：通过路由协议协商交互路由条目优点：配置相对简单，能动态适应拓扑变化缺点：相对静态路由不安全分类：按距离矢量和链路状态来划分，分为以下三种：距离矢量路由协议：RIP 链路状态路由协议：OSPF 混合型路由协议：EIGRP 按有类和无类来划分，分为以下两种：有类路由协议：传递路由条目时，不携带掩码（不支持VLSM和CIDR）无类路由协议：传递路由条目时，携带掩码（支持VLSM和CIDR）","categories":[{"name":"网络基础","slug":"网络基础","permalink":"http://yoursite.com/categories/网络基础/"}],"tags":[]},{"title":"zabbix问题","slug":"zabbix","date":"2018-12-26T09:42:00.000Z","updated":"2018-12-28T07:30:25.124Z","comments":true,"path":"2018/12/26/zabbix/","link":"","permalink":"http://yoursite.com/2018/12/26/zabbix/","excerpt":"","text":"Assuming that agent dropped connection because of access permissions. 解决方法：修改客户端的配置文件zabbix_agentd.conf1、给serverActive和Hostname加注释 2、因为是采用C/S架构，客户端和服务器端不是同一台机器，所以还要在配置文件中加上两行： serverActive表示zabbix主动监控server的ip地址（默认server是主动来agent拿数据，serverActive表示agent主动推送数据给服务器端）","categories":[{"name":"QA","slug":"QA","permalink":"http://yoursite.com/categories/QA/"}],"tags":[]},{"title":"-bash: netstat: command not found","slug":"bash-netstat-command-not-found","date":"2018-12-26T07:54:00.000Z","updated":"2018-12-26T07:55:19.937Z","comments":true,"path":"2018/12/26/bash-netstat-command-not-found/","link":"","permalink":"http://yoursite.com/2018/12/26/bash-netstat-command-not-found/","excerpt":"","text":"yum install net-tools -y","categories":[{"name":"QA","slug":"QA","permalink":"http://yoursite.com/categories/QA/"}],"tags":[]},{"title":"交换技术（交换防环技术）","slug":"交换技术（交换防环技术）","date":"2018-12-26T01:26:00.000Z","updated":"2018-12-26T01:51:24.785Z","comments":true,"path":"2018/12/26/交换技术（交换防环技术）/","link":"","permalink":"http://yoursite.com/2018/12/26/交换技术（交换防环技术）/","excerpt":"","text":"1、STP基本概述（1）STP定义spanning-tree，生成树协议–通过选举机制选举出阻塞端口进而阻塞活动链路，直至剩下一条活动链路（2）STP功能用于防止环路备注：环路定义：首尾相连，无始无终环路危害：广播风暴（广播、组播、未知单播）；桥接表损坏，也叫CAM表（广播风暴+交换机学习功能）；重复帧环路本质：有多条活动链路 2、STP角色选举（1）设备角色根桥交换机（根桥选举原则：最小BID，BID=优先级+MAC地址）非根桥交换机（非根桥交换机收到TC包，会把MAC地址清空；TC包只有根桥才能发送）（2）端口角色a、根端口，简写RP根端口选举原则：最小cost值（cost=BPDU包内的cost值+接收端口的cost值）最小发送者BID（BID=优先级+MAC地址）最小发送者PID（PID=端口优先级+端口编号）备注：每一非根桥交换机上有且只有一个根端口b、指定端口，简写DP备注：根桥上所有端口都是指定端口每一条链路有且只有一个指定端口c、阻塞端口，简写block 3、STP参数修改通过修改STP选举参数，阻塞指定端口 4、STP端口状态机 5、STP链路收敛（1）直接链路失效–30s （2）间接链路失效–50s 6、STP数据分组 正常BPDU 次级BPDU TCN TCA TC TCA/TC","categories":[{"name":"网络基础","slug":"网络基础","permalink":"http://yoursite.com/categories/网络基础/"}],"tags":[]},{"title":"交换技术（交换安全技术）","slug":"交换技术（交换安全技术）","date":"2018-12-25T09:22:00.000Z","updated":"2018-12-26T01:24:51.829Z","comments":true,"path":"2018/12/25/交换技术（交换安全技术）/","link":"","permalink":"http://yoursite.com/2018/12/25/交换技术（交换安全技术）/","excerpt":"","text":"1、MAC地址绑定（1）MAC地址表MAC地址组成 查看MAC地址表 查看MAC地址 一对多关系 （2）需求用于限定PC只能通过特定接口上网（3）配置 2、port-security（1）需求：此F0/1接口只支持PCA数据通过 （2）配置","categories":[{"name":"网络基础","slug":"网络基础","permalink":"http://yoursite.com/categories/网络基础/"}],"tags":[]},{"title":"交换技术（交换冗余技术）","slug":"交换技术（交换冗余技术）","date":"2018-12-25T08:46:00.000Z","updated":"2018-12-25T08:58:18.682Z","comments":true,"path":"2018/12/25/交换技术（交换冗余技术）/","link":"","permalink":"http://yoursite.com/2018/12/25/交换技术（交换冗余技术）/","excerpt":"","text":"以太通道1、定义通过捆绑多条链路逻辑增加链路带宽（链路冗余）2、命令（1）配置： （2）查看： 3、限制条件（1）物理限制：接口物理参数必须匹配（2）逻辑限制：协议必须匹配协议种类： 协议分类：a、链路聚合控制协议（行业里的） b、端口汇聚协议（思科私有） 4、增强技术 （1）配置 （2）查看","categories":[{"name":"网络基础","slug":"网络基础","permalink":"http://yoursite.com/categories/网络基础/"}],"tags":[]},{"title":"交换技术（交换通信技术）","slug":"交换技术（交换通信技术）","date":"2018-12-25T06:13:00.000Z","updated":"2018-12-25T06:24:12.433Z","comments":true,"path":"2018/12/25/交换技术（交换通信技术）/","link":"","permalink":"http://yoursite.com/2018/12/25/交换技术（交换通信技术）/","excerpt":"","text":"1、单臂路由（1）why网关配置接口不够用；路由器识别不了vlan tag（2）what功能：实现不同vlan间的数据通信（3）how 2、三层交换通信（1）why单臂路由拓展性差，带宽限制严重，由此又引入了三层交换技术（2）what三层交换接口，简称SVI（switch virtual interface）（3）how 3、DHCP（1）why动态分配IP、掩码、网关、DNS（2）whatdynamic host configuration protocol，动态主机配置协议（3）how部署方式：a、内置部署结构图 配置命令（服务器端） 配置命令（客户端） b、旁路部署结构图 配置命令（服务器端） 配置命令（客户端）","categories":[{"name":"网络基础","slug":"网络基础","permalink":"http://yoursite.com/categories/网络基础/"}],"tags":[]},{"title":"交换技术（交换基础技术）","slug":"交换技术（交换基础技术）","date":"2018-12-25T03:23:00.000Z","updated":"2018-12-25T03:44:07.659Z","comments":true,"path":"2018/12/25/交换技术（交换基础技术）/","link":"","permalink":"http://yoursite.com/2018/12/25/交换技术（交换基础技术）/","excerpt":"","text":"1、vlan技术（1）why （2）what （3）how 2、trunk技术（1）why （2）what （3）how 3、DTP技术（1）why （2）whatDTP定义：dynamic trunking protocol，动态中继协议（思科私有） 端口模式：access：不能发送和接收协商信息trunk：能发送和接收协商信息desirable：能发送和接收协商信息auto：不能发送但能接收协商信息 链路模式：OFF模式 ON模式 DD模式 DA模式 链路规则：至少一端能发送协商信息，另一端能接收协商信息封装协议：802.1Q（3）how 4、VTP技术（1）why （2）whatVTP定义：vlan trunking protocol，vlan中继协议（思科私有）VTP角色：server：创建、删除、修改、发送、学习和传递vlan信息，修改所有VTP参数备注：当出现多个server时，配置版本号低的向高的学习；创建、删除、修改vlan，配置版本号都会加1；domain和password一致才能学习vlan信息client：学习和传递vlan信息transparent：创建、删除、修改和传递vlan信息，修改部分VTP参数VTP过程： （3）how创建VTP： VTP修剪：适用场景：假如AB两交换机，A有VLAN2 VLAN3 VLAN 4。B只有VLAN2，则VLAN3和VLAN4的信息无需转发到B交换机。VTP修剪可以节约链路资源","categories":[{"name":"网络基础","slug":"网络基础","permalink":"http://yoursite.com/categories/网络基础/"}],"tags":[]},{"title":"交换基础","slug":"交换基础","date":"2018-12-25T03:17:00.000Z","updated":"2018-12-25T03:20:13.943Z","comments":true,"path":"2018/12/25/交换基础/","link":"","permalink":"http://yoursite.com/2018/12/25/交换基础/","excerpt":"","text":"1、局域网概述 2、局域网术语 3、以太网标准 4、交换机原理","categories":[{"name":"网络基础","slug":"网络基础","permalink":"http://yoursite.com/categories/网络基础/"}],"tags":[]},{"title":"思科设备基本管理之三（文件管理）","slug":"思科设备基本管理之三（配置文件管理）","date":"2018-12-20T09:19:00.000Z","updated":"2018-12-20T09:22:01.770Z","comments":true,"path":"2018/12/20/思科设备基本管理之三（配置文件管理）/","link":"","permalink":"http://yoursite.com/2018/12/20/思科设备基本管理之三（配置文件管理）/","excerpt":"","text":"配置文件管理1、保存 2、删除 3、备份 IOS文件管理1、升级 2、删除 3、重灌（1）路由器IOS （2）交换机IOS","categories":[{"name":"网络基础","slug":"网络基础","permalink":"http://yoursite.com/categories/网络基础/"}],"tags":[]},{"title":"思科设备基本管理之二（密码管理）","slug":"思科设备基本管理之二","date":"2018-12-20T09:06:00.000Z","updated":"2018-12-20T09:13:20.244Z","comments":true,"path":"2018/12/20/思科设备基本管理之二/","link":"","permalink":"http://yoursite.com/2018/12/20/思科设备基本管理之二/","excerpt":"","text":"密码管理1、密码配置（1）enable密码 （2）console密码只需要密码： 需要用户名和密码： （3）telnet密码只需要密码： 需要用户名和密码： 2、密码破解（1）路由器破解原理： 破解过程： （2）交换机破解原理： 破解过程：","categories":[{"name":"网络基础","slug":"网络基础","permalink":"http://yoursite.com/categories/网络基础/"}],"tags":[]},{"title":"思科设备基本管理之一","slug":"思科设备基本管理","date":"2018-12-20T08:51:00.000Z","updated":"2018-12-20T09:17:16.285Z","comments":true,"path":"2018/12/20/思科设备基本管理/","link":"","permalink":"http://yoursite.com/2018/12/20/思科设备基本管理/","excerpt":"","text":"1、启动流程（1）交换机加电自检；bootstrap引导程序；从FLASH里寻找并加载IOS；从FLASH寻找并加载config.txt （2）路由器加电自检；bootstrap引导程序；从FLASH寻找并加载IOS；从NVRAM里寻找并加载startup-config 2、管理方式（1）带外管理：通过console线连接管理（2）带内管理：通过网线互联设备，telnet管理 3、配置模式用户模式：&gt;特权模式：#全局配置模式：（config）#exit：从当前模式返回到上一级模式end：从当前模式返回至特权模式 4、设备端口（1）端口类型 （2）端口命名 （3）端口配置 5、常用命令（1）标配命令 （2）常用show命令","categories":[{"name":"网络基础","slug":"网络基础","permalink":"http://yoursite.com/categories/网络基础/"}],"tags":[]},{"title":"进制转换","slug":"进制转换","date":"2018-12-19T08:34:00.000Z","updated":"2018-12-19T08:36:11.985Z","comments":true,"path":"2018/12/19/进制转换/","link":"","permalink":"http://yoursite.com/2018/12/19/进制转换/","excerpt":"","text":"二进制位权 二进制转十进制 二进制转十六进制 十进制转十六进制","categories":[{"name":"网络基础","slug":"网络基础","permalink":"http://yoursite.com/categories/网络基础/"}],"tags":[{"name":"进制转换","slug":"进制转换","permalink":"http://yoursite.com/tags/进制转换/"}]},{"title":"nmap","slug":"nmap","date":"2018-12-19T08:01:00.000Z","updated":"2018-12-19T08:01:21.931Z","comments":true,"path":"2018/12/19/nmap/","link":"","permalink":"http://yoursite.com/2018/12/19/nmap/","excerpt":"","text":"nmap:扫描器之王主要概念:探测主机是否在线、扫描主机开放端口和嗅探网络服务，用于网络探测和安全扫描扫描类型:(1)-sT:tcp扫描，用来建立一个tcp连接。如果成功则认为目标端口正在监听，否则认为端口没有监听程序。这种扫描很容易被检测到，在目标主机的日志中会记录大批的连接请求和错误信息(2)-sU:udp扫描，如果返回icmp不可达的错误信息说明端口是关闭的(3)-sS:tcp同步扫描(tcp syn)，只向目标发出syn数据包，如果收到syn/ack响应就认为目标端口正在监听，并立即断开连接，否则认为端口没有监听程序。这种扫描称为半开扫描，最大的好处是很少有系统会把这个记入系统日志(4)-sA:这种高级的扫描方法通常可以穿过防火墙(5)-sW:滑动窗口扫描，非常类似于ack的扫描(6)-sV:version版本扫描(7)-sL:显示扫描的所有主机列表(8)-sP:找出主机是否存在于网络中 nmap基本操作:(1)nmap 192.168.1.1(2)nmap 192.168.1.1 192.168.1.2(3)nmap 192.168.0-25.1-254(4)nmap magedu.com(5)nmap -vv 192.168.1.1(6)nmap -vv -p 3389 192.168..1(7)扫描除了某ip之外的所有子网主机:nmap 192.168.1.1/24 -exclude 192.168.1.10(8)扫描除了某文件中的ip之外的所有子网主机:nmap 192.168.1.1/24 -excludefile gov.txt(9)显示扫描的所有主机列表:nmap -sL 192.168.1.1/24(10)ping扫描，只用于找出主机是否存在于网络中:nmap -sP 192.168.1.1-255","categories":[{"name":"linux抓包管理","slug":"linux抓包管理","permalink":"http://yoursite.com/categories/linux抓包管理/"}],"tags":[{"name":"nmap","slug":"nmap","permalink":"http://yoursite.com/tags/nmap/"}]},{"title":"nc","slug":"nc","date":"2018-12-19T07:59:00.000Z","updated":"2018-12-19T08:00:01.003Z","comments":true,"path":"2018/12/19/nc/","link":"","permalink":"http://yoursite.com/2018/12/19/nc/","excerpt":"","text":"nc(由nc包提供，包名叫nc) #另外一个实现:ncat(由nmap提供,包名叫nmap)(1)传输文件文件传输:监听者为接收方nc -l PORT &gt; /file (监听端口，-l表示监听)nc IP PORT &lt; /file 文件传输:监听者为传输方nc -l PORT &lt; /filenc IP PORT &gt; /file (2)传输目录:需要先归档 (3)web客户端nc作为web客户端来访问web服务器nc WEBSERVER PORTGET /index.html HTTP/1.1Host:172.16.10.1 (4)扫描器nc -v -w 1 172.16.10.1 -z 1-1023-v:详细显示-w:超时时间-z:只扫描，不做其他任何动作 (5)聊天器nc -l PORTnc IP PORT例如:在一台主机上监听某个端口:nc -l 2333在另外一台主机上，nc 172.16.10.1 2333 -p 2333通过这样的方式，就可以在两台主机上相互传送信息了 (6)其他选项-s SOURCE_IP","categories":[{"name":"linux抓包管理","slug":"linux抓包管理","permalink":"http://yoursite.com/categories/linux抓包管理/"}],"tags":[{"name":"nc","slug":"nc","permalink":"http://yoursite.com/tags/nc/"}]},{"title":"tcpdump","slug":"tcpdump-1","date":"2018-12-19T07:57:00.000Z","updated":"2018-12-19T07:58:24.875Z","comments":true,"path":"2018/12/19/tcpdump-1/","link":"","permalink":"http://yoursite.com/2018/12/19/tcpdump-1/","excerpt":"","text":"tcpdump:网络嗅探器(需要将网卡设置为混杂模式，promisc)-i:interface-w:file(保存至文件)-r:file(读取文件)-nn:第一个n表示把地址显示为数字的形式，第二个n表示把协议显示为数字的形式-X:hex(16进制)以及ASCII格式显示-XX:除了有-X的作用之外，还会显示链路层首部相关信息-A:ASCII格式显示-v:显示详细的信息-vv:显示更加详细的信息expression:关键字:type:host、net、port、portrangedirection:src、dst、src or dst、src and dstprotocol:ether(以太网)、ip、arp、tcp、udp、icmp、wlan组合条件:andornot 举例子:(1)tcpdump -i eth0(2)tcpdump -i eth0 tcp dst port 80 (-n/-nn)(3)tcpdump -i eth0 -nn host 172.16.10.1(4)tcpdump -i eth0 -nn dst host 172.16.10.1(5)tcpdump -i eth0 -nn src and dst host 172.16.10.1(6)tcpdump -i eth0 -nn host 172.16.10.1 and 172.16.10.10(7)tcpdump -i eth0 -nn host 172.16.10.1 and (172.16.10.2 or 172.16.10.10)(8)tcpdump -i eth0 -A tcp port 80(9)tcpdump -i eth0 -X tcp port 80(10)tcpdump -i eth0 -XX tcp port 80(11)tcpdump -i eth0 -A -v tcp port 80(12)tcpdump -i eth0 -A -vv tcp port 80","categories":[{"name":"linux抓包管理","slug":"linux抓包管理","permalink":"http://yoursite.com/categories/linux抓包管理/"}],"tags":[{"name":"tcpdump","slug":"tcpdump","permalink":"http://yoursite.com/tags/tcpdump/"}]},{"title":"windows远程桌面（mstsc）无法复制粘贴","slug":"远程桌面（mstsc）无法复制","date":"2018-12-19T06:52:00.000Z","updated":"2018-12-19T06:55:01.381Z","comments":true,"path":"2018/12/19/远程桌面（mstsc）无法复制/","link":"","permalink":"http://yoursite.com/2018/12/19/远程桌面（mstsc）无法复制/","excerpt":"","text":"解决方法：在远程服务器上重启rdpclip.exe进程即可。 1、打开资源管理器，杀掉rdpclip.exe进程 2、开始——》运行，输入：rdpclip.exe，回车重启该进程。","categories":[{"name":"QA","slug":"QA","permalink":"http://yoursite.com/categories/QA/"}],"tags":[{"name":"mstsc","slug":"mstsc","permalink":"http://yoursite.com/tags/mstsc/"}]},{"title":"IP地址","slug":"IP地址","date":"2018-12-19T06:39:00.000Z","updated":"2018-12-19T06:48:18.688Z","comments":true,"path":"2018/12/19/IP地址/","link":"","permalink":"http://yoursite.com/2018/12/19/IP地址/","excerpt":"","text":"1、ip地址分类：（1）按ABCDE来分 （2）按公有、私有来分 2、私有ip地址分类： 3、ip地址中的网络位（通过子网掩码来区分） 4、ip地址中的主机位（通过子网掩码来区分） 5、子网划分 （1）掩码的1必须是连续的 （2）子网划分公式","categories":[{"name":"网络基础","slug":"网络基础","permalink":"http://yoursite.com/categories/网络基础/"}],"tags":[{"name":"ip地址","slug":"ip地址","permalink":"http://yoursite.com/tags/ip地址/"}]},{"title":"TCP/IP协议族","slug":"TCP-IP协议族","date":"2018-12-19T05:38:00.000Z","updated":"2018-12-19T05:56:26.888Z","comments":true,"path":"2018/12/19/TCP-IP协议族/","link":"","permalink":"http://yoursite.com/2018/12/19/TCP-IP协议族/","excerpt":"","text":"协议1、ARP （1）数据分用 （2）ARP过程 （3）APR报文 2、IP （1）IP报文 Identification用于标识数据包身份，数值不同则代表是不同的数据包 （2）数据分片 上图为数据分片和数据重组过程，与MTU密切相关 （3）MTU 上图为各层的MTU，决定各层限制的传输数据包大小 （4）进制转换 上图为进制转换 （5）TTL 上图为TTL在传递过程的变化，TTL值为0时不传递。TTL主要是用于防止环路的 3、ICMP traceroute &amp;&amp; tracert原理 4、TCP （1）面向连接服务（三次握手+四次关闭） （2）可靠传输（syn/ack+定时器+重传机制） （3）流控（滑动窗口） （4）多路复用（ip+port=套接字） 5、UDP TCP与UDP区别的通俗性理解：","categories":[{"name":"网络基础","slug":"网络基础","permalink":"http://yoursite.com/categories/网络基础/"}],"tags":[{"name":"TCP/IP","slug":"TCP-IP","permalink":"http://yoursite.com/tags/TCP-IP/"}]},{"title":"封装和解封装","slug":"封装和解封装","date":"2018-12-19T02:58:00.000Z","updated":"2018-12-19T03:00:19.703Z","comments":true,"path":"2018/12/19/封装和解封装/","link":"","permalink":"http://yoursite.com/2018/12/19/封装和解封装/","excerpt":"","text":"图解：图一 图二","categories":[{"name":"网络基础","slug":"网络基础","permalink":"http://yoursite.com/categories/网络基础/"}],"tags":[{"name":"封装","slug":"封装","permalink":"http://yoursite.com/tags/封装/"},{"name":"解封装","slug":"解封装","permalink":"http://yoursite.com/tags/解封装/"}]},{"title":"OSI七层模型","slug":"OSI七层模型-1","date":"2018-12-19T02:00:00.000Z","updated":"2018-12-19T02:03:12.015Z","comments":true,"path":"2018/12/19/OSI七层模型-1/","link":"","permalink":"http://yoursite.com/2018/12/19/OSI七层模型-1/","excerpt":"","text":"","categories":[{"name":"网络基础","slug":"网络基础","permalink":"http://yoursite.com/categories/网络基础/"}],"tags":[{"name":"七层模型","slug":"七层模型","permalink":"http://yoursite.com/tags/七层模型/"}]},{"title":"设备和网络发展史","slug":"OSI七层模型","date":"2018-12-19T02:00:00.000Z","updated":"2018-12-19T02:30:08.595Z","comments":true,"path":"2018/12/19/OSI七层模型/","link":"","permalink":"http://yoursite.com/2018/12/19/OSI七层模型/","excerpt":"","text":"","categories":[{"name":"网络基础","slug":"网络基础","permalink":"http://yoursite.com/categories/网络基础/"}],"tags":[{"name":"设备发展史","slug":"设备发展史","permalink":"http://yoursite.com/tags/设备发展史/"}]},{"title":"jenkins配置","slug":"jenkins配置","date":"2018-12-17T07:47:00.000Z","updated":"2018-12-17T07:47:53.415Z","comments":true,"path":"2018/12/17/jenkins配置/","link":"","permalink":"http://yoursite.com/2018/12/17/jenkins配置/","excerpt":"","text":"","categories":[{"name":"jenkins","slug":"jenkins","permalink":"http://yoursite.com/categories/jenkins/"}],"tags":[]},{"title":"jenkins（备份、主目录结构、默认路径）","slug":"jenkins（备份、主目录结构、默认路径）","date":"2018-12-17T07:46:00.000Z","updated":"2018-12-17T07:46:32.355Z","comments":true,"path":"2018/12/17/jenkins（备份、主目录结构、默认路径）/","link":"","permalink":"http://yoursite.com/2018/12/17/jenkins（备份、主目录结构、默认路径）/","excerpt":"","text":"","categories":[{"name":"jenkins","slug":"jenkins","permalink":"http://yoursite.com/categories/jenkins/"}],"tags":[]},{"title":"jenkins（CI、优势、版本）","slug":"jenkins（CI、优势、版本）","date":"2018-12-17T07:44:00.000Z","updated":"2018-12-17T07:44:16.395Z","comments":true,"path":"2018/12/17/jenkins（CI、优势、版本）/","link":"","permalink":"http://yoursite.com/2018/12/17/jenkins（CI、优势、版本）/","excerpt":"","text":"","categories":[{"name":"jenkins","slug":"jenkins","permalink":"http://yoursite.com/categories/jenkins/"}],"tags":[]},{"title":"jenkins安装","slug":"jenkins安装","date":"2018-12-17T06:37:00.000Z","updated":"2018-12-17T06:41:47.345Z","comments":true,"path":"2018/12/17/jenkins安装/","link":"","permalink":"http://yoursite.com/2018/12/17/jenkins安装/","excerpt":"","text":"6、进入选择插件安装界面，选择第一个（Install suggested plugins） 7、插件安装完成之后，需要创建第一个用户 8、创建完用户之后，就可以使用jenkins了","categories":[{"name":"jenkins","slug":"jenkins","permalink":"http://yoursite.com/categories/jenkins/"}],"tags":[]},{"title":"Git && Giuhub(Github部分)","slug":"Git-Giuhub-Github部分","date":"2018-12-14T06:27:00.000Z","updated":"2018-12-14T06:27:36.393Z","comments":true,"path":"2018/12/14/Git-Giuhub-Github部分/","link":"","permalink":"http://yoursite.com/2018/12/14/Git-Giuhub-Github部分/","excerpt":"","text":"","categories":[{"name":"Git && Github","slug":"Git-Github","permalink":"http://yoursite.com/categories/Git-Github/"}],"tags":[{"name":"Github","slug":"Github","permalink":"http://yoursite.com/tags/Github/"}]},{"title":"Git && Github(Git部分)","slug":"Git","date":"2018-12-14T06:20:00.000Z","updated":"2018-12-14T06:25:30.817Z","comments":true,"path":"2018/12/14/Git/","link":"","permalink":"http://yoursite.com/2018/12/14/Git/","excerpt":"","text":"","categories":[{"name":"Git && Github","slug":"Git-Github","permalink":"http://yoursite.com/categories/Git-Github/"}],"tags":[{"name":"Git","slug":"Git","permalink":"http://yoursite.com/tags/Git/"}]},{"title":"cloudwatch","slug":"cloudwatch","date":"2018-12-10T09:14:00.000Z","updated":"2018-12-19T07:30:47.422Z","comments":true,"path":"2018/12/10/cloudwatch/","link":"","permalink":"http://yoursite.com/2018/12/10/cloudwatch/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[{"name":"cloudwatch","slug":"cloudwatch","permalink":"http://yoursite.com/tags/cloudwatch/"}]},{"title":"keepalived安装与配置文件","slug":"keepalived安装与配置文件","date":"2018-12-07T06:45:00.000Z","updated":"2018-12-07T09:43:52.027Z","comments":true,"path":"2018/12/07/keepalived安装与配置文件/","link":"","permalink":"http://yoursite.com/2018/12/07/keepalived安装与配置文件/","excerpt":"","text":"keepalived目前已经被官方收录进linux版本当中，使用yum就可以下载安装keepalived yum info keepalived 查看系统中的keepalived版本yum install keepalived 安装keepalivedrpm -ql keepalived 查看安装keepalived生成了哪些文件在centos7中，cat /usr/lib/systemd/system/keepalived.service 查看keepalived的启动等配置信息cat /etc/sysconfig/keepalived 查看keepalived支持的参数帮助 keepalived的配置文件（三部分）：1、global configuration2、vrrpd configuration:分两段，第一段是vrrp instance，第二段是vrrp synchonization group3、lvs configuration:根据配置文件生成lvs规则备注：可以通过man keepalived.conf查看keepalived配置文件的配置帮助详细配置：1、global_defs:（1）notification_email（2）notification_email_from（3）smtp_server（4）smtp_connection_timeout（5）router_id hostname（6）vrrp_mcast_group 224.x.x.x #定义多播地址，224不变，后面三位可以变化 2、vrrp_instance:（1）state maste或backup（2）interface 在centos7中，int dev名字是eno16777736（3）virtual_router_id vrid是唯一的,跟虚拟mac相关，虚拟mac的格式为00-00-5E-00-01-{VRID} #虚拟mac的格式，前面是固定的，后面补上vrid；master和backup的virtual_router_id必须是一样的，因为id是一样说明master和backup是在同一个虚拟路由器中（4）priority 0到255之间的数字，数字越大，优先级越高，优先级高的是master（5）adver_init 发送心跳信息的时间间隔，默认是1（6）authentication {认证 auth_type PASS 这里是简单字符认证 auth_pass xxxx openssl rand -hex 4,生成十六进制的随机字符串}（7）virtual_ipaddress 定义虚拟ip地址，同一个虚拟路由器中的master和backup的vip的配置也是一样的（8）nopreempt:非抢占模式，默认为抢占模式 HA cluster配置前提：1、本机的主机名与host中定义的主机名保持一致，要与hostname(uname -n)获得名称保持一致，因为需要根据主机名进行彼此通信(各节点要能解析主机名，一般建议通过host文件进行解析，配置文件为/etc/hosts)2、各节点时间同步3、确保iptables和selinux不会成为服务的障碍iptables -L -n 查看iptables规则getenforce 查看linux状态","categories":[{"name":"keepalived","slug":"keepalived","permalink":"http://yoursite.com/categories/keepalived/"}],"tags":[{"name":"keepalived","slug":"keepalived","permalink":"http://yoursite.com/tags/keepalived/"}]},{"title":"linux进程管理","slug":"linux进程管理","date":"2018-12-07T03:43:00.000Z","updated":"2018-12-07T09:44:31.235Z","comments":true,"path":"2018/12/07/linux进程管理/","link":"","permalink":"http://yoursite.com/2018/12/07/linux进程管理/","excerpt":"","text":"1、进程的优先级：0到139,140个优先级，数字越小，表示优先级越高其中，0到99是内核决定的，100到139是可以由用户调整的用户可以通过调整nice值来进行调整，默认每个进程的nice值都是0nice值的取值范围是-20到19，对应100到139（普通用户只能调大nice值来降低优先级，管理员才有权限调大和调小nice值）调整nice值：（1）调整已经启动的进程的nice值：renice NI PID（2）在启动时指定nice值：nice -n NI COMMANDinit进程：第一个进程,是所有进程的父进程，进程号为1 2、每一个进程的相关属性信息在/proc目录下，其下的每一个目录对应一个进程，对应的数字就是进程号（可能是曾经存在过的进程） 3、进程的状态D:不可中断的睡眠S:可以中断的睡眠R:运行或就绪T:停止Z:僵死&lt;:高优先级进程N:低优先级进程+:前台进程组中的进程l:多线程进程s:会话进程首进程 4、进程相关命令：ps命令：有2种风格，system V风格和BSD风格sysV风格（需要加横杠-）：-o:显示指定字段的信息（默认只显示前台进程）要想显示所有，则使用ps -axo 字段1，字段2 BSD风格（不需要加横杠-）：a:显示所有跟终端有关的进程（跟终端有关：在终端中通过命令行运行启动的）x:显示所有跟终端无关的进程（跟终端无关：系统启动的时候自动启动的进程，用户还没登录就已经产生的进程）u:显示进程跟哪个用户相关 pstree命令:显示当前系统的进程树pgrep命令:根据进程名，查找进程的进程号用法:pgrep 进程，如果加上选项-u user可以指定以哪个用户的身份运行的进程pidof命令:根据程序名，查找其相关进程的ID号 top命令:默认根据CPU大小进行排序 （1）在top命令运行过程中按键：N:根据内存大小排序P:根据CPU大小排序T:根据占用CPU时间大小排序 l:是否显示平均负载和启动时间t:是否显示进程和CPU状态相关的信息m:是否显示内存相关信息c:是否显示完整的命令行信息k:是否终止某个进程q:退出top （2）运行top命令时指定选项参数:-d num:指定刷新时长，单位是s-b:批模式，一屏一屏向后翻-n num:在批模式下，显示多少屏，显示完成之后自动退出 前台作业送到后台:ctrl+z:把正在前台的作业送到后台并停止运行COMMAND &amp;:让命令在后台执行 jobs:查看后台的所有作业作业号:不同于进程号+:命令将默认操作的作业-:命令将第二个默认操作的作业 bg:让后台的停止作业继续运行bg [JOBID]fg:将后台的作业调回前台fg [JOBID] kill %JOBID:终止某作业 其他命令:vmstat 1 5:查看系统状态，每隔1秒刷新1次，显示5次就停止退出uptime:跟top显示内容的第一行是一样的 5、进程间通信（IPC）两种方式:（1）共享内存（2）信号:signal 6、重要的信号（通过数字表示）：1:SIGHUP，让一个进程不用重启，就可以重读其配置文件，并让新的配置信息生效2:SIGINT，相当于ctrl-c，中断一个进程9:SIGKILL，杀死一个进程15:SIGTERM，终止一个进程备注：kill默认发送就是15号信号 指定一个信号：信号号码:kill -9信号名称:kill -SIGKILL信号名称简写:kill -KILL备注：kill -l:查看各种信号名称以及对应的号码killall 进程名:但凡是这个进程名的进程都会被杀死","categories":[{"name":"linux进程管理","slug":"linux进程管理","permalink":"http://yoursite.com/categories/linux进程管理/"}],"tags":[{"name":"进程","slug":"进程","permalink":"http://yoursite.com/tags/进程/"}]},{"title":"网络负载均衡器","slug":"网络负载均衡器","date":"2018-12-07T03:37:00.000Z","updated":"2018-12-19T07:31:59.647Z","comments":true,"path":"2018/12/07/网络负载均衡器/","link":"","permalink":"http://yoursite.com/2018/12/07/网络负载均衡器/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[{"name":"网络负载均衡器","slug":"网络负载均衡器","permalink":"http://yoursite.com/tags/网络负载均衡器/"}]},{"title":"应用程序负载均衡器","slug":"应用程序负载均衡器","date":"2018-12-07T03:36:00.000Z","updated":"2018-12-19T07:32:43.439Z","comments":true,"path":"2018/12/07/应用程序负载均衡器/","link":"","permalink":"http://yoursite.com/2018/12/07/应用程序负载均衡器/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[{"name":"应用程序负载均衡器","slug":"应用程序负载均衡器","permalink":"http://yoursite.com/tags/应用程序负载均衡器/"}]},{"title":"传统负载均衡器（一些概念）","slug":"传统负载均衡器（一些概念）","date":"2018-12-07T03:35:00.000Z","updated":"2018-12-19T07:33:24.927Z","comments":true,"path":"2018/12/07/传统负载均衡器（一些概念）/","link":"","permalink":"http://yoursite.com/2018/12/07/传统负载均衡器（一些概念）/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[{"name":"ELB概念","slug":"ELB概念","permalink":"http://yoursite.com/tags/ELB概念/"}]},{"title":"传统负载均衡器（健康检查）","slug":"传统负载均衡器（健康检查）","date":"2018-12-07T03:33:00.000Z","updated":"2018-12-19T07:34:05.355Z","comments":true,"path":"2018/12/07/传统负载均衡器（健康检查）/","link":"","permalink":"http://yoursite.com/2018/12/07/传统负载均衡器（健康检查）/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[{"name":"健康检查","slug":"健康检查","permalink":"http://yoursite.com/tags/健康检查/"}]},{"title":"传统负载均衡器（特点）","slug":"传统负载均衡器（特点）","date":"2018-12-07T03:29:00.000Z","updated":"2018-12-19T07:35:20.815Z","comments":true,"path":"2018/12/07/传统负载均衡器（特点）/","link":"","permalink":"http://yoursite.com/2018/12/07/传统负载均衡器（特点）/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[{"name":"ELB","slug":"ELB","permalink":"http://yoursite.com/tags/ELB/"}]},{"title":"AMI和EBS快照的使用场景","slug":"AMI和EBS快照的使用场景","date":"2018-12-07T02:22:00.000Z","updated":"2018-12-19T07:36:27.291Z","comments":true,"path":"2018/12/07/AMI和EBS快照的使用场景/","link":"","permalink":"http://yoursite.com/2018/12/07/AMI和EBS快照的使用场景/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[{"name":"AMI","slug":"AMI","permalink":"http://yoursite.com/tags/AMI/"},{"name":"EBS快照","slug":"EBS快照","permalink":"http://yoursite.com/tags/EBS快照/"}]},{"title":"EBS快照","slug":"EBS快照","date":"2018-12-07T02:21:00.000Z","updated":"2018-12-19T07:39:04.464Z","comments":true,"path":"2018/12/07/EBS快照/","link":"","permalink":"http://yoursite.com/2018/12/07/EBS快照/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[{"name":"EBS快照","slug":"EBS快照","permalink":"http://yoursite.com/tags/EBS快照/"}]},{"title":"AMI","slug":"AMI系统镜像和EBS快照","date":"2018-12-07T02:20:00.000Z","updated":"2018-12-19T07:39:42.200Z","comments":true,"path":"2018/12/07/AMI系统镜像和EBS快照/","link":"","permalink":"http://yoursite.com/2018/12/07/AMI系统镜像和EBS快照/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[{"name":"AMI","slug":"AMI","permalink":"http://yoursite.com/tags/AMI/"}]},{"title":"EC2存储","slug":"EC2实例-1","date":"2018-12-07T01:46:00.000Z","updated":"2018-12-19T07:40:23.044Z","comments":true,"path":"2018/12/07/EC2实例-1/","link":"","permalink":"http://yoursite.com/2018/12/07/EC2实例-1/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[{"name":"EC2存储","slug":"EC2存储","permalink":"http://yoursite.com/tags/EC2存储/"}]},{"title":"安全组","slug":"全组-1","date":"2018-12-06T06:46:00.000Z","updated":"2018-12-19T07:46:42.253Z","comments":true,"path":"2018/12/06/全组-1/","link":"","permalink":"http://yoursite.com/2018/12/06/全组-1/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[{"name":"安全组","slug":"安全组","permalink":"http://yoursite.com/tags/安全组/"}]},{"title":"EC2实例（计费类型）","slug":"EC2","date":"2018-12-04T08:37:00.000Z","updated":"2019-01-11T08:08:31.973Z","comments":true,"path":"2018/12/04/EC2/","link":"","permalink":"http://yoursite.com/2018/12/04/EC2/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[{"name":"EC2","slug":"EC2","permalink":"http://yoursite.com/tags/EC2/"}]},{"title":"EC2实例（特性）","slug":"EC2实例2","date":"2018-12-04T08:34:00.000Z","updated":"2018-12-19T07:48:31.369Z","comments":true,"path":"2018/12/04/EC2实例2/","link":"","permalink":"http://yoursite.com/2018/12/04/EC2实例2/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[{"name":"EC2","slug":"EC2","permalink":"http://yoursite.com/tags/EC2/"}]},{"title":"EC2实例（简介、运行平台、访问方式）","slug":"EC2实例","date":"2018-12-04T08:22:00.000Z","updated":"2019-01-11T08:07:43.021Z","comments":true,"path":"2018/12/04/EC2实例/","link":"","permalink":"http://yoursite.com/2018/12/04/EC2实例/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[{"name":"EC2","slug":"EC2","permalink":"http://yoursite.com/tags/EC2/"}]},{"title":"IAM服务","slug":"IAM","date":"2018-11-30T06:48:00.000Z","updated":"2018-12-19T07:49:59.573Z","comments":true,"path":"2018/11/30/IAM/","link":"","permalink":"http://yoursite.com/2018/11/30/IAM/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[{"name":"IAM","slug":"IAM","permalink":"http://yoursite.com/tags/IAM/"}]},{"title":"申请AWS免费套餐","slug":"申请AWS免费套餐","date":"2018-11-30T03:23:00.000Z","updated":"2018-12-19T07:51:01.450Z","comments":true,"path":"2018/11/30/申请AWS免费套餐/","link":"","permalink":"http://yoursite.com/2018/11/30/申请AWS免费套餐/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[{"name":"AWS免费套餐","slug":"AWS免费套餐","permalink":"http://yoursite.com/tags/AWS免费套餐/"}]},{"title":"AWS分区","slug":"AWS分区","date":"2018-11-30T03:21:00.000Z","updated":"2018-12-19T07:53:20.050Z","comments":true,"path":"2018/11/30/AWS分区/","link":"","permalink":"http://yoursite.com/2018/11/30/AWS分区/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[{"name":"AWS分区","slug":"AWS分区","permalink":"http://yoursite.com/tags/AWS分区/"}]},{"title":"云计算技术","slug":"云计算","date":"2018-11-30T03:20:00.000Z","updated":"2018-12-19T07:54:17.274Z","comments":true,"path":"2018/11/30/云计算/","link":"","permalink":"http://yoursite.com/2018/11/30/云计算/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"http://yoursite.com/tags/云计算/"}]},{"title":"AWS服务","slug":"Untitled","date":"2018-11-30T03:17:00.000Z","updated":"2018-12-19T07:54:55.094Z","comments":true,"path":"2018/11/30/Untitled/","link":"","permalink":"http://yoursite.com/2018/11/30/Untitled/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[{"name":"AWS服务","slug":"AWS服务","permalink":"http://yoursite.com/tags/AWS服务/"}]},{"title":"源码安装puppet服务端","slug":"Untitled-1","date":"2018-11-22T03:11:00.000Z","updated":"2018-11-22T07:27:30.901Z","comments":true,"path":"2018/11/22/Untitled-1/","link":"","permalink":"http://yoursite.com/2018/11/22/Untitled-1/","excerpt":"","text":"1、安装ruby(版本：1.8.7)wget http://ftp.ruby-lang.org/pub/ruby/ruby-1.8.7-p358.zipunzip ruby-1.8.7cd ruby-1.8.7./configure –prefix=/usr/local/puppetmake &amp;&amp; make install因为安装ruby的位置不在系统环境变量中，所以需要手动导入系统环境变量export PATH=$PATH:/usr/local/puppet/bin/:/usr/local/puppet/sbin/ 2、安装ruby-shadowgit clone https://github.com/apalmblad/ruby-shadow.gitcd ruby-shadowruby extconf.rbmake &amp;&amp; make install 3、安装facter(版本：1.7.4)wget http://downloads.puppetlabs.com/facter/facter-1.7.4.tar.gztar zxvf facter-1.7.4.tar.gzcd facter-1.7.4ruby install.rb 4、安装puppet(版本：2.7.25)wget http://downloads.puppetlabs.com/puppet/puppet-2.7.25.tar.gzcd puppet-2.7.25ruby install.rb –full 有坑:到这一步，提示不能加载openssl，因此先安装openssl：apt-get install opensslapt-get install libssl-devel安装libssl-devel的时候，提示”apt-get install E: 无法定位软件包问题”尝试更新apt源，在/etc/apt的sources.list 添加镜像源deb http://archive.ubuntu.com/ubuntu/ trusty main universe restricted multiverse，然后apt-get update对apt-get进行更新，再次执行apt-get install libssl-devel，还是同样的报错。这时候尝试使用aptitude软件包管理器安装libssl-dev包:(1)安装aptitudeapt-get install aptitude(2)使用aptitude安装 libssl-dev包aptitude install libssl-dev安装完openssl之后，重新运行puppet安装命令”ruby install.rb –full”，依然提示无法load openssl，这时候需要进入到ruby的源码解压目录cd ruby-1.8.7-p358/ext/openssl,执行ruby extconf.rb可以生成编译openssl扩展的Makefile，然后make &amp;&amp; make install，这时候再运行puppet安装命令”ruby install.rb –full”就可以安装上puppet了。","categories":[{"name":"安装篇","slug":"安装篇","permalink":"http://yoursite.com/categories/安装篇/"}],"tags":[{"name":"puppet","slug":"puppet","permalink":"http://yoursite.com/tags/puppet/"}]},{"title":"挂载和卸载","slug":"挂载和卸载","date":"2018-11-13T01:39:00.000Z","updated":"2018-11-13T02:23:10.815Z","comments":true,"path":"2018/11/13/挂载和卸载/","link":"","permalink":"http://yoursite.com/2018/11/13/挂载和卸载/","excerpt":"","text":"挂载:将新的文件系统关联至当前根文件系统卸载:将某文件系统从当前根文件系统的关联关系移除 mount:挂载mount 设备 挂载点备注:1、设备可以是设备文件(/dev/sda5)、卷标(LABEL=”XXX”)、UUID(UUID=”XXX”)2、挂载点必须是目录，要求如下:(1)此目录没有被其他进程使用(2)此目录得事先存在(3)目录中的原有文件将会暂时隐藏3、挂载完成后，通过挂载点访问对应文件系统上的文件4、mount不带任何选项，会显示当前系统中已经挂载的设备以及挂载点可选参数:-a:表示/etc/fstab文件中定义的所有文件系统-n:挂载设备时，不把信息写入mtab文件(默认情况下，mount每挂载一个设备，会把挂载的设备信息保存至/etc/mtab文件)备注:mtab是mount table的简称，直接mount显示的信息就是mtab文件中的信息-t:指定挂载设备上的文件系统类型。不使用此选项时，mount会调用blkid获取对应文件系统类型-r:只读挂载，挂载光盘时常用此选项-w:读写挂载-o:指定额外的挂载选项，也即指定文件系统启用的属性额外的挂载选项有:remount:重新挂载当前文件系统(mount -o remount /dev/sda5 [/mnt/test] 备注:重新挂载的时候，可以省略挂载点)ro:只读挂载(等于-r)rw:读写挂载(等于-w) umount:卸载umount 设备 or umount 挂载点备注:卸载的时候，需要切换到跟挂载点无关的目录上去。如果你在挂载点上运行umount命令，会提示”device is busy”","categories":[{"name":"linux磁盘管理","slug":"linux磁盘管理","permalink":"http://yoursite.com/categories/linux磁盘管理/"}],"tags":[{"name":"挂载","slug":"挂载","permalink":"http://yoursite.com/tags/挂载/"},{"name":"卸载","slug":"卸载","permalink":"http://yoursite.com/tags/卸载/"}]},{"title":"设备文件管理","slug":"设备文件管理","date":"2018-11-12T09:12:00.000Z","updated":"2018-11-12T09:13:40.359Z","comments":true,"path":"2018/11/12/设备文件管理/","link":"","permalink":"http://yoursite.com/2018/11/12/设备文件管理/","excerpt":"","text":"设备文件:设备文件作为设备的访问入口，被内核识别，分两种1、b:块设备，以块为单位进行随机访问，例如硬盘2、c:字符设备，以字符为单位进行线性访问，例如键盘 创建设备文件:mknod -m 权限 文件名 文件类型(b或c) 主设备号 次设备号其中，1、设备文件名:IDE、ATA:hd开头的文件名SATA、SCSI、USB:sd开头的文件名(a、b、c…区分同一类型下的不同设备)2、设备号:/dev目录下的文件有两个数字属性:主设备号:major number，标识设备类型次设备号:minor number，标识同一类型下的不同设备(这种文件没有大小，有点类似于链接文件。因为大小指的是它真正占用磁盘块的大小，而设备文件只是作为设备的一个访问入口，因此没有大小)","categories":[{"name":"linux磁盘管理","slug":"linux磁盘管理","permalink":"http://yoursite.com/categories/linux磁盘管理/"}],"tags":[{"name":"设备文件","slug":"设备文件","permalink":"http://yoursite.com/tags/设备文件/"}]},{"title":"磁盘和分区管理","slug":"磁盘和分区管理","date":"2018-11-12T09:06:00.000Z","updated":"2018-11-13T03:15:52.888Z","comments":true,"path":"2018/11/12/磁盘和分区管理/","link":"","permalink":"http://yoursite.com/2018/11/12/磁盘和分区管理/","excerpt":"","text":"磁盘:真空的，需要防尘，磁盘主要分两种(1)机械硬盘:目前主流，比较遗憾(2)固态硬盘:性能相对好一点的磁盘 磁盘基本术语(硬件方面):(1)盘片(2)盘面:每一块盘片有两块盘面(3)磁头(4)磁道(5)扇区:512字节(6)机械臂(7)柱面:磁道组成的逻辑分区柱面具有以下特点:1、存储数据就是按照柱面来存储的，读取数据也是2、划分分区也是按照柱面来划分3、从外到内，柱面的编号从0开始4、同一个转轴，越靠外面的磁道，转速越快(这也是我们大多数操作系统安装在C盘的原因) 磁盘基本术语(软件方面):磁盘出厂前，需要低级格式化，划分磁道分区1、MBR:master boot record，主引导记录(0盘片0磁道0扇区的那一块地方就是MBR，属于磁盘，是全局的存储空间，独立于操作系统之外)MBR的大小为512字节，分为3个部分，446字节叫做BootLoader，叫做引导加载器，是一段程序代码，作用是引导操作系统正确启动起来；接下来的64字节，每16字节标识一个主分区，因此操作系统最多可以划分4个主分区；剩下的2个字节叫做魔数，标识MBR是否有效。2、分区:partition，划分分区的作用是创建文件系统，每一个分区就是一个文件系统。 要正常使用一块磁盘，需要经过:低级格式化（由硬盘厂商来完成）–做分区–高级格式化（创建文件系统）–挂载 磁盘分区命令:查看当前系统识别了多少块硬盘：fdisk -l查看当前系统某块硬盘的具体信息：fdisk -l /dev/sda管理磁盘分区：fdisk /dev/sda （启动一个交互式界面）m：for helpp：显示当前分区，包括没保存的改动n：创建新的分区e：创建新的扩展分区p：创建新的主分区d：删除一个分区w：保存退出q：不保存退出t：修改分区类型L：修改的时候查看分区类型（以确定某种类型对应的编号）创建完分区之后需要内核识别才能够格式化。查看内核已经识别的分区：cat /proc/partitions通知内核重读分区表：partprobe #Redhat6上使用了新命令:partx备注:partprobe是默认重读所有磁盘上的分区表，当然我们也可以指定内核重读哪一块磁盘，比如说partprobe /dev/sda 创建分区例子:1、创建3个逻辑分区(得先创建扩展分区，在扩展分区的基础上创建逻辑分区。主分区不能创建逻辑分区；扩展分区不能使用，只能使用在扩展分区上划分出来的逻辑分区)(1)fdisk /dev/sda #会进入一个交互界面，备注:进入交互界面后，如果在创建分区的过程中敲错命令，直接删除键是删不掉的，需要按住ctrl+删除键来删除(2)p #查看分区(3)n(4)e #创建扩展分区(5)n(6)+2G #创建第一个逻辑分区，大小为2G(7)n(8)+5G #创建第二个逻辑分区，大小为5G(9)n(10)+1G #创建第三个逻辑分区，大小为1G(11)p #查看分区(12)w #保存退出(13)cat /proc/partitions #查看内核是否识别新创建的分区(14)partprobe /dev/sda #指定内核重读/dev/sda分区表 2、创建SWAP分区(备注:SWAP分区是磁盘上的空间，允许内存过载使用。一旦内存耗尽，可以临时拿硬盘上的SWAP来应急，防止系统崩溃甚至宕机。SWAP分区必须是一个单独的分区)(1)首先新建一个新的分区:fdisk #准备新建分区p #查看已有分区n #新建分区+1G #新建1G的分区L #查看分区类型t #调整分区类型8 #对第几块磁盘调整类型L #查看分区类型82 #linux swap的分区编码p #查看是否已经建好swap分区w #保存退出partprobe /dev/sda #通知内核重读分区表(2)创建好分区之后，需要创建文件系统(swap分区也是有自己的文件系统的)mkswap /dev/sda8(3)启用和关闭交换分区的交换空间(类似于mount，但是有专门的命令，不用mount)启用:swapon /dev/sda8可选参数:-a:启用所有定义在/etc/fstab文件中的交换设备关闭:swapoff /dev/sda8 其他命令:1、blkid:block id，查看磁盘设备的相关属性UUID:用于唯一标识磁盘设备TYPE:用于标识文件系统类型LABEL:显示卷标 2、e2label:专门用于查看或者定义卷标e2label /dev/sda5 查看卷标e2label /dev/sda5 labelname 设定卷标 3、free:查看系统上物理内存和交换分区的使用情况(默认单位是字节)-m:以MB为单位显示内存使用情况buffer:缓冲，保存的是元数据cache:缓存，保存的是数据(这两段空间可以清除数据，不会影响到数据的完整性，对系统性能会有影响) 4、df:显示整个磁盘分区的使用情况(以磁盘块个数来显示大小)可选参数:-h:人性化显示-i:以inode个数显示大小-P:不换行显示备注:与du的区别:du显示目录或者目录的子目录所占用的大小可选参数:-h:人性化显示-s:显示目录所占据的整体的大小 5、dd:复制可选参数:if= #指定数据来源of= #指定数据存储目标bs=1 #以一个字节为单位count=2 #复制2次，跟bs=1结合使用就是复制2个字节的数据例子:1、创建1M的数据:dd if=/dev/zero of=/var/swapfile bs=1 count=10242、拿一个文件，哪怕你没有分区，没有多余的空间可以创建分区，我们照样可以找个文件来暂时性的当做交换分区来使用(性能差，但可以临时救急)(1)dd if=/dev/zero of=/var/swapfile bs=1M count=1024(2)mkswap /var/swapfile(3)swapon /var/swapfile与cp的区别:(1)cp是以文件为单位的，dd是以数据流为单位的(数据流就是01代码)(2)dd可以复制不完整的数据","categories":[{"name":"linux磁盘管理","slug":"linux磁盘管理","permalink":"http://yoursite.com/categories/linux磁盘管理/"}],"tags":[{"name":"磁盘","slug":"磁盘","permalink":"http://yoursite.com/tags/磁盘/"},{"name":"分区","slug":"分区","permalink":"http://yoursite.com/tags/分区/"}]},{"title":"文件系统管理","slug":"ntitled","date":"2018-11-12T09:01:00.000Z","updated":"2018-11-13T03:29:02.942Z","comments":true,"path":"2018/11/12/ntitled/","link":"","permalink":"http://yoursite.com/2018/11/12/ntitled/","excerpt":"","text":"文件系统:1、创建分区之后，要实现快速存储文件和查询文件，需要在这个分区上创建文件系统2、文件系统是一个管理软件，也是存储在磁盘的某个位置上的，但并不是在分区上，文件系统的数据在分区上3、文件系统把分区分为两部分，元数据区域(类似索引)和存储真正数据的区域新增、删除、复制、剪切文件的原理都跟文件系统的原理相关，比如说:(1)为什么剪切文件比复制文件的速度要快答:因为剪切的时候数据内容不变，变的是inode(2)为什么有些文件删除了还可以通过文件恢复器找回来？文件粉碎机的原理是什么？答:删除就是删除inode对应的磁盘块，原来的数据原封不动；粉碎就是用一堆随机数去覆盖原来的数据4、linux支持的文件系统:ext2、ext3、ext4、xfs、reiserfs、jfs、nfs…备注:(1)linux的vfs(虚拟文件系统)使得linux可以支持不同类型的文件系统(2)linux也支持fat32格式(windows平台)文件系统，但是本身不叫fat32，而叫做vfat；同样支持NTFS(windows平台)文件系统,但是支持不太好，写入速度慢，甚至严重的话会导致系统崩溃(3)要留意内核支持哪些文件系统，比如ext2，ext3等。只有内核中具有某种文件系统的模块，它才能支持这种文件系统。cat /proc/filesystems:查看当前内核所支持的文件系统类型(4)ext3和ext2的区别:ext3:日志文件系统，分为3个区域，元数据区、数据区、日志区。对数据进行读写操作的时候，先把inode放到日志区进行操作，操作完成之后再放到元数据区。如果这时候断电或者系统崩溃，下次开机的时候直接查找日志区有哪些inode文件就可以知道有哪些文件是损坏的，而不用从头到尾扫描所有的文件。ext3最大的功能在于能够加快文件系统修复的速度。ext2:就是采取从头到尾的扫描方式，如果存储数据很大的话这样扫描查找会导致机器崩溃，修复速度很慢。ext2是linux上唯一的非日志文件系统。有些情况下，对于安全性、完整性要求不高并且会频繁的大量读写小文件的时候，使用ext2尤佳。 创建完分区，下面就可以创建文件系统commands:1、mkfs:make file system，创建文件系统-t 指定文件系统类型mkfs -t ext2 = mkfs.ext2mkfs -t ext3 = mkfs.ext3mkfs -t vfat = mkfs.vfat2、mke2fs:专门创建或者管理ext系列文件系统:-j journal，直接创建ext3系列的文件系统(默认是创建ext2系列的文件系统)-b 指定block size(块大小)，默认是4096，可以取值为1024,2048-L 指定分区label(卷标)-m # 指定预留给超级用户的块数百分比(直接指定数字即可，不用加%。防止空间填满管理员也无法进入，因此预留一些空间出来，默认应该是20%)-i # 指定为多少字节的空间创建一个inode(默认是8192，这里给出的数值应该是块大小的2^n倍。块大小默认是4096字节)-F #强制创建文件系统(少用)-E #用户指定额外的文件系统属性(少用) 3、tune2fs:调整文件系统相关属性(例如:tune2fs -j /dev/sda2)可选参数:-j:不损坏原有数据，将ext2升级为ext3-L labelname:设定或修改卷标-m #:调整预留百分比-r #:指定预留块数-c #:指定挂载次数达到#次之后进行自检，0或者-1表示关闭此功能-i #:每挂载使用多少天之后进行自检，0或者-1表示关闭此功能(因为系统默认是挂载达到多少次或者多少天之后进行自检，如果文件很大而自检次数hen频繁的话，系统的IO会很高，有时会影响到系统的性能。所以通过设定-c和-i来修改默认的自检次数或者天数)-l /dev/sda5:显示超级块的信息(所有块组的信息都存储在超级块中)-o:设定默认挂载选项 4、dumpe2fs:显示文件系统属性信息可选参数:-h:只显示超级块中的信息 5、fsck:filesystem check，检查并修复linux文件系统可选参数:-t:指定文件系统类型(不指定也没关系，fsck会自动调用blkid来查看类型)-a:自动修复(不与用户交互) 6、e2fsck:专门用于检查并修复ext2、ext的文件系统可选参数:-f:强制检查-p:自动修复(也可以使用-a) 文件系统配置文件:/etc/fstabOS在初始化时，会自动挂载此文件中定义的每个文件系统配置文件格式:第一列:要挂载的设备，/dev/sda5第二列:挂载点，/mnt/test第三列:文件系列类型，ext3第四列:挂载选项，默认是defaults第五列:转储频率，跟文件系统备份相关，每多少天做一次完全备份第六列:文件系统检测次序，只有根文件系统为1，可以多个文件系统为2。0标识不检测注意事项:(1)以上设置可以让/dev/sda5在开机之后自动挂载到/mnt/test上(2)如果挂载设备时一个swap分区的话，它的挂载点也是swap(3)伪文件系统:tmpfs、devpts、sysfs、proc，用来实现特定功能的，不得不挂载(2)转储频率:0表示不备份，1表示每天都要备份，2表示每2天备份一次等等","categories":[{"name":"linux磁盘管理","slug":"linux磁盘管理","permalink":"http://yoursite.com/categories/linux磁盘管理/"}],"tags":[{"name":"文件系统","slug":"文件系统","permalink":"http://yoursite.com/tags/文件系统/"}]},{"title":"IP、TCP、UDP","slug":"IP报文和TCP报文","date":"2018-10-31T01:47:00.000Z","updated":"2018-10-31T02:42:22.783Z","comments":true,"path":"2018/10/31/IP报文和TCP报文/","link":"","permalink":"http://yoursite.com/2018/10/31/IP报文和TCP报文/","excerpt":"","text":"1、IP报文(1)IP VERSION:IP版本号(2)HEAD LEN:报文首部长度(3)TYPE OF SERVICE(TOS):服务类型(在现实生活中比如快递中的加急快件等)(4)TOTAL LEN:整个数据报文的长度(5)FRAGMENT ID:标识分片之后的报文;FRAGMENT OFFSET:标识分片之后的报文组合 #其中MF(MORE FRAGMENT)值为1表示报文分片;DF值为1表示报文没有分片(6)TTL:定义最大跳数(7)PROTOCOL:定义IP网络层上一层的协议(8)HEADER CHECKSUM:校验和，判断数据前后是否一致(9)源IP(10)目的IP(11)OPTION:可选选项(12)要传输的数据 2、TCP报文(1)TCP HEADER:TCP首部(2)SOURCE PORT:源端口(3)DESTINATION PORT:目标端口(4)SEQUENCE NUMBER:序列号(5)ACKNOWLEDGEMENT NUMBER:确认号(6)HEADER LENGTH:首部长度(7)URG:紧急位(8)URGENT POINTER:紧急指针(URG值为1表示指针有效，否则指针无效)(9)ACK:确认位(确认位为1，确认号有效；确认位为0，确认号无效)(10)PUSH值为1表示有优先传输的特权(因为数据传输都是通过网卡来传输的，不同的进程数据，在发送之前，会放置发送缓冲区当中再逐个的往外发送；同样的接收数据也会先保存到接收缓冲区当中。PUSH为1表示不再先保存至缓冲区当中，而是直接往外发送或者接收)(11)RST:重置位(12)SYN:三次握手发的包(13)FIN:四次关闭发的包(14)WINDOW SIZE:窗口大小(当发送方发送数据的速率和接收方接收数据的速率不一致的时候需要用到，其实发送速率和接收速率取决于发送缓冲区和接收缓冲区可容纳的数据)(15)TCP CHECKSUM:TCP校验和(16)OPTION:可选选项(17)DATA:数据 3、TCP与UDP的区别:TCP，transmission control protocol，传输控制协议(相当于打电话，特点是可靠，但是效率低)UDP，user datagram protocol，用户数据报协议(相当于发短信，特点是不靠谱，但是速度快)备注:对于即时通讯都是采用UDP协议，比如QQ，它是在应用层来保证通讯的可靠性 4、三次握手和四次关闭:(1)三次握手A:SYN=1,sn=100(sn即seq num，序列号，随机生成)B:SYN=1,ACK=1,an=101(an即ack num，确认号，序列号加1)，sn=300(随机生成)A:ACK=1,an=301(2)四次关闭A:FIN=1B:ACK=1B:FIN=1A:ACK=1","categories":[{"name":"linux网络管理","slug":"linux网络管理","permalink":"http://yoursite.com/categories/linux网络管理/"}],"tags":[{"name":"IP","slug":"IP","permalink":"http://yoursite.com/tags/IP/"},{"name":"TCP","slug":"TCP","permalink":"http://yoursite.com/tags/TCP/"},{"name":"UDP","slug":"UDP","permalink":"http://yoursite.com/tags/UDP/"}]},{"title":"linux软件编译安装","slug":"inux软件编译安装","date":"2018-10-30T06:09:00.000Z","updated":"2018-10-30T06:37:31.958Z","comments":true,"path":"2018/10/30/inux软件编译安装/","link":"","permalink":"http://yoursite.com/2018/10/30/inux软件编译安装/","excerpt":"","text":"首先，程序运行过程：源程序–&gt;编译–&gt;链接–&gt;运行c语言是将源代码编译成二进制格式，编译需要编译环境(开发环境)、编译工具等(跟C语言相比，脚本语言是解释器直接解释成二进制格式，不需要编译) 编译环境:因为linux的内核是使用c语言开发的，有部分跟平台相关的代码是用汇编语言写的。linux上运行的众多gnu软件，大多数也是用c开发的。因此最流行的的开发环境：C、C++、PERL、JAVA、PYTHON等。 编译工具:gcc:C的编译工具，全称是GNU complier cg++:C++的编译工具make:C或者C++的项目管理工具makefile:定义了make按什么顺序去编译这些源程序文件中的源程序automake:–&gt;makefile.in–&gt;makefileautoconf:–&gt;configure 编译安装三步骤:(注意要在源程序的目录下操作)前提:准备开发环境(编译环境)，最简单的就是安装两个组”Development tools”和”Development libraries”1、configure–help #获取帮助–prefix= #指定软件安装路径(会自动生成/bin和/sbin目录)–sysconfdir= #指定配置文件安装目录(如果不指定的话，默认安装在软件安装路径下的conf目录或者etc目录)–conf-path= #指定配置文件安装文件configure功能:(1)让用户选择编译特性(通过参数赋值)(2)检查编译环境2、make3、make install 编译安装之后的一些环境变量的问题:1、修改PATH环境变量，以能够识别此程序的二进制文件路径(提示找不到命令，大多是原因是命令的路径没有包含在$PATH中)在/etc/profile.d/目录下建立一个以.sh为名称后缀的文件，在里面定义export PATH=$PATH:/path/to/somewhere然后重新登录一下终端，比如克隆一个终端，配置即可生效 2、默认情况下，系统搜索库文件的路径是/lib，/usr/lib，要增加额外的搜索路径在/etc/ld.so.conf.d/目录下创建以.conf为后缀名的文件，然后把要增添的路径写到此文件中(例如apache的库文件路径/usr/local/apache/lib)然后运行ldconfig，通知系统重新搜索库文件-v则显示重新搜索库文件的过程 3、增加头文件的搜索路径，默认是/usr/include增加搜索路径的方式有两种:(使用链接)ln -s /usr/local/apache/include/* /usr/include(这会创建一堆链接，对将来管理这些链接的时候不方便)ln -s /usr/local/apache/include /usr/include/apache(推荐使用这种方式) 4、man文件路径默认安装在–prefix指定的目录下的man目录","categories":[{"name":"linux软件管理","slug":"linux软件管理","permalink":"http://yoursite.com/categories/linux软件管理/"}],"tags":[{"name":"编译安装","slug":"编译安装","permalink":"http://yoursite.com/tags/编译安装/"}]},{"title":"rpm包的前端工具--yum","slug":"rpm包的前端工具-yum","date":"2018-10-30T03:45:00.000Z","updated":"2018-10-30T06:04:32.012Z","comments":true,"path":"2018/10/30/rpm包的前端工具-yum/","link":"","permalink":"http://yoursite.com/2018/10/30/rpm包的前端工具-yum/","excerpt":"","text":"why–为什么是yumyum依赖于rpm，功能比rpm强大因为rpm有一个很大的缺陷就是依赖关系，yum的出现就是用来解决依赖关系的 what–什么是yum(1)yum架构:C/S架构(2)yum仓库:yum的工作依赖于server端的yum仓库(yum repository)yum仓库中的元数据文件(位于repodata目录下):primary.xml.gz:所有rpm包的列表、各种包的依赖关系、每个rpm包安装生成的文件列表(局部概念)filelists.xml.gz:当前仓库中所有rpm包的文件列表(全局概念)other.xml.gz:额外信息，rpm包的修改日志(单个软件包各个发行版的发行时间、作者等)repomd.xml:记录的是上面三个文件的时间戳和校验和comps*-.xml:rpm分组信息(3)yum配置:/etc/yum.confyum仓库的配置文件:/etc/yum.repos.d/目录下面的各个文件就是各个仓库文件(文件名格式:file.repo，必须是以repo结尾)定义repo文件:(for example)[Repo_ID]name=Descriptionbaseurl= #有三种路径，ftp、http、file(本地)ftp://http://file:///(第3个/表示根路径)enable={1|0} #1表示启用gpgcheck={1|0} #1表示校验gpgkey= #如果设置gpgcheck=1必须有此项，否则不需要此项 how–怎么使用yum备注:要注意跟rpm命令对比下，很多命令的功能是差不多的(1)yum clean:清缓存(2)yum list [all|available|installed]:查看所有的安装包，包括安装的和未安装的(已安装的最后一个字段显示install，未安装的显示[Repo_ID]，也就是仓库文件里面的第一行定义的那个ID)yum list all:显示所有的软件包(直接yum list默认也是显示所有的软件包)yum list available:可用的，仓库中有但是未安装的yum list installed:已经安装的yum list updates:可用的升级yum list all +通配符的包名:查看匹配的软件包(3)yum repolist [all|enabled|disabled]:查看库的信息yum repolist all:显示所有repo列表及其简要信息yun repolist enabled:显示可用的repo列表及其简要信息(直接yum repolist默认就是显示enabled的repo表)yum repolist disabled:显示不可用的repo列表及其简要信息(4)yum install:安装软件包(5)yum update:默认升级到最新版本yum update-to:指定升级到特定版本(6)yum remove/rease:卸载(7)yum info:查看软件包的简要信息(8)yum provide/whatprovides:查看指定的文件或特性是由哪个包生成的(9)软件包组groupyum groupinfoyum grouplistyum groupremoveyum groupupdateyum groupinstallyum grouplocalinstall备注:groupinstall和grouplocalinstall的区别在于，install只需要指定包名，localinstall则必须指定包文件，也就是以rpm包结尾的文件。用yum相比用rpm安装的好处在于，如果仓库中刚好包有依赖包，yumlocalinstall可以解决依赖关系 创建yum仓库:createrepo命令","categories":[{"name":"linux软件管理","slug":"linux软件管理","permalink":"http://yoursite.com/categories/linux软件管理/"}],"tags":[{"name":"yum","slug":"yum","permalink":"http://yoursite.com/tags/yum/"}]},{"title":"ubuntu16.04安装MongoDB","slug":"MongoDB","date":"2018-10-24T07:30:00.000Z","updated":"2018-10-24T08:05:13.425Z","comments":true,"path":"2018/10/24/MongoDB/","link":"","permalink":"http://yoursite.com/2018/10/24/MongoDB/","excerpt":"","text":"1、通过tgz压缩包安装:(1)wget https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-ubuntu1604-4.0.3.tgz(2)tar zxvf mongodb-linux-x86_64-ubuntu1604-4.0.3.tgz(3)cp -pr mongodb-linux-x86_64-ubuntu1604-4.0.3 /usr/local/mongodb #-p表示保留源文件的属性，-r表示递归复制(4)bin/mongod &amp; #会报错，因为不指定数据目录的时候，默认会以/data/db目录作为数据目录，因此不存在/data/db目录时会报错，可以创建一个/data/db目录，也可以在启动mongod的时候指定dbpath为自定义的数据目录，像这样:bin/mongod –dbpath= ~/db(5)可以通过bin/mongod –help来查看mongod的帮助选项备注:通过这样的方式安装的mongod，默认没有配置文件，需要自己创建配置文件。一般不建议通过这种方式安装mongod 2、通过apt-get安装:(1)导入软件源公钥sudo apt-key adv –keyserver hkp://keyserver.ubuntu.com:80 –recv EA312927(2)为mongodb创建软件源list文件ubuntu16.04:echo “deb http://repo.mongodb.org/apt/ubuntu xenial/mongodb-org/3.4 multiverse” | sudo tee /etc/apt/sources.list.d/mongodb-org-3.4.list #mongodb-org/3.4 的3.4 为版本号，可更换为你想要安装的版本(3)更新软件源sudo apt-get update #更新的时候可能会报错，提示由于没有公钥，无法验证下列签名： NO_PUBKEY 3EE66BD3F599ACE3这时候，只需要重新运行第一步，软件源公钥替换成错误提示中的key，然后重新运行sudo apt-get update(4)安装mongodbapt-get install -y mongodb-org #如果想要安装指定的版本，使用下面的命令:sudo apt-get install -y mongodb-org=3.2.9 mongodb-org-server=3.2.9 mongodb-org-shell=3.2.9 mongodb-org-mongos=3.2.9 mongodb-org-tools=3.2.9(上面的命令需要把3.4改为3.2)(5)开机启动systemctl enable mongod(6)启动、停止mongod和查看mongod服务状态systemctl start mongod.servicesystemctl stop mongod.servicesystemctl status mongod.service备注:mongodb启动报错，其中大量提到WiredTiger error，主要报错提示如下txn-recover: unsupported WiredTiger file version WiredTiger error这时候，把/data/db目录下的文件清空，再重新启动就可以了(亲测有效)，但是如果数据库中有重要数据, 不建议采取此方法。安装参考链接:https://github.com/cgDeepLearn/LinuxSetups/blob/master/docs/databases/mongodb.md 补充mongodb图形化工具:NoSQLBooster for MongoDB(windows)下载链接:https://nosqlbooster.com/downloads工具截图:","categories":[{"name":"安装篇","slug":"安装篇","permalink":"http://yoursite.com/categories/安装篇/"}],"tags":[{"name":"mongodb","slug":"mongodb","permalink":"http://yoursite.com/tags/mongodb/"}]},{"title":"QA","slug":"QA","date":"2018-10-22T03:29:00.000Z","updated":"2018-10-29T04:07:10.034Z","comments":true,"path":"2018/10/22/QA/","link":"","permalink":"http://yoursite.com/2018/10/22/QA/","excerpt":"","text":"1、mysql max_allowed_packet自动重置为1024 最后发现是被人搞了。发现过程:打开general.log记录日志，查找日志(1)grep “SET GLOBAL” ubuntu.log，日志截图，发现有改动痕迹 (2)选择某一个query ID，例如188592 (3)把这个链接的文件下载下来，360马上就提示这是一个病毒文件 因此，被人搞是确定无疑了。。 然后，赶紧把mysql的密码改了(原密码是mysql…因为这个服务器还没上线，所以密码也设置得很简单…)","categories":[{"name":"QA","slug":"QA","permalink":"http://yoursite.com/categories/QA/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/tags/mysql/"}]},{"title":"NFS入门","slug":"NFS","date":"2018-10-19T05:39:00.000Z","updated":"2018-10-19T07:57:16.806Z","comments":true,"path":"2018/10/19/NFS/","link":"","permalink":"http://yoursite.com/2018/10/19/NFS/","excerpt":"","text":"1、NFS介绍NFS是”Network File system”的缩写，即网络文件系统网络文件系统是应用层的一种应用服务，它主要应用于linux与linux系统，linux与unix系统之间的文件或目录的共享。当用户想要使用远程文件的时候，只要用mount命令就可以把远程文件系统挂载到本地的文件系统上，操作远程文件就跟操作自己本地操作系统的文件一样。采用NFS之后省去了登录的过程，方便了用户访问系统资源。一言以蔽之，NFS的主要功能就是通过网络让不同的主机系统之间可以彼此共享文件或目录。 2、NFS原理对于linux而言，文件系统是在内核空间实现的，即文件系统比如ext3、ext4等是在kernel启动时，以内核模块的身份加载运行的。类似的，NFS(网络文件系统)也是工作在内核空间。NFS本身的服务没有提供数据传递的协议，而是通过使用RPC(Remote Procedure Call)来实现。具体实现过程如下:(1)本地用户要使用NFS服务器中的文件，先向内核发起请求，内核调用NFS模块以及rpc client(2)rpc client向rpc server发起连接(3)在连接之前，NFS服务除了启动nfsd本身监听的端口2049/tcp和2049/udp，还会启动其他进程(如mount，statd,rquotad等)已完成文件共享，这些进程的端口是不固定的，是每次NFS服务启动时向RPC服务注册的，RPC服务会随机分配未使用的端口(4)完成连接，接受访问请求(5)NFS应用程序向内核发起请求(6)内核调用文件系统然后client端通过获取的NFS端口来建立和server端的NFS连接并进行数据的传输简单来说，NFS客户端与服务端的通信过程:(1)先与rpc服务通信(tcp和udp的111端口)(2)再根据rpc提供的mounted监听端口，与mounted通信；mounted进程会对用户进行验证，验证通过返回用户一个通行证(3)最后客户端与nfsd进程建立联系进行通信 3、NFS服务器端组件:nfs-utilsrpm -ql nfs-utils #查看nfs-utils程序所生成的文件NFS服务端将启动3个主进程:(1)nfsd，跟NFS文件传输相关，工作在tcp和udp的2049端口(2)mounted，跟客户端挂载相关，随机端口(3)quotad，跟磁盘配额相关，随机端口备注:mounted和quotad的端口是随机产生的，不是固定的，每次重启nfs端口会发生变化。由此我们最好自定义端口。定义mounted和quotad进程监听固定端口:编辑/etc/sysconfig/nfs文件 #MOUNTED_PORT= #QUOTAD_PORT= #LOCKED_TCPPORT= #LOCKED_UDPPORT= 4、rpc介绍(1)rpc，远程过程调用，是一种编程技术，主要是用于简化分布式应用程序的开发。因为如果需要在两台主机上的进程进行通信，那么客户端、服务器端必须要处理网络传输中的网络请求、网络响应等等。这时候就大大增加了程序员开发的难度。因此就出现了rpc的框架。由此，程序员在开发客户端和服务端的时候，不需要再下功夫去处理网络协议报文的封装，因为rpc在底层就完成了这种观功能。(2)NFS是基于rpc来进行网络传输的，使得本地主机访问远程主机的时候，就好像本地主机访问本地一样。网络通讯过程对于本地主机来说是透明的。(3)在linux提供rpc服务的程序，叫做portmap，自身监听在tcp和udp的111端口。rpc与portmap的关系是，rpc是协议，portmap是实现，相当于http协议和apache、nginx、lightted的关系(4)rpc实现数据交换，可以基于二进制格式，也可以基于文本格式，基于文本格式比较常见的叫做XLRPC，后来又发展为SOAP 5、NFS介绍NFS是由SUN公司开发的，NFS版本有:NFSV1(SUN公司内部使用)NFSV2(早期公开版)NFSV3(在RHEL5上使用)NFSV4(在RHEL6上使用)NFS的缺点:(1)NFS可以基于认证，但是在认证这一块的功能是非常弱的，只认ID号，不认用户名举例子:假如在一台主机上有一个用户名叫做tom，通过NFS在另外一台主机上创建了一个目录，那么a.如果另外一台主机上没有tom这个用户，那么创建的目录的属主和属组是tom对应的uid和gidb.如果另外一台主机上有一个叫做jerry的用户，他的uid跟tom的uid一样，那么在另外一台主机上创建的这个目录的属主和属组就是jerry正是因为NFS不支持用户名认证，所以NFS一般不支持在互联网上使用，多用于在内网中各主机之间实现文件共享服务(2)NFS只支持在linux/unix上进行通信，不支持在windows主机上通信(linux上的NFS其实就相当于windows上的网上邻居，所以windows网上邻居的功能也是基于类似于rpc的协议来实现的) 6、NFS配置文件:/etc/exports只需要在这个文件中定义共享哪个目录出去，并且能够让客户端挂载，就能够让客户端像使用本地目录那样来使用这个共享出去的目录查看NFS的exports配置帮助的相关文档:man export 7、export文件格式:共享目录 客户端列表备注:(1)如果有多个客户端，客户端之间用空白字符分隔；而且每个客户端必须跟上一个小括号，里面定义了此客户端的访问特性，比如访问权限等(2)编辑保存之后需要重启nfs服务(3)文件系统访问特性有:ro:只读rw:只写sync:同步async:异步root_squash:将root用户映射为来宾用户，默认开启此功能no_root_squash:一台主机上的root用户访问另外一台主机的文件系统，是以另外一台主机的文件系统的root用户身份来访问的all_squash:将所有访问的用户映射为来宾用户anonuid,anongid:指定映射的来宾用户的uid和gid 8、命令相关(1)showmount命令:这个命令在客户端和服务端都可以使用-a:列出所有的客户端地址以及挂载的目录 #showmount -a 服务端IP，这条命令在客户端和服务端都可以实现-e:显示服务器共享了哪些目录 #showmount -e 服务端IP-d:显示NFS服务器共享出来的目录有哪些是被客户端挂载了的 #showmount -d 服务端IP (2)exportfs命令:-a:一般是跟-r或者-u选项同时使用，表示重新挂载(或者说导出，export)所有目录(或者说文件系统)或者取消挂载(导出)所有目录(文件系统)-r:重新导出-u:取消导出(这时候export下的所有文件系统或者目录都不能被客户端访问) #exportfs -uav-v:显示详细信息备注:当我们修改export文件的时候，需要重启nfs服务配置才会生效。使用exportfs就可以不用重启nfs服务，相当于reload (3)rpcinfo命令rpcinfo -p IP #查看mount或者quotad监听的端口号rpcinfo -p localhost #查看本机上rpc程序所监听的端口 (4)mount命令客户端使用mount命令挂载:mount -t nfs NFS_SERVER:/PATH /PATH #需要指定类型为nfsmount -t nfs 172.16.100.7:/shared /mnt/nfs #把172.16.100.7的shared目录共享出去，客户端挂载该目录即可使用 9、NFS开机自启动chkconfig nfs on 10、客户端开机自动挂载nfs目录编辑/etc/fstab文件，格式如下:172.16.100.1:/shared /mnt/nfs nfs defaults 0 0172.16.100.1:/shared /mnt/nfs nfs defaults,_rnetdev 0 0备注:man mount有一个挂载选项需要关注，_rnetdev:如果文件系统挂不上，就自动忽略掉 参考链接:https://www.cnblogs.com/whych/p/9196537.html","categories":[{"name":"linux共享服务","slug":"linux共享服务","permalink":"http://yoursite.com/categories/linux共享服务/"}],"tags":[{"name":"NFS","slug":"NFS","permalink":"http://yoursite.com/tags/NFS/"}]},{"title":"HTML基础","slug":"Untitled-3","date":"2018-10-17T07:14:00.000Z","updated":"2018-12-19T08:02:50.231Z","comments":true,"path":"2018/10/17/Untitled-3/","link":"","permalink":"http://yoursite.com/2018/10/17/Untitled-3/","excerpt":"","text":"HTML:HyperText Markup Language,超文本标记语言 1、HTML特点(1)HTML不需要编译，直接由浏览器执行(2)HTML文件是一个文本文件(3)HTML文件必须使用html或者xml为文件名后缀(4)HTML大小写不敏感 2、HTML基本结构 3、HTML标签(1)&lt;&gt;括起来(2)一般成对出现，分开始标签和结束标签。结束标签比开始标签多一个/(3)单标签:没有结束标签(4)标签属性 4、HTML标签类型(1)标题标签:h1到h6 (2)段落标签 段落标签align属性left:多对齐right:右对齐center:居中对齐justify:对行进行伸展，这样每行都可以有相等的长度(3)文字标签 (4)换行标签 (5)水平线标签 水平线标签属性width:设置水平线宽度，可以是像素或者是百分比color:设置水平线颜色align:设置水平线对齐方式noshade:设置水平线无阴影(6)列表标签之无序列表 无序列表标签type属性disc:圆点square:正方形circle:空心圆(7)列表标签之有序列表 有序列表标签type属性1:数字1,2…a:小写字母a,b..A:大写字母A,B..i:小写罗马数字iI:大写罗马数字I(8)列表标签之定义列表 (9)图像标签 图像标签属性 (10)超链接标签 超链接标签属性 5、HTML元素在开始标签和结束标签中的所有代码，称为HTML元素 6、HTML注释 7、DOCTYPE文档类型声明 8、网页编码设置","categories":[{"name":"HTML","slug":"HTML","permalink":"http://yoursite.com/categories/HTML/"}],"tags":[{"name":"html","slug":"html","permalink":"http://yoursite.com/tags/html/"}]},{"title":"grep入门","slug":"grep","date":"2018-10-17T06:08:00.000Z","updated":"2018-10-17T06:23:13.109Z","comments":true,"path":"2018/10/17/grep/","link":"","permalink":"http://yoursite.com/2018/10/17/grep/","excerpt":"","text":"grep:根据模式搜索文本，并将符合模式的文本行显示出来 模式(pattern)的概念:文本字符和正则表达式的元字符组合而成的匹配条件 grep版本:(1)grep(2)egrep(3)fgrep grep用法:grep [option] pattern [file…]备注:(1)模式(pattern)要用引号引起来。在shell中，单引号是强引用，双引号是弱引用。(2)强引用指的是单引号里面的内容会原封不动(3)弱引用指的是引用变量，变量会被赋值为对应的值(4)在模式引用中，只要不涉及到变量的引用，单引号和双引号都可以；如果模式中没有包含正则表达式的元字符的时候，实际上不加引号也可以 option:-i 忽略大小写–color 匹配的字符高亮显示(可以通过别名，用alias grep=’grep –color’将grep的高亮显示作为默认显示)-v 反向grep-o 只显示被模式匹配到的字符串(默认会显示包含模式匹配到的整行文本)-E 支持扩展的正则表达式(相当于egrep)-A n 显示匹配到的字符串所在行及向下的n行-B n 显示匹配到的字符串所在行及向上的n行-C n 显示匹配到的字符串所在行及其上和其下的n行","categories":[{"name":"linux文本处理","slug":"linux文本处理","permalink":"http://yoursite.com/categories/linux文本处理/"}],"tags":[{"name":"grep","slug":"grep","permalink":"http://yoursite.com/tags/grep/"}]},{"title":"正则表达式","slug":"正则表达式","date":"2018-10-17T03:45:00.000Z","updated":"2018-12-10T09:36:46.354Z","comments":true,"path":"2018/10/17/正则表达式/","link":"","permalink":"http://yoursite.com/2018/10/17/正则表达式/","excerpt":"","text":"regular expression，简写REGEXP主要关注正则表达式里面的一些元字符，这些字符不表示本身的意义，而表示一些通配的意义(正则表达式默认工作在贪婪模式下，即尽可能长的匹配) 模式的概念:字符和正则表达式的元字符组合起来过滤文本的过滤条件 正则表达式分两类:basic regexp:基本正则表达式extended regexp:扩展正则表达式 基本正则表达式:(1)字符匹配. 匹配任意单个字符[] 匹配指定范围之内的任意单个字符[^] 匹配指定范围之外的任意单个字符也可以字符集合的方法来表示匹配字符集合里面的任意单个字符[:digit:] 数字[:alpha:] 所有字母[:alnum:] 数字和字母[:lower:] 小写字母[:upper:] 大写字母[:punct:] 标点符号[:space:] 空白字符注意:使用字符集合的时候，还要使用一个方括号括起来，就是要用到两个方括号 (2)次数匹配:* 匹配其前面的字符任意次.* 匹配任意长度的任意字符(跟通配符中的*表示的一样)\\? 匹配其前面的字符0次或1次\\{m,n\\} 匹配其前面的字符最少m次，最多n次(反斜线是用来转义的，因为在bash shell中，花括号会被理解成命令行展开)\\{m\\} 匹配其前面的字符最少m次举栗子:a.*b 表示a开头，b结尾，中间是任意长度的任意字符\\{1,\\} 最少1次\\{0,3\\} 最多3次 (3)位置锚定^ 锚定行首，此字符后面的任意内容必须出现在行首$ 锚定行尾，此字符前面的任意内容必须出现在行尾^$ 表示空白行\\&lt;或者\\b:锚定词首，其后面的任意字符必须作为单词的首部出现>或者\\b:锚定词尾，其前面的任意字符必须作为单词的尾部出现举栗子:\\&lt;root\\&gt; 匹配单词root(root既是词首，也是词尾) (4)分组\\(..\\)\\(ab\\) ab作为一个整体，ab可以出现0次、1次或者多次分组的主要目的是:后向引用，在后面引用前面括号括起来的内容\\1 引用第一个小括号分组中的内容\\2 引用第二个小括号分组中的内容\\3 引用第三个小括号分组中的内容举栗子:grep ‘\\(l..e\\).\\1’ test.txt可以匹配到以下两行:He love his lover.He like his liker. 扩展正则表达式:(1)字符匹配. 匹配任意单个字符[] 匹配指定范围之内的任意单个字符[^] 匹配指定范围之外的任意单个字符 (2)次数匹配* 匹配其前面的字符任意次.* 匹配任意长度的任意字符(跟通配符中的*表示的一样)?:匹配其前面的字符0次或1次+:匹配其前面的字符至少1次，相当于{1,}{m,n} 匹配其前面的字符最少m次，最多n次(在扩展正则表达式中，不需要加反斜线){m} 匹配其前面的字符最少m次 (3)位置锚定^ 锚定行首，此字符后面的任意内容必须出现在行首$ 锚定行尾，此字符前面的任意内容必须出现在行尾\\&lt;或者\\b:锚定词首，其后面的任意字符必须作为单词的首部出现>或者\\b:锚定词尾，其前面的任意字符必须作为单词的尾部出现 (4)分组() #不需要加反斜线\\1 引用第一个小括号分组中的内容\\2 引用第二个小括号分组中的内容\\3… (5)竖线| 表示或者的意思C|cat 匹配C或者cat(C|c)at 匹配Cat或者cat 总结:1、基本正则表达式和扩展正则表达式的区别:(1)扩展正则表达式中，表示分组的括号和表示次数匹配的花括号和问号，前面都不需要加反斜线(2)扩展正则表达式中，次数匹配多了一个”+”号，表示匹配一次或者多次(3)扩展正则表达式中，多了一个竖线的符号，表示或者的意思 2、正则表达式和通配符的区别:在文本过滤工具里面，都是用正则表达式，比如像awk、sed、grep等，都是针对文件内容的；而通配符是linux系统本身就支持的，多用在文件名上，比如像find、ls、cp，等等 通配符:* 任意长度的任意字符? 任意单个字符[] 指定范围内[^] 指定范围外","categories":[{"name":"linux文本处理","slug":"linux文本处理","permalink":"http://yoursite.com/categories/linux文本处理/"}],"tags":[{"name":"正则","slug":"正则","permalink":"http://yoursite.com/tags/正则/"}]},{"title":"awk入门","slug":"awk入门","date":"2018-10-17T03:37:00.000Z","updated":"2019-02-25T03:52:03.895Z","comments":true,"path":"2018/10/17/awk入门/","link":"","permalink":"http://yoursite.com/2018/10/17/awk入门/","excerpt":"","text":"awk:报告生成器，根据输入信息，将输入信息格式化之后再显示出来 awk版本:(1)awk(2)new awk,简称nawk(3)gnome awk,简称gwak awk使用格式:awk [options] ‘PATTERN { action }’ file1,file2… options:-F 指定分隔符BEGIN{OFS=””} 指定输出分隔符 在options中使用的内置变量(1)awk内置变量之记录变量:FS:读取文本时所使用的字段分隔符，默认是空白字符RS:读取文本时所使用的换行符OFS:输出分隔符ORS:输出换行符 (2)awk内置变量之数据变量:NR:awk命令所处理的记录数。如果有多个文件，这个数目会把处理的多个文件中的行统一计数FNR:记录正处理的行是当前这一文件中被总共处理的行中是第几行NF:用于统计正在处理的行中的字段总数($NF:正在被处理的行中的最后一个字段) 常见的PATTERN类型:1.regexp，正则表达式，格式为/reglar expression/示例：awk -F: ‘/^r/{print $1}’ /etc/passwd #显示passwd文件中以r开头的用户名2.expression，表达式，比如$1 ~ /foo/ 或$1 == “magedu”等示例：awk -F: ‘$3&gt;=500{print $1,$3}’ /etc/passwd #显示passwd文件中uid大于300的用户及其uidawk -F: ‘$7~”bash$”{print $1,$7}’ /etc/passwd #显示passwd文件中以bash shell为shell的用户名及其对应的shell3.BEGIN/END,特殊模式，在awk命令执行之前运行一次或结束之前运行一次BEGIN:在awk处理文本第一行之前执行END:在awk处理文本最后一行之前执行实例：awk -F: ‘BEGIN{print “Username ID Shell”}{printf “%-10s%-10s%-20s\\n”,$1,$3,$7}END{print “end of report”}’ /etc/passwd #在第一行打印”Username ID Shell”，在最后一行打印”end of report” 常见的actions类型:控制语句：1.if-else实例：awk -F: ‘{if ($1==”root”) print $1,”admin”;else print $1,”common user”}’ /etc/passwd2.while实例：awk -F: ‘{i=1;while (i&lt;=3) {print $i;i++}}’ /etc/passwd3.do-whileawk -F: ‘{i=1;do {print $i;i++}while(i&lt;=3)}’ /etc/passwd4.forawk -F: ‘{for(i=1;i&lt;=3;i++)print $i}’ /etc/passwd5.case6.break,continue(跳过本字段)7.next(跳过本行) awk使用数组：示例：awk -F: ‘{shell[$NF]++}END{for(A in shell){print A,shell[A]}}’ /etc/passwd #生成一个shell数组，并统计passwd文件中各种shell的个数，A指的是下标netstat -tan | awk ‘/^tcp/{STATE{$NF}++}END{for (S IN STATE){print S,STATE[S]}}’ #生成一个STATE数组，并统计各种程序状态的个数，S指的是下标awk ‘{counts[$1]++}END{for(ip in counts){printf “%-20s:%d\\n”,ip,count[ip]}}’ /var/log/httpd/access.log #统计web日志文件中IP地址的访问量备注：awk中的下标很独特，可以是任意字符串","categories":[{"name":"linux文本处理","slug":"linux文本处理","permalink":"http://yoursite.com/categories/linux文本处理/"}],"tags":[{"name":"awk","slug":"awk","permalink":"http://yoursite.com/tags/awk/"}]},{"title":"初步认识docker","slug":"docker入门","date":"2018-10-12T01:26:00.000Z","updated":"2018-12-19T07:24:19.329Z","comments":true,"path":"2018/10/12/docker入门/","link":"","permalink":"http://yoursite.com/2018/10/12/docker入门/","excerpt":"","text":"什么是dockerdocker是一个开源的应用容器引擎，让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的linux机器中，也可以实现虚拟化。docker的目标是实现轻量级操作系统虚拟化的解决方案。(基于Go语言开发) docker简单原理docker的基础是linux容器(LXC)、Cgroup技术。docker是在LXC的基础上进行了进一步的封装，让用户不再需要去关心容器的管理，使得操作更加简便。用户操作docker的容器就像操作一个快速轻量级的虚拟机一样简单。与传统虚拟户(KVM、XEN等)相比较：(1)docker是在操作系统层面上实现虚拟化，直接复用本地主机的操作系统(由下往上:硬件-&gt;host操作系统-&gt;docker engine-&gt;应用库-&gt;应用app) (2)传统的虚拟化方式是在硬件的基础上，虚拟出自己的系统，再在系统上部署相关的APP应用(由下往上:硬件-&gt;host操作系统-&gt;hypervisor-&gt;guest操作系统-&gt;应用库-&gt;应用app) docker组件(1)镜像:其实就是模板，跟我们常见的ISO镜像类似，是一个样板(2)容器:使用镜像常见的应用或系统，我们称之为一个容器(容器相当于启动之后的镜像)(3)仓库:仓库就是存放镜像的地方，分为公开仓库(public)和私有仓库(private)两种形式 docker技术组件linux内核的命名空间(namespace)，用于隔离文件系统、进程和网络(1)文件系统隔离:每个容器都有自己的root文件系统(2)进程隔离:每个容器都运行在自己的进程环境中(3)网络隔离:容器间的虚拟网络接口和IP地址都是分开的(4)资源隔离和分组:使用Cgroups(即control group，linux内核特性之一)将cpu和内存之类的资源独立分配给每个docker容器(5)写时复制:文件系统都是通过写时复制创建的(6)日志:容器产生的STDOUT、STDIN和STDERR这些IO流都会被收集并记入日志(7)交互式shell:用户可以创建一个伪tty终端，为容器提供一个交互式shell docker虚拟化特点(1)操作启动快运行时的性能获得极大的提升，管理操作(开始、停止、重启等)都是以秒或者毫秒为单位的(2)轻量级虚拟化你会拥有足够的”操作系统”，仅需添加或减少镜像即可。在一台服务器上可以部署100~1000个container容器，但是传统虚拟化虚拟出10~20个虚拟机就已经很好了(3)开源免费(4)前景及云支持 使用docker的优势(1)提供一个简单、轻量的建模方式用户上手docker非常快，只需要几分钟就可以将自己的程序”docker化”,docker依赖于”写时复制”(copy-on-write)模型，使得修改应用程序也非常迅速。(2)职责的逻辑分离使用docker，开发人员只需要关心容器中运行的应用程序，运维人员只需要关心如何管理容器，从而降低”开发时一切正常，肯定是运维问题”的风险。(3)快速、高效的开发生命周期docker的目标之一就是缩短代码从开发、测试到部署、上线运行的周期，让你的应用程序具备可移植性、易于构建、易于协作。(4)鼓励使用面向服务的架构docker推荐单个容器只运行一个应用程序，这样就形成了一个分布式的应用程序模型。在这种模型下，应用程序或服务都可以表示为一系列内部互联的容器，从而使分布式部署应用程序或者扩展应用程序变得简单。 docker安装先决条件(1)运行64位CPU架构的计算机，不支持32位的CPU(2)运行linux3.8或更高版本的内核查看内核版本:uname -a目前3.8内核已经可以通过apt-get来安装，内核更新步骤:apt-get updateapt-get install linux-headers-3.8.0-27-genericupdate-grubreboot(3)内核必须支持一种适合的存储驱动，默认是Device Mapper检查主机是否安装Device-mapper:grep device-mapper /proc/devices如果没有出现device-mapper的相关信息，可以尝试加载dm_mod模块:modprobe dm_mod(4)内核必须支持并开启cgroup和namespace(命名空间)的功能cgroup和namespace自2.6版本就已经集成到linux内核中，目前为止功能非常稳定 docker安装默认docker只能在centos6.5以上机器才能使用yum直接安装，如果是其他版本的话需要安装centos扩展源epel。docker官方要求linux kernel至少要3.8以上。在centos6.5系统上安装docker:(1)关闭selinux(2)安装epel源wget http://ftp.riken.jp/Linux/fedora/epel/6/x86_64/epel-release-6-8.noarch.rpmrpm -ivh epel-release-6-8.noarch.rpm(3)安装依赖yum install lxc libcgroup device-mapper-event-libsdevice-mapper* -y(4)安装dockeryum install docker-io(5)docker启动/etc/init.d/docker start在ubuntu 16.04安装docker:(1)安装wget -qO- https://get.docker.com/ | sh(2)启动/etc/init.d/docker start备注:在ubuntu中，如果使用UFW，需要在UFW中启用数据报文转发，才能让docker正常工作。因为UFW默认情况下会丢弃所有转发的数据包。修改/etc/default/ufw，将DEFAULT_FORWARD_POLICY=”DROP”修改为DEFAULT_FORWARD_POLICY=”ACCEPT”，保存修改内容并通过ufw reload重启UFW即可 docker常用命令docker version #查看docker版本docker images #查看当前的docker所有镜像docker info #检查docker是否已经正确安装并运行docker search centos #搜索可用的docker镜像docker pull centos #从公有仓库中下载镜像cat centos.tar | docker import - centos6 #导入镜像，导入centos.tar镜像并重命名为centos6docker export id &gt; centos6.tar #导出镜像，根据id导出镜像并重命名为centos6.tardocker ps -l #查看最后一个容器的iddocker ps -a #查看所有容器docker run centos echo “hello world” #在容器中运行”hello world”docker run centos yum install ntpdate #在容器中安装ntpdate程序docker run -i -t centos /bin/bash #在容器中启动一个/bin/bash shell环境，可以登入操作，-t表示打开一个终端，-i表示交互式输入docker run -d centos:v1 /bin/bash #在后台启动一个/bin/bash shell环境，-d表示在后台以daemon方式启动docker run -d -p 80:80 -p 8022:22 centos:v2 #-p指定容器启动后docker上运行的端口映射为容器里运行的端口，80:80中第一个80表示docker系统(本机)的80端口，第二个80表示docker虚拟机(docker容器)里面的端口。用户默认访问本机80端口，自动映射到容器里面的80端口docker commit 2313132 centos:v1 #提交刚修改的容器docker stop id #关闭容器docker start id #启动容器docker rm id #删除容器","categories":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/categories/docker/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/tags/docker/"}]},{"title":"初识java","slug":"初识java","date":"2018-10-10T08:33:00.000Z","updated":"2018-12-07T06:34:55.897Z","comments":true,"path":"2018/10/10/初识java/","link":"","permalink":"http://yoursite.com/2018/10/10/初识java/","excerpt":"","text":"1、先了解一下PHP(1)PHP是开发语言，也是运行环境作为开发语言，PHP属于脚本语言，也属于动态语言 (2)PHP编译过程:为简化编译过程，引入Zend Engine，编译成opcode，第一次编译第二次就不用编译；但是像Apache，每一个进程都使用一个独立的进程空间，因此第一个进程编译的结果第二个进程无法使用，因此又引入了缓存，像Xcache、APC、eAccelerator。 (3)PHP与C(面向过程)、C++(面向对象)相比较:PHP具有动态语言和脚本语言的灵活性、便捷性、移植性好C和C++移植困难、维护成本高，但是高速、性能好，一般用来开发驱动和底层程序等 插入介绍一些linux系统知识:(1)最底层:System call，系统调用上一层:API(application programming interface)，应用编程接口，有windows api和linux api再上一层:POSIX(POS全称portable operation system)，可移植操作系统，后面的IX是为了兼容linux操作系统的叫法。POSIX可以实现跨平台编译，POSIX是一种规范。(2)程序可以跨平台编译，但是不能跨平台运行(因为windows和linux的动态库不一样，windows系统是.so文件，linux系统是.dll文件)。因此，又出现一种叫做ABI的接口，ABI全称是application binary interface，可以拟合不同操作系统的二进制格式。在linux中，二进制格式是ELF；在windows中，二进制格式是EXE 最后引入java，java的出现就是为了能够在不同的操作系统上运行应用程序java包含四个独立又彼此相关的技术:(1)java程序设计语言(2)jvm(java virtual machine)，又叫java虚拟机(3)java class文件格式(4)java api彼此相关:java编程语言结合java api，编译成java class文件格式(字节码)，在jvm上运行(name.java–&gt;name.class,还有各种公有类和私有类跑在jvm上) 2、java apijava ee包含多个独立的api，servlet(硬编码)和jsp(.jsp-&gt;.java-&gt;.class)就是其中的两个，而java ee中著名的api还还包含以下几个:java ee api:(1)ehj(enterprise javabeans):java相关的诸多高级功能的实现，如rmi(remote method invocation)，对象/关系映射，跨越多个数据源的分布式事务等(2)jms(java message service):高性能异步消息服务，实现java ee应用程序与非java程序的透明通信(3)jmx(java management extensions):在程序运行时对其进行交互式监控和管理的机制(4)jta(java transaction api):允许应用程序在自身的一个或多个组件中平滑的处理错误的机制(5)javamail:通过工业标准的POP/SMTP/IMAP协议发送和接收邮件的机制 java se api:jndi(java naming and directory interface):用于与ldap服务交互的apijaxp(java api for xml processing):用于分析和转换xml 3、介绍jvmjvm最大的特点:一次编译，到处运行(once for all)jvm实现方式:(1)一次性解释器，解释字节码并执行(2)即时编译器(just-in-time complier)，依赖于更多内存缓存解释后的结果(3)自适应编译器，监控执行频率较高的代码，并将结果缓存下来(二八法则，缓存20%左右的代码，提高80%左右的速度) jvm分类:(1)hotspot，sum公司自己的jvm，hotspot又分为两类:jre:java运行环境，运行(编译)所需；jre=java语言+java se apijdk:java开发环境(包含jre，是jre的超集)，运行(编译)+开发所需；jdk=java语言+java api+jvm，jdk是实现java程序开发的最小环境(2)openjdk，开源界的jvm开发+运行的开源实现 java分类(根据java应用领域的不同):(1)java se:standard edition，标准版本，早期也叫做J2SE(2)java ee:enterprise edition，企业版本，早期也叫做J2EE(3)java me:mobile edition，移动版本，早期也叫做J2ME(用的很少) #2指的是第二版 4、介绍jdk:(1)jdk包格式jdk 1.6 update 32(jdk1.6的第32次升级，软件包名称是jdk-1.6.32)jdk 1.7 update 9(jdk1.7的第9次升级，软件包名称是jdk-1.7.9)(2)jdk安装方式rmp包通用二进制格式源码编译(3)命令yum list all|grep java #查看操作系统自身提供的jdk软件包java -version #查看java版本 5、介绍jsp(1)早期的时候，出现了applet这种小程序，用于开发动态网站；applet是开发在客户端运行的应用程序，基于web技术(2)接着，出现一种叫做CGI(common gateway interface)规范，能够让用户访问某种资源的时候，触发web服务器，调用额外的程序执行。除了CGI规范，java还提供了一种叫做servlet的规范，用来兼容applet和CGI；servlet是开发运行在服务器端的应用程序，基于CGI技术(3)在servlet的基础上进行升级改造，又引入了jsp(java server page)，用来嵌入java语言；jsp将servlet简化，开发者只需要将java程序嵌入到html代码中 #虽然说jsp拜托了servlet的束缚，但是jsp还是要通过Jasper先转换成servlet；jsp框架能够让java以嵌入式代码的方式嵌入到html代码中，从而实现基于java的动态网站开发 6、介绍java类(类库)有三类:(1)applet(2)servlet(3)jsp.jsp通过Jasper转换为.java.java通过jvm转换为.class 7、垃圾回收机制java程序可以实现自动内存回收，通过GC(gabbage collect)来完成(1)垃圾回收器:cms(Concurrent Mark-Sweep)，cms是以牺牲吞吐量为代价来获得最短回收停顿时间的垃圾回收器。对于要求服务器响应速度的应用上，这种垃圾回收器非常适合。在启动JVM参数加上-XX:+UseConcMarkSweepGC ，这个参数表示对于老年代的回收采用CMS。CMS采用的基础算法是：标记—清除。(2)cms过程:初始标记、并发标记、并发预处理、重新标记、并发清理、并发重置(3)cms优缺点:优点:并发收集、低停顿缺点:无法收集浮动垃圾，由于基于标记-清除算法，可能会产生碎片 8、java配置参数-XX:+ #开启此参数指定的功能-XX:- #关闭此参数指定的功能-XX:= #给option指定的选项赋值示例:java -XX:+PrintFlagsFinal #查看java配置所支持的参数 9、java工具sun jdk免费提供给用户监控和故障处理工具:(在jdk安装目录的bin目录下有很多java工具和命令)(1)jps:java process status tool，显示指定系统内的所有hotspot虚拟机进程的列表信息(2)jstat:jvm staticstics monitoring tool，收集并显示hotspot虚拟机各方面的运行数据(3)jinfo:显示正在运行的某hotspot虚拟机配置信息(4)jmap:生成某hotspot虚拟机的内存转储快照 可视化工具:(1)jconsole:java的监控和管理控制台(2)jvisualvm:java虚拟机控制台 #java工具除了sun开源的工具，还有很多商业的工具","categories":[{"name":"tomcat","slug":"tomcat","permalink":"http://yoursite.com/categories/tomcat/"}],"tags":[{"name":"java","slug":"java","permalink":"http://yoursite.com/tags/java/"}]},{"title":"redis高级功能","slug":"redis高级功能","date":"2018-10-08T09:20:00.000Z","updated":"2018-12-19T07:21:52.861Z","comments":true,"path":"2018/10/08/redis高级功能/","link":"","permalink":"http://yoursite.com/2018/10/08/redis高级功能/","excerpt":"","text":"1、redis认证实现方法:(1)通过配置文件redis.conf修改requirepass PASSWORD #定义连接redis时的密码(2)通过客户端redis-cli修改auth PASSWORD #验证密码，PASSWORD为配置文件中requirepass定义的密码 2、redis事务(1)通过MULTI、EXEC、WATCH等命令实现事务功能:将一个命令或多个命令归并为一个操作提请服务器按顺序执行的机制举栗子:multi #启动(开始)一个事务……exec #执行(结束)一个事务 (2)watch:乐观锁在exec命令执行之前，用于监视指定键；如果监视中的某任意键数据被修改，则服务器拒绝执行事务(因为watch是监视数据是否被修改，一旦确认数据被修改，则放弃使用数据，而不是拒绝对方使用数据，所以叫乐观锁) (3)redis事务与传统关系型数据库的事务最大区别在于:redis不支持回滚 3、redis持久化:本质上是内存数据库redis持久化有两种机制:(1)RDB:快照机制，按事先制定的策略，周期性的将数据保存至磁盘，数据文件默认为dunp.rdb客户端也可以显式使用save或bgsave命令启动快照保存机制save:同步，在主线中保存快照，此时会阻塞所有客户端请求bgsave:异步，bg表示back-ground，后台运行，不会阻塞客户端请求 与rdb相关的配置文件参数:stop-write-on-bgsave-error yes #出错时停止写入rdbcompression yes #rdb文件是否执行压缩来节省磁盘空间rdbchecksum yes #是否对rdb的镜像文件做校验码检测dbfilename dump.rdb #指明文件名dir /var/lib/redis #指明rdb文件保存的目录 (2)AOF：append only file的缩写，把redis的每一个操作命令以附加的形式，附加到指定文件的尾部，会导致文件很大。记录每一次写操作至指定的文件尾部实现持久化，当redis重启时，可以通过重新执行文件中的命令在内存中重建数据库。通过bgrewriteaof来实现aof文件重写，不会读取正在使用的aof文件，而是通过将内存中的数据以命令的方式保存到临时文件中，完成之后替换原来的aof文件 与aof相关的配置文件参数:appendonly no #没有开启aof功能appendfilename “appendonly.aof” #文件名appendfsync always #每次收到写命令就立即写到aof文件appendfsync everysec #每秒钟写一次(折中的方式)appendfsync no #不通知内核，内核爱怎么写就怎么写no-appendfsync-on-write no #重写的时候对新写的操作不做sync操作，而是暂存在内存当中auto-aof-rewrite-percentage 100auto-aof-rewrite-min-size 64m aof重写过程:a.redis主进程通过fork创建子进程b.子进程根据redis内存中的数据创建数据库重建命令序列于临时文件中c.父进程继承client的请求，并会把这些请求中的写操作继续追加至原来的aof文件中；额外的，这些新的写请求还会被放置于一个缓冲队列中d.子进程重写完成，会通知父进程；父进程把缓冲中的命令写到临时文件中e.父进程用临时文件替换老的aof文件 使用子进程进行AOF重写的问题：子进程在进行AOF重写期间，服务器进程还要继续处理命令请求，而新的命令可能对现有的数据进行修改，这会让当前数据库的数据和重写后的AOF文件中的数据不一致如何修正:为了解决这种数据不一致的问题，Redis增加了一个AOF重写缓存，这个缓存在fork出子进程之后开始启用，Redis服务器主进程在执行完写命令之后，会同时将这个写命令追加到AOF缓冲区和AOF重写缓冲区即子进程在执行AOF重写时，主进程需要执行以下三个工作：执行client发来的命令请求；将写命令追加到现有的AOF文件中；将写命令追加到AOF重写缓存中。参考链接:https://blog.csdn.net/hezhiqiang1314/article/details/69396887 备注:重写本身不能取代备份，还应该指定备份策略，对redis数据库进行定期备份rdb与aof同时启用的时候:a.bgsave和bgrewriteaof不会同时执行b.在redis服务器启动数据恢复时，会优先使用aof 4、复制功能(1)特点:a.一个master可以有多个slaveb.支持链式复制c.master以非阻塞的方式同步数据至salve(2)主从(配置):slave slaveof master_ip master_port(3)认证如果master使用requirepass开启了认证功能，从服务器要使用masterauth 来连入服务请求来使用此密码进行验证 5、HA高可用通过sentinel来管理多个redis服务器实现HAsentinel作用:(1)用于监视主服务器(2)实现通知功能(notification)(3)实现自动故障转移 sentinel协议:(1)流言协议:接收主服务器是否下线的通知(2)投票协议:决定哪个服务器成为新的主服务器 sentinel启动:(1)redis-sentinel /path/to/file.conf(2)redis-server /path/to/file.conf –sentinel启动过程:(1)服务器自身初始化，运行redis-server中专用于sentinel功能的代码(2)初始化sentinel状态，根据给定的配置文件，初始化监控的master服务器列表(3)创建指向master的连接 sentinel下线:(1)主观下线:一个sentinel实例判断出某节点下线(2)客观下线:多个sentinel节点协商好判断出某节点下线 sentinel专用配置文件:/etc/redis-sentinel.conf(1)sentinel monitor mymaster 127.0.0.1 6379 2(2代表投票数) #多个sentinel的情况下，有2票投票从服务器成为主服务器的话，从服务器就会成为新的主服务器(2)sentinel down-after-milliseconds mymaster 30000 #30秒找不到主服务器就判断离线(3)sentinel parallel-syncs mymaster 2 #允许多少个从服务器向主服务器发起同步请求(4)sentinel failover-timeout mymaster 20 #主服务器发生故障，故障转移超时时间(故障转移超过这个时间，判断故障转移失败) sentinel专用命令(都以sentinel开头):sentinel masters:列出所有监视的主服务器sentinel slaves master_name:获取指定主服务器的从节点sentinel get-master-addr-by-name master_name:根据name获取master地址sentinel reset:重置操作sentinel failover &lt;master_name&gt;:手动执行故障转移操作 sentinel连接:(1)客户端连接sentinel示例redis-cli -h ipaddr -p 26379(sentinel默认端口)(2)客户端连接从节点示例redis-cli -h ipaddr -p 6380(自定义redis端口) 6、集群clustering:redis3.0以后支持分布式数据库，通过分片机制进行数据分析，clustering内的每个节点仅存数据库的一部分数据，也被称作去中心化(每一个节点都可以接入客户请求)。这样，每个节点都持有全局元数据，但仅持有一部分数据优点:(1)无中心化，gossip分散式模式(2)更少的来回次数并降低延迟(3)自动于多个redis节点进行分片(4)不需要第三方软件支持协调机制缺点:(1)依赖于redis3.0或更高版本(2)需要时间验证其稳定性(3)没有后台界面(4)需要智能客户端(5)redis客户端必须支持redis cluster架构","categories":[{"name":"redis","slug":"redis","permalink":"http://yoursite.com/categories/redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://yoursite.com/tags/redis/"}]},{"title":"redis安装、配置及基本命令操作","slug":"redis配置及基本命令操作","date":"2018-10-08T08:19:00.000Z","updated":"2018-12-19T07:19:56.057Z","comments":true,"path":"2018/10/08/redis配置及基本命令操作/","link":"","permalink":"http://yoursite.com/2018/10/08/redis配置及基本命令操作/","excerpt":"","text":"1、redis特点:(1)原子性:要么全部执行，要么全部不执行(2)一致性:支持事务(3)隔离性:单线程(4)持久性:异步写入磁盘，避免雪崩效应 2、首先介绍一下redis3.0特性:(1)支持redis cluster(2)支持新的”embedded string”(3)LRU算法的改进改进如下:a.预设随机抽取5个样本，插入并排序至一个pool，移除最佳者，如此反复，直到内存用量小于maxmemory的设定b.样本5比先前的3多c.从局部最优趋向全局最优 3、redis组件:(1)redis-server(服务端)(2)redis-cli(客户端)(3)redis-benchmark(压测工具)(4)redis-check-dump &amp; redis-check-aof(检查持久化文件是否完整，分别对应rdb和aof格式) 4、redis官方站点:www.redis.ioyum info redis #查看epel源是否含有redis的安装包yum localinstall redis-3.0.2-1.el6.reml.x86_64.rpm #本地安装redisrpm -ql redis #查看安装redis时安装了哪些文件redis-server –help #查看帮助 5、redis配置文件(常用配置):(1)tcp-backlog #指等待队列。当并发量大的时候，redis可能会忙不过来。这时候需要额外找一个地方，将新的请求缓存下来，这个位置就叫backlog(2)redis.sock #服务端和客户端在同一台机器的时候，建议以sock文件的方式进行通信。好处是在内存当中直接交换，而不需要经过tcp/ip协议栈进行封装和解封装(3)timeout 0 #0表示连接不会超时(4)snapshotting配置:save 900 1 表示在900秒内有一个键发生变化，就做一次快照(5)replication配置:主从(6)daemonize yes #启动程序时，程序在后台运行 6、redis基本命令:(1)通过redis-cli客户端连接redis之后，可以通过help命令查看帮助help +tab键 #查看redis支持哪些类型help @STRING #查看字符串帮助help append #查看append命令的用法 (2)连接(connection)命令:help @connection #查看连接相关命令AUTH #验证PING #测试服务器是否在线，在线的话会返回PONGECHO #显示命令，例如ECHO ‘hello’QUIT #退出命令SELECT #选择数据库 (3)服务器(server)命令:help @server #查看服务器相关命令CLIENT SETNAME connection-name #设定连接名CLIENT GETNAME #查看连接名CLIENT KILL ip:port kill #关闭client (4)配置(config)命令:INFO #查看redis信息，信息包含很多段，例如INFO memory可以查看内存段的信息CONFIG RESETSTAT #重置INFO中所统计的数据CONFIG SET #运行中修改，也就是在内存中修改，不会同步到硬盘中CONFIG REWRITE #将配置写到硬盘当中CONFIG GET (如dir) #查看配置 7、redis支持的数据结构:(1)string #help @string，查看string支持的命令string支持的命令:set #help set，查看set帮助getappendstrlen (2)integer #help @integer，查看integer支持的命令integer支持的命令:incr #help incr，查看incr帮助decr (3)list [a,b,c,d] #help @list，查看list支持的命令list支持的命令:rpush #help rpush，查看rpush帮助lpushrpoplpoplindexlsetllen (4)set {a,b,c,d} #help @set，查看set支持的命令set支持的命令:sadd #help sadd，查看sadd帮助sinter #求交集sunion #求并集spop #随机弹出，set无序sismember #成员运算符 (5)sorted set {a:1,b:2,c:3} #help @sorten_set，查看sorten_set支持的命令sorten_set支持的命令:zadd #help zadd，查看zadd帮助zrangezcardzrank (6)hash {field1:”a”,field2:”b”}，说白了就是映射，也称为关联数组 #help @hash，查看hash支持的命令hash支持的命令:hset #help hset，查看set帮助hsetnxhgethkeyshvalshlenhdel (7)bitmaps #help @bitmaps，查看bitmaps支持的命令(8)hyperloglog #help @hyperloglog，查看hyperloglog支持的命令 …. 8、清空数据库:FLUSHDB:清空当前库FLUSHALL:清空所有库","categories":[{"name":"redis","slug":"redis","permalink":"http://yoursite.com/categories/redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://yoursite.com/tags/redis/"}]},{"title":"开始认识redis","slug":"初识redis","date":"2018-10-08T06:59:00.000Z","updated":"2018-12-19T07:18:59.620Z","comments":true,"path":"2018/10/08/初识redis/","link":"","permalink":"http://yoursite.com/2018/10/08/初识redis/","excerpt":"","text":"redis属于nosql的一种。首先介绍一下nosql的分类:1、key-value nosql，比如redis，memcached2、column family nosql(列式存储)，比如hbase3、documentation nosql(文档存储)，比如mongodb4、graph nosql(图形存储) redis特性:1、key-value cache and store2、in-memory3、single threaded(单线程，因为redis占用cpu的消耗很低，因此cpu一般不会成为瓶颈)4、支持持久化(snapshotting，快照方式，异步写入到磁盘:AOF，append only file)5、支持主从(借助于sentinel实现一定意义上的HA:高可用)6、支持分布式集群(clustering)7、支持string、list、hash(关联数组)、set、sorted set(有序集合)、bitmap、hyperloglog redis与memcached比较:redis优势:1、支持的数据类型丰富，包括hash、lists、sets、sorted set、hyperloglog2、内建replication及cluster3、就地更新操作(in-place update)4、支持持久化(异步写入磁盘，避免雪崩效应)memcached优势:1、多线程(善用多核CPU，更少的阻塞操作)2、更少的内存开销3、更少的内存分配压力4、可能有更少的内存碎片","categories":[{"name":"redis","slug":"redis","permalink":"http://yoursite.com/categories/redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://yoursite.com/tags/redis/"}]},{"title":"解决rabbitmq的web管理界面无法使用guest用户登录的问题","slug":"解决rabbitmq的web管理界面无法使用guest用户登录的问题","date":"2018-09-29T09:26:00.000Z","updated":"2018-09-29T09:27:15.108Z","comments":true,"path":"2018/09/29/解决rabbitmq的web管理界面无法使用guest用户登录的问题/","link":"","permalink":"http://yoursite.com/2018/09/29/解决rabbitmq的web管理界面无法使用guest用户登录的问题/","excerpt":"","text":"为了解决这个问题，需要在rabbitmq的配置文件中将loopback_users配置设置为空，如编写配置文件:/etc/rabbitmq/rabbitmq.config，并在其中添加以下内容： [{rabbit, [{loopback_users, []}]}]. 保存后重启rabbitmq-server即可随意使用guest用户名和密码来登录了(当然这个做法非常不安全)。","categories":[],"tags":[{"name":"rabbitmq","slug":"rabbitmq","permalink":"http://yoursite.com/tags/rabbitmq/"}]},{"title":"iptables删除已有的规则","slug":"iptables删除已有的规则","date":"2018-09-29T09:21:00.000Z","updated":"2018-12-10T09:31:44.817Z","comments":true,"path":"2018/09/29/iptables删除已有的规则/","link":"","permalink":"http://yoursite.com/2018/09/29/iptables删除已有的规则/","excerpt":"","text":"比如要删除input链上的某条规则，先要查询input链的所有规则iptables -L INPUT –line-numbers 查看你所要删除的规则是第几条，比如要删除第3条iptables -D INPUT 3","categories":[{"name":"iptables","slug":"iptables","permalink":"http://yoursite.com/categories/iptables/"}],"tags":[{"name":"iptables","slug":"iptables","permalink":"http://yoursite.com/tags/iptables/"}]},{"title":"mysql启动报错:\"[ERROR] Table 'mysql.user' doesn't exist\"","slug":"mysql启动报错","date":"2018-09-29T09:16:00.000Z","updated":"2018-12-19T07:29:31.466Z","comments":true,"path":"2018/09/29/mysql启动报错/","link":"","permalink":"http://yoursite.com/2018/09/29/mysql启动报错/","excerpt":"","text":"这是因为编译安装mysql时指定了”–datadir=/usr/local/mysql/data”,所以在新增加一个/etc/my.cnf文件的时候，需要在my.cnf里面指定datadir=/usr/local/mysql/data 然后重启mysql就可以正常启动了","categories":[{"name":"QA","slug":"QA","permalink":"http://yoursite.com/categories/QA/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/tags/mysql/"}]},{"title":"ubuntu安装ansible","slug":"ubuntu安装ansible","date":"2018-09-26T08:13:00.000Z","updated":"2018-10-08T05:50:39.916Z","comments":true,"path":"2018/09/26/ubuntu安装ansible/","link":"","permalink":"http://yoursite.com/2018/09/26/ubuntu安装ansible/","excerpt":"","text":"1、安装add-apt-repository必要套件apt-get install -y python-software-properties software-properties-common 2、使用ansible官方的PPA套件来源add-apt-repository -y ppa:ansible/ansible 3、升级apt-getapt-get update 4、安装ansibleapt-get install -y ansible","categories":[{"name":"安装篇","slug":"安装篇","permalink":"http://yoursite.com/categories/安装篇/"}],"tags":[{"name":"ansible","slug":"ansible","permalink":"http://yoursite.com/tags/ansible/"}]},{"title":"集群的概念","slug":"集群的概念","date":"2018-09-23T10:31:00.000Z","updated":"2018-09-23T10:42:13.270Z","comments":true,"path":"2018/09/23/集群的概念/","link":"","permalink":"http://yoursite.com/2018/09/23/集群的概念/","excerpt":"","text":"1、LB集群:lvs,nginx(lvs,nginx也可以实现高可用，但是相对来说在高可用中keepalived比较常见)2、HA集群:keepalived,heartbeat,corosync3、HP集群:高性能集群、超算集群，在互联网公司中很少见，一般在国家级实验室或者超算实验室中比较常见(HP集群一般可以用分布式计算来替换) 延伸:分布式计算中的一些概念分布式存储:HDFS分布式计算:YARNbatch:mapreducein-memory:sparkstream:storm HA cluster配置前提:1、本机的主机名与host中定义的主机名保持一致，要与hostname(uname -n)获得的名称保持一致 #根据主机名彼此通信配置主机名:在centos6中,/etc/sysconfig/networks在centos7中，hostnamectl set-hostname HOSTNAME #各节点要能相互解析主机名:一般建议通过host文件进行解析(配置文件/etc/hosts)2、各节点时间同步3、确保iptables及selinux不会成为服务的阻碍iptables -L -n #查看iptables规则getenforce #查看selinux状态","categories":[{"name":"高可用web","slug":"高可用web","permalink":"http://yoursite.com/categories/高可用web/"}],"tags":[{"name":"集群","slug":"集群","permalink":"http://yoursite.com/tags/集群/"}]},{"title":"keepalived配置实例","slug":"keepalived配置实例","date":"2018-09-23T09:53:00.000Z","updated":"2018-12-07T06:39:29.278Z","comments":true,"path":"2018/09/23/keepalived配置实例/","link":"","permalink":"http://yoursite.com/2018/09/23/keepalived配置实例/","excerpt":"","text":"实例一启动keepalived之后找不到配置文件:1、编辑/etc/rsyslog.conf #指明各类日志文件中的信息加上一句，local3.* /var/log/keepalived.log 2、编辑/etc/sysconfig/keepalived,加上一句，KEEPALIVED_OPTIONS=”-D -S 3” #指明keepalived日志文件的facility(等级)为3 3、重启rsyslog,keepalived服务在centos7中，systemctl restart rsyslog.servicesystemctl restart keepalived.service 实例二手动调度vip在两台主机中转移在配置文件中，1、vrrp实例之外加上一个函数vrrp_script chk_maintainnance{ script “[[ -f /etc/keepalived/down]] &amp;&amp; exit 1 || exit 0” interval 1 weight -2} 2、vrrp实例之内调用这个函数track_script{ chk_maintainnance}用法:只需要touch /etc/keepalived/down,vip就会转移；删除down文件又会转移到另一台主机 实例三配置虚拟路由器组vrrp_sync_group VG_1{ group { VI_1 VI_2 }} vrrp_instance VI_1{ eth0 vip #对外部客户} vrrp_instance VI_2{ eth1 dip #对内部主机} 实例四主机状态发生改变时发送通知:在vrrp实例中定义 #notify scripts,alert as above –自定义脚本 notify_master | #当前节点转换为master时，发送相应消息 notify_backup | #当前节点转换为backup时，发送相应消息 notify_fault |&lt;QUOTED_STRING&gt; #当前节点转换为fault(发生故障)时，发送相应消息 notify | smtp_alert实例:””括起来的内容就是表示QUOTED_STRINGnotify_master “/etc/keepalived/notify.sh master”notify_backup “/etc/keepalived/notify.sh backup”notify_fault “/etc/keepalived/notify.sh fault” 下面是一个notify脚本的简单示例: #!/bin/bashvip=172.16.100.1contact=‘root@localhost’ notify(){ mailsubject=”hostname to be $1:$vip floating” mailbody=”date &#39;+%F %H:%M:%S&#39;:vrrp transtion,hostname change to be $1” echo $mailbody|mail -s “$mailsubject” $contact} case “$1” in master) notify master #/etc/rc.d/init.d/haproxy start exit 0 ;; backup) notify backup #/etc/rc.d/init.d/haproxy stop exit 0 ;; fault) notify fault #/etc/rc.d/init.d/haproxy stop exit 0 ;; *) echo “Usage:basename $0 {master|backup|fault}” exit 1 ;;esac","categories":[{"name":"keepalived","slug":"keepalived","permalink":"http://yoursite.com/categories/keepalived/"}],"tags":[{"name":"keepalived","slug":"keepalived","permalink":"http://yoursite.com/tags/keepalived/"}]},{"title":"初步认识Keepalived","slug":"eepalived简介、组件及配置文件","date":"2018-09-22T08:16:00.000Z","updated":"2018-12-19T07:27:54.750Z","comments":true,"path":"2018/09/22/eepalived简介、组件及配置文件/","link":"","permalink":"http://yoursite.com/2018/09/22/eepalived简介、组件及配置文件/","excerpt":"","text":"keepalived是vrrp协议在linux主机上的实现，能够根据配置文件自动生成ipvs规则，对各RS做健康状态检查。1、特点(1)轻量级(2)以守护进程的形式(3)节点类型分为active/passive 2、组件(1)vrrp stack(2)checkers(3)ipvs wrapper 3、keepalived涉及的协议(1)组播:主服务器发送hello信息给从服务器，证明”I am alive”配置同进退vrrp实例时，要注意多播地址，每一组实例默认会分配一个组播地址。如果是在配置文件中指定一个组播地址，则只能配置一组实例；如果需要配置多组实例(不让其中一台主机有空闲)，则需要在各组实例的配置中配置上组播地址 (2)ntp:network time protocol格式:ntpdate timeserver_ip，以这个时间服务器的时间为准，同步自己的时间date命令调整时间的格式:”date 月日时分年.秒” (3)vrrp:virtual routing redundent protocol，虚拟路由冗余协议(vrrp是路由交换协议，keepalived是vrrp在linux上的实现)vrrp是一种容错协议，保证当主机的下一跳路由出现故障时，由另一台路由器来代替出故障的路由器进行工作，从而保障网络通信的连续性和可靠性。在vrrp协议中，分为master和backup两种角色。 vrrp中的一些概念: vrid:虚拟路由器标识，有相同vrid的一组路由器构成一个虚拟路由器 虚拟Mac:一个虚拟路由器拥有一个虚拟Mac，通常情况下虚拟路由器回应arp请求使用的是虚拟Mac 优先级:vrrp根据优先级来确定虚拟路由器中每台路由器的地位 非抢占模式:即使backup路由器的优先级比master高，也不会抢占master的地位 抢占模式:根据优先级的大小来确定谁是master vrrp工作原理: a.虚拟路由器中的路由器根据优先级选举出master，master路由器通过发送免费arp报文，将自己的虚拟Mac地址通知给其他与其连接的设备或主机，从而承担报文转发任务 b.master路由器周期性发送vrrp报文，以公布其配置信息(优先级)和工作状况 c.如果master路由器出现故障，虚拟路由器中的backup路由器将根据优先级重新选举新的master d.虚拟路由器切换时，master路由器由一台设备切换成另外一台设备，新的master路由器只是简单的发送一个携带虚拟路由器的Mac地址和虚拟ip地址信息的免费arp报文，这样就可以更新与之连接的设备或主机的arp信息 e.backup路由器优先级高于master的时候，由backup路由器的工作方式(抢占或非抢占)来决定是否重新选举master vrrp认证方式: a.无认证 b.简单字符认证(将认证字符插入到vrrp报文中) c.md5认证(利用认证字符和MD5算法对vrrp报文进行加密)","categories":[{"name":"keepalived","slug":"keepalived","permalink":"http://yoursite.com/categories/keepalived/"}],"tags":[{"name":"keepalived","slug":"keepalived","permalink":"http://yoursite.com/tags/keepalived/"}]},{"title":"ubuntu 16.04搭建Hexo博客后台管理系统","slug":"ubuntu-16-04搭建Hexo博客后台管理系统","date":"2018-09-20T06:40:00.000Z","updated":"2018-09-20T07:00:40.481Z","comments":true,"path":"2018/09/20/ubuntu-16-04搭建Hexo博客后台管理系统/","link":"","permalink":"http://yoursite.com/2018/09/20/ubuntu-16-04搭建Hexo博客后台管理系统/","excerpt":"","text":"1、安装Hexo-adminnpm install –save hexo-admin #之前已经介绍安装Hexo,参考链接:https://leungzj.github.io/2018/09/19/ubuntu16-04-%E6%90%AD%E5%BB%BAHexo%E5%8D%9A%E5%AE%A2/ 2、启动服务hexo s &amp; 3、访问后台http://你的ip地址:4000/admin 4、后台启用密码登录(默认无密码)点击”Setup authentification here” 弹出设置窗口，按要求填入登录用户名和密码，然后将”admin config section”下面那一段代码复制到Hexo的配置文件_config.yml即可 5、重启Hexokillall hexohexo s &amp; 6、更换Hexo主题先切换到Hexo所在安装目录，通过git下载主题文件到本地文件夹git clone https://github.com/BosenY/Lap.git theme/lap #Hexo主题汇总链接:https://hexo.io/themes/ 7、修改Hexo配置文件_config.yml 8、保存配置文件，重新生成并重启Hexo服务hexo ghexo dkillall hexohexo s &amp;","categories":[{"name":"搭建篇","slug":"搭建篇","permalink":"http://yoursite.com/categories/搭建篇/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://yoursite.com/tags/Hexo/"}]},{"title":"secureCRT连接ubuntu显示中文乱码的解决方法","slug":"secureCRT显示中文乱码","date":"2018-09-20T05:33:00.000Z","updated":"2018-09-20T05:52:17.443Z","comments":true,"path":"2018/09/20/secureCRT显示中文乱码/","link":"","permalink":"http://yoursite.com/2018/09/20/secureCRT显示中文乱码/","excerpt":"","text":"一、ubuntu设置1、在/var/lib/locales/supported.d/local文件中添加一行:zh_CN.UTF-8 UTF-8 执行sudo locale-gen下载文件 2、在/etc/environment文件中添加两行:LANG=”zh_CN.UTF-8”LC_ALL=”zh_CN.UTF-8” 3、在~/.profile文件中添加两行:export LANG=”zh_CN.UTF-8”export LC_ALL=”zh_CN.UTF-8 执行source ~/.profile 二、secureCRT设置1、选择options – session options，弹出设置窗口2、选择terminal – emulation，terminal下拉表选择linux，并在”ansi color”前面方框打上勾 3、选择terminal – appearance，”current color scheme”选择traditional font字体选择fangsong，script选择”Chinese GB2312” character encoding下拉表选择utf-8 退出当前crt窗口，重新登录试试！","categories":[{"name":"工具篇","slug":"工具篇","permalink":"http://yoursite.com/categories/工具篇/"}],"tags":[{"name":"secureCRT","slug":"secureCRT","permalink":"http://yoursite.com/tags/secureCRT/"}]},{"title":"ubuntu16.04 源码编译安装boost1_59_0","slug":"ubuntu16-04-源码编译安装boost1-59-0","date":"2018-09-19T08:31:00.000Z","updated":"2018-09-19T08:38:34.285Z","comments":true,"path":"2018/09/19/ubuntu16-04-源码编译安装boost1-59-0/","link":"","permalink":"http://yoursite.com/2018/09/19/ubuntu16-04-源码编译安装boost1-59-0/","excerpt":"","text":"1、下载源码包wget https://iweb.dl.sourceforge.net/project/boost/boost/1.59.0/boost_1_59_0.tar.gz 2、解压缩tar zxvf boost_1_59_0.tar.gz 3、进入解压缩目录cd boost_1_59_0/ 4、运行bootstrap.sh脚本./bootstrap.sh –with-libraries=all –with-toolset=gcc参数解释:–with-libraries指定编译哪些boost库，all的话就是全部编译，只想编译部分库的话就把库的名称写上，用逗号分隔即可–with-toolset指定编译时使用哪种编译器，Linux下使用gcc即可，如果系统中安装了多个版本的gcc，在这里可以指定gcc的版本，比如–with-toolset=gcc-4.4 5、编译boost./b2 toolset=gcc 6、安装boost./b2 install可以加–prefix参数:用来指定boost的安装目录，不加此参数的话默认的头文件在/usr/local/include/boost目录下，库文件在/usr/local/lib/目录下 7、更新系统的动态链接库ldconfig","categories":[{"name":"安装篇","slug":"安装篇","permalink":"http://yoursite.com/categories/安装篇/"}],"tags":[{"name":"boost","slug":"boost","permalink":"http://yoursite.com/tags/boost/"}]},{"title":"ubuntu16.04 搭建Hexo博客","slug":"ubuntu16-04-搭建Hexo博客","date":"2018-09-19T06:56:00.000Z","updated":"2018-09-19T09:09:42.422Z","comments":true,"path":"2018/09/19/ubuntu16-04-搭建Hexo博客/","link":"","permalink":"http://yoursite.com/2018/09/19/ubuntu16-04-搭建Hexo博客/","excerpt":"","text":"一、安装Node.js1、安装curlapt install curl 2、安装node.jscurl -sL https://deb.nodesource.com/setup_8.x | sudo -E bash -apt install -y nodejs 3、检查版本(有版本号输出表示安装完成)node -vnpm -v 二、安装Hexo1、npm install -g hexo-cli 2、进入你希望建站的文件夹(必须是一个空的文件夹)，执行初始化命令:hexo init 3、安装依赖包:npm install 至此，Hexo本地博客搭建完成。 三、Hexo常用命令hexo help:查看帮助hexo init:初始化一个目录hexo generate:生成网页，在public目录查看整个网站的文件，简写为hexo ghexo server:用来启动本地站点，执行后即可在浏览器中输localhost:4000查看，简写为hexo shexo deploy:部署.deploy目录，可以简化为hexo dhexo clean:清除缓存，强烈建议每次部署deploy之前先清理缓存 四、使用github pages服务部署hexoGiuhub Page介绍:我们用来托管博客的服务叫做 Github Pages，它是 Github 用来提供给个人/组织或者项目的网页服务，只需要部署到你的 Github Repository，推送代码，便可以实时呈现。 1、首先要使用邮箱注册Github账号 2、设置gitgit config –global user.email “you@example.com“git config –global user.name “Your Name” 3、安装插件npm install hexo-deployer-git –save #为了部署到Github上，需要安装hexo-deployer-git插件 4、生成ssh秘钥ssh-keygen -t rsa -C you@example.com #-C后面跟住你在github的用户名邮箱，这样公钥才会被github认可 5、查看你的公钥，添加到Github账户的sshkey中less ~/.ssh/id_rsa.pub 6、Github上新建项目，项目名称为”用户名.github.io”，例如我的用户名是leungzj，则创建的项目名为leungzj.github.io 7、在setting–SSH and GPG keys中，添加生成的公钥，也就是将~/.ssh/id_rsa.pub的内容添加到这里 8、修改Hexo配置文件 9、编译并上传部署到Githubhexo generate #编译hexo deploy #将hexo部署到Github io上 10、访问Hexo博客通过用户名.github.io就可以Hexo博客啦！例如我的博客:https://leungzj.github.io/","categories":[{"name":"搭建篇","slug":"搭建篇","permalink":"http://yoursite.com/categories/搭建篇/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://yoursite.com/tags/Hexo/"}]},{"title":"ubuntu16.04 源码编译安装mysql5.7","slug":"安装篇-ubuntu16-04-安装mysql5-7","date":"2018-09-19T05:36:00.000Z","updated":"2019-01-09T07:07:07.173Z","comments":true,"path":"2018/09/19/安装篇-ubuntu16-04-安装mysql5-7/","link":"","permalink":"http://yoursite.com/2018/09/19/安装篇-ubuntu16-04-安装mysql5-7/","excerpt":"","text":"1、安装依赖sudo apt-get install make cmake gcc g++ bison libncurses5-dev build-essential 2、下载mysql 5.7源码包下载地址：https://dev.mysql.com/downloads/mysql/在”select operating system”中选择”source code”，我下载的版本是mysql-5.7.23 3、解压缩tar zxvf mysql-5.7.23.tar.gz -C /usr/localcd /usr/local/mysql-5.7.23/ 4、编译安装cmake . -DCMAKE_INSTALL_PREFIX=/usr/local/mysql -DMYSQL_DATADIR=/usr/local/mysql/data -DSYSCONFDIR=/etc -DWITH_INNOBASE_STORAGE_ENGINE=1 -DWITH_ARCHIVE_STORAGE_ENGINE=1 -DWITH_BLACKHOLE_STORAGE_ENGINE=1 -DWITH_PARTITION_STORAGE_ENGINE=1 -DWITH_PERFSCHEMA_STORAGE_ENGINE=1 -DWITHOUT_EXAMPLE_STORAGE_ENGINE=1 -DWITHOUT_FEDERATED_STORAGE_ENGINE=1 -DDEFAULT_CHARSET=utf8 -DDEFAULT_COLLATION=utf8_general_ci -DWITH_EXTRA_CHARSETS=all -DENABLED_LOCAL_INFILE=1 -DWITH_READLINE=1 -DMYSQL_UNIX_ADDR=/usr/local/mysql/mysql.sock -DMYSQL_TCP_PORT=3306 -DMYSQL_USER=mysql -DCOMPILATION_COMMENT=”lq-edition” -DENABLE_DTRACE=0 -DOPTIMIZER_TRACE=1 -DWITH_DEBUG=1 运行到这一步，出现报错信息:“CMake Error at cmake/boost.cmake:81 (MESSAGE): You can download it with -DDOWNLOAD_BOOST=1 -DWITH_BOOST=“提示需要安装boost库，安装参考链接:https://leungzj.github.io/2018/09/19/ubuntu16-04-%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85boost1-59-0/ makemake install 5、配置mysql(1)创建用户和用户组groupadd mysqluseradd -g mysql mysql (2)设置mysql安装目录的权限cd /usr/local/mysqlchown -R mysql:mysql ./ (3)mysql初始化 #这里会生成一个mysql临时登录密码，需要记下来，稍后登录mysql会用到bin/mysqld –initialize –user=mysql (4)启动mysqlsupport-files/mysql.server start (5)修改mysql登录密码bin/mysql -u root -pSET PASSWORD FOR ‘root‘@’localhost’ = PASSWORD(‘newpassword’); 6、远程连接mysql用类似navicat的客户端连接mysql，如果出现提示”is not allowed to connect”，需要在mysql命令行上设置远程连接权限，检查iptables是否开放3306端口(1)GRANT ALL ON . TO ‘root‘@’%’ IDENTIFIED BY ‘password’ WITH GRANT OPTION;(2)iptables -A INPUT -P tcp –dport 3306 -j ACCEPT","categories":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/categories/mysql/"}],"tags":[]}]}