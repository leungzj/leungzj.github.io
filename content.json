{"meta":{"title":"Jim's Blog","subtitle":null,"description":null,"author":"Jim","url":"http://yoursite.com"},"pages":[{"title":"","date":"2018-10-30T03:17:12.022Z","updated":"2018-10-30T03:17:12.022Z","comments":true,"path":"baidu_verify_HCnRC8FAR2.html","permalink":"http://yoursite.com/baidu_verify_HCnRC8FAR2.html","excerpt":"","text":"HCnRC8FAR2"},{"title":"","date":"2018-10-17T02:15:56.847Z","updated":"2018-10-17T02:15:56.843Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":"关于运维工程师，熟悉网络、运维、数据库、自学前端、python，志向于全栈认证：CCNA,SAA,PMP,中级网络工程师，目前在考高级项目管理师 { name: ‘jim’ age: ‘28’ gender: ‘男’ profession: ‘Operation’ experience: ‘3年’ address: ‘广东省广州市’ education: ‘本科’ github: ‘https://github.com/leungzj&#39; email: &#39;18826400669@163.com‘ blog: ‘leungzj.github.io’ description: ‘技术改变世界’ skills: [ 网络、运维、SQL、python...(持续更新中) ] }"},{"title":"","date":"2018-10-24T03:57:39.862Z","updated":"2018-10-24T03:57:39.854Z","comments":true,"path":"books/index.html","permalink":"http://yoursite.com/books/index.html","excerpt":"","text":"docker:《第一本docker书》 python:《python编程:从入门到实践》 mongodb:《MongoDB权威指南》"},{"title":"categories","date":"2018-09-19T09:02:45.000Z","updated":"2018-09-19T09:06:58.378Z","comments":true,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2018-10-17T03:21:43.737Z","updated":"2018-10-17T03:21:43.733Z","comments":false,"path":"links/index.html","permalink":"http://yoursite.com/links/index.html","excerpt":"","text":""},{"title":"标签","date":"2018-10-17T02:54:58.153Z","updated":"2018-10-17T02:54:58.153Z","comments":false,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"","slug":"Untitled-1","date":"2018-11-15T09:04:00.000Z","updated":"2018-11-15T09:51:25.588Z","comments":true,"path":"2018/11/15/Untitled-1/","link":"","permalink":"http://yoursite.com/2018/11/15/Untitled-1/","excerpt":"","text":"1、进程的优先级:0-139，一共140个优先级，数字越小，优先级越高。0-99:内核决定的100-139:可以由用户调整的备注:(1)用户可以通过调整nice值来进行调整，默认每个进程的nice值都是0。(2)nice值的取值范围是-20到19，对应100-139 #普通用户只能调大nice值来降低优先级，管理员才能调大和调小nice值(3)调整nice值:调整已经启动的进程的nice值:renice NI PID在启动时指定nice值:nice -n NI COMMAND(4)每一个进程的相关属性信息在/proc目录下，其下的每一个目录对应一个进程，数字表示的目录对应进程号是那个数字的进程(5)init进程是第一个进程,是所有进程的父进程。init的进程号是1 2、查看进程的命令:(1)ps:有两种风格sysV风格(需要加-)ps -o 字段 #显示指定字段的信息(默认只显示前台进程)ps -axo 字段1，字段2 #显示所有的进程(前台和后台) BSD风格(不需要加-)a:显示所有跟终端有关的进程u:显示进程跟哪个用户相关x:显示所有跟终端无关的进程 (2)pstree:显示当前系统的进程树(进程与子进程)(3)pgrep 进程:显示指定进程的进程号-u user:指定以哪个用户的身份运行的进程(4)pidof 程序:根据程序名称，查找其相关进程的ID号 3、进程的分类:(1)跟终端相关的进程:在终端中通过命令行启动(2)跟终端无关的进程:系统启动的时候自动启动的进程，用户还没有登录就已经产生的进程 4、进程的状态:(1)D:不可中断的睡眠(2)S:可中断的睡眠(3)R:运行或就绪(4)T:停止(5)Z:僵死(6)&lt;:高优先级进程(7)N:低优先级进程(8)+:前台进程组中的进程(9)l:多线程进程(10)s:会话进程首进程 5、杀死进程:(1)信号的分类: #kill -l:可以查看各种信号名称及对应的号码SIGHUP，用数值1表示，让一个进程不用重启，就可以重读其配置文件，并让新的配置信息生效SIGINT，用数值2表示，相当于ctrl-c，中断一个进程SIGKILL，用数值9表示，杀死一个进程SIGTERM，用数值15表示，终止一个进程 #kill默认发送的就是15号信号(2)指定信号:指定信号号码:kill -9指定信号名称:kill -SIGKILL(3)killall 进程名:但凡是这个进程名的进程都会被杀死","categories":[{"name":"linux进程管理","slug":"linux进程管理","permalink":"http://yoursite.com/categories/linux进程管理/"}],"tags":[{"name":"进程","slug":"进程","permalink":"http://yoursite.com/tags/进程/"}]},{"title":"挂载和卸载","slug":"挂载和卸载","date":"2018-11-13T01:39:00.000Z","updated":"2018-11-13T02:23:10.815Z","comments":true,"path":"2018/11/13/挂载和卸载/","link":"","permalink":"http://yoursite.com/2018/11/13/挂载和卸载/","excerpt":"","text":"挂载:将新的文件系统关联至当前根文件系统卸载:将某文件系统从当前根文件系统的关联关系移除 mount:挂载mount 设备 挂载点备注:1、设备可以是设备文件(/dev/sda5)、卷标(LABEL=”XXX”)、UUID(UUID=”XXX”)2、挂载点必须是目录，要求如下:(1)此目录没有被其他进程使用(2)此目录得事先存在(3)目录中的原有文件将会暂时隐藏3、挂载完成后，通过挂载点访问对应文件系统上的文件4、mount不带任何选项，会显示当前系统中已经挂载的设备以及挂载点可选参数:-a:表示/etc/fstab文件中定义的所有文件系统-n:挂载设备时，不把信息写入mtab文件(默认情况下，mount每挂载一个设备，会把挂载的设备信息保存至/etc/mtab文件)备注:mtab是mount table的简称，直接mount显示的信息就是mtab文件中的信息-t:指定挂载设备上的文件系统类型。不使用此选项时，mount会调用blkid获取对应文件系统类型-r:只读挂载，挂载光盘时常用此选项-w:读写挂载-o:指定额外的挂载选项，也即指定文件系统启用的属性额外的挂载选项有:remount:重新挂载当前文件系统(mount -o remount /dev/sda5 [/mnt/test] 备注:重新挂载的时候，可以省略挂载点)ro:只读挂载(等于-r)rw:读写挂载(等于-w) umount:卸载umount 设备 or umount 挂载点备注:卸载的时候，需要切换到跟挂载点无关的目录上去。如果你在挂载点上运行umount命令，会提示”device is busy”","categories":[{"name":"linux磁盘管理","slug":"linux磁盘管理","permalink":"http://yoursite.com/categories/linux磁盘管理/"}],"tags":[{"name":"挂载","slug":"挂载","permalink":"http://yoursite.com/tags/挂载/"},{"name":"卸载","slug":"卸载","permalink":"http://yoursite.com/tags/卸载/"}]},{"title":"设备文件管理","slug":"设备文件管理","date":"2018-11-12T09:12:00.000Z","updated":"2018-11-12T09:13:40.359Z","comments":true,"path":"2018/11/12/设备文件管理/","link":"","permalink":"http://yoursite.com/2018/11/12/设备文件管理/","excerpt":"","text":"设备文件:设备文件作为设备的访问入口，被内核识别，分两种1、b:块设备，以块为单位进行随机访问，例如硬盘2、c:字符设备，以字符为单位进行线性访问，例如键盘 创建设备文件:mknod -m 权限 文件名 文件类型(b或c) 主设备号 次设备号其中，1、设备文件名:IDE、ATA:hd开头的文件名SATA、SCSI、USB:sd开头的文件名(a、b、c…区分同一类型下的不同设备)2、设备号:/dev目录下的文件有两个数字属性:主设备号:major number，标识设备类型次设备号:minor number，标识同一类型下的不同设备(这种文件没有大小，有点类似于链接文件。因为大小指的是它真正占用磁盘块的大小，而设备文件只是作为设备的一个访问入口，因此没有大小)","categories":[{"name":"linux磁盘管理","slug":"linux磁盘管理","permalink":"http://yoursite.com/categories/linux磁盘管理/"}],"tags":[{"name":"设备文件","slug":"设备文件","permalink":"http://yoursite.com/tags/设备文件/"}]},{"title":"磁盘和分区管理","slug":"磁盘和分区管理","date":"2018-11-12T09:06:00.000Z","updated":"2018-11-13T03:15:52.888Z","comments":true,"path":"2018/11/12/磁盘和分区管理/","link":"","permalink":"http://yoursite.com/2018/11/12/磁盘和分区管理/","excerpt":"","text":"磁盘:真空的，需要防尘，磁盘主要分两种(1)机械硬盘:目前主流，比较遗憾(2)固态硬盘:性能相对好一点的磁盘 磁盘基本术语(硬件方面):(1)盘片(2)盘面:每一块盘片有两块盘面(3)磁头(4)磁道(5)扇区:512字节(6)机械臂(7)柱面:磁道组成的逻辑分区柱面具有以下特点:1、存储数据就是按照柱面来存储的，读取数据也是2、划分分区也是按照柱面来划分3、从外到内，柱面的编号从0开始4、同一个转轴，越靠外面的磁道，转速越快(这也是我们大多数操作系统安装在C盘的原因) 磁盘基本术语(软件方面):磁盘出厂前，需要低级格式化，划分磁道分区1、MBR:master boot record，主引导记录(0盘片0磁道0扇区的那一块地方就是MBR，属于磁盘，是全局的存储空间，独立于操作系统之外)MBR的大小为512字节，分为3个部分，446字节叫做BootLoader，叫做引导加载器，是一段程序代码，作用是引导操作系统正确启动起来；接下来的64字节，每16字节标识一个主分区，因此操作系统最多可以划分4个主分区；剩下的2个字节叫做魔数，标识MBR是否有效。2、分区:partition，划分分区的作用是创建文件系统，每一个分区就是一个文件系统。 要正常使用一块磁盘，需要经过:低级格式化（由硬盘厂商来完成）–做分区–高级格式化（创建文件系统）–挂载 磁盘分区命令:查看当前系统识别了多少块硬盘：fdisk -l查看当前系统某块硬盘的具体信息：fdisk -l /dev/sda管理磁盘分区：fdisk /dev/sda （启动一个交互式界面）m：for helpp：显示当前分区，包括没保存的改动n：创建新的分区e：创建新的扩展分区p：创建新的主分区d：删除一个分区w：保存退出q：不保存退出t：修改分区类型L：修改的时候查看分区类型（以确定某种类型对应的编号）创建完分区之后需要内核识别才能够格式化。查看内核已经识别的分区：cat /proc/partitions通知内核重读分区表：partprobe #Redhat6上使用了新命令:partx备注:partprobe是默认重读所有磁盘上的分区表，当然我们也可以指定内核重读哪一块磁盘，比如说partprobe /dev/sda 创建分区例子:1、创建3个逻辑分区(得先创建扩展分区，在扩展分区的基础上创建逻辑分区。主分区不能创建逻辑分区；扩展分区不能使用，只能使用在扩展分区上划分出来的逻辑分区)(1)fdisk /dev/sda #会进入一个交互界面，备注:进入交互界面后，如果在创建分区的过程中敲错命令，直接删除键是删不掉的，需要按住ctrl+删除键来删除(2)p #查看分区(3)n(4)e #创建扩展分区(5)n(6)+2G #创建第一个逻辑分区，大小为2G(7)n(8)+5G #创建第二个逻辑分区，大小为5G(9)n(10)+1G #创建第三个逻辑分区，大小为1G(11)p #查看分区(12)w #保存退出(13)cat /proc/partitions #查看内核是否识别新创建的分区(14)partprobe /dev/sda #指定内核重读/dev/sda分区表 2、创建SWAP分区(备注:SWAP分区是磁盘上的空间，允许内存过载使用。一旦内存耗尽，可以临时拿硬盘上的SWAP来应急，防止系统崩溃甚至宕机。SWAP分区必须是一个单独的分区)(1)首先新建一个新的分区:fdisk #准备新建分区p #查看已有分区n #新建分区+1G #新建1G的分区L #查看分区类型t #调整分区类型8 #对第几块磁盘调整类型L #查看分区类型82 #linux swap的分区编码p #查看是否已经建好swap分区w #保存退出partprobe /dev/sda #通知内核重读分区表(2)创建好分区之后，需要创建文件系统(swap分区也是有自己的文件系统的)mkswap /dev/sda8(3)启用和关闭交换分区的交换空间(类似于mount，但是有专门的命令，不用mount)启用:swapon /dev/sda8可选参数:-a:启用所有定义在/etc/fstab文件中的交换设备关闭:swapoff /dev/sda8 其他命令:1、blkid:block id，查看磁盘设备的相关属性UUID:用于唯一标识磁盘设备TYPE:用于标识文件系统类型LABEL:显示卷标 2、e2label:专门用于查看或者定义卷标e2label /dev/sda5 查看卷标e2label /dev/sda5 labelname 设定卷标 3、free:查看系统上物理内存和交换分区的使用情况(默认单位是字节)-m:以MB为单位显示内存使用情况buffer:缓冲，保存的是元数据cache:缓存，保存的是数据(这两段空间可以清除数据，不会影响到数据的完整性，对系统性能会有影响) 4、df:显示整个磁盘分区的使用情况(以磁盘块个数来显示大小)可选参数:-h:人性化显示-i:以inode个数显示大小-P:不换行显示备注:与du的区别:du显示目录或者目录的子目录所占用的大小可选参数:-h:人性化显示-s:显示目录所占据的整体的大小 5、dd:复制可选参数:if= #指定数据来源of= #指定数据存储目标bs=1 #以一个字节为单位count=2 #复制2次，跟bs=1结合使用就是复制2个字节的数据例子:1、创建1M的数据:dd if=/dev/zero of=/var/swapfile bs=1 count=10242、拿一个文件，哪怕你没有分区，没有多余的空间可以创建分区，我们照样可以找个文件来暂时性的当做交换分区来使用(性能差，但可以临时救急)(1)dd if=/dev/zero of=/var/swapfile bs=1M count=1024(2)mkswap /var/swapfile(3)swapon /var/swapfile与cp的区别:(1)cp是以文件为单位的，dd是以数据流为单位的(数据流就是01代码)(2)dd可以复制不完整的数据","categories":[{"name":"linux磁盘管理","slug":"linux磁盘管理","permalink":"http://yoursite.com/categories/linux磁盘管理/"}],"tags":[{"name":"磁盘","slug":"磁盘","permalink":"http://yoursite.com/tags/磁盘/"},{"name":"分区","slug":"分区","permalink":"http://yoursite.com/tags/分区/"}]},{"title":"文件系统管理","slug":"ntitled","date":"2018-11-12T09:01:00.000Z","updated":"2018-11-13T03:29:02.942Z","comments":true,"path":"2018/11/12/ntitled/","link":"","permalink":"http://yoursite.com/2018/11/12/ntitled/","excerpt":"","text":"文件系统:1、创建分区之后，要实现快速存储文件和查询文件，需要在这个分区上创建文件系统2、文件系统是一个管理软件，也是存储在磁盘的某个位置上的，但并不是在分区上，文件系统的数据在分区上3、文件系统把分区分为两部分，元数据区域(类似索引)和存储真正数据的区域新增、删除、复制、剪切文件的原理都跟文件系统的原理相关，比如说:(1)为什么剪切文件比复制文件的速度要快答:因为剪切的时候数据内容不变，变的是inode(2)为什么有些文件删除了还可以通过文件恢复器找回来？文件粉碎机的原理是什么？答:删除就是删除inode对应的磁盘块，原来的数据原封不动；粉碎就是用一堆随机数去覆盖原来的数据4、linux支持的文件系统:ext2、ext3、ext4、xfs、reiserfs、jfs、nfs…备注:(1)linux的vfs(虚拟文件系统)使得linux可以支持不同类型的文件系统(2)linux也支持fat32格式(windows平台)文件系统，但是本身不叫fat32，而叫做vfat；同样支持NTFS(windows平台)文件系统,但是支持不太好，写入速度慢，甚至严重的话会导致系统崩溃(3)要留意内核支持哪些文件系统，比如ext2，ext3等。只有内核中具有某种文件系统的模块，它才能支持这种文件系统。cat /proc/filesystems:查看当前内核所支持的文件系统类型(4)ext3和ext2的区别:ext3:日志文件系统，分为3个区域，元数据区、数据区、日志区。对数据进行读写操作的时候，先把inode放到日志区进行操作，操作完成之后再放到元数据区。如果这时候断电或者系统崩溃，下次开机的时候直接查找日志区有哪些inode文件就可以知道有哪些文件是损坏的，而不用从头到尾扫描所有的文件。ext3最大的功能在于能够加快文件系统修复的速度。ext2:就是采取从头到尾的扫描方式，如果存储数据很大的话这样扫描查找会导致机器崩溃，修复速度很慢。ext2是linux上唯一的非日志文件系统。有些情况下，对于安全性、完整性要求不高并且会频繁的大量读写小文件的时候，使用ext2尤佳。 创建完分区，下面就可以创建文件系统commands:1、mkfs:make file system，创建文件系统-t 指定文件系统类型mkfs -t ext2 = mkfs.ext2mkfs -t ext3 = mkfs.ext3mkfs -t vfat = mkfs.vfat2、mke2fs:专门创建或者管理ext系列文件系统:-j journal，直接创建ext3系列的文件系统(默认是创建ext2系列的文件系统)-b 指定block size(块大小)，默认是4096，可以取值为1024,2048-L 指定分区label(卷标)-m # 指定预留给超级用户的块数百分比(直接指定数字即可，不用加%。防止空间填满管理员也无法进入，因此预留一些空间出来，默认应该是20%)-i # 指定为多少字节的空间创建一个inode(默认是8192，这里给出的数值应该是块大小的2^n倍。块大小默认是4096字节)-F #强制创建文件系统(少用)-E #用户指定额外的文件系统属性(少用) 3、tune2fs:调整文件系统相关属性(例如:tune2fs -j /dev/sda2)可选参数:-j:不损坏原有数据，将ext2升级为ext3-L labelname:设定或修改卷标-m #:调整预留百分比-r #:指定预留块数-c #:指定挂载次数达到#次之后进行自检，0或者-1表示关闭此功能-i #:每挂载使用多少天之后进行自检，0或者-1表示关闭此功能(因为系统默认是挂载达到多少次或者多少天之后进行自检，如果文件很大而自检次数hen频繁的话，系统的IO会很高，有时会影响到系统的性能。所以通过设定-c和-i来修改默认的自检次数或者天数)-l /dev/sda5:显示超级块的信息(所有块组的信息都存储在超级块中)-o:设定默认挂载选项 4、dumpe2fs:显示文件系统属性信息可选参数:-h:只显示超级块中的信息 5、fsck:filesystem check，检查并修复linux文件系统可选参数:-t:指定文件系统类型(不指定也没关系，fsck会自动调用blkid来查看类型)-a:自动修复(不与用户交互) 6、e2fsck:专门用于检查并修复ext2、ext的文件系统可选参数:-f:强制检查-p:自动修复(也可以使用-a) 文件系统配置文件:/etc/fstabOS在初始化时，会自动挂载此文件中定义的每个文件系统配置文件格式:第一列:要挂载的设备，/dev/sda5第二列:挂载点，/mnt/test第三列:文件系列类型，ext3第四列:挂载选项，默认是defaults第五列:转储频率，跟文件系统备份相关，每多少天做一次完全备份第六列:文件系统检测次序，只有根文件系统为1，可以多个文件系统为2。0标识不检测注意事项:(1)以上设置可以让/dev/sda5在开机之后自动挂载到/mnt/test上(2)如果挂载设备时一个swap分区的话，它的挂载点也是swap(3)伪文件系统:tmpfs、devpts、sysfs、proc，用来实现特定功能的，不得不挂载(2)转储频率:0表示不备份，1表示每天都要备份，2表示每2天备份一次等等","categories":[{"name":"linux磁盘管理","slug":"linux磁盘管理","permalink":"http://yoursite.com/categories/linux磁盘管理/"}],"tags":[{"name":"文件系统","slug":"文件系统","permalink":"http://yoursite.com/tags/文件系统/"}]},{"title":"linux软件包管理器--rpm","slug":"Untitled-2","date":"2018-10-31T03:15:00.000Z","updated":"2018-10-31T03:57:26.092Z","comments":true,"path":"2018/10/31/Untitled-2/","link":"","permalink":"http://yoursite.com/2018/10/31/Untitled-2/","excerpt":"","text":"1、软件包管理器核心功能:(1)打包成一文件:二进制程序，库文件，配置文件，帮助文件 – 制作软件包(2)生成数据库:追踪所安装的每一个文件(例如将来卸载的时候就到各自的目录去移除即可) – 安装、卸载、升级、查询、校验 2、rpm命名：主包:bind-9.7.1-1.i586.el5.rpm子包:bind-libs-9.7.1-1.i586.el5.rpmbind-utils-9.7.1-1.i586.el5.rpm包名格式:name-version-release.arch.rpmbind-major.minor.release-release.arch.rpm(第一个release是制作者的发行号，第二个release是下载之后改良之后的发行号)举例子:bind-9.7.1-1.noarch.rpm(既可以在32位平台上运行，又可以在64位平台上运行。表示跟平台没有关系，什么平台上安装都可以运行)bind-9.7.1-1.ppc.rpm(这表明在powerPC平台上运行) 总结:(1)name-version-release.arch(版本号，发行号，平台)(2)版本号又可以分为主版本号（mahor）和次版本号（minor）(3)主版本号:重大改进 次版本号:某个子功能发生重大改变 发行号(也叫修正号):修改了部分bug，调整了一点功能 3、rpm包分类：两种格式：(1)二进制格式：已经编译好的(2)源码格式：未编译的 各有优劣：(1)二进制格式已经编译好，简便快捷。因为源码编译对于一些大型的软件是一个很繁杂的过程。因此二进制格式的RPM包的版本有时候很长一段时间都不会更新。因此版本会落后于源码包，甚至落后很多，所以也会发生一些漏洞而带来一些安全性的问题。(2)源码格式需要在自己的主机上编译，能够更好地依赖主机的硬件性能。有些特性是编译的时候选定的，源码编译可以根据自己的需要来安装某些特定的我们需要的功能特性。 4、rpm功能安装，查询，卸载，升级，校验，数据库的重建，验证数据等工作(1)安装：rpm -i 路径/包文件-h:以#显示进度，每个#表示2%-v:显示详细过程-vv:显示更加详细的过程 –nodeps:忽略依赖关系 –replacepkgs:重新安装，替换原有安装 –oldpackage:降级，就是升级了新版本之后发现跟其他软件包有冲突然后做降级处理 –force:强制安装，可以实现重装或者降级（’–’表示二级参数）常用选项:-ivh (2)查询rpm -q 包名(不是文件，文件是以.rpm结尾) ==》注：上面包名格式中的name字段就是包名例如：zsh-4.2.6-6.el5.i386.rpm ==》这是包文件zsh ==&gt;这才是包名===包名-q:查询指定的包是否已经安装-qa:查询已经安装的所有包（其后不需要指定包名）-qi:查询指定包的说明信息（比如说rpm包的功能，什么时候安装的，谁制作的，rpm包的大小等等）-ql:查询指定包安装后生成的文件列表-qc:查询指定包安装的配置文件-qd:查询指定包安装的帮助文件-q –script:查询指定包中包含的脚本（包含四类脚本：安装前，安装后，卸载前，卸载后）===文件名-qf 路径/文件名:查询指定的文件是由哪个rpm包生成的备注:如果某rpm包尚未安装而我们需要查询其说明信息、安装后会产生的文件等：(在-p参数就可以)rpm -qpi 路径/包文件（包文件跟文件名又不一样）rpm -qpl 路径/包文件rpm -qpc 路径/包文件rpm -qpd 路径/包文件 (3)升级rpm -Uvh 路径/新的包文件 #如果装有老版本的，则升级；否则，则安装rpm -Fvh 路径/新的包文件 #如果装有老版本的，则升级；否则，则退出 –oldpackage:降级 (4)卸载rpm -e 包名 –nodeps 忽略依赖关系 (5)校验rpm -V 包名 (6)重建数据库:rpm的数据库在:/var/lib/rpm下rpm –rebuild:重建数据库。一定会重新建立，不管有还是没有 –initdb:初始化数据库。没有才建立，有就不用建立 (7)检验来源合法性及软件完整性rpm –import /etc/pki/rpm-gpg/RPM-GPG-KEY-redhat-release（先导入密钥，不然运行下一步-K会报错）rpm -K 包文件dsa,gpg:验证来源合法性，也就是验证签名，可以使用–nosignature，略过此项sha1,md5:验证软件包完整性，可以使用–nodigest，略过此项","categories":[{"name":"linux软件管理","slug":"linux软件管理","permalink":"http://yoursite.com/categories/linux软件管理/"}],"tags":[{"name":"rpm","slug":"rpm","permalink":"http://yoursite.com/tags/rpm/"}]},{"title":"IP、TCP、UDP","slug":"IP报文和TCP报文","date":"2018-10-31T01:47:00.000Z","updated":"2018-10-31T02:42:22.783Z","comments":true,"path":"2018/10/31/IP报文和TCP报文/","link":"","permalink":"http://yoursite.com/2018/10/31/IP报文和TCP报文/","excerpt":"","text":"1、IP报文(1)IP VERSION:IP版本号(2)HEAD LEN:报文首部长度(3)TYPE OF SERVICE(TOS):服务类型(在现实生活中比如快递中的加急快件等)(4)TOTAL LEN:整个数据报文的长度(5)FRAGMENT ID:标识分片之后的报文;FRAGMENT OFFSET:标识分片之后的报文组合 #其中MF(MORE FRAGMENT)值为1表示报文分片;DF值为1表示报文没有分片(6)TTL:定义最大跳数(7)PROTOCOL:定义IP网络层上一层的协议(8)HEADER CHECKSUM:校验和，判断数据前后是否一致(9)源IP(10)目的IP(11)OPTION:可选选项(12)要传输的数据 2、TCP报文(1)TCP HEADER:TCP首部(2)SOURCE PORT:源端口(3)DESTINATION PORT:目标端口(4)SEQUENCE NUMBER:序列号(5)ACKNOWLEDGEMENT NUMBER:确认号(6)HEADER LENGTH:首部长度(7)URG:紧急位(8)URGENT POINTER:紧急指针(URG值为1表示指针有效，否则指针无效)(9)ACK:确认位(确认位为1，确认号有效；确认位为0，确认号无效)(10)PUSH值为1表示有优先传输的特权(因为数据传输都是通过网卡来传输的，不同的进程数据，在发送之前，会放置发送缓冲区当中再逐个的往外发送；同样的接收数据也会先保存到接收缓冲区当中。PUSH为1表示不再先保存至缓冲区当中，而是直接往外发送或者接收)(11)RST:重置位(12)SYN:三次握手发的包(13)FIN:四次关闭发的包(14)WINDOW SIZE:窗口大小(当发送方发送数据的速率和接收方接收数据的速率不一致的时候需要用到，其实发送速率和接收速率取决于发送缓冲区和接收缓冲区可容纳的数据)(15)TCP CHECKSUM:TCP校验和(16)OPTION:可选选项(17)DATA:数据 3、TCP与UDP的区别:TCP，transmission control protocol，传输控制协议(相当于打电话，特点是可靠，但是效率低)UDP，user datagram protocol，用户数据报协议(相当于发短信，特点是不靠谱，但是速度快)备注:对于即时通讯都是采用UDP协议，比如QQ，它是在应用层来保证通讯的可靠性 4、三次握手和四次关闭:(1)三次握手A:SYN=1,sn=100(sn即seq num，序列号，随机生成)B:SYN=1,ACK=1,an=101(an即ack num，确认号，序列号加1)，sn=300(随机生成)A:ACK=1,an=301(2)四次关闭A:FIN=1B:ACK=1B:FIN=1A:ACK=1","categories":[{"name":"linux网络管理","slug":"linux网络管理","permalink":"http://yoursite.com/categories/linux网络管理/"}],"tags":[{"name":"IP","slug":"IP","permalink":"http://yoursite.com/tags/IP/"},{"name":"TCP","slug":"TCP","permalink":"http://yoursite.com/tags/TCP/"},{"name":"UDP","slug":"UDP","permalink":"http://yoursite.com/tags/UDP/"}]},{"title":"linux软件编译安装","slug":"inux软件编译安装","date":"2018-10-30T06:09:00.000Z","updated":"2018-10-30T06:37:31.958Z","comments":true,"path":"2018/10/30/inux软件编译安装/","link":"","permalink":"http://yoursite.com/2018/10/30/inux软件编译安装/","excerpt":"","text":"首先，程序运行过程：源程序–&gt;编译–&gt;链接–&gt;运行c语言是将源代码编译成二进制格式，编译需要编译环境(开发环境)、编译工具等(跟C语言相比，脚本语言是解释器直接解释成二进制格式，不需要编译) 编译环境:因为linux的内核是使用c语言开发的，有部分跟平台相关的代码是用汇编语言写的。linux上运行的众多gnu软件，大多数也是用c开发的。因此最流行的的开发环境：C、C++、PERL、JAVA、PYTHON等。 编译工具:gcc:C的编译工具，全称是GNU complier cg++:C++的编译工具make:C或者C++的项目管理工具makefile:定义了make按什么顺序去编译这些源程序文件中的源程序automake:–&gt;makefile.in–&gt;makefileautoconf:–&gt;configure 编译安装三步骤:(注意要在源程序的目录下操作)前提:准备开发环境(编译环境)，最简单的就是安装两个组”Development tools”和”Development libraries”1、configure–help #获取帮助–prefix= #指定软件安装路径(会自动生成/bin和/sbin目录)–sysconfdir= #指定配置文件安装目录(如果不指定的话，默认安装在软件安装路径下的conf目录或者etc目录)–conf-path= #指定配置文件安装文件configure功能:(1)让用户选择编译特性(通过参数赋值)(2)检查编译环境2、make3、make install 编译安装之后的一些环境变量的问题:1、修改PATH环境变量，以能够识别此程序的二进制文件路径(提示找不到命令，大多是原因是命令的路径没有包含在$PATH中)在/etc/profile.d/目录下建立一个以.sh为名称后缀的文件，在里面定义export PATH=$PATH:/path/to/somewhere然后重新登录一下终端，比如克隆一个终端，配置即可生效 2、默认情况下，系统搜索库文件的路径是/lib，/usr/lib，要增加额外的搜索路径在/etc/ld.so.conf.d/目录下创建以.conf为后缀名的文件，然后把要增添的路径写到此文件中(例如apache的库文件路径/usr/local/apache/lib)然后运行ldconfig，通知系统重新搜索库文件-v则显示重新搜索库文件的过程 3、增加头文件的搜索路径，默认是/usr/include增加搜索路径的方式有两种:(使用链接)ln -s /usr/local/apache/include/* /usr/include(这会创建一堆链接，对将来管理这些链接的时候不方便)ln -s /usr/local/apache/include /usr/include/apache(推荐使用这种方式) 4、man文件路径默认安装在–prefix指定的目录下的man目录","categories":[{"name":"linux软件管理","slug":"linux软件管理","permalink":"http://yoursite.com/categories/linux软件管理/"}],"tags":[{"name":"编译安装","slug":"编译安装","permalink":"http://yoursite.com/tags/编译安装/"}]},{"title":"rpm包的前端工具--yum","slug":"rpm包的前端工具-yum","date":"2018-10-30T03:45:00.000Z","updated":"2018-10-30T06:04:32.012Z","comments":true,"path":"2018/10/30/rpm包的前端工具-yum/","link":"","permalink":"http://yoursite.com/2018/10/30/rpm包的前端工具-yum/","excerpt":"","text":"why–为什么是yumyum依赖于rpm，功能比rpm强大因为rpm有一个很大的缺陷就是依赖关系，yum的出现就是用来解决依赖关系的 what–什么是yum(1)yum架构:C/S架构(2)yum仓库:yum的工作依赖于server端的yum仓库(yum repository)yum仓库中的元数据文件(位于repodata目录下):primary.xml.gz:所有rpm包的列表、各种包的依赖关系、每个rpm包安装生成的文件列表(局部概念)filelists.xml.gz:当前仓库中所有rpm包的文件列表(全局概念)other.xml.gz:额外信息，rpm包的修改日志(单个软件包各个发行版的发行时间、作者等)repomd.xml:记录的是上面三个文件的时间戳和校验和comps*-.xml:rpm分组信息(3)yum配置:/etc/yum.confyum仓库的配置文件:/etc/yum.repos.d/目录下面的各个文件就是各个仓库文件(文件名格式:file.repo，必须是以repo结尾)定义repo文件:(for example)[Repo_ID]name=Descriptionbaseurl= #有三种路径，ftp、http、file(本地)ftp://http://file:///(第3个/表示根路径)enable={1|0} #1表示启用gpgcheck={1|0} #1表示校验gpgkey= #如果设置gpgcheck=1必须有此项，否则不需要此项 how–怎么使用yum备注:要注意跟rpm命令对比下，很多命令的功能是差不多的(1)yum clean:清缓存(2)yum list [all|available|installed]:查看所有的安装包，包括安装的和未安装的(已安装的最后一个字段显示install，未安装的显示[Repo_ID]，也就是仓库文件里面的第一行定义的那个ID)yum list all:显示所有的软件包(直接yum list默认也是显示所有的软件包)yum list available:可用的，仓库中有但是未安装的yum list installed:已经安装的yum list updates:可用的升级yum list all +通配符的包名:查看匹配的软件包(3)yum repolist [all|enabled|disabled]:查看库的信息yum repolist all:显示所有repo列表及其简要信息yun repolist enabled:显示可用的repo列表及其简要信息(直接yum repolist默认就是显示enabled的repo表)yum repolist disabled:显示不可用的repo列表及其简要信息(4)yum install:安装软件包(5)yum update:默认升级到最新版本yum update-to:指定升级到特定版本(6)yum remove/rease:卸载(7)yum info:查看软件包的简要信息(8)yum provide/whatprovides:查看指定的文件或特性是由哪个包生成的(9)软件包组groupyum groupinfoyum grouplistyum groupremoveyum groupupdateyum groupinstallyum grouplocalinstall备注:groupinstall和grouplocalinstall的区别在于，install只需要指定包名，localinstall则必须指定包文件，也就是以rpm包结尾的文件。用yum相比用rpm安装的好处在于，如果仓库中刚好包有依赖包，yumlocalinstall可以解决依赖关系 创建yum仓库:createrepo命令","categories":[{"name":"linux软件管理","slug":"linux软件管理","permalink":"http://yoursite.com/categories/linux软件管理/"}],"tags":[{"name":"yum","slug":"yum","permalink":"http://yoursite.com/tags/yum/"}]},{"title":"ubuntu16.04安装MongoDB","slug":"MongoDB","date":"2018-10-24T07:30:00.000Z","updated":"2018-10-24T08:05:13.425Z","comments":true,"path":"2018/10/24/MongoDB/","link":"","permalink":"http://yoursite.com/2018/10/24/MongoDB/","excerpt":"","text":"1、通过tgz压缩包安装:(1)wget https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-ubuntu1604-4.0.3.tgz(2)tar zxvf mongodb-linux-x86_64-ubuntu1604-4.0.3.tgz(3)cp -pr mongodb-linux-x86_64-ubuntu1604-4.0.3 /usr/local/mongodb #-p表示保留源文件的属性，-r表示递归复制(4)bin/mongod &amp; #会报错，因为不指定数据目录的时候，默认会以/data/db目录作为数据目录，因此不存在/data/db目录时会报错，可以创建一个/data/db目录，也可以在启动mongod的时候指定dbpath为自定义的数据目录，像这样:bin/mongod –dbpath= ~/db(5)可以通过bin/mongod –help来查看mongod的帮助选项备注:通过这样的方式安装的mongod，默认没有配置文件，需要自己创建配置文件。一般不建议通过这种方式安装mongod 2、通过apt-get安装:(1)导入软件源公钥sudo apt-key adv –keyserver hkp://keyserver.ubuntu.com:80 –recv EA312927(2)为mongodb创建软件源list文件ubuntu16.04:echo “deb http://repo.mongodb.org/apt/ubuntu xenial/mongodb-org/3.4 multiverse” | sudo tee /etc/apt/sources.list.d/mongodb-org-3.4.list #mongodb-org/3.4 的3.4 为版本号，可更换为你想要安装的版本(3)更新软件源sudo apt-get update #更新的时候可能会报错，提示由于没有公钥，无法验证下列签名： NO_PUBKEY 3EE66BD3F599ACE3这时候，只需要重新运行第一步，软件源公钥替换成错误提示中的key，然后重新运行sudo apt-get update(4)安装mongodbapt-get install -y mongodb-org #如果想要安装指定的版本，使用下面的命令:sudo apt-get install -y mongodb-org=3.2.9 mongodb-org-server=3.2.9 mongodb-org-shell=3.2.9 mongodb-org-mongos=3.2.9 mongodb-org-tools=3.2.9(上面的命令需要把3.4改为3.2)(5)开机启动systemctl enable mongod(6)启动、停止mongod和查看mongod服务状态systemctl start mongod.servicesystemctl stop mongod.servicesystemctl status mongod.service备注:mongodb启动报错，其中大量提到WiredTiger error，主要报错提示如下txn-recover: unsupported WiredTiger file version WiredTiger error这时候，把/data/db目录下的文件清空，再重新启动就可以了(亲测有效)，但是如果数据库中有重要数据, 不建议采取此方法。安装参考链接:https://github.com/cgDeepLearn/LinuxSetups/blob/master/docs/databases/mongodb.md 补充mongodb图形化工具:NoSQLBooster for MongoDB(windows)下载链接:https://nosqlbooster.com/downloads工具截图:","categories":[{"name":"安装篇","slug":"安装篇","permalink":"http://yoursite.com/categories/安装篇/"}],"tags":[{"name":"mongodb","slug":"mongodb","permalink":"http://yoursite.com/tags/mongodb/"}]},{"title":"QA","slug":"QA","date":"2018-10-22T03:29:00.000Z","updated":"2018-10-29T04:07:10.034Z","comments":true,"path":"2018/10/22/QA/","link":"","permalink":"http://yoursite.com/2018/10/22/QA/","excerpt":"","text":"1、mysql max_allowed_packet自动重置为1024 最后发现是被人搞了。发现过程:打开general.log记录日志，查找日志(1)grep “SET GLOBAL” ubuntu.log，日志截图，发现有改动痕迹 (2)选择某一个query ID，例如188592 (3)把这个链接的文件下载下来，360马上就提示这是一个病毒文件 因此，被人搞是确定无疑了。。 然后，赶紧把mysql的密码改了(原密码是mysql…因为这个服务器还没上线，所以密码也设置得很简单…)","categories":[{"name":"QA","slug":"QA","permalink":"http://yoursite.com/categories/QA/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/tags/mysql/"}]},{"title":"2018/10/19","slug":"2018-10-19","date":"2018-10-19T09:25:00.000Z","updated":"2018-10-19T09:26:39.903Z","comments":true,"path":"2018/10/19/2018-10-19/","link":"","permalink":"http://yoursite.com/2018/10/19/2018-10-19/","excerpt":"","text":"也许我爱的已不是你，而是对你付出的热情。就像一座神庙，即使荒芜，仍然是祭坛。一座雕像，即使坍塌，仍然是神。 -莱蒙托夫","categories":[{"name":"摘抄","slug":"摘抄","permalink":"http://yoursite.com/categories/摘抄/"}],"tags":[{"name":"给你的情书","slug":"给你的情书","permalink":"http://yoursite.com/tags/给你的情书/"}]},{"title":"tcpdump、nc、nmap","slug":"tcpdump","date":"2018-10-19T08:49:00.000Z","updated":"2018-10-19T09:22:13.183Z","comments":true,"path":"2018/10/19/tcpdump/","link":"","permalink":"http://yoursite.com/2018/10/19/tcpdump/","excerpt":"","text":"1、tcpdump:网络嗅探器(需要将网卡设置为混杂模式，promisc) -i:interface -w:file(保存至文件) -r:file(读取文件) -nn:第一个n表示把地址显示为数字的形式，第二个n表示把协议显示为数字的形式 -X:hex(16进制)以及ASCII格式显示 -XX:除了有-X的作用之外，还会显示链路层首部相关信息 -A:ASCII格式显示 -v:显示详细的信息 -vv:显示更加详细的信息 expression: 关键字: type:host、net、port、portrange direction:src、dst、src or dst、src and dst protocol:ether(以太网)、ip、arp、tcp、udp、icmp、wlan 组合条件: and or not 举例子: (1)tcpdump -i eth0 (2)tcpdump -i eth0 tcp dst port 80 (-n/-nn) (3)tcpdump -i eth0 -nn host 172.16.10.1 (4)tcpdump -i eth0 -nn dst host 172.16.10.1 (5)tcpdump -i eth0 -nn src and dst host 172.16.10.1 (6)tcpdump -i eth0 -nn host 172.16.10.1 and 172.16.10.10 (7)tcpdump -i eth0 -nn host 172.16.10.1 and (172.16.10.2 or 172.16.10.10) (8)tcpdump -i eth0 -A tcp port 80 (9)tcpdump -i eth0 -X tcp port 80 (10)tcpdump -i eth0 -XX tcp port 80 (11)tcpdump -i eth0 -A -v tcp port 80 (12)tcpdump -i eth0 -A -vv tcp port 80 2、nc(由nc包提供，包名叫nc) #另外一个实现:ncat(由nmap提供,包名叫nmap)(1)传输文件文件传输:监听者为接收方nc -l PORT &gt; /file (监听端口，-l表示监听)nc IP PORT &lt; /file 文件传输:监听者为传输方nc -l PORT &lt; /filenc IP PORT &gt; /file (2)传输目录:需要先归档 (3)web客户端nc作为web客户端来访问web服务器nc WEBSERVER PORTGET /index.html HTTP/1.1Host:172.16.10.1 (4)扫描器nc -v -w 1 172.16.10.1 -z 1-1023 -v:详细显示 -w:超时时间 -z:只扫描，不做其他任何动作 (5)聊天器nc -l PORTnc IP PORT例如:在一台主机上监听某个端口:nc -l 2333在另外一台主机上，nc 172.16.10.1 2333 -p 2333通过这样的方式，就可以在两台主机上相互传送信息了 (6)其他选项-s SOURCE_IP 3、nmap:扫描器之王主要概念:探测主机是否在线、扫描主机开放端口和嗅探网络服务，用于网络探测和安全扫描扫描类型:(1)-sT:tcp扫描，用来建立一个tcp连接。如果成功则认为目标端口正在监听，否则认为端口没有监听程序。这种扫描很容易被检测到，在目标主机的日志中会记录大批的连接请求和错误信息(2)-sU:udp扫描，如果返回icmp不可达的错误信息说明端口是关闭的(3)-sS:tcp同步扫描(tcp syn)，只向目标发出syn数据包，如果收到syn/ack响应就认为目标端口正在监听，并立即断开连接，否则认为端口没有监听程序。这种扫描称为半开扫描，最大的好处是很少有系统会把这个记入系统日志(4)-sA:这种高级的扫描方法通常可以穿过防火墙(5)-sW:滑动窗口扫描，非常类似于ack的扫描(6)-sV:version版本扫描(7)-sL:显示扫描的所有主机列表(8)-sP:找出主机是否存在于网络中 nmap基本操作:(1)nmap 192.168.1.1(2)nmap 192.168.1.1 192.168.1.2(3)nmap 192.168.0-25.1-254(4)nmap magedu.com(5)nmap -vv 192.168.1.1(6)nmap -vv -p 3389 192.168..1(7)扫描除了某ip之外的所有子网主机:nmap 192.168.1.1/24 -exclude 192.168.1.10(8)扫描除了某文件中的ip之外的所有子网主机:nmap 192.168.1.1/24 -excludefile gov.txt(9)显示扫描的所有主机列表:nmap -sL 192.168.1.1/24(10)ping扫描，只用于找出主机是否存在于网络中:nmap -sP 192.168.1.1-255","categories":[{"name":"linux简单应用","slug":"linux简单应用","permalink":"http://yoursite.com/categories/linux简单应用/"}],"tags":[{"name":"tcpdump","slug":"tcpdump","permalink":"http://yoursite.com/tags/tcpdump/"},{"name":"nc","slug":"nc","permalink":"http://yoursite.com/tags/nc/"},{"name":"nmap","slug":"nmap","permalink":"http://yoursite.com/tags/nmap/"},{"name":"抓包","slug":"抓包","permalink":"http://yoursite.com/tags/抓包/"},{"name":"扫描","slug":"扫描","permalink":"http://yoursite.com/tags/扫描/"}]},{"title":"NFS入门","slug":"NFS","date":"2018-10-19T05:39:00.000Z","updated":"2018-10-19T07:57:16.806Z","comments":true,"path":"2018/10/19/NFS/","link":"","permalink":"http://yoursite.com/2018/10/19/NFS/","excerpt":"","text":"1、NFS介绍NFS是”Network File system”的缩写，即网络文件系统网络文件系统是应用层的一种应用服务，它主要应用于linux与linux系统，linux与unix系统之间的文件或目录的共享。当用户想要使用远程文件的时候，只要用mount命令就可以把远程文件系统挂载到本地的文件系统上，操作远程文件就跟操作自己本地操作系统的文件一样。采用NFS之后省去了登录的过程，方便了用户访问系统资源。一言以蔽之，NFS的主要功能就是通过网络让不同的主机系统之间可以彼此共享文件或目录。 2、NFS原理对于linux而言，文件系统是在内核空间实现的，即文件系统比如ext3、ext4等是在kernel启动时，以内核模块的身份加载运行的。类似的，NFS(网络文件系统)也是工作在内核空间。NFS本身的服务没有提供数据传递的协议，而是通过使用RPC(Remote Procedure Call)来实现。具体实现过程如下:(1)本地用户要使用NFS服务器中的文件，先向内核发起请求，内核调用NFS模块以及rpc client(2)rpc client向rpc server发起连接(3)在连接之前，NFS服务除了启动nfsd本身监听的端口2049/tcp和2049/udp，还会启动其他进程(如mount，statd,rquotad等)已完成文件共享，这些进程的端口是不固定的，是每次NFS服务启动时向RPC服务注册的，RPC服务会随机分配未使用的端口(4)完成连接，接受访问请求(5)NFS应用程序向内核发起请求(6)内核调用文件系统然后client端通过获取的NFS端口来建立和server端的NFS连接并进行数据的传输简单来说，NFS客户端与服务端的通信过程:(1)先与rpc服务通信(tcp和udp的111端口)(2)再根据rpc提供的mounted监听端口，与mounted通信；mounted进程会对用户进行验证，验证通过返回用户一个通行证(3)最后客户端与nfsd进程建立联系进行通信 3、NFS服务器端组件:nfs-utilsrpm -ql nfs-utils #查看nfs-utils程序所生成的文件NFS服务端将启动3个主进程:(1)nfsd，跟NFS文件传输相关，工作在tcp和udp的2049端口(2)mounted，跟客户端挂载相关，随机端口(3)quotad，跟磁盘配额相关，随机端口备注:mounted和quotad的端口是随机产生的，不是固定的，每次重启nfs端口会发生变化。由此我们最好自定义端口。定义mounted和quotad进程监听固定端口:编辑/etc/sysconfig/nfs文件 #MOUNTED_PORT= #QUOTAD_PORT= #LOCKED_TCPPORT= #LOCKED_UDPPORT= 4、rpc介绍(1)rpc，远程过程调用，是一种编程技术，主要是用于简化分布式应用程序的开发。因为如果需要在两台主机上的进程进行通信，那么客户端、服务器端必须要处理网络传输中的网络请求、网络响应等等。这时候就大大增加了程序员开发的难度。因此就出现了rpc的框架。由此，程序员在开发客户端和服务端的时候，不需要再下功夫去处理网络协议报文的封装，因为rpc在底层就完成了这种观功能。(2)NFS是基于rpc来进行网络传输的，使得本地主机访问远程主机的时候，就好像本地主机访问本地一样。网络通讯过程对于本地主机来说是透明的。(3)在linux提供rpc服务的程序，叫做portmap，自身监听在tcp和udp的111端口。rpc与portmap的关系是，rpc是协议，portmap是实现，相当于http协议和apache、nginx、lightted的关系(4)rpc实现数据交换，可以基于二进制格式，也可以基于文本格式，基于文本格式比较常见的叫做XLRPC，后来又发展为SOAP 5、NFS介绍NFS是由SUN公司开发的，NFS版本有:NFSV1(SUN公司内部使用)NFSV2(早期公开版)NFSV3(在RHEL5上使用)NFSV4(在RHEL6上使用)NFS的缺点:(1)NFS可以基于认证，但是在认证这一块的功能是非常弱的，只认ID号，不认用户名举例子:假如在一台主机上有一个用户名叫做tom，通过NFS在另外一台主机上创建了一个目录，那么a.如果另外一台主机上没有tom这个用户，那么创建的目录的属主和属组是tom对应的uid和gidb.如果另外一台主机上有一个叫做jerry的用户，他的uid跟tom的uid一样，那么在另外一台主机上创建的这个目录的属主和属组就是jerry正是因为NFS不支持用户名认证，所以NFS一般不支持在互联网上使用，多用于在内网中各主机之间实现文件共享服务(2)NFS只支持在linux/unix上进行通信，不支持在windows主机上通信(linux上的NFS其实就相当于windows上的网上邻居，所以windows网上邻居的功能也是基于类似于rpc的协议来实现的) 6、NFS配置文件:/etc/exports只需要在这个文件中定义共享哪个目录出去，并且能够让客户端挂载，就能够让客户端像使用本地目录那样来使用这个共享出去的目录查看NFS的exports配置帮助的相关文档:man export 7、export文件格式:共享目录 客户端列表备注:(1)如果有多个客户端，客户端之间用空白字符分隔；而且每个客户端必须跟上一个小括号，里面定义了此客户端的访问特性，比如访问权限等(2)编辑保存之后需要重启nfs服务(3)文件系统访问特性有:ro:只读rw:只写sync:同步async:异步root_squash:将root用户映射为来宾用户，默认开启此功能no_root_squash:一台主机上的root用户访问另外一台主机的文件系统，是以另外一台主机的文件系统的root用户身份来访问的all_squash:将所有访问的用户映射为来宾用户anonuid,anongid:指定映射的来宾用户的uid和gid 8、命令相关(1)showmount命令:这个命令在客户端和服务端都可以使用-a:列出所有的客户端地址以及挂载的目录 #showmount -a 服务端IP，这条命令在客户端和服务端都可以实现-e:显示服务器共享了哪些目录 #showmount -e 服务端IP-d:显示NFS服务器共享出来的目录有哪些是被客户端挂载了的 #showmount -d 服务端IP (2)exportfs命令:-a:一般是跟-r或者-u选项同时使用，表示重新挂载(或者说导出，export)所有目录(或者说文件系统)或者取消挂载(导出)所有目录(文件系统)-r:重新导出-u:取消导出(这时候export下的所有文件系统或者目录都不能被客户端访问) #exportfs -uav-v:显示详细信息备注:当我们修改export文件的时候，需要重启nfs服务配置才会生效。使用exportfs就可以不用重启nfs服务，相当于reload (3)rpcinfo命令rpcinfo -p IP #查看mount或者quotad监听的端口号rpcinfo -p localhost #查看本机上rpc程序所监听的端口 (4)mount命令客户端使用mount命令挂载:mount -t nfs NFS_SERVER:/PATH /PATH #需要指定类型为nfsmount -t nfs 172.16.100.7:/shared /mnt/nfs #把172.16.100.7的shared目录共享出去，客户端挂载该目录即可使用 9、NFS开机自启动chkconfig nfs on 10、客户端开机自动挂载nfs目录编辑/etc/fstab文件，格式如下:172.16.100.1:/shared /mnt/nfs nfs defaults 0 0172.16.100.1:/shared /mnt/nfs nfs defaults,_rnetdev 0 0备注:man mount有一个挂载选项需要关注，_rnetdev:如果文件系统挂不上，就自动忽略掉 参考链接:https://www.cnblogs.com/whych/p/9196537.html","categories":[{"name":"linux共享服务","slug":"linux共享服务","permalink":"http://yoursite.com/categories/linux共享服务/"}],"tags":[{"name":"NFS","slug":"NFS","permalink":"http://yoursite.com/tags/NFS/"}]},{"title":"HTML基础","slug":"Untitled-3","date":"2018-10-17T07:14:00.000Z","updated":"2018-10-17T08:21:02.927Z","comments":true,"path":"2018/10/17/Untitled-3/","link":"","permalink":"http://yoursite.com/2018/10/17/Untitled-3/","excerpt":"","text":"HTML:HyperText Markup Language,超文本标记语言 1、HTML特点(1)HTML不需要编译，直接由浏览器执行(2)HTML文件是一个文本文件(3)HTML文件必须使用html或者xml为文件名后缀(4)HTML大小写不敏感 2、HTML基本结构 3、HTML标签(1)&lt;&gt;括起来(2)一般成对出现，分开始标签和结束标签。结束标签比开始标签多一个/(3)单标签:没有结束标签(4)标签属性 4、HTML标签类型(1)标题标签:h1到h6 (2)段落标签 段落标签align属性left:多对齐right:右对齐center:居中对齐justify:对行进行伸展，这样每行都可以有相等的长度(3)文字标签 (4)换行标签 (5)水平线标签 水平线标签属性width:设置水平线宽度，可以是像素或者是百分比color:设置水平线颜色align:设置水平线对齐方式noshade:设置水平线无阴影(6)列表标签之无序列表 无序列表标签type属性disc:圆点square:正方形circle:空心圆(7)列表标签之有序列表 有序列表标签type属性1:数字1,2…a:小写字母a,b..A:大写字母A,B..i:小写罗马数字iI:大写罗马数字I(8)列表标签之定义列表 (9)图像标签 图像标签属性 (10)超链接标签 超链接标签属性 5、HTML元素在开始标签和结束标签中的所有代码，称为HTML元素 6、HTML注释 7、DOCTYPE文档类型声明 8、网页编码设置","categories":[{"name":"前端技术","slug":"前端技术","permalink":"http://yoursite.com/categories/前端技术/"}],"tags":[{"name":"html","slug":"html","permalink":"http://yoursite.com/tags/html/"}]},{"title":"grep入门","slug":"grep","date":"2018-10-17T06:08:00.000Z","updated":"2018-10-17T06:23:13.109Z","comments":true,"path":"2018/10/17/grep/","link":"","permalink":"http://yoursite.com/2018/10/17/grep/","excerpt":"","text":"grep:根据模式搜索文本，并将符合模式的文本行显示出来 模式(pattern)的概念:文本字符和正则表达式的元字符组合而成的匹配条件 grep版本:(1)grep(2)egrep(3)fgrep grep用法:grep [option] pattern [file…]备注:(1)模式(pattern)要用引号引起来。在shell中，单引号是强引用，双引号是弱引用。(2)强引用指的是单引号里面的内容会原封不动(3)弱引用指的是引用变量，变量会被赋值为对应的值(4)在模式引用中，只要不涉及到变量的引用，单引号和双引号都可以；如果模式中没有包含正则表达式的元字符的时候，实际上不加引号也可以 option:-i 忽略大小写–color 匹配的字符高亮显示(可以通过别名，用alias grep=’grep –color’将grep的高亮显示作为默认显示)-v 反向grep-o 只显示被模式匹配到的字符串(默认会显示包含模式匹配到的整行文本)-E 支持扩展的正则表达式(相当于egrep)-A n 显示匹配到的字符串所在行及向下的n行-B n 显示匹配到的字符串所在行及向上的n行-C n 显示匹配到的字符串所在行及其上和其下的n行","categories":[{"name":"linux文本处理","slug":"linux文本处理","permalink":"http://yoursite.com/categories/linux文本处理/"}],"tags":[{"name":"grep","slug":"grep","permalink":"http://yoursite.com/tags/grep/"}]},{"title":"正则表达式","slug":"正则表达式","date":"2018-10-17T03:45:00.000Z","updated":"2018-10-17T06:46:16.004Z","comments":true,"path":"2018/10/17/正则表达式/","link":"","permalink":"http://yoursite.com/2018/10/17/正则表达式/","excerpt":"","text":"regular expression，简写REGEXP主要关注正则表达式里面的一些元字符，这些字符不表示本身的意义，而表示一些通配的意义(正则表达式默认工作在贪婪模式下，即尽可能长的匹配) 模式的概念:字符和正则表达式的元字符组合起来过滤文本的过滤条件 正则表达式分两类:basic regexp:基本正则表达式extended regexp:扩展正则表达式 基本正则表达式:(1)字符匹配. 匹配任意单个字符[] 匹配指定范围之内的任意单个字符[^] 匹配指定范围之外的任意单个字符也可以字符集合的方法来表示匹配字符集合里面的任意单个字符[:digit:] 数字[:alpha:] 所有字母[:alnum:] 数字和字母[:lower:] 小写字母[:upper:] 大写字母[:punct:] 标点符号[:space:] 空白字符注意:使用字符集合的时候，还要使用一个方括号括起来，就是要用到两个方括号 (2)次数匹配:* 匹配其前面的字符任意次.* 匹配任意长度的任意字符(跟通配符中的表示的一样)\\? 匹配其前面的字符0次或1次\\{m,n\\} 匹配其前面的字符最少m次，最多n次(反斜线是用来转义的，因为在bash shell中，花括号会被理解成命令行展开)\\{m\\} 匹配其前面的字符最少m次举栗子:a.b 表示a开头，b结尾，中间是任意长度的任意字符\\{1,\\} 最少1次\\{0,3\\} 最多3次 (3)位置锚定^ 锚定行首，此字符后面的任意内容必须出现在行首$ 锚定行尾，此字符前面的任意内容必须出现在行尾^$ 表示空白行\\&lt;或者\\b:锚定词首，其后面的任意字符必须作为单词的首部出现>或者\\b:锚定词尾，其前面的任意字符必须作为单词的尾部出现举栗子:\\&lt;root\\&gt; 匹配单词root(root既是词首，也是词尾) (4)分组\\(..\\)\\(ab\\) ab作为一个整体，ab可以出现0次、1次或者多次分组的主要目的是:后向引用，在后面引用前面括号括起来的内容\\1 引用第一个小括号分组中的内容\\2 引用第二个小括号分组中的内容\\3 引用第三个小括号分组中的内容举栗子:grep ‘\\(l..e\\).\\1’ test.txt可以匹配到以下两行:He love his lover.He like his liker. 扩展正则表达式:(1)字符匹配. 匹配任意单个字符[] 匹配指定范围之内的任意单个字符[^] 匹配指定范围之外的任意单个字符 (2)次数匹配* 匹配其前面的字符任意次.* 匹配任意长度的任意字符(跟通配符中的*表示的一样)?:匹配其前面的字符0次或1次+:匹配其前面的字符至少1次，相当于{1,}{m,n} 匹配其前面的字符最少m次，最多n次(在扩展正则表达式中，不需要加反斜线){m} 匹配其前面的字符最少m次 (3)位置锚定^ 锚定行首，此字符后面的任意内容必须出现在行首$ 锚定行尾，此字符前面的任意内容必须出现在行尾\\&lt;或者\\b:锚定词首，其后面的任意字符必须作为单词的首部出现>或者\\b:锚定词尾，其前面的任意字符必须作为单词的尾部出现 (4)分组() #不需要加反斜线\\1 引用第一个小括号分组中的内容\\2 引用第二个小括号分组中的内容\\3… (5)竖线| 表示或者的意思C|cat 匹配C或者cat(C|c)at 匹配Cat或者cat 总结:1、基本正则表达式和扩展正则表达式的区别:(1)扩展正则表达式中，表示分组的括号和表示次数匹配的花括号和问号，前面都不需要加反斜线(2)扩展正则表达式中，次数匹配多了一个”+”号，表示匹配一次或者多次(3)扩展正则表达式中，多了一个竖线的符号，表示或者的意思 2、正则表达式和通配符的区别:在文本过滤工具里面，都是用正则表达式，比如像awk、sed、grep等，都是针对文件内容的；而通配符是linux系统本身就支持的，多用在文件名上，比如像find、ls、cp，等等 通配符:* 任意长度的任意字符? 任意单个字符[] 指定范围内[^] 指定范围外","categories":[{"name":"linux文本处理","slug":"linux文本处理","permalink":"http://yoursite.com/categories/linux文本处理/"}],"tags":[{"name":"正则","slug":"正则","permalink":"http://yoursite.com/tags/正则/"}]},{"title":"awk入门","slug":"awk入门","date":"2018-10-17T03:37:00.000Z","updated":"2018-10-17T06:11:15.695Z","comments":true,"path":"2018/10/17/awk入门/","link":"","permalink":"http://yoursite.com/2018/10/17/awk入门/","excerpt":"","text":"awk:报告生成器，根据输入信息，将输入信息格式化之后再显示出来 awk版本:(1)awk(2)nwe awk,简称nawk(3)gnome awk,简称gwak awk使用格式:awk [options] ‘PATTERN { action }’ file2,file2… options:-F 指定分隔符BEGIN{OFS=””} 指定输出分隔符 在options中使用的内置变量(1)awk内置变量之记录变量:FS:读取文本时所使用的字段分隔符，默认是空白字符RS:输入文本信息所使用的换行符OFS:输出分隔符ORS:输出行分隔符 (2)awk内置变量之数据变量:NR:awk命令所处理的记录数。如果有多个文件，这个数目会把处理的多个文件中的行统一计数FNR:记录正处理的行是当前这一文件中被总共处理的行中是第几行NF:用于统计正在处理的行中的字段总数($NF:正在被处理的行中的最后一个字段) 常见的PATTERN类型:1.regexp，正则表达式，格式为/reglar expression/示例：awk -F: ‘/^r/{print $1}’ /etc/passwd #显示passwd文件中以r开头的用户名2.expression，表达式，比如$1 ~ /foo/ 或$1 == “magedu”等示例：awk -F: ‘$3&gt;=500{print $1,$3}’ /etc/passwd #显示passwd文件中uid大于300的用户及其uidawk -F: ‘$7~”bash$”{print $1,$7}’ /etc/passwd #显示passwd文件中以bash shell为shell的用户名及其对应的shell3.BEGIN/END,特殊模式，在awk命令执行之前运行一次货结束之前运行一次BEGIN:在awk处理文本第一行之前执行END:在awk处理文本最后一行之前执行实例：awk -F: ‘BEGIN{print “Username ID Shell”}{printf “%-10s%-10s%-20s\\n”,$1,$3,$7}END{print “end of report”}’ /etc/passwd #在第一行打印”Username ID Shell”，在最后一行打印”end of report” 常见的actions类型:控制语句：1.if-else实例：awk -F: ‘{if ($1==”root”) print $1,”admin”;else print $1,”common user”}’ /etc/passwd2.while实例：awk -F: ‘{i=1;while (i&lt;=3) {print $i;i++}}’ /etc/passwd3.do-whileawk -F: ‘{i=1;do {print $i;i++}while(i&lt;=3)}’ /etc/passwd4.forawk -F: ‘{for(i=1;i&lt;=3;i++)print $i}’ /etc/passwd5.case6.break,continue(跳过本字段)7.next(跳过本行) awk使用数组：示例：awk -F: ‘{shell[$NF]++}END{for(A in shell){print A,shell[A]}}’ /etc/passwd #生成一个shell数组，并统计passwd文件中各种shell的个数，A指的是下标netstat -tan | awk ‘/^tcp/{STATE{$NF}++}END{for (S IN STATE){print S,STATE[S]}}’ #生成一个STATE数组，并统计各种程序状态的个数，S指的是下标awk ‘{counts[$1]++}END{for(ip in counts){printf “%-20s:%d\\n”,ip,count[ip]}}’ /var/log/httpd/access.log #统计web日志文件中IP地址的访问量备注：awk中的下标很独特，可以是任意字符串","categories":[{"name":"linux文本处理","slug":"linux文本处理","permalink":"http://yoursite.com/categories/linux文本处理/"}],"tags":[{"name":"awk","slug":"awk","permalink":"http://yoursite.com/tags/awk/"}]},{"title":"2018/10/16","slug":"给你的情书","date":"2018-10-16T03:00:00.000Z","updated":"2018-10-17T07:12:46.652Z","comments":true,"path":"2018/10/16/给你的情书/","link":"","permalink":"http://yoursite.com/2018/10/16/给你的情书/","excerpt":"","text":"想起你的时候就想起夜半的野百合一支晃摇着节奏的野百合想起远方嫁给岩石的海鸟想起河神有几只鞋跑丢在太长的大陆跑丢在人群中想起丝绸仅仅成为东方母亲的蒙面我便是诗人 –海子《想起你的时候》","categories":[{"name":"摘抄","slug":"摘抄","permalink":"http://yoursite.com/categories/摘抄/"}],"tags":[{"name":"给你的情书","slug":"给你的情书","permalink":"http://yoursite.com/tags/给你的情书/"}]},{"title":"docker","slug":"docker入门","date":"2018-10-12T01:26:00.000Z","updated":"2018-10-12T09:38:38.748Z","comments":true,"path":"2018/10/12/docker入门/","link":"","permalink":"http://yoursite.com/2018/10/12/docker入门/","excerpt":"","text":"什么是dockerdocker是一个开源的应用容器引擎，让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的linux机器中，也可以实现虚拟化。docker的目标是实现轻量级操作系统虚拟化的解决方案。(基于Go语言开发) docker简单原理docker的基础是linux容器(LXC)、Cgroup技术。docker是在LXC的基础上进行了进一步的封装，让用户不再需要去关心容器的管理，使得操作更加简便。用户操作docker的容器就像操作一个快速轻量级的虚拟机一样简单。与传统虚拟户(KVM、XEN等)相比较：(1)docker是在操作系统层面上实现虚拟化，直接复用本地主机的操作系统(由下往上:硬件-&gt;host操作系统-&gt;docker engine-&gt;应用库-&gt;应用app) (2)传统的虚拟化方式是在硬件的基础上，虚拟出自己的系统，再在系统上部署相关的APP应用(由下往上:硬件-&gt;host操作系统-&gt;hypervisor-&gt;guest操作系统-&gt;应用库-&gt;应用app) docker组件(1)镜像:其实就是模板，跟我们常见的ISO镜像类似，是一个样板(2)容器:使用镜像常见的应用或系统，我们称之为一个容器(容器相当于启动之后的镜像)(3)仓库:仓库就是存放镜像的地方，分为公开仓库(public)和私有仓库(private)两种形式 docker技术组件linux内核的命名空间(namespace)，用于隔离文件系统、进程和网络(1)文件系统隔离:每个容器都有自己的root文件系统(2)进程隔离:每个容器都运行在自己的进程环境中(3)网络隔离:容器间的虚拟网络接口和IP地址都是分开的(4)资源隔离和分组:使用Cgroups(即control group，linux内核特性之一)将cpu和内存之类的资源独立分配给每个docker容器(5)写时复制:文件系统都是通过写时复制创建的(6)日志:容器产生的STDOUT、STDIN和STDERR这些IO流都会被收集并记入日志(7)交互式shell:用户可以创建一个伪tty终端，为容器提供一个交互式shell docker虚拟化特点(1)操作启动快运行时的性能获得极大的提升，管理操作(开始、停止、重启等)都是以秒或者毫秒为单位的(2)轻量级虚拟化你会拥有足够的”操作系统”，仅需添加或减少镜像即可。在一台服务器上可以部署100~1000个container容器，但是传统虚拟化虚拟出10~20个虚拟机就已经很好了(3)开源免费(4)前景及云支持 使用docker的优势(1)提供一个简单、轻量的建模方式用户上手docker非常快，只需要几分钟就可以将自己的程序”docker化”,docker依赖于”写时复制”(copy-on-write)模型，使得修改应用程序也非常迅速。(2)职责的逻辑分离使用docker，开发人员只需要关心容器中运行的应用程序，运维人员只需要关心如何管理容器，从而降低”开发时一切正常，肯定是运维问题”的风险。(3)快速、高效的开发生命周期docker的目标之一就是缩短代码从开发、测试到部署、上线运行的周期，让你的应用程序具备可移植性、易于构建、易于协作。(4)鼓励使用面向服务的架构docker推荐单个容器只运行一个应用程序，这样就形成了一个分布式的应用程序模型。在这种模型下，应用程序或服务都可以表示为一系列内部互联的容器，从而使分布式部署应用程序或者扩展应用程序变得简单。 docker安装先决条件(1)运行64位CPU架构的计算机，不支持32位的CPU(2)运行linux3.8或更高版本的内核查看内核版本:uname -a目前3.8内核已经可以通过apt-get来安装，内核更新步骤:apt-get updateapt-get install linux-headers-3.8.0-27-genericupdate-grubreboot(3)内核必须支持一种适合的存储驱动，默认是Device Mapper检查主机是否安装Device-mapper:grep device-mapper /proc/devices如果没有出现device-mapper的相关信息，可以尝试加载dm_mod模块:modprobe dm_mod(4)内核必须支持并开启cgroup和namespace(命名空间)的功能cgroup和namespace自2.6版本就已经集成到linux内核中，目前为止功能非常稳定 docker安装默认docker只能在centos6.5以上机器才能使用yum直接安装，如果是其他版本的话需要安装centos扩展源epel。docker官方要求linux kernel至少要3.8以上。在centos6.5系统上安装docker:(1)关闭selinux(2)安装epel源wget http://ftp.riken.jp/Linux/fedora/epel/6/x86_64/epel-release-6-8.noarch.rpmrpm -ivh epel-release-6-8.noarch.rpm(3)安装依赖yum install lxc libcgroup device-mapper-event-libsdevice-mapper* -y(4)安装dockeryum install docker-io(5)docker启动/etc/init.d/docker start在ubuntu 16.04安装docker:(1)安装wget -qO- https://get.docker.com/ | sh(2)启动/etc/init.d/docker start备注:在ubuntu中，如果使用UFW，需要在UFW中启用数据报文转发，才能让docker正常工作。因为UFW默认情况下会丢弃所有转发的数据包。修改/etc/default/ufw，将DEFAULT_FORWARD_POLICY=”DROP”修改为DEFAULT_FORWARD_POLICY=”ACCEPT”，保存修改内容并通过ufw reload重启UFW即可 docker常用命令docker version #查看docker版本docker images #查看当前的docker所有镜像docker info #检查docker是否已经正确安装并运行docker search centos #搜索可用的docker镜像docker pull centos #从公有仓库中下载镜像cat centos.tar | docker import - centos6 #导入镜像，导入centos.tar镜像并重命名为centos6docker export id &gt; centos6.tar #导出镜像，根据id导出镜像并重命名为centos6.tardocker ps -l #查看最后一个容器的iddocker ps -a #查看所有容器docker run centos echo “hello world” #在容器中运行”hello world”docker run centos yum install ntpdate #在容器中安装ntpdate程序docker run -i -t centos /bin/bash #在容器中启动一个/bin/bash shell环境，可以登入操作，-t表示打开一个终端，-i表示交互式输入docker run -d centos:v1 /bin/bash #在后台启动一个/bin/bash shell环境，-d表示在后台以daemon方式启动docker run -d -p 80:80 -p 8022:22 centos:v2 #-p指定容器启动后docker上运行的端口映射为容器里运行的端口，80:80中第一个80表示docker系统(本机)的80端口，第二个80表示docker虚拟机(docker容器)里面的端口。用户默认访问本机80端口，自动映射到容器里面的80端口docker commit 2313132 centos:v1 #提交刚修改的容器docker stop id #关闭容器docker start id #启动容器docker rm id #删除容器","categories":[{"name":"容器技术","slug":"容器技术","permalink":"http://yoursite.com/categories/容器技术/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/tags/docker/"}]},{"title":"初识java","slug":"初识java","date":"2018-10-10T08:33:00.000Z","updated":"2018-10-15T03:40:52.015Z","comments":true,"path":"2018/10/10/初识java/","link":"","permalink":"http://yoursite.com/2018/10/10/初识java/","excerpt":"","text":"1、先了解一下PHP(1)PHP是开发语言，也是运行环境作为开发语言，PHP属于脚本语言，也属于动态语言 (2)PHP编译过程:为简化编译过程，引入Zend Engine，编译成opcode，第一次编译第二次就不用编译；但是像Apache，每一个进程都使用一个独立的进程空间，因此第一个进程编译的结果第二个进程无法使用，因此又引入了缓存，像Xcache、APC、eAccelerator。 (3)PHP与C(面向过程)、C++(面向对象)相比较:PHP具有动态语言和脚本语言的灵活性、便捷性、移植性好C和C++移植困难、维护成本高，但是高速、性能好，一般用来开发驱动和底层程序等 插入介绍一些linux系统知识:(1)最底层:System call，系统调用上一层:API(application programming interface)，应用编程接口，有windows api和linux api再上一层:POSIX(POS全称portable operation system)，可移植操作系统，后面的IX是为了兼容linux操作系统的叫法。POSIX可以实现跨平台编译，POSIX是一种规范。(2)程序可以跨平台编译，但是不能跨平台运行(因为windows和linux的动态库不一样，windows系统是.so文件，linux系统是.dll文件)。因此，又出现一种叫做ABI的接口，ABI全称是application binary interface，可以拟合不同操作系统的二进制格式。在linux中，二进制格式是ELF；在windows中，二进制格式是EXE 最后引入java，java的出现就是为了能够在不同的操作系统上运行应用程序java包含四个独立又彼此相关的技术:(1)java程序设计语言(2)jvm(java virtual machine)，又叫java虚拟机(3)java class文件格式(4)java api彼此相关:java编程语言结合java api，编译成java class文件格式(字节码)，在jvm上运行(name.java–&gt;name.class,还有各种公有类和私有类跑在jvm上) 2、java apijava ee包含多个独立的api，servlet(硬编码)和jsp(.jsp-&gt;.java-&gt;.class)就是其中的两个，而java ee中著名的api还还包含以下几个:java ee api:(1)ehj(enterprise javabeans):java相关的诸多高级功能的实现，如rmi(remote method invocation)，对象/关系映射，跨越多个数据源的分布式事务等(2)jms(java message service):高性能异步消息服务，实现java ee应用程序与非java程序的透明通信(3)jmx(java management extensions):在程序运行时对其进行交互式监控和管理的机制(4)jta(java transaction api):允许应用程序在自身的一个或多个组件中平滑的处理错误的机制(5)javamail:通过工业标准的POP/SMTP/IMAP协议发送和接收邮件的机制 java se api:jndi(java naming and directory interface):用于与ldap服务交互的apijaxp(java api for xml processing):用于分析和转换xml 3、介绍jvmjvm最大的特点:一次编译，到处运行(once for all)jvm实现方式:(1)一次性解释器，解释字节码并执行(2)即时编译器(just-in-time complier)，依赖于更多内存缓存解释后的结果(3)自适应编译器，监控执行频率较高的代码，并将结果缓存下来(二八法则，缓存20%左右的代码，提高80%左右的速度) jvm分类:(1)hotspot，sum公司自己的jvm，hotspot又分为两类:jre:java运行环境，运行(编译)所需；jre=java语言+java se apijdk:java开发环境(包含jre，是jre的超集)，运行(编译)+开发所需；jdk=java语言+java api+jvm，jdk是实现java程序开发的最小环境(2)openjdk，开源界的jvm开发+运行的开源实现 java分类(根据java应用领域的不同):(1)java se:standard edition，标准版本，早期也叫做J2SE(2)java ee:enterprise edition，企业版本，早期也叫做J2EE(3)java me:mobile edition，移动版本，早期也叫做J2ME(用的很少) #2指的是第二版 4、介绍jdk:(1)jdk包格式jdk 1.6 update 32(jdk1.6的第32次升级，软件包名称是jdk-1.6.32)jdk 1.7 update 9(jdk1.7的第9次升级，软件包名称是jdk-1.7.9)(2)jdk安装方式rmp包通用二进制格式源码编译(3)命令yum list all|grep java #查看操作系统自身提供的jdk软件包java -version #查看java版本 5、介绍jsp(1)早期的时候，出现了applet这种小程序，用于开发动态网站；applet是开发在客户端运行的应用程序，基于web技术(2)接着，出现一种叫做CGI(common gateway interface)规范，能够让用户访问某种资源的时候，触发web服务器，调用额外的程序执行。除了CGI规范，java还提供了一种叫做servlet的规范，用来兼容applet和CGI；servlet是开发运行在服务器端的应用程序，基于CGI技术(3)在servlet的基础上进行升级改造，又引入了jsp(java server page)，用来嵌入java语言；jsp将servlet简化，开发者只需要将java程序嵌入到html代码中 #虽然说jsp拜托了servlet的束缚，但是jsp还是要通过Jasper先转换成servlet；jsp框架能够让java以嵌入式代码的方式嵌入到html代码中，从而实现基于java的动态网站开发 6、介绍java类(类库)有三类:(1)applet(2)servlet(3)jsp.jsp通过Jasper转换为.java.java通过jvm转换为.class 7、垃圾回收机制java程序可以实现自动内存回收，通过GC(gabbage collect)来完成(1)垃圾回收器:cms(Concurrent Mark-Sweep)，cms是以牺牲吞吐量为代价来获得最短回收停顿时间的垃圾回收器。对于要求服务器响应速度的应用上，这种垃圾回收器非常适合。在启动JVM参数加上-XX:+UseConcMarkSweepGC ，这个参数表示对于老年代的回收采用CMS。CMS采用的基础算法是：标记—清除。(2)cms过程:初始标记、并发标记、并发预处理、重新标记、并发清理、并发重置(3)cms优缺点:优点:并发收集、低停顿缺点:无法收集浮动垃圾，由于基于标记-清除算法，可能会产生碎片 8、java配置参数-XX:+ #开启此参数指定的功能-XX:- #关闭此参数指定的功能-XX:= #给option指定的选项赋值示例:java -XX:+PrintFlagsFinal #查看java配置所支持的参数 9、java工具sun jdk免费提供给用户监控和故障处理工具:(在jdk安装目录的bin目录下有很多java工具和命令)(1)jps:java process status tool，显示指定系统内的所有hotspot虚拟机进程的列表信息(2)jstat:jvm staticstics monitoring tool，收集并显示hotspot虚拟机各方面的运行数据(3)jinfo:显示正在运行的某hotspot虚拟机配置信息(4)jmap:生成某hotspot虚拟机的内存转储快照 可视化工具:(1)jconsole:java的监控和管理控制台(2)jvisualvm:java虚拟机控制台 #java工具除了sun开源的工具，还有很多商业的工具","categories":[{"name":"高可用web","slug":"高可用web","permalink":"http://yoursite.com/categories/高可用web/"}],"tags":[{"name":"tomcat","slug":"tomcat","permalink":"http://yoursite.com/tags/tomcat/"}]},{"title":"redis高级功能","slug":"redis高级功能","date":"2018-10-08T09:20:00.000Z","updated":"2018-10-10T06:18:55.021Z","comments":true,"path":"2018/10/08/redis高级功能/","link":"","permalink":"http://yoursite.com/2018/10/08/redis高级功能/","excerpt":"","text":"1、redis认证实现方法:(1)通过配置文件redis.conf修改requirepass PASSWORD #定义连接redis时的密码(2)通过客户端redis-cli修改auth PASSWORD #验证密码，PASSWORD为配置文件中requirepass定义的密码 2、redis事务(1)通过MULTI、EXEC、WATCH等命令实现事务功能:将一个命令或多个命令归并为一个操作提请服务器按顺序执行的机制举栗子:multi #启动(开始)一个事务……exec #执行(结束)一个事务 (2)watch:乐观锁在exec命令执行之前，用于监视指定键；如果监视中的某任意键数据被修改，则服务器拒绝执行事务(因为watch是监视数据是否被修改，一旦确认数据被修改，则放弃使用数据，而不是拒绝对方使用数据，所以叫乐观锁) (3)redis事务与传统关系型数据库的事务最大区别在于:redis不支持回滚 3、redis持久化:本质上是内存数据库redis持久化有两种机制:(1)RDB:快照机制，按事先制定的策略，周期性的将数据保存至磁盘，数据文件默认为dunp.rdb客户端也可以显式使用save或bgsave命令启动快照保存机制save:同步，在主线中保存快照，此时会阻塞所有客户端请求bgsave:异步，bg表示back-ground，后台运行，不会阻塞客户端请求 与rdb相关的配置文件参数:stop-write-on-bgsave-error yes #出错时停止写入rdbcompression yes #rdb文件是否执行压缩来节省磁盘空间rdbchecksum yes #是否对rdb的镜像文件做校验码检测dbfilename dump.rdb #指明文件名dir /var/lib/redis #指明rdb文件保存的目录 (2)AOF：append only file的缩写，把redis的每一个操作命令以附加的形式，附加到指定文件的尾部，会导致文件很大。记录每一次写操作至指定的文件尾部实现持久化，当redis重启时，可以通过重新执行文件中的命令在内存中重建数据库。通过bgrewriteaof来实现aof文件重写，不会读取正在使用的aof文件，而是通过将内存中的数据以命令的方式保存到临时文件中，完成之后替换原来的aof文件 与aof相关的配置文件参数:appendonly no #没有开启aof功能appendfilename “appendonly.aof” #文件名appendfsync always #每次收到写命令就立即写到aof文件appendfsync everysec #每秒钟写一次(折中的方式)appendfsync no #不通知内核，内核爱怎么写就怎么写no-appendfsync-on-write no #重写的时候对新写的操作不做sync操作，而是暂存在内存当中auto-aof-rewrite-percentage 100auto-aof-rewrite-min-size 64m aof重写过程:a.redis主进程通过fork创建子进程b.子进程根据redis内存中的数据创建数据库重建命令序列于临时文件中c.父进程继承client的请求，并会把这些请求中的写操作继续追加至原来的aof文件中；额外的，这些新的写请求还会被放置于一个缓冲队列中d.子进程重写完成，会通知父进程；父进程把缓冲中的命令写到临时文件中e.父进程用临时文件替换老的aof文件 使用子进程进行AOF重写的问题：子进程在进行AOF重写期间，服务器进程还要继续处理命令请求，而新的命令可能对现有的数据进行修改，这会让当前数据库的数据和重写后的AOF文件中的数据不一致如何修正:为了解决这种数据不一致的问题，Redis增加了一个AOF重写缓存，这个缓存在fork出子进程之后开始启用，Redis服务器主进程在执行完写命令之后，会同时将这个写命令追加到AOF缓冲区和AOF重写缓冲区即子进程在执行AOF重写时，主进程需要执行以下三个工作：执行client发来的命令请求；将写命令追加到现有的AOF文件中；将写命令追加到AOF重写缓存中。参考链接:https://blog.csdn.net/hezhiqiang1314/article/details/69396887 备注:重写本身不能取代备份，还应该指定备份策略，对redis数据库进行定期备份rdb与aof同时启用的时候:a.bgsave和bgrewriteaof不会同时执行b.在redis服务器启动数据恢复时，会优先使用aof 4、复制功能(1)特点:a.一个master可以有多个slaveb.支持链式复制c.master以非阻塞的方式同步数据至salve(2)主从(配置):slave slaveof master_ip master_port(3)认证如果master使用requirepass开启了认证功能，从服务器要使用masterauth 来连入服务请求来使用此密码进行验证 5、HA高可用通过sentinel来管理多个redis服务器实现HAsentinel作用:(1)用于监视主服务器(2)实现通知功能(notification)(3)实现自动故障转移 sentinel协议:(1)流言协议:接收主服务器是否下线的通知(2)投票协议:决定哪个服务器成为新的主服务器 sentinel启动:(1)redis-sentinel /path/to/file.conf(2)redis-server /path/to/file.conf –sentinel启动过程:(1)服务器自身初始化，运行redis-server中专用于sentinel功能的代码(2)初始化sentinel状态，根据给定的配置文件，初始化监控的master服务器列表(3)创建指向master的连接 sentinel下线:(1)主观下线:一个sentinel实例判断出某节点下线(2)客观下线:多个sentinel节点协商好判断出某节点下线 sentinel专用配置文件:/etc/redis-sentinel.conf(1)sentinel monitor mymaster 127.0.0.1 6379 2(2代表投票数) #多个sentinel的情况下，有2票投票从服务器成为主服务器的话，从服务器就会成为新的主服务器(2)sentinel down-after-milliseconds mymaster 30000 #30秒找不到主服务器就判断离线(3)sentinel parallel-syncs mymaster 2 #允许多少个从服务器向主服务器发起同步请求(4)sentinel failover-timeout mymaster 20 #主服务器发生故障，故障转移超时时间(故障转移超过这个时间，判断故障转移失败) sentinel专用命令(都以sentinel开头):sentinel masters:列出所有监视的主服务器sentinel slaves master_name:获取指定主服务器的从节点sentinel get-master-addr-by-name master_name:根据name获取master地址sentinel reset:重置操作sentinel failover &lt;master_name&gt;:手动执行故障转移操作 sentinel连接:(1)客户端连接sentinel示例redis-cli -h ipaddr -p 26379(sentinel默认端口)(2)客户端连接从节点示例redis-cli -h ipaddr -p 6380(自定义redis端口) 6、集群clustering:redis3.0以后支持分布式数据库，通过分片机制进行数据分析，clustering内的每个节点仅存数据库的一部分数据，也被称作去中心化(每一个节点都可以接入客户请求)。这样，每个节点都持有全局元数据，但仅持有一部分数据优点:(1)无中心化，gossip分散式模式(2)更少的来回次数并降低延迟(3)自动于多个redis节点进行分片(4)不需要第三方软件支持协调机制缺点:(1)依赖于redis3.0或更高版本(2)需要时间验证其稳定性(3)没有后台界面(4)需要智能客户端(5)redis客户端必须支持redis cluster架构","categories":[{"name":"数据库","slug":"数据库","permalink":"http://yoursite.com/categories/数据库/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://yoursite.com/tags/redis/"}]},{"title":"redis安装、配置及基本命令操作","slug":"redis配置及基本命令操作","date":"2018-10-08T08:19:00.000Z","updated":"2018-10-10T06:22:00.185Z","comments":true,"path":"2018/10/08/redis配置及基本命令操作/","link":"","permalink":"http://yoursite.com/2018/10/08/redis配置及基本命令操作/","excerpt":"","text":"1、redis特点:(1)原子性:要么全部执行，要么全部不执行(2)一致性:支持事务(3)隔离性:单线程(4)持久性:异步写入磁盘，避免雪崩效应 2、首先介绍一下redis3.0特性:(1)支持redis cluster(2)支持新的”embedded string”(3)LRU算法的改进改进如下:a.预设随机抽取5个样本，插入并排序至一个pool，移除最佳者，如此反复，直到内存用量小于maxmemory的设定b.样本5比先前的3多c.从局部最优趋向全局最优 3、redis组件:(1)redis-server(服务端)(2)redis-cli(客户端)(3)redis-benchmark(压测工具)(4)redis-check-dump &amp; redis-check-aof(检查持久化文件是否完整，分别对应rdb和aof格式) 4、redis官方站点:www.redis.ioyum info redis #查看epel源是否含有redis的安装包yum localinstall redis-3.0.2-1.el6.reml.x86_64.rpm #本地安装redisrpm -ql redis #查看安装redis时安装了哪些文件redis-server –help #查看帮助 5、redis配置文件(常用配置):(1)tcp-backlog #指等待队列。当并发量大的时候，redis可能会忙不过来。这时候需要额外找一个地方，将新的请求缓存下来，这个位置就叫backlog(2)redis.sock #服务端和客户端在同一台机器的时候，建议以sock文件的方式进行通信。好处是在内存当中直接交换，而不需要经过tcp/ip协议栈进行封装和解封装(3)timeout 0 #0表示连接不会超时(4)snapshotting配置:save 900 1 表示在900秒内有一个键发生变化，就做一次快照(5)replication配置:主从(6)daemonize yes #启动程序时，程序在后台运行 6、redis基本命令:(1)通过redis-cli客户端连接redis之后，可以通过help命令查看帮助help +tab键 #查看redis支持哪些类型help @STRING #查看字符串帮助help append #查看append命令的用法 (2)连接(connection)命令:help @connection #查看连接相关命令AUTH #验证PING #测试服务器是否在线，在线的话会返回PONGECHO #显示命令，例如ECHO ‘hello’QUIT #退出命令SELECT #选择数据库 (3)服务器(server)命令:help @server #查看服务器相关命令CLIENT SETNAME connection-name #设定连接名CLIENT GETNAME #查看连接名CLIENT KILL ip:port kill #关闭client (4)配置(config)命令:INFO #查看redis信息，信息包含很多段，例如INFO memory可以查看内存段的信息CONFIG RESETSTAT #重置INFO中所统计的数据CONFIG SET #运行中修改，也就是在内存中修改，不会同步到硬盘中CONFIG REWRITE #将配置写到硬盘当中CONFIG GET (如dir) #查看配置 7、redis支持的数据结构:(1)string #help @string，查看string支持的命令string支持的命令:set #help set，查看set帮助getappendstrlen (2)integer #help @integer，查看integer支持的命令integer支持的命令:incr #help incr，查看incr帮助decr (3)list [a,b,c,d] #help @list，查看list支持的命令list支持的命令:rpush #help rpush，查看rpush帮助lpushrpoplpoplindexlsetllen (4)set {a,b,c,d} #help @set，查看set支持的命令set支持的命令:sadd #help sadd，查看sadd帮助sinter #求交集sunion #求并集spop #随机弹出，set无序sismember #成员运算符 (5)sorted set {a:1,b:2,c:3} #help @sorten_set，查看sorten_set支持的命令sorten_set支持的命令:zadd #help zadd，查看zadd帮助zrangezcardzrank (6)hash {field1:”a”,field2:”b”}，说白了就是映射，也称为关联数组 #help @hash，查看hash支持的命令hash支持的命令:hset #help hset，查看set帮助hsetnxhgethkeyshvalshlenhdel (7)bitmaps #help @bitmaps，查看bitmaps支持的命令(8)hyperloglog #help @hyperloglog，查看hyperloglog支持的命令 …. 8、清空数据库:FLUSHDB:清空当前库FLUSHALL:清空所有库","categories":[{"name":"数据库","slug":"数据库","permalink":"http://yoursite.com/categories/数据库/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://yoursite.com/tags/redis/"}]},{"title":"初识redis","slug":"初识redis","date":"2018-10-08T06:59:00.000Z","updated":"2018-10-08T08:18:01.950Z","comments":true,"path":"2018/10/08/初识redis/","link":"","permalink":"http://yoursite.com/2018/10/08/初识redis/","excerpt":"","text":"redis属于nosql的一种。首先介绍一下nosql的分类:1、key-value nosql，比如redis，memcached2、column family nosql(列式存储)，比如hbase3、documentation nosql(文档存储)，比如mongodb4、graph nosql(图形存储) redis特性:1、key-value cache and store2、in-memory3、single threaded(单线程，因为redis占用cpu的消耗很低，因此cpu一般不会成为瓶颈)4、支持持久化(snapshotting，快照方式，异步写入到磁盘:AOF，append only file)5、支持主从(借助于sentinel实现一定意义上的HA:高可用)6、支持分布式集群(clustering)7、支持string、list、hash(关联数组)、set、sorted set(有序集合)、bitmap、hyperloglog redis与memcached比较:redis优势:1、支持的数据类型丰富，包括hash、lists、sets、sorted set、hyperloglog2、内建replication及cluster3、就地更新操作(in-place update)4、支持持久化(异步写入磁盘，避免雪崩效应)memcached优势:1、多线程(善用多核CPU，更少的阻塞操作)2、更少的内存开销3、更少的内存分配压力4、可能有更少的内存碎片","categories":[{"name":"数据库","slug":"数据库","permalink":"http://yoursite.com/categories/数据库/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://yoursite.com/tags/redis/"}]},{"title":"解决rabbitmq的web管理界面无法使用guest用户登录的问题","slug":"解决rabbitmq的web管理界面无法使用guest用户登录的问题","date":"2018-09-29T09:26:00.000Z","updated":"2018-09-29T09:27:15.108Z","comments":true,"path":"2018/09/29/解决rabbitmq的web管理界面无法使用guest用户登录的问题/","link":"","permalink":"http://yoursite.com/2018/09/29/解决rabbitmq的web管理界面无法使用guest用户登录的问题/","excerpt":"","text":"为了解决这个问题，需要在rabbitmq的配置文件中将loopback_users配置设置为空，如编写配置文件:/etc/rabbitmq/rabbitmq.config，并在其中添加以下内容： [{rabbit, [{loopback_users, []}]}]. 保存后重启rabbitmq-server即可随意使用guest用户名和密码来登录了(当然这个做法非常不安全)。","categories":[],"tags":[{"name":"rabbitmq","slug":"rabbitmq","permalink":"http://yoursite.com/tags/rabbitmq/"}]},{"title":"iptables删除已有的规则","slug":"iptables删除已有的规则","date":"2018-09-29T09:21:00.000Z","updated":"2018-09-29T09:24:02.852Z","comments":true,"path":"2018/09/29/iptables删除已有的规则/","link":"","permalink":"http://yoursite.com/2018/09/29/iptables删除已有的规则/","excerpt":"","text":"比如要删除input链上的某条规则，先要查询input链的所有规则iptables -L INPUT –line-numbers 查看你所要删除的规则是第几条，比如要删除第3条iptables -D INPUT 3","categories":[{"name":"linux简单应用","slug":"linux简单应用","permalink":"http://yoursite.com/categories/linux简单应用/"}],"tags":[{"name":"iptables","slug":"iptables","permalink":"http://yoursite.com/tags/iptables/"}]},{"title":"mysql启动报错:\"[ERROR] Table 'mysql.user' doesn't exist\"","slug":"mysql启动报错","date":"2018-09-29T09:16:00.000Z","updated":"2018-10-08T05:52:09.396Z","comments":true,"path":"2018/09/29/mysql启动报错/","link":"","permalink":"http://yoursite.com/2018/09/29/mysql启动报错/","excerpt":"","text":"这是因为编译安装mysql时指定了”–datadir=/usr/local/mysql/data”,所以在新增加一个/etc/my.cnf文件的时候，需要在my.cnf里面指定datadir=/usr/local/mysql/data 然后重启mysql就可以正常启动了","categories":[{"name":"数据库","slug":"数据库","permalink":"http://yoursite.com/categories/数据库/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/tags/mysql/"}]},{"title":"ubuntu安装ansible","slug":"ubuntu安装ansible","date":"2018-09-26T08:13:00.000Z","updated":"2018-10-08T05:50:39.916Z","comments":true,"path":"2018/09/26/ubuntu安装ansible/","link":"","permalink":"http://yoursite.com/2018/09/26/ubuntu安装ansible/","excerpt":"","text":"1、安装add-apt-repository必要套件apt-get install -y python-software-properties software-properties-common 2、使用ansible官方的PPA套件来源add-apt-repository -y ppa:ansible/ansible 3、升级apt-getapt-get update 4、安装ansibleapt-get install -y ansible","categories":[{"name":"安装篇","slug":"安装篇","permalink":"http://yoursite.com/categories/安装篇/"}],"tags":[{"name":"ansible","slug":"ansible","permalink":"http://yoursite.com/tags/ansible/"}]},{"title":"集群的概念","slug":"集群的概念","date":"2018-09-23T10:31:00.000Z","updated":"2018-09-23T10:42:13.270Z","comments":true,"path":"2018/09/23/集群的概念/","link":"","permalink":"http://yoursite.com/2018/09/23/集群的概念/","excerpt":"","text":"1、LB集群:lvs,nginx(lvs,nginx也可以实现高可用，但是相对来说在高可用中keepalived比较常见)2、HA集群:keepalived,heartbeat,corosync3、HP集群:高性能集群、超算集群，在互联网公司中很少见，一般在国家级实验室或者超算实验室中比较常见(HP集群一般可以用分布式计算来替换) 延伸:分布式计算中的一些概念分布式存储:HDFS分布式计算:YARNbatch:mapreducein-memory:sparkstream:storm HA cluster配置前提:1、本机的主机名与host中定义的主机名保持一致，要与hostname(uname -n)获得的名称保持一致 #根据主机名彼此通信配置主机名:在centos6中,/etc/sysconfig/networks在centos7中，hostnamectl set-hostname HOSTNAME #各节点要能相互解析主机名:一般建议通过host文件进行解析(配置文件/etc/hosts)2、各节点时间同步3、确保iptables及selinux不会成为服务的阻碍iptables -L -n #查看iptables规则getenforce #查看selinux状态","categories":[{"name":"高可用web","slug":"高可用web","permalink":"http://yoursite.com/categories/高可用web/"}],"tags":[{"name":"集群","slug":"集群","permalink":"http://yoursite.com/tags/集群/"}]},{"title":"keepalived配置实例","slug":"keepalived配置实例","date":"2018-09-23T09:53:00.000Z","updated":"2018-10-08T05:58:15.385Z","comments":true,"path":"2018/09/23/keepalived配置实例/","link":"","permalink":"http://yoursite.com/2018/09/23/keepalived配置实例/","excerpt":"","text":"实例一启动keepalived之后找不到配置文件:1、编辑/etc/rsyslog.conf #指明各类日志文件中的信息加上一句，local3.* /var/log/keepalived.log 2、编辑/etc/sysconfig/keepalived,加上一句，KEEPALIVED_OPTIONS=”-D -S 3” #指明keepalived日志文件的facility(等级)为3 3、重启rsyslog,keepalived服务在centos7中，systemctl restart rsyslog.servicesystemctl restart keepalived.service 实例二手动调度vip在两台主机中转移在配置文件中，1、vrrp实例之外加上一个函数vrrp_script chk_maintainnance{ script “[[ -f /etc/keepalived/down]] &amp;&amp; exit 1 || exit 0” interval 1 weight -2} 2、vrrp实例之内调用这个函数track_script{ chk_maintainnance}用法:只需要touch /etc/keepalived/down,vip就会转移；删除down文件又会转移到另一台主机 实例三配置虚拟路由器组vrrp_sync_group VG_1{ group { VI_1 VI_2 }} vrrp_instance VI_1{ eth0 vip #对外部客户} vrrp_instance VI_2{ eth1 dip #对内部主机} 实例四主机状态发生改变时发送通知:在vrrp实例中定义 #notify scripts,alert as above –自定义脚本 notify_master | #当前节点转换为master时，发送相应消息 notify_backup | #当前节点转换为backup时，发送相应消息 notify_fault |&lt;QUOTED_STRING&gt; #当前节点转换为fault(发生故障)时，发送相应消息 notify | smtp_alert实例:””括起来的内容就是表示QUOTED_STRINGnotify_master “/etc/keepalived/notify.sh master”notify_backup “/etc/keepalived/notify.sh backup”notify_fault “/etc/keepalived/notify.sh fault” 下面是一个notify脚本的简单示例: #!/bin/bashvip=172.16.100.1contact=‘root@localhost’ notify(){ mailsubject=”hostname to be $1:$vip floating” mailbody=”date &#39;+%F %H:%M:%S&#39;:vrrp transtion,hostname change to be $1” echo $mailbody|mail -s “$mailsubject” $contact} case “$1” in master) notify master #/etc/rc.d/init.d/haproxy start exit 0 ;; backup) notify backup #/etc/rc.d/init.d/haproxy stop exit 0 ;; fault) notify fault #/etc/rc.d/init.d/haproxy stop exit 0 ;; *) echo “Usage:basename $0 {master|backup|fault}” exit 1 ;;esac","categories":[{"name":"高可用web","slug":"高可用web","permalink":"http://yoursite.com/categories/高可用web/"}],"tags":[{"name":"keepalived","slug":"keepalived","permalink":"http://yoursite.com/tags/keepalived/"}]},{"title":"keepalived在centos7中的安装和配置文件","slug":"keepalived在centos7中的安装及配置","date":"2018-09-23T09:37:00.000Z","updated":"2018-10-08T05:58:39.041Z","comments":true,"path":"2018/09/23/keepalived在centos7中的安装及配置/","link":"","permalink":"http://yoursite.com/2018/09/23/keepalived在centos7中的安装及配置/","excerpt":"","text":"keepalived目前已经被官方收录进linux版本当中，在centos中使用yum就可以下载安装keepalivedyum info keepalived #查看系统中的keepalived版本yun install keepalived #安装keepalivedrpm -ql keepalived #查看安装keepalived生成了哪些文件cat /usr/lib/systemd/system/keepalived.service #查看keepalived的启动等配置信息cat /etc/sysconfig/keepalived #查看keepalived支持的参数帮助 keepalived配置文件:分为三部分1、global configuration2、vrrp configuration #分两段，第一段vrrp instance，第二段vrrp synchonization group3、lvs configuration #根据配置文件生成lvs规则 man keepalived.conf #查看keepalived配置文件的配置帮助详细配置:1、global_defs:notification_emailnotification_email_fromsmtp_serversmtp_connection_timeoutrouter_id #即hostanmevrrp_mcast_group 224.x.x.x #定义多播地址，224固定不变，后面三位可以变化 2、vrrp_instance:state #master或backupinterface #在centos7中，int dev的名字是eno16777736virtual_router_id #vrid是唯一的，跟虚拟Mac相关，虚拟Mac的格式是00-00-5E-00-01-{vrid} #根据Mac格式，前面是固定的，后面补上vrid。温馨提示，master和backup的virtual_router_id必须是一样的，因为id一样说明master和backup是在同一个虚拟路由器中priority #0到255的数字，数字越大，优先级越高，优先级高的是masteradver_init #发送心跳信息的时间间隔，默认是1authentication { auth_type PASS #这里是简单字符认证 auth_pass xxxx #}virtual_ipaddress #定义虚拟ip地址，同一个虚拟路由器中的master和backup的vip的配置是一样的nopreempt #非抢占模式，默认为抢占模式","categories":[{"name":"高可用web","slug":"高可用web","permalink":"http://yoursite.com/categories/高可用web/"}],"tags":[{"name":"keepalived","slug":"keepalived","permalink":"http://yoursite.com/tags/keepalived/"}]},{"title":"初识Keepalived","slug":"eepalived简介、组件及配置文件","date":"2018-09-22T08:16:00.000Z","updated":"2018-10-08T05:59:06.233Z","comments":true,"path":"2018/09/22/eepalived简介、组件及配置文件/","link":"","permalink":"http://yoursite.com/2018/09/22/eepalived简介、组件及配置文件/","excerpt":"","text":"keepalived是vrrp协议在linux主机上的实现，能够根据配置文件自动生成ipvs规则，对各RS做健康状态检查。1、特点(1)轻量级(2)以守护进程的形式(3)节点类型分为active/passive 2、组件(1)vrrp stack(2)checkers(3)ipvs wrapper 3、keepalived涉及的协议(1)组播:主服务器发送hello信息给从服务器，证明”I am alive”配置同进退vrrp实例时，要注意多播地址，每一组实例默认会分配一个组播地址。如果是在配置文件中指定一个组播地址，则只能配置一组实例；如果需要配置多组实例(不让其中一台主机有空闲)，则需要在各组实例的配置中配置上组播地址 (2)ntp:network time protocol格式:ntpdate timeserver_ip，以这个时间服务器的时间为准，同步自己的时间date命令调整时间的格式:”date 月日时分年.秒” (3)vrrp:virtual routing redundent protocol，虚拟路由冗余协议(vrrp是路由交换协议，keepalived是vrrp在linux上的实现)vrrp是一种容错协议，保证当主机的下一跳路由出现故障时，由另一台路由器来代替出故障的路由器进行工作，从而保障网络通信的连续性和可靠性。在vrrp协议中，分为master和backup两种角色。 vrrp中的一些概念: vrid:虚拟路由器标识，有相同vrid的一组路由器构成一个虚拟路由器 虚拟Mac:一个虚拟路由器拥有一个虚拟Mac，通常情况下虚拟路由器回应arp请求使用的是虚拟Mac 优先级:vrrp根据优先级来确定虚拟路由器中每台路由器的地位 非抢占模式:即使backup路由器的优先级比master高，也不会抢占master的地位 抢占模式:根据优先级的大小来确定谁是master vrrp工作原理: a.虚拟路由器中的路由器根据优先级选举出master，master路由器通过发送免费arp报文，将自己的虚拟Mac地址通知给其他与其连接的设备或主机，从而承担报文转发任务 b.master路由器周期性发送vrrp报文，以公布其配置信息(优先级)和工作状况 c.如果master路由器出现故障，虚拟路由器中的backup路由器将根据优先级重新选举新的master d.虚拟路由器切换时，master路由器由一台设备切换成另外一台设备，新的master路由器只是简单的发送一个携带虚拟路由器的Mac地址和虚拟ip地址信息的免费arp报文，这样就可以更新与之连接的设备或主机的arp信息 e.backup路由器优先级高于master的时候，由backup路由器的工作方式(抢占或非抢占)来决定是否重新选举master vrrp认证方式: a.无认证 b.简单字符认证(将认证字符插入到vrrp报文中) c.md5认证(利用认证字符和MD5算法对vrrp报文进行加密)","categories":[{"name":"高可用web","slug":"高可用web","permalink":"http://yoursite.com/categories/高可用web/"}],"tags":[{"name":"keepalived","slug":"keepalived","permalink":"http://yoursite.com/tags/keepalived/"}]},{"title":"小麦","slug":"小麦","date":"2018-09-20T09:34:11.000Z","updated":"2018-09-20T09:34:16.584Z","comments":true,"path":"2018/09/20/小麦/","link":"","permalink":"http://yoursite.com/2018/09/20/小麦/","excerpt":"","text":"有一个姑娘叫小麦","categories":[],"tags":[]},{"title":"ubuntu 16.04搭建Hexo博客后台管理系统","slug":"ubuntu-16-04搭建Hexo博客后台管理系统","date":"2018-09-20T06:40:00.000Z","updated":"2018-09-20T07:00:40.481Z","comments":true,"path":"2018/09/20/ubuntu-16-04搭建Hexo博客后台管理系统/","link":"","permalink":"http://yoursite.com/2018/09/20/ubuntu-16-04搭建Hexo博客后台管理系统/","excerpt":"","text":"1、安装Hexo-adminnpm install –save hexo-admin #之前已经介绍安装Hexo,参考链接:https://leungzj.github.io/2018/09/19/ubuntu16-04-%E6%90%AD%E5%BB%BAHexo%E5%8D%9A%E5%AE%A2/ 2、启动服务hexo s &amp; 3、访问后台http://你的ip地址:4000/admin 4、后台启用密码登录(默认无密码)点击”Setup authentification here” 弹出设置窗口，按要求填入登录用户名和密码，然后将”admin config section”下面那一段代码复制到Hexo的配置文件_config.yml即可 5、重启Hexokillall hexohexo s &amp; 6、更换Hexo主题先切换到Hexo所在安装目录，通过git下载主题文件到本地文件夹git clone https://github.com/BosenY/Lap.git theme/lap #Hexo主题汇总链接:https://hexo.io/themes/ 7、修改Hexo配置文件_config.yml 8、保存配置文件，重新生成并重启Hexo服务hexo ghexo dkillall hexohexo s &amp;","categories":[{"name":"搭建篇","slug":"搭建篇","permalink":"http://yoursite.com/categories/搭建篇/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://yoursite.com/tags/Hexo/"}]},{"title":"secureCRT连接ubuntu显示中文乱码的解决方法","slug":"secureCRT显示中文乱码","date":"2018-09-20T05:33:00.000Z","updated":"2018-09-20T05:52:17.443Z","comments":true,"path":"2018/09/20/secureCRT显示中文乱码/","link":"","permalink":"http://yoursite.com/2018/09/20/secureCRT显示中文乱码/","excerpt":"","text":"一、ubuntu设置1、在/var/lib/locales/supported.d/local文件中添加一行:zh_CN.UTF-8 UTF-8 执行sudo locale-gen下载文件 2、在/etc/environment文件中添加两行:LANG=”zh_CN.UTF-8”LC_ALL=”zh_CN.UTF-8” 3、在~/.profile文件中添加两行:export LANG=”zh_CN.UTF-8”export LC_ALL=”zh_CN.UTF-8 执行source ~/.profile 二、secureCRT设置1、选择options – session options，弹出设置窗口2、选择terminal – emulation，terminal下拉表选择linux，并在”ansi color”前面方框打上勾 3、选择terminal – appearance，”current color scheme”选择traditional font字体选择fangsong，script选择”Chinese GB2312” character encoding下拉表选择utf-8 退出当前crt窗口，重新登录试试！","categories":[{"name":"工具篇","slug":"工具篇","permalink":"http://yoursite.com/categories/工具篇/"}],"tags":[{"name":"secureCRT","slug":"secureCRT","permalink":"http://yoursite.com/tags/secureCRT/"}]},{"title":"ubuntu16.04 源码编译安装boost1_59_0","slug":"ubuntu16-04-源码编译安装boost1-59-0","date":"2018-09-19T08:31:00.000Z","updated":"2018-09-19T08:38:34.285Z","comments":true,"path":"2018/09/19/ubuntu16-04-源码编译安装boost1-59-0/","link":"","permalink":"http://yoursite.com/2018/09/19/ubuntu16-04-源码编译安装boost1-59-0/","excerpt":"","text":"1、下载源码包wget https://iweb.dl.sourceforge.net/project/boost/boost/1.59.0/boost_1_59_0.tar.gz 2、解压缩tar zxvf boost_1_59_0.tar.gz 3、进入解压缩目录cd boost_1_59_0/ 4、运行bootstrap.sh脚本./bootstrap.sh –with-libraries=all –with-toolset=gcc参数解释:–with-libraries指定编译哪些boost库，all的话就是全部编译，只想编译部分库的话就把库的名称写上，用逗号分隔即可–with-toolset指定编译时使用哪种编译器，Linux下使用gcc即可，如果系统中安装了多个版本的gcc，在这里可以指定gcc的版本，比如–with-toolset=gcc-4.4 5、编译boost./b2 toolset=gcc 6、安装boost./b2 install可以加–prefix参数:用来指定boost的安装目录，不加此参数的话默认的头文件在/usr/local/include/boost目录下，库文件在/usr/local/lib/目录下 7、更新系统的动态链接库ldconfig","categories":[{"name":"安装篇","slug":"安装篇","permalink":"http://yoursite.com/categories/安装篇/"}],"tags":[{"name":"boost","slug":"boost","permalink":"http://yoursite.com/tags/boost/"}]},{"title":"ubuntu16.04 搭建Hexo博客","slug":"ubuntu16-04-搭建Hexo博客","date":"2018-09-19T06:56:00.000Z","updated":"2018-09-19T09:09:42.422Z","comments":true,"path":"2018/09/19/ubuntu16-04-搭建Hexo博客/","link":"","permalink":"http://yoursite.com/2018/09/19/ubuntu16-04-搭建Hexo博客/","excerpt":"","text":"一、安装Node.js1、安装curlapt install curl 2、安装node.jscurl -sL https://deb.nodesource.com/setup_8.x | sudo -E bash -apt install -y nodejs 3、检查版本(有版本号输出表示安装完成)node -vnpm -v 二、安装Hexo1、npm install -g hexo-cli 2、进入你希望建站的文件夹(必须是一个空的文件夹)，执行初始化命令:hexo init 3、安装依赖包:npm install 至此，Hexo本地博客搭建完成。 三、Hexo常用命令hexo help:查看帮助hexo init:初始化一个目录hexo generate:生成网页，在public目录查看整个网站的文件，简写为hexo ghexo server:用来启动本地站点，执行后即可在浏览器中输localhost:4000查看，简写为hexo shexo deploy:部署.deploy目录，可以简化为hexo dhexo clean:清除缓存，强烈建议每次部署deploy之前先清理缓存 四、使用github pages服务部署hexoGiuhub Page介绍:我们用来托管博客的服务叫做 Github Pages，它是 Github 用来提供给个人/组织或者项目的网页服务，只需要部署到你的 Github Repository，推送代码，便可以实时呈现。 1、首先要使用邮箱注册Github账号 2、设置gitgit config –global user.email “you@example.com“git config –global user.name “Your Name” 3、安装插件npm install hexo-deployer-git –save #为了部署到Github上，需要安装hexo-deployer-git插件 4、生成ssh秘钥ssh-keygen -t rsa -C you@example.com #-C后面跟住你在github的用户名邮箱，这样公钥才会被github认可 5、查看你的公钥，添加到Github账户的sshkey中less ~/.ssh/id_rsa.pub 6、Github上新建项目，项目名称为”用户名.github.io”，例如我的用户名是leungzj，则创建的项目名为leungzj.github.io 7、在setting–SSH and GPG keys中，添加生成的公钥，也就是将~/.ssh/id_rsa.pub的内容添加到这里 8、修改Hexo配置文件 9、编译并上传部署到Githubhexo generate #编译hexo deploy #将hexo部署到Github io上 10、访问Hexo博客通过用户名.github.io就可以Hexo博客啦！例如我的博客:https://leungzj.github.io/","categories":[{"name":"搭建篇","slug":"搭建篇","permalink":"http://yoursite.com/categories/搭建篇/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://yoursite.com/tags/Hexo/"}]},{"title":"ubuntu16.04 源码编译安装mysql5.7","slug":"安装篇-ubuntu16-04-安装mysql5-7","date":"2018-09-19T05:36:00.000Z","updated":"2018-09-20T02:42:02.370Z","comments":true,"path":"2018/09/19/安装篇-ubuntu16-04-安装mysql5-7/","link":"","permalink":"http://yoursite.com/2018/09/19/安装篇-ubuntu16-04-安装mysql5-7/","excerpt":"","text":"1、安装依赖sudo apt-get install make cmake gcc g++ bison libncurses5-dev build-essential 2、下载mysql 5.7源码包下载地址：https://dev.mysql.com/downloads/mysql/在”select operating system”中选择”source code”，我下载的版本是mysql-5.7.23 3、解压缩tar zxvf mysql-5.7.23.tar.gz -C /usr/localcd /usr/local/mysql-5.7.23/ 4、编译安装cmake . -DCMAKE_INSTALL_PREFIX=/usr/local/mysql -DMYSQL_DATADIR=/usr/local/mysql/data -DSYSCONFDIR=/etc -DWITH_INNOBASE_STORAGE_ENGINE=1 -DWITH_ARCHIVE_STORAGE_ENGINE=1 -DWITH_BLACKHOLE_STORAGE_ENGINE=1 -DWITH_PARTITION_STORAGE_ENGINE=1 -DWITH_PERFSCHEMA_STORAGE_ENGINE=1 -DWITHOUT_EXAMPLE_STORAGE_ENGINE=1 -DWITHOUT_FEDERATED_STORAGE_ENGINE=1 -DDEFAULT_CHARSET=utf8 -DDEFAULT_COLLATION=utf8_general_ci -DWITH_EXTRA_CHARSETS=all -DENABLED_LOCAL_INFILE=1 -DWITH_READLINE=1 -DMYSQL_UNIX_ADDR=/usr/local/mysql/mysql.sock -DMYSQL_TCP_PORT=3306 -DMYSQL_USER=mysql -DCOMPILATION_COMMENT=”lq-edition” -DENABLE_DTRACE=0 -DOPTIMIZER_TRACE=1 -DWITH_DEBUG=1 运行到这一步，出现报错信息:“CMake Error at cmake/boost.cmake:81 (MESSAGE): You can download it with -DDOWNLOAD_BOOST=1 -DWITH_BOOST=“提示需要安装boost库，安装参考链接:https://leungzj.github.io/2018/09/19/ubuntu16-04-%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85boost1-59-0/ makemake install 5、配置mysql(1)创建用户和用户组groupadd mysqluseradd -g mysql mysql (2)设置mysql安装目录的权限cd /usr/local/mysqlchown -R mysql:mysql ./ (3)mysql初始化 #这里会生成一个mysql临时登录密码，需要记下来，稍后登录mysql会用到bin/mysqld –initialize –user=mysql (4)启动mysqlsupport-files/mysql.server start (5)修改mysql登录密码bin/mysql -u root -pSET PASSWORD FOR ‘root‘@’localhost’ = PASSWORD(‘newpassword’); 6、远程连接mysql用类似navicat的客户端连接mysql，如果出现提示”is not allowed to connect”，需要在mysql命令行上设置远程连接权限，检查iptables是否开放3306端口(1)GRANT ALL ON . TO ‘root‘@’%’ IDENTIFIED BY ‘password’ WITH GRANT OPTION;(2)iptables -A INPUT -P tcp –dport 3306 -j ACCEPT","categories":[{"name":"安装篇","slug":"安装篇","permalink":"http://yoursite.com/categories/安装篇/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/tags/mysql/"}]}]}