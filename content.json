{"meta":{"title":"Jim's Blog","subtitle":null,"description":null,"author":"Jim","url":"http://yoursite.com"},"pages":[{"title":"","date":"2018-10-30T03:17:12.022Z","updated":"2018-10-30T03:17:12.022Z","comments":true,"path":"baidu_verify_HCnRC8FAR2.html","permalink":"http://yoursite.com/baidu_verify_HCnRC8FAR2.html","excerpt":"","text":"HCnRC8FAR2"},{"title":"","date":"2018-11-23T02:53:13.907Z","updated":"2018-11-23T02:53:13.907Z","comments":true,"path":"google6067bd16d98499cd.html","permalink":"http://yoursite.com/google6067bd16d98499cd.html","excerpt":"","text":"google-site-verification: google6067bd16d98499cd.html"},{"title":"","date":"2018-10-17T02:15:56.847Z","updated":"2018-10-17T02:15:56.843Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":"关于运维工程师，熟悉网络、运维、数据库、自学前端、python，志向于全栈认证：CCNA,SAA,PMP,中级网络工程师，目前在考高级项目管理师 { name: ‘jim’ age: ‘28’ gender: ‘男’ profession: ‘Operation’ experience: ‘3年’ address: ‘广东省广州市’ education: ‘本科’ github: ‘https://github.com/leungzj&#39; email: &#39;18826400669@163.com‘ blog: ‘leungzj.github.io’ description: ‘技术改变世界’ skills: [ 网络、运维、SQL、python...(持续更新中) ] }"},{"title":"友情链接","date":"2018-10-17T03:21:43.737Z","updated":"2018-10-17T03:21:43.733Z","comments":false,"path":"links/index.html","permalink":"http://yoursite.com/links/index.html","excerpt":"","text":""},{"title":"标签","date":"2018-10-17T02:54:58.153Z","updated":"2018-10-17T02:54:58.153Z","comments":false,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""},{"title":"","date":"2018-12-17T02:52:24.170Z","updated":"2018-12-17T02:52:24.170Z","comments":true,"path":"books/index.html","permalink":"http://yoursite.com/books/index.html","excerpt":"","text":"docker:《第一本docker书》 python:《python编程:从入门到实践》 mongodb:《MongoDB权威指南》 shell:《linux与Unix_shell编程指南》 puppet:《puppet权威指南》 jenkins:《jenkins权威指南》"},{"title":"categories","date":"2018-09-19T09:02:45.000Z","updated":"2018-09-19T09:06:58.378Z","comments":true,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"ECS（容器代理、安全性）","slug":"ECS（容器代理、安全性）","date":"2019-01-14T06:18:00.000Z","updated":"2019-01-14T06:18:32.237Z","comments":true,"path":"2019/01/14/ECS（容器代理、安全性）/","link":"","permalink":"http://yoursite.com/2019/01/14/ECS（容器代理、安全性）/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[]},{"title":"ECS（调度、集群）","slug":"ECS（调度、集群）","date":"2019-01-14T06:17:00.000Z","updated":"2019-01-14T06:17:22.956Z","comments":true,"path":"2019/01/14/ECS（调度、集群）/","link":"","permalink":"http://yoursite.com/2019/01/14/ECS（调度、集群）/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[]},{"title":"ECS（fargate、两种模式）","slug":"ECS（fargate、两种模式）","date":"2019-01-14T06:15:00.000Z","updated":"2019-01-14T06:15:55.492Z","comments":true,"path":"2019/01/14/ECS（fargate、两种模式）/","link":"","permalink":"http://yoursite.com/2019/01/14/ECS（fargate、两种模式）/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[]},{"title":"ECS（任务定义）","slug":"ECS（任务定义）","date":"2019-01-14T06:13:00.000Z","updated":"2019-01-14T06:14:18.488Z","comments":true,"path":"2019/01/14/ECS（任务定义）/","link":"","permalink":"http://yoursite.com/2019/01/14/ECS（任务定义）/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[]},{"title":"ECS（定义、特点）","slug":"ECS（定义、特点）","date":"2019-01-14T06:12:00.000Z","updated":"2019-01-14T06:12:29.260Z","comments":true,"path":"2019/01/14/ECS（定义、特点）/","link":"","permalink":"http://yoursite.com/2019/01/14/ECS（定义、特点）/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[]},{"title":"docker（容器与虚拟化的区别）","slug":"docker（容器与虚拟化的区别）","date":"2019-01-14T03:17:00.000Z","updated":"2019-01-14T03:18:06.343Z","comments":true,"path":"2019/01/14/docker（容器与虚拟化的区别）/","link":"","permalink":"http://yoursite.com/2019/01/14/docker（容器与虚拟化的区别）/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[]},{"title":"docker（特点、优点）","slug":"docker（特点、优点）","date":"2019-01-14T03:15:00.000Z","updated":"2019-01-14T03:16:08.327Z","comments":true,"path":"2019/01/14/docker（特点、优点）/","link":"","permalink":"http://yoursite.com/2019/01/14/docker（特点、优点）/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[]},{"title":"docker（组件）","slug":"docker（组件）","date":"2019-01-14T03:14:00.000Z","updated":"2019-01-14T03:15:03.354Z","comments":true,"path":"2019/01/14/docker（组件）/","link":"","permalink":"http://yoursite.com/2019/01/14/docker（组件）/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[]},{"title":"docker（起源、定义）","slug":"docker（起源、定义）","date":"2019-01-14T03:13:00.000Z","updated":"2019-01-14T03:13:47.242Z","comments":true,"path":"2019/01/14/docker（起源、定义）/","link":"","permalink":"http://yoursite.com/2019/01/14/docker（起源、定义）/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[]},{"title":"EC2置放群组（特点）","slug":"EC2置放群组（特点）","date":"2019-01-14T02:58:03.000Z","updated":"2019-01-14T02:58:10.336Z","comments":true,"path":"2019/01/14/EC2置放群组（特点）/","link":"","permalink":"http://yoursite.com/2019/01/14/EC2置放群组（特点）/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"EC2置放群组（定义、最佳实践）","slug":"EC2置放群组（定义、最佳实践）","date":"2019-01-14T02:56:00.000Z","updated":"2019-01-14T02:57:05.256Z","comments":true,"path":"2019/01/14/EC2置放群组（定义、最佳实践）/","link":"","permalink":"http://yoursite.com/2019/01/14/EC2置放群组（定义、最佳实践）/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[]},{"title":"弹性伸缩（扩展选项、默认的实例终止策略、与ELB搭配使用）","slug":"弹性伸缩（扩展选项、默认的实例终止策略、与ELB搭配使用）","date":"2019-01-11T09:10:00.000Z","updated":"2019-01-11T09:12:22.268Z","comments":true,"path":"2019/01/11/弹性伸缩（扩展选项、默认的实例终止策略、与ELB搭配使用）/","link":"","permalink":"http://yoursite.com/2019/01/11/弹性伸缩（扩展选项、默认的实例终止策略、与ELB搭配使用）/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[]},{"title":"弹性伸缩（启动配置、弹性伸缩组）","slug":"弹性伸缩（启动配置、弹性伸缩组）","date":"2019-01-11T09:08:00.000Z","updated":"2019-01-11T09:08:57.803Z","comments":true,"path":"2019/01/11/弹性伸缩（启动配置、弹性伸缩组）/","link":"","permalink":"http://yoursite.com/2019/01/11/弹性伸缩（启动配置、弹性伸缩组）/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[]},{"title":"弹性伸缩（定义、功能、参数）","slug":"弹性伸缩（定义、功能、参数）","date":"2019-01-11T09:04:00.000Z","updated":"2019-01-11T09:05:16.106Z","comments":true,"path":"2019/01/11/弹性伸缩（定义、功能、参数）/","link":"","permalink":"http://yoursite.com/2019/01/11/弹性伸缩（定义、功能、参数）/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[]},{"title":"bootstrap开机脚本","slug":"bootstrap开机脚本","date":"2019-01-11T08:19:00.000Z","updated":"2019-01-11T08:20:21.507Z","comments":true,"path":"2019/01/11/bootstrap开机脚本/","link":"","permalink":"http://yoursite.com/2019/01/11/bootstrap开机脚本/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[]},{"title":"EC2实例（数据类型）","slug":"EC2实例（数据类型）","date":"2019-01-11T08:11:00.000Z","updated":"2019-01-11T08:12:04.902Z","comments":true,"path":"2019/01/11/EC2实例（数据类型）/","link":"","permalink":"http://yoursite.com/2019/01/11/EC2实例（数据类型）/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[]},{"title":"vmware虚拟机：Exception 0xc000001d  has occurred.","slug":"vmware虚拟机：Exception-0xc000001d-has-occurred","date":"2019-01-11T07:39:00.000Z","updated":"2019-01-11T07:41:17.320Z","comments":true,"path":"2019/01/11/vmware虚拟机：Exception-0xc000001d-has-occurred/","link":"","permalink":"http://yoursite.com/2019/01/11/vmware虚拟机：Exception-0xc000001d-has-occurred/","excerpt":"","text":"解决方案：虚拟机设置，点击显示器，加速3D图形前面的打勾去掉即可。","categories":[{"name":"QA","slug":"QA","permalink":"http://yoursite.com/categories/QA/"}],"tags":[]},{"title":"docker容器篇","slug":"docker容器","date":"2019-01-10T07:10:00.000Z","updated":"2019-01-10T08:58:21.178Z","comments":true,"path":"2019/01/10/docker容器/","link":"","permalink":"http://yoursite.com/2019/01/10/docker容器/","excerpt":"","text":"1、运行容器指定容器启动时执行的命令的三种方法：（1）CMD命令（2）ENTRYPOINT命令（3）在docker run命令行中指定举例：（1）在容器启动时执行pwd，返回的/是容器中的当前目录 （2）执行docker ps或者docker container ls查看当前运行的容器 （3）执行docker ps -a或者docker container ls -a查看所有容器（-a会显示所有状态的容器） 可以看到容器已经退出，状态为exited 让容器保持运行状态的两种方法：（1）通过执行一个长期运行的命令来保持容器的运行状态（例如循环） 打开另外一个终端查看容器的状态缺点是：这种方法始终会占用一个终端（2）加上参数-d以后台方式启动容器 通过docker ps看到的container id是短id，短id是长id的前12个字符 停止容器：docker stop “短id” 指定容器名称：docker run –name “my_httpd_server” -d httpd docker ps可以看到容器运行的命令是httpd-foreground docker history可以知道这个命令是通过CMD指定的 2、进入容器两种进入容器的方法：（1）docker attach 通过id attach到容器的启动命令终端，然后可以看到echo每隔1秒打印hello-world（2）docker exec -it就是以交互模式打开，执行bash，其结果就是打开一个bash终端，就可以像在普通的linux中一样执行命令了。执行exit会退出容器，回到docker host（3）两者的区别attach直接进入容器启动命令的终端，不会启动新的进程；exec则是在容器中打开新的终端，并且可以启动新的进程；如果想直接在终端中查看启动命令的输出，用attach。其他情况用exec。通过docker log -f也可以查看启动命令的输出（-f与tail -f类似，能够持续打印输出） 指定容器的三种方法：（1）短ID（2）长ID（3）容器名称（通过–name为容器命名。重命名容器可以执行docker rename） 3、常用命令create：创建容器run：运行容器pause：暂停容器unpause：取消暂停stop：发送SIGTERM停止容器kill：发送SIGKILL快速停止容器start：启动容器restart：重新启动容器attach：attach到容器启动进程的终端exec：在容器中启动新进程，通常使用”-it”参数logs：显示容器启动进程的控制台输出，用”-f”持续打印rm：从磁盘中删除容器 4、资源限额内存限额：（1）内存定义：内存包含两部分，物理内存和swap（2）设置命令：-m或–memory：设置内存的使用限额，例如100M，2G–memory-swap：设置内存+swap的使用限额（备注：不单单是指swap，而是内存和swap的总和）（3）举例：例子1docker run -m 200M –memory-swap=300M ubuntu这条指令的意思是该容器最多允许使用200M的内存和100M的swap。默认上面两组参数的值为1，即对该容器内存和swap的使用没有限制 例子2docker run -it -m 200M –memory-swap=300M progrium/stress –vm 1 –vm-bytes 280M备注：–vm 1是指启动一个内存工作线程；–vm-bytes 280M是指每个线程分配280M内存运行结果： 结论：可以正常工作工作过程：分配 280M 内存。释放 280M 内存。再分配 280M 内存。再释放 280M 内存。一直循环…… 例子3docker run -it -m 200M –memory-swap=300M progrium/stress –vm 1 –vm-bytes 310M运行结果： 结论：不能正常工作工作过程：分配的内存超过限额，stress 线程报错，容器退出 备注：如果在启动容器时只指定 -m 而不指定 –memory-swap，那么 –memory-swap 默认为 -m 的两倍，比如：docker run -it -m 200M ubuntu容器最多使用 200M 物理内存和 200M swap。 CPU限额：设置命令：-c或者–cpu-shares：设置容器使用cpu的权重备注：（1）与内存限额不同，通过 -c 设置的 cpu share 并不是 CPU 资源的绝对数量，而是一个相对的权重值。也就是说，某个容器最终能分配到的 CPU 资源取决于它的 cpu share 占所有容器 cpu share 总和的比例。（2）比如说，在docker host中启动了两个容器docker run –name “container_A” -c 1024 ubuntudocker run –name “container_A” -c 512 ubuntucontainer_A 的 cpu share 1024，是 container_B 的两倍。当两个容器都需要 CPU 资源时，container_A 可以得到的 CPU 是 container_B 的两倍。（3）这种按权重分配cpu只会发生在cpu资源紧张的时候。如果 container_A 处于空闲状态，这时，为了充分利用 CPU 资源，container_B 也可以分配到全部可用的 CPU。 举例：（1）启动container_a 备注：–cpu是用来设置工作线程的数量。因为当前host只有一颗cpu，所以一个工作线程就能将cpu压满。如果host有多颗cpu，则需要相应增加–cpu的数量。（2）打开另一个终端，启动container_b （3）再打开一个终端，执行top命令 结论：container_a消耗的cpu是container_d的2倍（4）暂停container_a （5）container_b在container_a空闲的情况下可以用满整颗CPU IO限额：（1）IO定义：block io指的是磁盘的读写，docker可以通过设置权重、限制bps和iops的方式控制容器读写磁盘的带宽（2）限制IO的两种方式：设置权重：通过设置–blkio-weight参数来修改权重，默认值是500举例：container_a读写磁盘的带宽是container_b的两倍docker run -it –name container_a –blkio-weight 600 ubuntudocker run -it –name container_b –blkio-weight 300 ubuntu 限制bps和iops：（1）定义：bps：byte per second，每秒读写的数据量iops：io per second，每秒io的次数（2）可以通过以下参数控制容器的bps和iops：–device-read-bps：限制读某个设备的bps；–device-write-bps：限制写某个设备的bps；–device-read-iops：限制读某个设备的iops；–device-write-iops：限制写某个设备的iops。（3）举例：限制容器写/dev/sda的速率为30MB/sdocker run -it –device-write-bps /dev/sda:30MB ubuntu限速情况下的运行结果： 对比不限速情况下的运行结果： 备注：oflag=direct 指定用 direct IO 方式写文件，这样 –device-write-bps 才能生效 5、底层技术cgroup（1）作用：实现资源限额（2）定义：全称control group。Linux 操作系统通过 cgroup 可以设置进程使用 CPU、内存 和 IO 资源的限额。之前设置的–cpu-shares、-m、–device-write-bps 实际上就是在配置 cgroup（3）举例：启动一个容器： 查看容器ID： 查看cgroup目录： 在 /sys/fs/cgroup/cpu/docker 目录中，Linux 会为每个容器创建一个 cgroup 目录，以容器长ID 命名备注：目录中包含所有与 cpu 相关的 cgroup 配置，文件 cpu.shares 保存的就是 –cpu-shares 的配置，值为 512；同样的，/sys/fs/cgroup/memory/docker 和 /sys/fs/cgroup/blkio/docker 中保存的是内存以及 Block IO 的 cgroup 配置。 namespace（1）作用：实现资源隔离（2）定义：在每个容器中，我们都可以看到文件系统，网卡等资源，这些资源看上去是容器自己的。拿网卡来说，每个容器都会认为自己有一块独立的网卡，即使 host 上只有一块物理网卡。这种方式非常好，它使得容器更像一个独立的计算机。Linux 实现这种方式的技术是 namespace。namespace 管理着 host 中全局唯一的资源，并可以让每个容器都觉得只有自己在使用它。（3）六种namespace：六种namespace分别对应六种资源：Mount、UTS、IPC、PID、Network和User（4）六种资源：Mount namespace：Mount namespace 让容器看上去拥有整个文件系统。容器有自己的 / 目录，可以执行 mount 和 umount 命令。当然我们知道这些操作只在当前容器中生效，不会影响到 host 和其他容器； UTS namespace：UTS namespace 让容器有自己的 hostname。 默认情况下，容器的 hostname 是它的短ID，可以通过 -h 或 –hostname 参数设置； IPC namespace：IPC namespace 让容器拥有自己的共享内存和信号量（semaphore）来实现进程间通信，而不会与 host 和其他容器的 IPC 混在一起； PID namespace：容器在 host 中以进程的形式运行。例如当前 host 中运行了两个容器； Network namespace：Network namespace 让容器拥有自己独立的网卡、IP、路由等资源； User namespace：User namespace 让容器能够管理自己的用户，host 不能看到容器中创建的用户。","categories":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/categories/docker/"}],"tags":[]},{"title":"mysql基本使用","slug":"mysql数据库基础","date":"2019-01-09T07:12:00.000Z","updated":"2019-01-09T09:50:49.070Z","comments":true,"path":"2019/01/09/mysql数据库基础/","link":"","permalink":"http://yoursite.com/2019/01/09/mysql数据库基础/","excerpt":"","text":"1、mysql安装（1）专用软件包管理器：deb（ubuntu系统）和rpm(Redhat、centos、Fedora、suse系统)备注：rpm包可以由两种组织制作，一种是操作系统发行商（Redhat）制作，一种是mysql官方制作（2）通用二进制格式包gcc:x86（32位），x64（64位）（3）源代码包5.5、5.6之后的mysql不再用make编译，而是改用cmake（跨平台）；5.5、5.6本身没有提供cmake，需要自定义安装；mysql 6之后就已经集成了cmake备注：源代码方式和二进制包方式的区分（1）二进制包里面包括了已经经过编译,可以马上运行的程序。你只需要下载和解包(安装)它们以后,就马上可以使用；源代码包里面包括了程序原始的程序代码,需要在你的计算机上进行编译以后才可以产生可以运行程序，所以从源代码安装的时间会比较长。（2）二进制格式的包名字很长,都带有版本号、适应平台、适应的硬件类型等,而源码格式仅仅就是一个版本号的tar包：mysql-5.0.45.tar.gz 是源码包mysql-5.0.45-linux-x86_64-glibc23.tar.gz 是二进制包（3）源代码包里的文件往往会含有种种源代码文件,头文件.h、c代码源文件.c、C++代码源文件.cc/.cpp等;而二进制包里的文件则会有可执行文件(与软件同名的往往是主执行文件),标志是其所在路径含有名为bin的目录(仅有少数例外) 2、mysql版本alpha：内测版beta：公测版rc：发行候选版ga：通用发行版 3、进程间通信对于mysql客户端和服务端在同一主机的，不同进程间通过mysql.sock进行通信；对于mysql客户端和服务端不在同一主机的，不同进程间基于TCP/IP协议栈进行通信 4、mysql工具客户端工具（1）mysql：交互式输入SQL语句或从文件以批处理模式执行它们的命令行工具（2）mysqlaccess：检查访问主机名、用户名和数据库组合的权限的脚本（3）mysqladmin：管理工具，执行管理操作的客户程序，例如创建或删除数据库，重载授权表，将表刷新到硬盘上，以及重新打开日志文件。mysqladmin还可以用来检索版本、进程，以及服务器的状态信息。（4）mysqlbinlog：从二进制日志读取语句的工具。在二进制日志文件中包含执行过的语句，可用来帮助系统从崩溃中恢复（5）mysqlcheck：检查工具，检查、修复、分析以及优化表的表维护客户程序（6）mysqldump：备份工具，将mysql数据库转储到一个文件（7）mysqlhotcopy：当服务器在运行时，快速备份的工具（8）mysql import：导入工具，使用load data infile将文本文件导入相关表的客户程序（9）mysqlshow：显示数据库、表、列以及索引相关信息的客户程序 （1）\\d:定义语句结束符（2）\\c:提前终止语句执行(直接在后面加上\\c即可，但是加在结束符后面语句依然会执行)（3）\\r:重新连接到服务器（4）\\g:无论语句结束符是什么，直接将此语句送至服务端去执行（5）\\G:无论语句结束符是什么，直接将此语句送至服务端去执行，而且是以竖排的方式来显示(纵向显示，这对于横排显示不下一张表的时候，\\G是一种非常好的显示手段)（6）\\p:print,显示正在执行的命令（7）! COMMAND:执行shell命令(或者用system)（8）\\W:大写W表示语句执行之后显示警告信息（9）\\w:小写w表示语句执行之后不显示警告信息 服务端工具（1）mysqld：SQL后台程序（即mysql服务器进程）。该程序必须运行之后，客户端才能通过连接服务来访问数据库（2）mysqld_safe：服务器启动脚本。在Unix中推荐使用mysqld_safe来启动mysqld服务器。mysqld_safe增加了一些安全特性，例如当出现错误时重启服务器并向错误日志写入运行时间信息（3）mysql.server：服务器启动脚本。它调用mysqld_safe来启动mysql服务（4）mysql_multi：服务器启动脚本。用于启动或者停止系统上安装的多个mysql服务（5）myisampack：压缩myisam表以产生更小的只读表的一个工具（6）myisamchk：用来描述、检查、优化和维护myisam表的实用工具（7）mysql_install_db：该脚本用默认权限创建mysql授权表。通常只是在系统上首次安装mysql时执行一次备注：mysqld工具可能不在bin目录下，可能在{mysql安装目录}/mysql/libexec下 图形化工具mysql官方提供的图形化管理工具MySQL WorkbenchMySQL Workbenck也有两个版本：（1）MySQL Workbench Community Edition，也就是社区版本。（2）MySQL Workbench Standard Edition，也就是商业版本，是按年收取费用的。 其他工具mysql_configmysql在安装完后，一般在${MYSQL_HOME}/bin目录下有mysql_config工具，它不是一个二进制文件，是一个脚本工具。当我们在编译自己的mysql客户端时，可用通过mysql_config工具获取很多的有用的编译参数，例如使用mysql_config –include可以获取mysql的mysql在安装时的一些头文件位置，或者mysql_config–libs可以获取mysql的头文件及共享库等编译参数。例如：mysql_config–include #得到-I/usr/include/mysqlmysql_config –libs #得到-L/usr/lib/mysql-lmysqlclient -lz -lcrypt -lnsl -lm -L/usr/lib -lssl -lcrypto 备注：（1）修改用户密码：mysqladmin -u username -h hostname password ‘new_password’ -p ‘old_password’也可以这样修改：set password for ‘username‘@’host’=password(‘new_password’)（2）SELECT DATABASE();#查看当前使用的默认数据库连入数据库的时候，还可以通过–database db_name(或者-D db_name)来指定默认的数据库 5、mysqladmin工具mysqladmin create hellodb #不用连上数据库直接在linux命令行下创建(会读取my.cnf下的数据库的定义)mysqladmin -uroot -p password -h host_name create hellodb还有其他一些子命令，比如：mysqladmin drop db_name:删除dbmysqladmin ping:测试对方mysql服务器是否在线：mysqladmin -uroot -p -hhostname(或主机ip) pingmysqladmin processlist:显示正在执行的进程(线程列表)(相当于连上mysql之后执行的SHOW PROCESSES)mysqladmin status:显示mysql服务器的状态status的高级用法：mysqladmin status –sleep 2 #定义多久显示一次mysqladmin status –count 2 #定义显示次数mysqladmin extended-status:显示状态变量(状态变量对于查询mysql服务器状态和排除故障至关重要)mysqladmin variables:显示服务器变量(跟状态变量区分)mysqladmin flush-privileges(等同于reload):让mysql重读授权表mysqladmin flush-status:重置大多数的服务器状态变量mysqladmin flush-threads:重置线程缓存mysqladmin flush-logs:中继日志滚动mysqladmin flush-hosts:重置连接的hostmysqladmin refresh:相当于mysqladmin flush-logs和mysqladmin flush-hostsmysqladmin shutdown:关闭mysql服务器mysqladmin version:显示当前服务器版本及状态信息mysqladmin start-slave:启动复制，启动从服务器复制线程mysqladmin stop-slave:关闭复制 6、表文件（1）对于myisam存储引擎来说.frm：表结构.MYD：表空间.MYI：表索引 （2）对于innodeDB存储引擎来说（默认所有表共享一个表空间文件，建议每个表单独一个表空间文件）.frm：表结构.ibd：表空间（表数据和表索引）.opt：定义字符集和排列规则（是一个文本文件，排列规则collation）","categories":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/categories/mysql/"}],"tags":[]},{"title":"关系型数据库基础理论","slug":"关系型数据库基础理论","date":"2019-01-09T06:20:00.000Z","updated":"2019-01-09T07:04:13.452Z","comments":true,"path":"2019/01/09/关系型数据库基础理论/","link":"","permalink":"http://yoursite.com/2019/01/09/关系型数据库基础理论/","excerpt":"","text":"1、关系模型和关系型数据库之间的联系关系模型：也叫结构化数据模型关系模型分类：（1）关系模型：最基本的（2）关系-实体模型：将数据拆分为多个不同实体（数据表），通过实体之间建立关联关系，也叫E-R模型（3）对象关系模型：基于对象的数据模型（比如图片）（4）半结构化数据模型：比如XML（扩展标记语言），存储数据的同时也存储数据的属性 关系型数据库能够处理以上的4种关系型数据模型 2、SQL语句分类（1）DML：数据操作语言（增删改查）insertdeleteupdateselect（2）DDL：数据定义语言（针对操作对象）createdropalter（3）DCL：数据控制语言（针对访问权限）grantrevoke 关系型数据库的对象有：库、表、索引、视图、用户、约束、存储过程、存储函数、触发器、事件调度器（类似于cron） 3、约束分类（1）域约束：数据类型约束（2）外键约束：引用完整性约束（使本表与另外的表关联起来的字段）（3）主键约束：某字段能唯一标识此字段所属的实体，并且不能为空（唯一标识本表）（4）唯一约束：跟主键约束类似，但是唯一约束可以为空，主键约束不能为空，而且一张表可以有多个唯一约束，但是只能有一个主键约束（5）检查性约束：除了用域约束来规定数据的类型之外，检查性约束可以规定数据不违反常理（比如规定一个人的年龄不超过150岁） 4、关系型数据分层表示层：表逻辑层：存储引擎物理层：数据文件 5、关键组件（1）查询管理器DDL解释器、DML解释器、查询执行引擎（2）存储管理器缓冲区管理器、文件管理器、事务管理器、权限和完整性管理器备注：因为对数据操作都是需要把数据从磁盘中读到内存，而内存往往比硬盘小得多，因此需要缓冲区管理器提供一种缓冲置换策略，将不常用的或者是已过期很久的一些操作置换出去，以此来腾出内存空间 6、进程与线程mysql是属于单进程多线程。线程分为守护线程和用户线程两种。守护线程：mysql内部的线程用户线程：比如连进来的用户（每一个用户连进来都建立一个线程，一个线程不能同时为多个用户服务，因为这涉及到权限交叉的问题）备注：在32位系统中，mysql只能使用到2.7G的内存（因此在生产环境中应该上64位的系统） 7、mysql与Oracle的区别最大的区别在于mysql支持插件式的存储引擎（也就是用户可以自行选择使用哪个存储引擎）备注：5.5.8之前，mysql默认的存储引擎是myisam，myisam不支持事务（myisam适用于查询比较多而修改比较少的场景，特别适用于数据仓库）；5.5.8之后，也就是mysql被Oracle收购之后，mysql的默认存储引擎变为innodeDB（innodeDB适用于在线事务管理系统，比如在线论坛等等） 8、SQL语句执行过程连接管理器–&gt;线程管理器–&gt;用户模块（验证身份）–&gt;命令分发模块–&gt;解析器–&gt;优化器（select）、表定义模块（update、delete、insert）、表维护模块（repair，检查、修改、备份、修复、优化等）、复制模块、状态报告模块–&gt;访问控制模块（检查用户是否有权限操作相关数据表）–&gt;表管理器（完成SQL操作，负责创建、读取或修改表结构定义文件，维护表描述符高速缓存，管理表锁）–&gt;存储引擎（数据库跟磁盘上的数据打交道的接口） 9、定长和变长对于定长的数据来说，查询的效率高，但是很容易造成空间浪费；对于变长的数据来说，查询效率慢，但是可以节省存储空间备注：在选择使用定长还是变长的时候，应该选择折中的方案 10、数据字典定义：存储元数据的表（在mysql初始化的时候，默认会生成一个叫做mysql的数据表，这个数据表就是用来存储数据库的相关元数据的，也就是数据字典）","categories":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/categories/mysql/"}],"tags":[]},{"title":"bash: ifconfig: command not found","slug":"bash-ifconfig-command-not-found","date":"2019-01-08T02:34:00.000Z","updated":"2019-01-08T02:37:08.948Z","comments":true,"path":"2019/01/08/bash-ifconfig-command-not-found/","link":"","permalink":"http://yoursite.com/2019/01/08/bash-ifconfig-command-not-found/","excerpt":"","text":"root@37e20725f95d:/usr/local/apache2# ifconfigbash: ifconfig: command not found 备注：debian默认没有安装ifconfig查看redhat（Centos）版本：cat /etc/redhat-release查看debian（ubuntu）版本：cat /etc/issue Debian系统：apt-get install net-tools","categories":[{"name":"QA","slug":"QA","permalink":"http://yoursite.com/categories/QA/"}],"tags":[{"name":"ifconfig","slug":"ifconfig","permalink":"http://yoursite.com/tags/ifconfig/"}]},{"title":" bash: ip: command not found","slug":"bash-ip-command-not-found","date":"2019-01-08T02:31:00.000Z","updated":"2019-01-08T02:32:05.155Z","comments":true,"path":"2019/01/08/bash-ip-command-not-found/","link":"","permalink":"http://yoursite.com/2019/01/08/bash-ip-command-not-found/","excerpt":"","text":"Centos安装:yum install iproute iproute-doc Ubuntu安装:apt-get install iproute iproute-doc","categories":[{"name":"QA","slug":"QA","permalink":"http://yoursite.com/categories/QA/"}],"tags":[{"name":"ip","slug":"ip","permalink":"http://yoursite.com/tags/ip/"}]},{"title":"Centos:brctl command not found","slug":"linux-brctl-command-not-found","date":"2019-01-08T02:27:00.000Z","updated":"2019-01-08T02:28:53.007Z","comments":true,"path":"2019/01/08/linux-brctl-command-not-found/","link":"","permalink":"http://yoursite.com/2019/01/08/linux-brctl-command-not-found/","excerpt":"","text":"[root@localhost ~]# brctl-bash: brctl: command not found 解决方法： [root@localhost ~]# yum install bridge-utils","categories":[{"name":"QA","slug":"QA","permalink":"http://yoursite.com/categories/QA/"}],"tags":[{"name":"brctl","slug":"brctl","permalink":"http://yoursite.com/tags/brctl/"}]},{"title":"docker镜像篇","slug":"docker镜像篇","date":"2019-01-07T01:28:00.000Z","updated":"2019-01-10T06:17:00.284Z","comments":true,"path":"2019/01/07/docker镜像篇/","link":"","permalink":"http://yoursite.com/2019/01/07/docker镜像篇/","excerpt":"","text":"1、最小镜像（1）定义hello-world是Docker官方提供的一个镜像，通常用来验证Docker是否安装成功（2）Dockerfile查看地址：https://github.com/docker-library/hello-world/blob/master/Dockerfile-linux.template 解释指令：FROM scratch：此镜像是从白手起家，从0开始构建的COPY hello /：将文件”hello”复制到镜像的根目录CMD [“/hello”]：容器启动时，执行/hello 2、base镜像（1）定义base镜像提供的是最小安装的linux发行版。能称作base镜像的通常都是各种linux发行版的Docker镜像，比如Ubuntu、Debian、Centos等（2）Dockerfile查看地址：https://github.com/CentOS/sig-cloud-instance-images/blob/a77b36c6c55559b0db5bf9e74e61d32ea709a179/docker/Dockerfile 解释指令：FROM、COPY、CMD这几个指令的作用跟hello-world镜像中的作用是一样的；ADD指令添加到镜像的tar包就是Centos7的rootfs。在制作镜像时，这个tar包会自动解压到/目录下，生成/dev、/proc、/bin等目录（3）含义不依赖其他镜像，从scratch构建；其他镜像可以以之为基础进行扩展（4）以Cenots为例下载镜像：docker pull centos查看镜像信息：docker images centos（备注：平时我们安装一个Centos至少都有几个GB，这里只有200MB。这是因为内核空间kernel的文件系统是bootfs，linux刚启动时会加载bootfs文件系统，之后bootfs会被卸载掉。而用户空间的文件系统是rootfs，包含我们熟悉的/dev、/proc、/bin等目录。对于base镜像来说，底层用host的kernel，自己只需要提供rootfs就行。对于一个精简的OS，rootfs可以很小，只需要包括最基本的命令、工具和程序库等）支持多种操作系统类型（备注：除Centos之外，base镜像可以模拟出多种操作系统环境。base镜像只是用户空间与发行版一致，kernel版本与发行版是不同的。因为所有容器共用host的kernel，因此在容器中无法对kernel升级。如果容器对kernel的版本有要求，比如说应用只能在某个kernel版本下运行，则不建议用容器，这种场景虚拟机可能更合适） 3、分层结构（1）定义通过扩展现有镜像，创建新的镜像（实际上，Docker Hub中99%的镜像都是通过在base镜像中安装和配置需要的软件构建出来的）（2）Dockerfile 解释指令：新镜像不再是从scratch开始，而是直接在Debian base镜像上构建；安装emacs编辑器；安装Apache2；容器启动时运行bash（3）好处：共享资源比如，有多个镜像都从相同的base镜像构建而来，那么Docker Hub只需要在磁盘上保存一份base镜像即可；同时内存中也只需要加载一份base镜像，就可以为所有容器服务了（4）copy-on-write特性定义：当需要修改时，才复制一份数据原理：当容器启动时，一个新的可写层被加载到镜像的顶部，这一层通常被称作”容器层”，”容器层”之下都叫”镜像层”；所有对容器的改动（无论是添加、删除或者是修改文件）都只会发生在容器层中；只有容器层是可写的，容器层下面的所有镜像层都是只读的，不会被容器修改，所以镜像可以被多个容器共享。（5）查看分层结构docker history：会显示镜像的构建历史，也就是Dockerfile的执行过程。ubuntu-with-vi-dockerfile与ubuntu镜像相比，确实只是多了顶部的一层 备注：docker history输出中IMAGE列出现，表示无法获取IMAGE ID，通常从Docker Hub下载的镜像会有这个问题 4、构建镜像（1）docker commit步骤：a、运行容器 -it参数的作用是以交互模式进入容器，并打开终端b、确认vim确实没有安装 c、安装vim（如果没有找到vim软件包，先apt-get update一下） d、打开一个新的窗口，查看当前运行的容器 silly_goldberg 是 Docker 为我们的容器随机分配的名字e、执行docker commit命令将容器保存为镜像 新镜像命名为ubuntu-with-vif、查看新镜像属性 从size上看到镜像因为安装了软件而变大了g、从新镜像启动容器，验证vi已经可以使用 总结：Docker并不建议用户通过这种方式构建镜像原因：这是一种手工创建镜像的方式，容易出错，效率低且可重复性弱；使用者并不知道镜像是如何创建出来的，里面是否有恶意程序。也就是说无法对镜像进行审计，存在安全隐患。（2）Dockerfile构建文件步骤：a、新建一个Dockerfile文件，内容如下：FROM ubuntuRUN apt-get update &amp;&amp; apt-get install -y vimb、运行docker build命令docker build -t ubuntu-with-vi-dockerfile .命令解释：-t将新镜像命名为ubuntu-with-vi-dockerfile；命令末尾的点号(.)，指明了build context为当前目录。目录下的所有文件和子目录都会被发送给Docker daemon。所以，不要将多余文件放到build context，特别不要把/、/usr作为build context，否则构建过程会相当缓慢甚至失败；我们也可以通过-f参数指定Dockerfile的位置。c、构建完成后，通过docker images查看镜像信息 5、缓存特性（1）定义缓存已有镜像的镜像层，构建新镜像时，如果某镜像层已经存在，就直接使用，无需重新创建（2）举例在前面的Dockerfile中添加一点新内容，往镜像中复制一个文件 （3）不使用缓存如果我们希望在构建镜像的时候不使用缓存，可以在docker build命令上加上–no-cache参数（4）缓存失效Dockerfile中每一个指令都会创建一个镜像层，上层是依赖下层的。无论什么时候，只要某一层发生变化，其上面所有层的缓存都会失效。也就是说，如果我们改变Dockerfile指令的执行顺序，或者修改或添加指令，都会使缓存失效。比如，交换前面的RUN和COPY的顺序，也会导致缓存失效。（5）使用场景构建镜像 &amp;&amp; 下载镜像 6、调试Dockerfile（1）定义如果Dockerfile由于某种原因执行到某个指令失败了，我们能够得到前一个指令成功执行构建出的镜像，这对调试Dockerfile非常有帮助（2）举例 运行在第三步的时候报错，我们可以利用第二部创建的镜像ba6402b1298d进行调试，方式是通过 docker run -it 启动镜像的一个容器。手工执行 RUN 指令很容易定位失败的原因是 busybox 镜像中没有 bash。 7、Dockerfile常用指令（1）FROM指定base镜像（2）MAINTAINER设置镜像的作者，可以是任意字符串（3）COPY将文件从build context复制到镜像（build context默认是当前目录，也可以通过-f来指定）COPY支持两种形式：COPY src destCOPY [“src”,”dest”]备注：src只能指定build context中的文件或目录（4）ADD与COPY类似，从build context复制文件到镜像。不同的是，如果src是归档文件（tar、zip、tgz、xz等），文件会被自动解压到dest（5）ENV设置环境变量，环境变量可以被后面的指令使用举例：…ENV MY_VERSION 1.3RUN apt-get install -y mypackage=$MY_VERSION…（6）EXPOSE指定容器中的进程会监听某个端口（7）VOLUME将文件或目录声明为volume（8）WORKDIR设置镜像中的当前工作目录（9）RUN在容器中运行指定的命令。通常用于安装应用和软件包两种格式：shell格式：RUN apt-get install python3Exec格式：RUN [“apt-get”,”install”,”python3”]举例：RUN apt-get update &amp;&amp; apt-get install -y \\bzr \\cvs \\git \\mercurial \\subversion备注：apt-get update和apt-get install被放在一个RUN指令中执行，这样能够保证每次安装的是最新的包。如果apt-get install在单独的RUN中执行，则会使用apt-get update创建的镜像层，而这一层可能是很久以前缓存的。（10）CMD设置容器启动时运行指定的指令，此命令会在容器启动且docker run没有指定其他指令时运行备注：如果docker run指定了其他命令，CMD指定的默认命令将会被忽略；如果Dockerfile中有多个CMD指令，只有最后一个CMD有效三种格式：shell格式：CMD echo “hello world”Exec格式：CMD [“/bin/echo”,”hello world”]与ENTRYPOINT搭配使用：CMD [“param1”,”param2”] ,此时ENTRYPOINT必须使用Exec格式，其用途是为ENTRYPOINT设置默认的参数举例：Dockerfile 片段如下：CMD echo “Hello world”运行容器 docker run -it [image] 将输出：Hello world但当后面加上一个命令，比如 docker run -it [image] /bin/bash，CMD 会被忽略掉，命令 bash 将被执行（11）ENTRYPOINT设置容器启动时运行的指令，看上去与CMD很像备注：与CMD不同的地方在于，ENTRYPOINT不会被忽略，一定会被执行，即使运行docker run时指定了其他指令；Dockerfile中有多个ENTRYPOINT命令，但是只有最后一个生效两种格式：shell格式：ENTRYPOINT echo “hello world”Exec格式：ENTRYPOINT [“/bin/echo”,”hello world”]举例：Dockerfile 片段如下：ENTRYPOINT [“/bin/echo”, “Hello”]CMD [“world”]当容器通过 docker run -it [image] 启动时，输出为：Hello world而如果通过 docker run -it [image] CloudMan 启动，则输出为：Hello CloudMan 8、镜像命名（1）组成实际上一个特定镜像的名字由两部分组成：repository和tag。格式为：[imagename]=[reposity]:[tag]默认如果docker build没有指定tag，会使用默认值latesttag的作用：常用于描述镜像的版本信息，比如httpd镜像 也可以是任意字符串，比如ubuntu镜像 打tag：docker tag myimage-v1.9.2 myimage:1docker tag myimage-v1.9.2 myimage:1.9docker tag myimage-v1.9.2 myimage:1.9.2docker tag myimage-v1.9.2 myimage:latest 9、搭建Registry（1）搭建公共Registry步骤：a、首先在docker hub上面注册一个账号b、命令行登录（用户名密码是你注册时提供的用户名和密码） c、修改镜像的repository使之与docker hub账号匹配 d、通过docker push将镜像上传到Docker Hub 备注：Docker 会上传镜像的每一层。如果是在官方镜像的基础上做了一点修改而得到新的镜像，Docker Hub 上已经有了全部的镜像层，所以真正上传的数据很少。同样的，如果我们的镜像是基于 base 镜像的，也只有新增加的镜像层会被上传。如果想上传同一 repository 中所有镜像，省略 tag 部分就可以了，例如：docker push liangzj/ubuntu-with-vi-dockerfilee、登录 https://hub.docker.com，在repository就可以看到上传的镜像 f、这个镜像就可以被下载使用了docker pull liangzj/ubuntu-with-vi-dockerfile:v1（2）搭建本地Registrywhy：Docker Hub虽然非常方便，但还是有些限制，比如，需要Internet连接，而且上传和下载的速度慢；上传到Docker Hub的镜像任何人都能够访问，虽然可以用私有repository，但不是免费的；安全原因很多组织不允许将镜像放到外网；解决方案就是搭建本地的Registry。步骤：a、启动registry容器 备注：使用的镜像是 registry:2-d是后台启动容器；-p是将容器的5000端口映射到host的5000端口。5000 是 registry 服务端口。-v是将容器的/var/lib/registry目录映射到host的/myregistry，用于存放镜像数据b、通过docker tag重命名镜像，使之与registry匹配 备注：localhost是文件/etc/hosts里面定义的主机名我们在镜像的前面加上了运行 registry 的主机名称和端口。c、通过docker push上传镜像 d、通过docker pull从本地registry下载镜像 10、常用操作子命令（1）images：显示镜像列表（2）history：显示镜像构建历史（3）commit：从容器创建新镜像（4）build：从Dockerfile构建镜像（5）tag：给镜像打tag（6）pull：从registry下载镜像（7）push：将镜像上传到registry（8）rmi：删除镜像（如果一个镜像对应了多个 tag，只有当最后一个 tag 被删除时，镜像才被真正删除）（9）search：搜索docker hub中的镜像（search 让我们无需打开浏览器，在命令行中就可以搜索 Docker Hub 中的镜像）","categories":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/categories/docker/"}],"tags":[]},{"title":"docker配置允许远程服务器的连接请求","slug":"docker配置允许远程服务器的连接请求","date":"2019-01-02T02:20:00.000Z","updated":"2019-01-02T02:23:42.864Z","comments":true,"path":"2019/01/02/docker配置允许远程服务器的连接请求/","link":"","permalink":"http://yoursite.com/2019/01/02/docker配置允许远程服务器的连接请求/","excerpt":"","text":"默认配置下，docker daemon只能响应来自本地host的客户端请求。如果要允许远程服务端请求，需要在配置文件中打开TCP监听。步骤如下：1、在环境变量 ExecStart 后面添加 -H tcp://0.0.0.0，允许来自任意 IP 的客户端连接（服务端） 2、重启 Docker daemon（服务端） 3、服务器 IP 为 120.79.244.203，客户端在命令行里加上 -H 参数，即可与远程服务器通信（客户端） 备注：info 子命令用于查看 Docker 服务器的信息。","categories":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/categories/docker/"}],"tags":[]},{"title":"docker架构与组件","slug":"docker架构与组件","date":"2019-01-02T02:01:00.000Z","updated":"2019-01-02T02:16:21.247Z","comments":true,"path":"2019/01/02/docker架构与组件/","link":"","permalink":"http://yoursite.com/2019/01/02/docker架构与组件/","excerpt":"","text":"1、why–为什么需要容器（1）背景今天，开发人员通常使用多种服务（比如 MQ，Cache，DB）构建和组装应用，而且应用很可能会部署到不同的环境，比如虚拟服务器，私有云和公有云。一方面应用包含多种服务，这些服务有自己所依赖的库和软件包；另一方面存在多种部署环境，服务在运行时可能需要动态迁移到不同的环境中。这就产生了一个问题：如何让每种服务能够在所有的部署环境中顺利运行？（2）引入docker的理由简要的答案是：容器使软件具备了超强的可移植能力。（3）docker的优势对于开发人员来说–Build Once, Run Anywhere容器意味着环境隔离和可重复性。开发人员只需为应用创建一次运行环境，然后打包成容器便可在其他机器上运行。另外，容器环境与所在的 Host 环境是隔离的，就像虚拟机一样，但更快更简单。 对于运维人员来说–Configure Once, Run Anything只需要配置好标准的 runtime 环境，服务器就可以运行任何容器。这使得运维人员的工作变得更高效，一致和可重复。容器消除了开发、测试、生产环境的不一致性。 2、what–什么是容器（1）定义容器是一种轻量级、可移植、自包含的软件打包技术，使应用程序可以在几乎任何地方以相同的方式运行。开发人员在自己笔记本上创建并测试好的容器，无需任何修改就能够在生产系统的虚拟机、物理服务器或公有云主机上运行。（2）组成应用程序本身；依赖：比如应用程序所需要的库或者其他软件（3）对比容器与虚拟机相同点：两者都是为应用提供封装何隔离不同点：a、容器在Host操作系统的用户空间中运行，与操作系统的其他进程隔离。这一点显著区别于虚拟机。b、由于所有的容器共享同一个Host OS，这使得容器在体积上要比虚拟机小很多。另外，启动容器不需要启动整个操作系统，所以容器部署和启动速度更快，开销更小，也更容易迁移。 3、how–容器是如何工作的（1）docker架构docker采用的是Client/Server架构。客户端向服务端发送请求，服务端负责构建、运行和分发容器。客户端和服务端可以运行在同一个Host上，客户端也可以通过socket或REST API与远程的服务器通信 （2）核心组件a、docker客户端定义：通过docker客户端我们可以方便地在Host上构建和运行容器。相关命令：最常用的Docker客户端是docker命令；直接输入docker可以查看docker支持的子命令。 b、docker服务端定义：Docker daemon以后台服务的方式运行在Docker host上，负责创建、运行、监控容器，构建、存储镜像。默认配置：默认配置下，Docker daemon只能响应来自本地Host的客户端请求。（也可以配置允许远程客户端请求） c、docker镜像定义：可将Docker镜像看着只读模板，通过它可以创建Docker容器。例如某个镜像可能包含一个Ubuntu操作系统、一个Apache HTTP Server以及用户开发的Web应用。生成镜像：可以从无到有开始创建镜像（可以将镜像的内容和创建步骤描述在一个文本文件中，这个文件被称作 Dockerfile，通过执行 docker build 命令可以构建出 Docker 镜像）；也可以下载并使用别人创建好的现成的镜像；还可以在现有镜像上创建新的镜像。 d、docker容器定义：Docker容器就是Docker镜像的运行实例。通俗理解：可以这么认为，对于应用软件，镜像是软件生命周期的构建和打包阶段，而容器则是启动和运行阶段。 e、registry定义：Registry 是存放 Docker 镜像的仓库。分类：公有：Docker Hub（https://hub.docker.com/） 是默认的 Registry，由 Docker 公司维护，上面有数以万计的镜像，用户可以自由下载和使用；私有：出于对速度或安全的考虑，用户也可以创建自己的私有 Registry。相关命令：docker pull：命令可以从 Registry 下载镜像。docker run：命令则是先下载镜像（如果本地没有），然后再启动容器。","categories":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/categories/docker/"}],"tags":[]},{"title":"docker基本安装","slug":"docker基本安装","date":"2018-12-29T03:16:00.000Z","updated":"2018-12-29T07:19:13.330Z","comments":true,"path":"2018/12/29/docker基本安装/","link":"","permalink":"http://yoursite.com/2018/12/29/docker基本安装/","excerpt":"","text":"1、docker安装在ubuntu下安装：（1）允许apt命令HTTPS访问docker源$ sudo apt-get install \\ apt-transport-https \\ ca-certificates \\ curl \\ software-properties-common （2）添加docker官方的GPGcurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - （3）将docker的源添加到/etc/apt/sources.list$ sudo add-apt-repository \\“deb [arch=amd64] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) \\ stable” （4）安装docker$ sudo apt-get update$ sudo apt-get install docker-ce 在centos7下安装：（1）更新yum源yum update（2）脚本安装curl -sSL https://get.docker.com/ | sh（3）启动dockerservice docker start 2、docker加速背景：由于 Docker Hub 的服务器在国外，下载镜像会比较慢。幸好 DaoCloud 为我们提供了免费的国内镜像服务。步骤：（1）在 daocloud.io 免费注册一个用户。登录后，点击顶部菜单“加速器”。 （2）点击之后，复制”配置Docker加速器”框中给出的命令，在你的服务器上执行我的是curl -sSL https://get.daocloud.io/daotools/set_mirror.sh | sh -s http://f1361db2.m.daocloud.io （3）重启docker$sudo systemctl restart docker.service 3、docker启动（1）容器启动过程（httpd为例）a、Docker daemon 发现本地没有 httpd 镜像b、daemon 从 Docker Hub 下载镜像c、下载完成，镜像 httpd 被保存到本地d、Docker daemon 启动容器（2）容器基本命令docker images：查看镜像docker ps：查看容器","categories":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/categories/docker/"}],"tags":[]},{"title":"apt-get update报错","slug":"apt-get-update报错","date":"2018-12-28T08:57:00.000Z","updated":"2018-12-28T09:05:09.096Z","comments":true,"path":"2018/12/28/apt-get-update报错/","link":"","permalink":"http://yoursite.com/2018/12/28/apt-get-update报错/","excerpt":"","text":"apt安装docker的时候，遇到apt-get update报错：下列签名无效：KEYEXPIRED 1544811256 处理步骤：1、用apt-key list 命令看一下，发现是mongoDB的gpg过期了，所以无法update 2、试着把mongoDB的gpg删除，用apt-key del 91FA4AD5，再次apt-get update，还是报错 3、这时候重新导入一个新的MongoDB public GPG Keyapt-key adv –keyserver hkp://keyserver.ubuntu.com:80 –recv 2930ADAE8CAF5059EE73BB4B58712A2291FA4AD5然后再执行apt-get update,这是update终于不会报错了这时候就可以安装docker了：$sudo apt-get install docker-ce","categories":[{"name":"QA","slug":"QA","permalink":"http://yoursite.com/categories/QA/"}],"tags":[]},{"title":"容器生态系统（容器支持技术）","slug":"容器生态系统（容器支持技术）","date":"2018-12-28T07:44:00.000Z","updated":"2018-12-28T07:52:46.504Z","comments":true,"path":"2018/12/28/容器生态系统（容器支持技术）/","link":"","permalink":"http://yoursite.com/2018/12/28/容器生态系统（容器支持技术）/","excerpt":"","text":"1、容器网络定义：容器的出现使网络拓扑变得更加动态和复杂。用户需要专门的解决方案来管理容器与容器，容器与其他实体之间的连通性和隔离性。分类：（1）docker原生：docker network（2）第三方开源：fannelweavecalico 2、服务发现定义：动态变化是微服务应用的一大特点。当负载增加时，集群会自动创建新的容器；负载减小，多余的容器会被销毁。容器也会根据 host 的资源使用情况在不同 host 中迁移，容器的 IP 和端口也会随之发生变化。因此需要提供服务发现这种机制，来保存容器集群中所有微服务最新的信息，比如 IP 和端口，并对外提供 API，提供服务查询功能。分类（典型方案）：（1）etcd（2）consul（3）zookeeper 3、监控定义：监控对于基础架构非常重要，而容器的动态特征对监控提出更多挑战。分类：（1）docker原生：docker ps/top/stats：docker ps/top/stats 是Docker 原生的命令行监控工具。docker stats API：用户可以通过 HTTP 请求获取容器的状态信息。（2）第三方开源：sysdigcAdvisor/HeapsterWeave Scope 4、数据管理定义：容器经常会在不同的 host 之间迁移，如何保证持久化数据也能够动态迁移，是数据管理的重要内容。分类：flocker（提供数据管理的相关能力） 5、日志管理定义：日志为问题排查和事件管理提供了重要依据。分类：（1）docker logs：docker logs是docker原生工具（2）logspout：logspout对日志提供了路由功能，它可以收集不同容器的日志并转发给其他工具进行后处理 6、安全性定义：对于年轻的容器，安全性一直是业界争论的焦点。分类：OpenSCAP（OpenSCAP能够对容器镜像进行扫描，发现潜在的漏洞。）","categories":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/categories/docker/"}],"tags":[]},{"title":"容器生态系统（容器平台技术）","slug":"容器生态系统（容器平台技术）","date":"2018-12-28T07:39:00.000Z","updated":"2018-12-28T07:43:01.371Z","comments":true,"path":"2018/12/28/容器生态系统（容器平台技术）/","link":"","permalink":"http://yoursite.com/2018/12/28/容器生态系统（容器平台技术）/","excerpt":"","text":"1、容器编排引擎定义：基于容器的应用一般会被划分为不同的组件，并以服务的形式运行在各自的容器中，通过 API 对外提供服务。为了保证应用的高可用，每个组件都可能会运行多个相同的容器。这些容器会组成集群，这时候我们就需要通过容器编排引擎来管理容器集群，包括容器管理、调度、集群定义和服务发现等。通过容器编排引擎，容器被有机的组合成微服务应用，实现业务需求。分类（当前主流）：（1）docker swarm：docker swarm 是 Docker 开发的容器编排引擎。（2）kubernetes：kubernetes 是 Google 领导开发的开源容器编排引擎，同时支持 Docker 和 CoreOS 容器。（3）mesos：mesos 是一个通用的集群资源调度平台，mesos 与 marathon 一起提供容器编排引擎功能。 2、容器管理平台定义：容器管理平台是架构在容器编排引擎之上的一个更为通用的平台。通常容器管理平台能够支持多种编排引擎，抽象了编排引擎的底层实现细节，为用户提供更方便的功能分类（典型代表）：（1）Rancher（2）ContainerShip 3、基于容器的PaaS定义：基于容器的 PaaS 为微服务应用开发人员和公司提供了开发、部署和管理应用的平台，使用户不必关心底层基础设施而专注于应用的开发。分类（典型代表）：（1）Deis（2）Flynn（3）Dokku","categories":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/categories/docker/"}],"tags":[]},{"title":"容器生态系统（容器核心技术）","slug":"容器生态系统（容器核心技术）","date":"2018-12-28T06:49:00.000Z","updated":"2018-12-28T07:25:18.320Z","comments":true,"path":"2018/12/28/容器生态系统（容器核心技术）/","link":"","permalink":"http://yoursite.com/2018/12/28/容器生态系统（容器核心技术）/","excerpt":"","text":"1、容器规范定义：容器不光是 Docker，还有其他容器，比如 CoreOS 的 rkt。为了保证容器生态的健康发展，保证不同容器之间能够兼容，包含 Docker、CoreOS、Google在内的若干公司共同成立了一个叫 Open Container Initiative（OCI） 的组织，其目是制定开放的容器规范。分类：目前 OCI 发布了两个规范：runtime spec 和 image format spec。有了这两个规范，不同组织和厂商开发的容器能够在不同的 runtime 上运行。这样就保证了容器的可移植性和互操作性。 2、容器runtime定义：runtime 是容器真正运行的地方。runtime 需要跟操作系统 kernel 紧密协作，为容器提供运行环境。类似于java与JVM的关系：Java 程序就好比是容器，JVM 则好比是 runtime。JVM 为 Java 程序提供运行环境。同样的道理，容器只有在 runtime 中才能运行。分类（目前主流）：（1）lxc：lxc 是 Linux 上老牌的容器 runtime。Docker 最初也是用 lxc 作为 runtime。（2）runc：runc 是 Docker 自己开发的容器 runtime，符合 oci 规范，也是现在 Docker 的默认 runtime。（3）rkt：rkt 是 CoreOS 开发的容器 runtime，符合 oci 规范，因而能够运行 Docker 的容器。 3、容器管理工具定义：容器管理工具对内与 runtime 交互，对外为用户提供 interface，比如 CLI。这就好比除了 JVM，还得提供 java 命令让用户能够启停应用分类：（1）lxd：lxc的管理工具lxd（2）docker engine：runc 的管理工具是 docker engine。可以理解为docker engine=docker daemon。docker engine 包含后台 deamon 和 cli 两个部分。我们通常提到 Docker，一般就是指的 docker engine（3）rkt cli：rkt 的管理工具是 rkt cli 4、容器定义工具定义：允许用户定义容器的内容和属性，这样容器就能够被保存，共享和重建。分类：（1）docker image：docker image 是 docker 容器的模板，runtime 依据 docker image 创建容器。（2）dockerfile：dockerfile是包含若干命令的文本文件，可以通过这些命令创建出 docker image。（3）ACI：ACI (App Container Image) 与 docker image 类似，只不过它是由 CoreOS 开发的 rkt 容器的 image 格式。 5、registries定义：容器是通过 image 创建的，需要有一个仓库来统一存放 image，这个仓库就叫做 Registry。分类：（1）docker registry：企业可以用 Docker Registry 构建私有的 Registry。（2）docker hub：Docker Hub（https://hub.docker.com） 是 Docker 为公众提供的托管 Registry，上面有很多现成的 image，为 Docker 用户提供了极大的便利。（3）Quay.io：Quay.io（https://quay.io/）是另一个公共托管 Registry，提供与 Docker Hub 类似的服务。 6、容器OS定义：容器 OS 是专门运行容器的操作系统。与常规 OS 相比，容器 OS 通常体积更小，启动更快。因为是为容器定制的 OS，通常它们运行容器的效率会更高。分类（杰出代表）：（1）CoreOS（2）atomic（3）ubuntu core","categories":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/categories/docker/"}],"tags":[]},{"title":"路由技术（动态路由之OSPF）","slug":"路由技术（动态路由之OSPF）","date":"2018-12-28T02:06:00.000Z","updated":"2018-12-28T02:20:15.382Z","comments":true,"path":"2018/12/28/路由技术（动态路由之OSPF）/","link":"","permalink":"http://yoursite.com/2018/12/28/路由技术（动态路由之OSPF）/","excerpt":"","text":"1、基本概述定义：开放性最短路径优先（用于替代有缺陷的RIP）2、基本特征（1）OSI层次：传输层，基于协议号89（2）协议类型：链路状态路由协议（3）有类/无类：无类（4）IGP/EGP：IGP（5）管理距离：110（6）度量值：cost=100/带宽（M）（7）路由更新：组播如果是Dother，组播地址224.0.0.5如果是DR/BDR，组播地址224.0.0.63、基本运行 4、路由表更新 5、运行环境决定因素：网络类型默认由介质类型决定环境分类：（1）广播多路访问（BMA）（2）非广播多路访问（NBMA）（3）点到点（P2P）（4）点到多点（P2MP）（5）点到多点非广播多路访问（P2MP-NBMA）–思科私有相关命令： 6、特殊概念（1）router-id定义：路由器的身份id，唯一代表一台ospf路由器（默认以最大物理接口ip作为router-id）功能：防止路由抖动选举规则：a、手动指定；b、最大环回接口IP；c、最大物理接口IP清除router-id： （2）DR/BDR定义：指定路由器/备份指定路由器，类似于班集体当中的班长/副班长的位置功能：设定DR和BDR可以避免报文重复发送而导致的链路资源浪费选举规则：a、最大ospf接口优先级，默认为1（优先级为0代表不参与DR/BDR的选举）b、最大物理接口IP（3）邻居/邻接邻居关系：Dother–Dother邻接关系：Dother–DR/BDR两者区别：邻接关系建立在邻居关系基础之上，就好像男女朋友关系是建立在男女性朋友关系之上（4）区域骨干区域：骨干区域是area 0非骨干区域：所有不是area 0的都是非骨干区域两者关系：a、流量中转：非骨干区域间数据通信，必须要经过骨干区域 area 0 中转b、拓扑规划：所有非骨干区域要挂载在骨干区域 area 0 上","categories":[{"name":"网络基础","slug":"网络基础","permalink":"http://yoursite.com/categories/网络基础/"}],"tags":[]},{"title":"路由技术（动态路由之EIGRP）","slug":"路由技术（动态路由之EIGRP）","date":"2018-12-28T01:53:00.000Z","updated":"2018-12-28T02:22:52.082Z","comments":true,"path":"2018/12/28/路由技术（动态路由之EIGRP）/","link":"","permalink":"http://yoursite.com/2018/12/28/路由技术（动态路由之EIGRP）/","excerpt":"","text":"1、基本概述定义：增强型内部网关路由协议（号称”收敛之王”），属于混合型路由协议（距离矢量+链路状态）2、基本特征（1）OSI层次：传输层，基于协议号88（2）协议类型：混合型（3）有类/无类：无类（4）IGP/EGP：IGP（5）管理距离：内部90，外部170（6）度量值：复合型度量值a、5个标准：带宽、负载、延迟、可靠性、MTUb、度量值计算：针对路由条目接收端口（7）路由更新：224.0.0.103、基本运行 4、路由表同步 5、特殊术语（1）通告距离（AD）：邻居告诉你他自己到达目的地的距离 （2）可行距离（FD）：本地到达目的地的距离 （3）可行条件（FC）：AD&lt;FD，用于防环（4）后继路由：最优路由（5）可行后继路由：次优路由（6）后继站：最优路由的下一跳（7）可行后继站：次优路由的下一跳","categories":[{"name":"网络基础","slug":"网络基础","permalink":"http://yoursite.com/categories/网络基础/"}],"tags":[]},{"title":"路由技术（动态路由之RIP）","slug":"路由技术（动态路由之RIP）","date":"2018-12-28T01:31:00.000Z","updated":"2018-12-28T07:29:09.304Z","comments":true,"path":"2018/12/28/路由技术（动态路由之RIP）/","link":"","permalink":"http://yoursite.com/2018/12/28/路由技术（动态路由之RIP）/","excerpt":"","text":"1、基本概述定义：路由信息协议版本：（1）RIPv1：有类，传递路由条目时，不携带掩码，默认开启主类汇总，不能关闭主类汇总（不能关闭主要是为了减少链路带宽消耗）（2）RIPv2：无类，传递路由条目时，携带掩码，默认开启主类汇总，可以关闭主类汇总（到目前带宽已经不是问题，而更加追求网络的真实性）2、基本特征（1）OSI层次：应用层，基于UDP520（2）协议类型：距离矢量路由协议（3）有类/无类：RIPv1–有类，RIPv2–无类（4）IGP/EGP：IGP（5）管理距离：120（6）度量值：最大跳数15跳，16跳为不可达（7）路由更新：RIPv1–广播RIPv2–组播224.0.0.93、基本运行 4、路由表同步 5、时间机制 （1）更新计时器–30s在RIP启动之后,平均每30秒（实际上为25.5~30秒间的随机数时间，之所以这样也是为了错峰发送更新，以防止所有路由器同时发送路由更新造成太大流量） 启用了RIP的接口会发送自己的除了被水平分割（split horizon）抑制的路由选择表的完整副本给所有相邻路由器的时间间隔，并且update的目标地址为255.255.255.255。（2）失效计时器–180s如果 180 秒（默认值）后还未收到可刷新现有路由的更新，则将该路由的度量设置为 16，路由表项将被标记为“x.x.x.x is possibly down”。在清除计时器超时以前，该路由仍将保留在路由表中。（此时RIP路由仍然用来转发数据包）（3）刷新计时器–240s默认情况下，清除计时器设置为 240 秒，比无效计时器长 60 秒。当清除计时器超时后，该路由将从路由表中删除。（4）抑制计时器–180s该计时器用于稳定路由信息，并有助于在拓扑结构根据新信息收敛的过程中防止路由环路。在某条路由被标记为不可达后，它处于抑制状态的时间必须足够长，以便拓扑结构中所有路由器能在此期间获知该不可达网络。默认情况下，抑制计时器设置为180 秒。失效计时器到时，立马进入180s的抑制计时器。6、防环机制（1）最大条数：最大跳数15跳，16跳为不可达（2）水平分割：我发给你的，不要发给我（3）路由毒化：故障点设备主动发送16跳路由，主动干掉故障路由（4）毒性逆转：转发16跳毒化路由（违背水平分割原则）（5）抑制计时器：防止路由表频繁翻动，增加了网络的稳定性（6）触发更新：一旦检测到路由崩溃，立即广播路由刷新报文，而不等到下一个刷新周期","categories":[{"name":"路由基础","slug":"路由基础","permalink":"http://yoursite.com/categories/路由基础/"}],"tags":[]},{"title":"路由技术（静态路由）","slug":"路由技术（静态路由）","date":"2018-12-27T08:44:00.000Z","updated":"2018-12-28T01:27:56.902Z","comments":true,"path":"2018/12/27/路由技术（静态路由）/","link":"","permalink":"http://yoursite.com/2018/12/27/路由技术（静态路由）/","excerpt":"","text":"1、定义管理员手动静态写入路由表2、配置：Config# ip route 目标网络号 目标网络掩码 下一跳/逃出接口3、特殊的静态路由（1）默认路由定义：路由器网关配置：ip route 0.0.0.0 0.0.0.0 下一跳/逃出接口（2）浮动默认路由定义：主备冗余配置：","categories":[{"name":"网络基础","slug":"网络基础","permalink":"http://yoursite.com/categories/网络基础/"}],"tags":[]},{"title":"路由基础","slug":"路由基础","date":"2018-12-27T08:36:00.000Z","updated":"2018-12-27T08:43:32.801Z","comments":true,"path":"2018/12/27/路由基础/","link":"","permalink":"http://yoursite.com/2018/12/27/路由基础/","excerpt":"","text":"1、路由功能依据路由表进行数据转发的功能2、路由最优选举原则：（1）最小管理距离（管理距离越小越可靠、安全）（2）最小度量值（度量值越小，本地到达目的网络的花销就越小）3、路由查询查询原则：（1）最长匹配原则（最长是指网络位最长）（2）递归查询 4、路由分类（1）静态路由定义：管理员手工静态写入路由表优点：安全性高，度量值为0缺点：配置繁琐，不能动态适应拓扑变化（2）动态路由定义：通过路由协议协商交互路由条目优点：配置相对简单，能动态适应拓扑变化缺点：相对静态路由不安全分类：按距离矢量和链路状态来划分，分为以下三种：距离矢量路由协议：RIP 链路状态路由协议：OSPF 混合型路由协议：EIGRP 按有类和无类来划分，分为以下两种：有类路由协议：传递路由条目时，不携带掩码（不支持VLSM和CIDR）无类路由协议：传递路由条目时，携带掩码（支持VLSM和CIDR）","categories":[{"name":"网络基础","slug":"网络基础","permalink":"http://yoursite.com/categories/网络基础/"}],"tags":[]},{"title":"zabbix问题","slug":"zabbix","date":"2018-12-26T09:42:00.000Z","updated":"2018-12-28T07:30:25.124Z","comments":true,"path":"2018/12/26/zabbix/","link":"","permalink":"http://yoursite.com/2018/12/26/zabbix/","excerpt":"","text":"Assuming that agent dropped connection because of access permissions. 解决方法：修改客户端的配置文件zabbix_agentd.conf1、给serverActive和Hostname加注释 2、因为是采用C/S架构，客户端和服务器端不是同一台机器，所以还要在配置文件中加上两行： serverActive表示zabbix主动监控server的ip地址（默认server是主动来agent拿数据，serverActive表示agent主动推送数据给服务器端）","categories":[{"name":"QA","slug":"QA","permalink":"http://yoursite.com/categories/QA/"}],"tags":[]},{"title":"-bash: netstat: command not found","slug":"bash-netstat-command-not-found","date":"2018-12-26T07:54:00.000Z","updated":"2018-12-26T07:55:19.937Z","comments":true,"path":"2018/12/26/bash-netstat-command-not-found/","link":"","permalink":"http://yoursite.com/2018/12/26/bash-netstat-command-not-found/","excerpt":"","text":"yum install net-tools -y","categories":[{"name":"QA","slug":"QA","permalink":"http://yoursite.com/categories/QA/"}],"tags":[]},{"title":"交换技术（交换防环技术）","slug":"交换技术（交换防环技术）","date":"2018-12-26T01:26:00.000Z","updated":"2018-12-26T01:51:24.785Z","comments":true,"path":"2018/12/26/交换技术（交换防环技术）/","link":"","permalink":"http://yoursite.com/2018/12/26/交换技术（交换防环技术）/","excerpt":"","text":"1、STP基本概述（1）STP定义spanning-tree，生成树协议–通过选举机制选举出阻塞端口进而阻塞活动链路，直至剩下一条活动链路（2）STP功能用于防止环路备注：环路定义：首尾相连，无始无终环路危害：广播风暴（广播、组播、未知单播）；桥接表损坏，也叫CAM表（广播风暴+交换机学习功能）；重复帧环路本质：有多条活动链路 2、STP角色选举（1）设备角色根桥交换机（根桥选举原则：最小BID，BID=优先级+MAC地址）非根桥交换机（非根桥交换机收到TC包，会把MAC地址清空；TC包只有根桥才能发送）（2）端口角色a、根端口，简写RP根端口选举原则：最小cost值（cost=BPDU包内的cost值+接收端口的cost值）最小发送者BID（BID=优先级+MAC地址）最小发送者PID（PID=端口优先级+端口编号）备注：每一非根桥交换机上有且只有一个根端口b、指定端口，简写DP备注：根桥上所有端口都是指定端口每一条链路有且只有一个指定端口c、阻塞端口，简写block 3、STP参数修改通过修改STP选举参数，阻塞指定端口 4、STP端口状态机 5、STP链路收敛（1）直接链路失效–30s （2）间接链路失效–50s 6、STP数据分组 正常BPDU 次级BPDU TCN TCA TC TCA/TC","categories":[{"name":"网络基础","slug":"网络基础","permalink":"http://yoursite.com/categories/网络基础/"}],"tags":[]},{"title":"交换技术（交换安全技术）","slug":"交换技术（交换安全技术）","date":"2018-12-25T09:22:00.000Z","updated":"2018-12-26T01:24:51.829Z","comments":true,"path":"2018/12/25/交换技术（交换安全技术）/","link":"","permalink":"http://yoursite.com/2018/12/25/交换技术（交换安全技术）/","excerpt":"","text":"1、MAC地址绑定（1）MAC地址表MAC地址组成 查看MAC地址表 查看MAC地址 一对多关系 （2）需求用于限定PC只能通过特定接口上网（3）配置 2、port-security（1）需求：此F0/1接口只支持PCA数据通过 （2）配置","categories":[{"name":"网络基础","slug":"网络基础","permalink":"http://yoursite.com/categories/网络基础/"}],"tags":[]},{"title":"交换技术（交换冗余技术）","slug":"交换技术（交换冗余技术）","date":"2018-12-25T08:46:00.000Z","updated":"2018-12-25T08:58:18.682Z","comments":true,"path":"2018/12/25/交换技术（交换冗余技术）/","link":"","permalink":"http://yoursite.com/2018/12/25/交换技术（交换冗余技术）/","excerpt":"","text":"以太通道1、定义通过捆绑多条链路逻辑增加链路带宽（链路冗余）2、命令（1）配置： （2）查看： 3、限制条件（1）物理限制：接口物理参数必须匹配（2）逻辑限制：协议必须匹配协议种类： 协议分类：a、链路聚合控制协议（行业里的） b、端口汇聚协议（思科私有） 4、增强技术 （1）配置 （2）查看","categories":[{"name":"网络基础","slug":"网络基础","permalink":"http://yoursite.com/categories/网络基础/"}],"tags":[]},{"title":"交换技术（交换通信技术）","slug":"交换技术（交换通信技术）","date":"2018-12-25T06:13:00.000Z","updated":"2018-12-25T06:24:12.433Z","comments":true,"path":"2018/12/25/交换技术（交换通信技术）/","link":"","permalink":"http://yoursite.com/2018/12/25/交换技术（交换通信技术）/","excerpt":"","text":"1、单臂路由（1）why网关配置接口不够用；路由器识别不了vlan tag（2）what功能：实现不同vlan间的数据通信（3）how 2、三层交换通信（1）why单臂路由拓展性差，带宽限制严重，由此又引入了三层交换技术（2）what三层交换接口，简称SVI（switch virtual interface）（3）how 3、DHCP（1）why动态分配IP、掩码、网关、DNS（2）whatdynamic host configuration protocol，动态主机配置协议（3）how部署方式：a、内置部署结构图 配置命令（服务器端） 配置命令（客户端） b、旁路部署结构图 配置命令（服务器端） 配置命令（客户端）","categories":[{"name":"网络基础","slug":"网络基础","permalink":"http://yoursite.com/categories/网络基础/"}],"tags":[]},{"title":"交换技术（交换基础技术）","slug":"交换技术（交换基础技术）","date":"2018-12-25T03:23:00.000Z","updated":"2018-12-25T03:44:07.659Z","comments":true,"path":"2018/12/25/交换技术（交换基础技术）/","link":"","permalink":"http://yoursite.com/2018/12/25/交换技术（交换基础技术）/","excerpt":"","text":"1、vlan技术（1）why （2）what （3）how 2、trunk技术（1）why （2）what （3）how 3、DTP技术（1）why （2）whatDTP定义：dynamic trunking protocol，动态中继协议（思科私有） 端口模式：access：不能发送和接收协商信息trunk：能发送和接收协商信息desirable：能发送和接收协商信息auto：不能发送但能接收协商信息 链路模式：OFF模式 ON模式 DD模式 DA模式 链路规则：至少一端能发送协商信息，另一端能接收协商信息封装协议：802.1Q（3）how 4、VTP技术（1）why （2）whatVTP定义：vlan trunking protocol，vlan中继协议（思科私有）VTP角色：server：创建、删除、修改、发送、学习和传递vlan信息，修改所有VTP参数备注：当出现多个server时，配置版本号低的向高的学习；创建、删除、修改vlan，配置版本号都会加1；domain和password一致才能学习vlan信息client：学习和传递vlan信息transparent：创建、删除、修改和传递vlan信息，修改部分VTP参数VTP过程： （3）how创建VTP： VTP修剪：适用场景：假如AB两交换机，A有VLAN2 VLAN3 VLAN 4。B只有VLAN2，则VLAN3和VLAN4的信息无需转发到B交换机。VTP修剪可以节约链路资源","categories":[{"name":"网络基础","slug":"网络基础","permalink":"http://yoursite.com/categories/网络基础/"}],"tags":[]},{"title":"交换基础","slug":"交换基础","date":"2018-12-25T03:17:00.000Z","updated":"2018-12-25T03:20:13.943Z","comments":true,"path":"2018/12/25/交换基础/","link":"","permalink":"http://yoursite.com/2018/12/25/交换基础/","excerpt":"","text":"1、局域网概述 2、局域网术语 3、以太网标准 4、交换机原理","categories":[{"name":"网络基础","slug":"网络基础","permalink":"http://yoursite.com/categories/网络基础/"}],"tags":[]},{"title":"思科设备基本管理之三（文件管理）","slug":"思科设备基本管理之三（配置文件管理）","date":"2018-12-20T09:19:00.000Z","updated":"2018-12-20T09:22:01.770Z","comments":true,"path":"2018/12/20/思科设备基本管理之三（配置文件管理）/","link":"","permalink":"http://yoursite.com/2018/12/20/思科设备基本管理之三（配置文件管理）/","excerpt":"","text":"配置文件管理1、保存 2、删除 3、备份 IOS文件管理1、升级 2、删除 3、重灌（1）路由器IOS （2）交换机IOS","categories":[{"name":"网络基础","slug":"网络基础","permalink":"http://yoursite.com/categories/网络基础/"}],"tags":[]},{"title":"思科设备基本管理之二（密码管理）","slug":"思科设备基本管理之二","date":"2018-12-20T09:06:00.000Z","updated":"2018-12-20T09:13:20.244Z","comments":true,"path":"2018/12/20/思科设备基本管理之二/","link":"","permalink":"http://yoursite.com/2018/12/20/思科设备基本管理之二/","excerpt":"","text":"密码管理1、密码配置（1）enable密码 （2）console密码只需要密码： 需要用户名和密码： （3）telnet密码只需要密码： 需要用户名和密码： 2、密码破解（1）路由器破解原理： 破解过程： （2）交换机破解原理： 破解过程：","categories":[{"name":"网络基础","slug":"网络基础","permalink":"http://yoursite.com/categories/网络基础/"}],"tags":[]},{"title":"思科设备基本管理之一","slug":"思科设备基本管理","date":"2018-12-20T08:51:00.000Z","updated":"2018-12-20T09:17:16.285Z","comments":true,"path":"2018/12/20/思科设备基本管理/","link":"","permalink":"http://yoursite.com/2018/12/20/思科设备基本管理/","excerpt":"","text":"1、启动流程（1）交换机加电自检；bootstrap引导程序；从FLASH里寻找并加载IOS；从FLASH寻找并加载config.txt （2）路由器加电自检；bootstrap引导程序；从FLASH寻找并加载IOS；从NVRAM里寻找并加载startup-config 2、管理方式（1）带外管理：通过console线连接管理（2）带内管理：通过网线互联设备，telnet管理 3、配置模式用户模式：&gt;特权模式：#全局配置模式：（config）#exit：从当前模式返回到上一级模式end：从当前模式返回至特权模式 4、设备端口（1）端口类型 （2）端口命名 （3）端口配置 5、常用命令（1）标配命令 （2）常用show命令","categories":[{"name":"网络基础","slug":"网络基础","permalink":"http://yoursite.com/categories/网络基础/"}],"tags":[]},{"title":"进制转换","slug":"进制转换","date":"2018-12-19T08:34:00.000Z","updated":"2018-12-19T08:36:11.985Z","comments":true,"path":"2018/12/19/进制转换/","link":"","permalink":"http://yoursite.com/2018/12/19/进制转换/","excerpt":"","text":"二进制位权 二进制转十进制 二进制转十六进制 十进制转十六进制","categories":[{"name":"网络基础","slug":"网络基础","permalink":"http://yoursite.com/categories/网络基础/"}],"tags":[{"name":"进制转换","slug":"进制转换","permalink":"http://yoursite.com/tags/进制转换/"}]},{"title":"nmap","slug":"nmap","date":"2018-12-19T08:01:00.000Z","updated":"2018-12-19T08:01:21.931Z","comments":true,"path":"2018/12/19/nmap/","link":"","permalink":"http://yoursite.com/2018/12/19/nmap/","excerpt":"","text":"nmap:扫描器之王主要概念:探测主机是否在线、扫描主机开放端口和嗅探网络服务，用于网络探测和安全扫描扫描类型:(1)-sT:tcp扫描，用来建立一个tcp连接。如果成功则认为目标端口正在监听，否则认为端口没有监听程序。这种扫描很容易被检测到，在目标主机的日志中会记录大批的连接请求和错误信息(2)-sU:udp扫描，如果返回icmp不可达的错误信息说明端口是关闭的(3)-sS:tcp同步扫描(tcp syn)，只向目标发出syn数据包，如果收到syn/ack响应就认为目标端口正在监听，并立即断开连接，否则认为端口没有监听程序。这种扫描称为半开扫描，最大的好处是很少有系统会把这个记入系统日志(4)-sA:这种高级的扫描方法通常可以穿过防火墙(5)-sW:滑动窗口扫描，非常类似于ack的扫描(6)-sV:version版本扫描(7)-sL:显示扫描的所有主机列表(8)-sP:找出主机是否存在于网络中 nmap基本操作:(1)nmap 192.168.1.1(2)nmap 192.168.1.1 192.168.1.2(3)nmap 192.168.0-25.1-254(4)nmap magedu.com(5)nmap -vv 192.168.1.1(6)nmap -vv -p 3389 192.168..1(7)扫描除了某ip之外的所有子网主机:nmap 192.168.1.1/24 -exclude 192.168.1.10(8)扫描除了某文件中的ip之外的所有子网主机:nmap 192.168.1.1/24 -excludefile gov.txt(9)显示扫描的所有主机列表:nmap -sL 192.168.1.1/24(10)ping扫描，只用于找出主机是否存在于网络中:nmap -sP 192.168.1.1-255","categories":[{"name":"linux抓包管理","slug":"linux抓包管理","permalink":"http://yoursite.com/categories/linux抓包管理/"}],"tags":[{"name":"nmap","slug":"nmap","permalink":"http://yoursite.com/tags/nmap/"}]},{"title":"nc","slug":"nc","date":"2018-12-19T07:59:00.000Z","updated":"2018-12-19T08:00:01.003Z","comments":true,"path":"2018/12/19/nc/","link":"","permalink":"http://yoursite.com/2018/12/19/nc/","excerpt":"","text":"nc(由nc包提供，包名叫nc) #另外一个实现:ncat(由nmap提供,包名叫nmap)(1)传输文件文件传输:监听者为接收方nc -l PORT &gt; /file (监听端口，-l表示监听)nc IP PORT &lt; /file 文件传输:监听者为传输方nc -l PORT &lt; /filenc IP PORT &gt; /file (2)传输目录:需要先归档 (3)web客户端nc作为web客户端来访问web服务器nc WEBSERVER PORTGET /index.html HTTP/1.1Host:172.16.10.1 (4)扫描器nc -v -w 1 172.16.10.1 -z 1-1023-v:详细显示-w:超时时间-z:只扫描，不做其他任何动作 (5)聊天器nc -l PORTnc IP PORT例如:在一台主机上监听某个端口:nc -l 2333在另外一台主机上，nc 172.16.10.1 2333 -p 2333通过这样的方式，就可以在两台主机上相互传送信息了 (6)其他选项-s SOURCE_IP","categories":[{"name":"linux抓包管理","slug":"linux抓包管理","permalink":"http://yoursite.com/categories/linux抓包管理/"}],"tags":[{"name":"nc","slug":"nc","permalink":"http://yoursite.com/tags/nc/"}]},{"title":"tcpdump","slug":"tcpdump-1","date":"2018-12-19T07:57:00.000Z","updated":"2018-12-19T07:58:24.875Z","comments":true,"path":"2018/12/19/tcpdump-1/","link":"","permalink":"http://yoursite.com/2018/12/19/tcpdump-1/","excerpt":"","text":"tcpdump:网络嗅探器(需要将网卡设置为混杂模式，promisc)-i:interface-w:file(保存至文件)-r:file(读取文件)-nn:第一个n表示把地址显示为数字的形式，第二个n表示把协议显示为数字的形式-X:hex(16进制)以及ASCII格式显示-XX:除了有-X的作用之外，还会显示链路层首部相关信息-A:ASCII格式显示-v:显示详细的信息-vv:显示更加详细的信息expression:关键字:type:host、net、port、portrangedirection:src、dst、src or dst、src and dstprotocol:ether(以太网)、ip、arp、tcp、udp、icmp、wlan组合条件:andornot 举例子:(1)tcpdump -i eth0(2)tcpdump -i eth0 tcp dst port 80 (-n/-nn)(3)tcpdump -i eth0 -nn host 172.16.10.1(4)tcpdump -i eth0 -nn dst host 172.16.10.1(5)tcpdump -i eth0 -nn src and dst host 172.16.10.1(6)tcpdump -i eth0 -nn host 172.16.10.1 and 172.16.10.10(7)tcpdump -i eth0 -nn host 172.16.10.1 and (172.16.10.2 or 172.16.10.10)(8)tcpdump -i eth0 -A tcp port 80(9)tcpdump -i eth0 -X tcp port 80(10)tcpdump -i eth0 -XX tcp port 80(11)tcpdump -i eth0 -A -v tcp port 80(12)tcpdump -i eth0 -A -vv tcp port 80","categories":[{"name":"linux抓包管理","slug":"linux抓包管理","permalink":"http://yoursite.com/categories/linux抓包管理/"}],"tags":[{"name":"tcpdump","slug":"tcpdump","permalink":"http://yoursite.com/tags/tcpdump/"}]},{"title":"windows远程桌面（mstsc）无法复制粘贴","slug":"远程桌面（mstsc）无法复制","date":"2018-12-19T06:52:00.000Z","updated":"2018-12-19T06:55:01.381Z","comments":true,"path":"2018/12/19/远程桌面（mstsc）无法复制/","link":"","permalink":"http://yoursite.com/2018/12/19/远程桌面（mstsc）无法复制/","excerpt":"","text":"解决方法：在远程服务器上重启rdpclip.exe进程即可。 1、打开资源管理器，杀掉rdpclip.exe进程 2、开始——》运行，输入：rdpclip.exe，回车重启该进程。","categories":[{"name":"QA","slug":"QA","permalink":"http://yoursite.com/categories/QA/"}],"tags":[{"name":"mstsc","slug":"mstsc","permalink":"http://yoursite.com/tags/mstsc/"}]},{"title":"IP地址","slug":"IP地址","date":"2018-12-19T06:39:00.000Z","updated":"2018-12-19T06:48:18.688Z","comments":true,"path":"2018/12/19/IP地址/","link":"","permalink":"http://yoursite.com/2018/12/19/IP地址/","excerpt":"","text":"1、ip地址分类：（1）按ABCDE来分 （2）按公有、私有来分 2、私有ip地址分类： 3、ip地址中的网络位（通过子网掩码来区分） 4、ip地址中的主机位（通过子网掩码来区分） 5、子网划分 （1）掩码的1必须是连续的 （2）子网划分公式","categories":[{"name":"网络基础","slug":"网络基础","permalink":"http://yoursite.com/categories/网络基础/"}],"tags":[{"name":"ip地址","slug":"ip地址","permalink":"http://yoursite.com/tags/ip地址/"}]},{"title":"TCP/IP协议族","slug":"TCP-IP协议族","date":"2018-12-19T05:38:00.000Z","updated":"2018-12-19T05:56:26.888Z","comments":true,"path":"2018/12/19/TCP-IP协议族/","link":"","permalink":"http://yoursite.com/2018/12/19/TCP-IP协议族/","excerpt":"","text":"协议1、ARP （1）数据分用 （2）ARP过程 （3）APR报文 2、IP （1）IP报文 Identification用于标识数据包身份，数值不同则代表是不同的数据包 （2）数据分片 上图为数据分片和数据重组过程，与MTU密切相关 （3）MTU 上图为各层的MTU，决定各层限制的传输数据包大小 （4）进制转换 上图为进制转换 （5）TTL 上图为TTL在传递过程的变化，TTL值为0时不传递。TTL主要是用于防止环路的 3、ICMP traceroute &amp;&amp; tracert原理 4、TCP （1）面向连接服务（三次握手+四次关闭） （2）可靠传输（syn/ack+定时器+重传机制） （3）流控（滑动窗口） （4）多路复用（ip+port=套接字） 5、UDP TCP与UDP区别的通俗性理解：","categories":[{"name":"网络基础","slug":"网络基础","permalink":"http://yoursite.com/categories/网络基础/"}],"tags":[{"name":"TCP/IP","slug":"TCP-IP","permalink":"http://yoursite.com/tags/TCP-IP/"}]},{"title":"封装和解封装","slug":"封装和解封装","date":"2018-12-19T02:58:00.000Z","updated":"2018-12-19T03:00:19.703Z","comments":true,"path":"2018/12/19/封装和解封装/","link":"","permalink":"http://yoursite.com/2018/12/19/封装和解封装/","excerpt":"","text":"图解：图一 图二","categories":[{"name":"网络基础","slug":"网络基础","permalink":"http://yoursite.com/categories/网络基础/"}],"tags":[{"name":"封装","slug":"封装","permalink":"http://yoursite.com/tags/封装/"},{"name":"解封装","slug":"解封装","permalink":"http://yoursite.com/tags/解封装/"}]},{"title":"OSI七层模型","slug":"OSI七层模型-1","date":"2018-12-19T02:00:00.000Z","updated":"2018-12-19T02:03:12.015Z","comments":true,"path":"2018/12/19/OSI七层模型-1/","link":"","permalink":"http://yoursite.com/2018/12/19/OSI七层模型-1/","excerpt":"","text":"","categories":[{"name":"网络基础","slug":"网络基础","permalink":"http://yoursite.com/categories/网络基础/"}],"tags":[{"name":"七层模型","slug":"七层模型","permalink":"http://yoursite.com/tags/七层模型/"}]},{"title":"设备和网络发展史","slug":"OSI七层模型","date":"2018-12-19T02:00:00.000Z","updated":"2018-12-19T02:30:08.595Z","comments":true,"path":"2018/12/19/OSI七层模型/","link":"","permalink":"http://yoursite.com/2018/12/19/OSI七层模型/","excerpt":"","text":"","categories":[{"name":"网络基础","slug":"网络基础","permalink":"http://yoursite.com/categories/网络基础/"}],"tags":[{"name":"设备发展史","slug":"设备发展史","permalink":"http://yoursite.com/tags/设备发展史/"}]},{"title":"jenkins配置","slug":"jenkins配置","date":"2018-12-17T07:47:00.000Z","updated":"2018-12-17T07:47:53.415Z","comments":true,"path":"2018/12/17/jenkins配置/","link":"","permalink":"http://yoursite.com/2018/12/17/jenkins配置/","excerpt":"","text":"","categories":[{"name":"jenkins","slug":"jenkins","permalink":"http://yoursite.com/categories/jenkins/"}],"tags":[]},{"title":"jenkins（备份、主目录结构、默认路径）","slug":"jenkins（备份、主目录结构、默认路径）","date":"2018-12-17T07:46:00.000Z","updated":"2018-12-17T07:46:32.355Z","comments":true,"path":"2018/12/17/jenkins（备份、主目录结构、默认路径）/","link":"","permalink":"http://yoursite.com/2018/12/17/jenkins（备份、主目录结构、默认路径）/","excerpt":"","text":"","categories":[{"name":"jenkins","slug":"jenkins","permalink":"http://yoursite.com/categories/jenkins/"}],"tags":[]},{"title":"jenkins（CI、优势、版本）","slug":"jenkins（CI、优势、版本）","date":"2018-12-17T07:44:00.000Z","updated":"2018-12-17T07:44:16.395Z","comments":true,"path":"2018/12/17/jenkins（CI、优势、版本）/","link":"","permalink":"http://yoursite.com/2018/12/17/jenkins（CI、优势、版本）/","excerpt":"","text":"","categories":[{"name":"jenkins","slug":"jenkins","permalink":"http://yoursite.com/categories/jenkins/"}],"tags":[]},{"title":"jenkins安装","slug":"jenkins安装","date":"2018-12-17T06:37:00.000Z","updated":"2018-12-17T06:41:47.345Z","comments":true,"path":"2018/12/17/jenkins安装/","link":"","permalink":"http://yoursite.com/2018/12/17/jenkins安装/","excerpt":"","text":"6、进入选择插件安装界面，选择第一个（Install suggested plugins） 7、插件安装完成之后，需要创建第一个用户 8、创建完用户之后，就可以使用jenkins了","categories":[{"name":"jenkins","slug":"jenkins","permalink":"http://yoursite.com/categories/jenkins/"}],"tags":[]},{"title":"Git && Giuhub(Github部分)","slug":"Git-Giuhub-Github部分","date":"2018-12-14T06:27:00.000Z","updated":"2018-12-14T06:27:36.393Z","comments":true,"path":"2018/12/14/Git-Giuhub-Github部分/","link":"","permalink":"http://yoursite.com/2018/12/14/Git-Giuhub-Github部分/","excerpt":"","text":"","categories":[{"name":"Git && Github","slug":"Git-Github","permalink":"http://yoursite.com/categories/Git-Github/"}],"tags":[{"name":"Github","slug":"Github","permalink":"http://yoursite.com/tags/Github/"}]},{"title":"Git && Github(Git部分)","slug":"Git","date":"2018-12-14T06:20:00.000Z","updated":"2018-12-14T06:25:30.817Z","comments":true,"path":"2018/12/14/Git/","link":"","permalink":"http://yoursite.com/2018/12/14/Git/","excerpt":"","text":"","categories":[{"name":"Git && Github","slug":"Git-Github","permalink":"http://yoursite.com/categories/Git-Github/"}],"tags":[{"name":"Git","slug":"Git","permalink":"http://yoursite.com/tags/Git/"}]},{"title":"cloudwatch","slug":"cloudwatch","date":"2018-12-10T09:14:00.000Z","updated":"2018-12-19T07:30:47.422Z","comments":true,"path":"2018/12/10/cloudwatch/","link":"","permalink":"http://yoursite.com/2018/12/10/cloudwatch/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[{"name":"cloudwatch","slug":"cloudwatch","permalink":"http://yoursite.com/tags/cloudwatch/"}]},{"title":"keepalived安装与配置文件","slug":"keepalived安装与配置文件","date":"2018-12-07T06:45:00.000Z","updated":"2018-12-07T09:43:52.027Z","comments":true,"path":"2018/12/07/keepalived安装与配置文件/","link":"","permalink":"http://yoursite.com/2018/12/07/keepalived安装与配置文件/","excerpt":"","text":"keepalived目前已经被官方收录进linux版本当中，使用yum就可以下载安装keepalived yum info keepalived 查看系统中的keepalived版本yum install keepalived 安装keepalivedrpm -ql keepalived 查看安装keepalived生成了哪些文件在centos7中，cat /usr/lib/systemd/system/keepalived.service 查看keepalived的启动等配置信息cat /etc/sysconfig/keepalived 查看keepalived支持的参数帮助 keepalived的配置文件（三部分）：1、global configuration2、vrrpd configuration:分两段，第一段是vrrp instance，第二段是vrrp synchonization group3、lvs configuration:根据配置文件生成lvs规则备注：可以通过man keepalived.conf查看keepalived配置文件的配置帮助详细配置：1、global_defs:（1）notification_email（2）notification_email_from（3）smtp_server（4）smtp_connection_timeout（5）router_id hostname（6）vrrp_mcast_group 224.x.x.x #定义多播地址，224不变，后面三位可以变化 2、vrrp_instance:（1）state maste或backup（2）interface 在centos7中，int dev名字是eno16777736（3）virtual_router_id vrid是唯一的,跟虚拟mac相关，虚拟mac的格式为00-00-5E-00-01-{VRID} #虚拟mac的格式，前面是固定的，后面补上vrid；master和backup的virtual_router_id必须是一样的，因为id是一样说明master和backup是在同一个虚拟路由器中（4）priority 0到255之间的数字，数字越大，优先级越高，优先级高的是master（5）adver_init 发送心跳信息的时间间隔，默认是1（6）authentication {认证 auth_type PASS 这里是简单字符认证 auth_pass xxxx openssl rand -hex 4,生成十六进制的随机字符串}（7）virtual_ipaddress 定义虚拟ip地址，同一个虚拟路由器中的master和backup的vip的配置也是一样的（8）nopreempt:非抢占模式，默认为抢占模式 HA cluster配置前提：1、本机的主机名与host中定义的主机名保持一致，要与hostname(uname -n)获得名称保持一致，因为需要根据主机名进行彼此通信(各节点要能解析主机名，一般建议通过host文件进行解析，配置文件为/etc/hosts)2、各节点时间同步3、确保iptables和selinux不会成为服务的障碍iptables -L -n 查看iptables规则getenforce 查看linux状态","categories":[{"name":"keepalived","slug":"keepalived","permalink":"http://yoursite.com/categories/keepalived/"}],"tags":[{"name":"keepalived","slug":"keepalived","permalink":"http://yoursite.com/tags/keepalived/"}]},{"title":"linux进程管理","slug":"linux进程管理","date":"2018-12-07T03:43:00.000Z","updated":"2018-12-07T09:44:31.235Z","comments":true,"path":"2018/12/07/linux进程管理/","link":"","permalink":"http://yoursite.com/2018/12/07/linux进程管理/","excerpt":"","text":"1、进程的优先级：0到139,140个优先级，数字越小，表示优先级越高其中，0到99是内核决定的，100到139是可以由用户调整的用户可以通过调整nice值来进行调整，默认每个进程的nice值都是0nice值的取值范围是-20到19，对应100到139（普通用户只能调大nice值来降低优先级，管理员才有权限调大和调小nice值）调整nice值：（1）调整已经启动的进程的nice值：renice NI PID（2）在启动时指定nice值：nice -n NI COMMANDinit进程：第一个进程,是所有进程的父进程，进程号为1 2、每一个进程的相关属性信息在/proc目录下，其下的每一个目录对应一个进程，对应的数字就是进程号（可能是曾经存在过的进程） 3、进程的状态D:不可中断的睡眠S:可以中断的睡眠R:运行或就绪T:停止Z:僵死&lt;:高优先级进程N:低优先级进程+:前台进程组中的进程l:多线程进程s:会话进程首进程 4、进程相关命令：ps命令：有2种风格，system V风格和BSD风格sysV风格（需要加横杠-）：-o:显示指定字段的信息（默认只显示前台进程）要想显示所有，则使用ps -axo 字段1，字段2 BSD风格（不需要加横杠-）：a:显示所有跟终端有关的进程（跟终端有关：在终端中通过命令行运行启动的）x:显示所有跟终端无关的进程（跟终端无关：系统启动的时候自动启动的进程，用户还没登录就已经产生的进程）u:显示进程跟哪个用户相关 pstree命令:显示当前系统的进程树pgrep命令:根据进程名，查找进程的进程号用法:pgrep 进程，如果加上选项-u user可以指定以哪个用户的身份运行的进程pidof命令:根据程序名，查找其相关进程的ID号 top命令:默认根据CPU大小进行排序 （1）在top命令运行过程中按键：N:根据内存大小排序P:根据CPU大小排序T:根据占用CPU时间大小排序 l:是否显示平均负载和启动时间t:是否显示进程和CPU状态相关的信息m:是否显示内存相关信息c:是否显示完整的命令行信息k:是否终止某个进程q:退出top （2）运行top命令时指定选项参数:-d num:指定刷新时长，单位是s-b:批模式，一屏一屏向后翻-n num:在批模式下，显示多少屏，显示完成之后自动退出 前台作业送到后台:ctrl+z:把正在前台的作业送到后台并停止运行COMMAND &amp;:让命令在后台执行 jobs:查看后台的所有作业作业号:不同于进程号+:命令将默认操作的作业-:命令将第二个默认操作的作业 bg:让后台的停止作业继续运行bg [JOBID]fg:将后台的作业调回前台fg [JOBID] kill %JOBID:终止某作业 其他命令:vmstat 1 5:查看系统状态，每隔1秒刷新1次，显示5次就停止退出uptime:跟top显示内容的第一行是一样的 5、进程间通信（IPC）两种方式:（1）共享内存（2）信号:signal 6、重要的信号（通过数字表示）：1:SIGHUP，让一个进程不用重启，就可以重读其配置文件，并让新的配置信息生效2:SIGINT，相当于ctrl-c，中断一个进程9:SIGKILL，杀死一个进程15:SIGTERM，终止一个进程备注：kill默认发送就是15号信号 指定一个信号：信号号码:kill -9信号名称:kill -SIGKILL信号名称简写:kill -KILL备注：kill -l:查看各种信号名称以及对应的号码killall 进程名:但凡是这个进程名的进程都会被杀死","categories":[{"name":"linux进程管理","slug":"linux进程管理","permalink":"http://yoursite.com/categories/linux进程管理/"}],"tags":[{"name":"进程","slug":"进程","permalink":"http://yoursite.com/tags/进程/"}]},{"title":"网络负载均衡器","slug":"网络负载均衡器","date":"2018-12-07T03:37:00.000Z","updated":"2018-12-19T07:31:59.647Z","comments":true,"path":"2018/12/07/网络负载均衡器/","link":"","permalink":"http://yoursite.com/2018/12/07/网络负载均衡器/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[{"name":"网络负载均衡器","slug":"网络负载均衡器","permalink":"http://yoursite.com/tags/网络负载均衡器/"}]},{"title":"应用程序负载均衡器","slug":"应用程序负载均衡器","date":"2018-12-07T03:36:00.000Z","updated":"2018-12-19T07:32:43.439Z","comments":true,"path":"2018/12/07/应用程序负载均衡器/","link":"","permalink":"http://yoursite.com/2018/12/07/应用程序负载均衡器/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[{"name":"应用程序负载均衡器","slug":"应用程序负载均衡器","permalink":"http://yoursite.com/tags/应用程序负载均衡器/"}]},{"title":"传统负载均衡器（一些概念）","slug":"传统负载均衡器（一些概念）","date":"2018-12-07T03:35:00.000Z","updated":"2018-12-19T07:33:24.927Z","comments":true,"path":"2018/12/07/传统负载均衡器（一些概念）/","link":"","permalink":"http://yoursite.com/2018/12/07/传统负载均衡器（一些概念）/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[{"name":"ELB概念","slug":"ELB概念","permalink":"http://yoursite.com/tags/ELB概念/"}]},{"title":"传统负载均衡器（健康检查）","slug":"传统负载均衡器（健康检查）","date":"2018-12-07T03:33:00.000Z","updated":"2018-12-19T07:34:05.355Z","comments":true,"path":"2018/12/07/传统负载均衡器（健康检查）/","link":"","permalink":"http://yoursite.com/2018/12/07/传统负载均衡器（健康检查）/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[{"name":"健康检查","slug":"健康检查","permalink":"http://yoursite.com/tags/健康检查/"}]},{"title":"传统负载均衡器（特点）","slug":"传统负载均衡器（特点）","date":"2018-12-07T03:29:00.000Z","updated":"2018-12-19T07:35:20.815Z","comments":true,"path":"2018/12/07/传统负载均衡器（特点）/","link":"","permalink":"http://yoursite.com/2018/12/07/传统负载均衡器（特点）/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[{"name":"ELB","slug":"ELB","permalink":"http://yoursite.com/tags/ELB/"}]},{"title":"AMI和EBS快照的使用场景","slug":"AMI和EBS快照的使用场景","date":"2018-12-07T02:22:00.000Z","updated":"2018-12-19T07:36:27.291Z","comments":true,"path":"2018/12/07/AMI和EBS快照的使用场景/","link":"","permalink":"http://yoursite.com/2018/12/07/AMI和EBS快照的使用场景/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[{"name":"AMI","slug":"AMI","permalink":"http://yoursite.com/tags/AMI/"},{"name":"EBS快照","slug":"EBS快照","permalink":"http://yoursite.com/tags/EBS快照/"}]},{"title":"EBS快照","slug":"EBS快照","date":"2018-12-07T02:21:00.000Z","updated":"2018-12-19T07:39:04.464Z","comments":true,"path":"2018/12/07/EBS快照/","link":"","permalink":"http://yoursite.com/2018/12/07/EBS快照/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[{"name":"EBS快照","slug":"EBS快照","permalink":"http://yoursite.com/tags/EBS快照/"}]},{"title":"AMI","slug":"AMI系统镜像和EBS快照","date":"2018-12-07T02:20:00.000Z","updated":"2018-12-19T07:39:42.200Z","comments":true,"path":"2018/12/07/AMI系统镜像和EBS快照/","link":"","permalink":"http://yoursite.com/2018/12/07/AMI系统镜像和EBS快照/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[{"name":"AMI","slug":"AMI","permalink":"http://yoursite.com/tags/AMI/"}]},{"title":"EC2存储","slug":"EC2实例-1","date":"2018-12-07T01:46:00.000Z","updated":"2018-12-19T07:40:23.044Z","comments":true,"path":"2018/12/07/EC2实例-1/","link":"","permalink":"http://yoursite.com/2018/12/07/EC2实例-1/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[{"name":"EC2存储","slug":"EC2存储","permalink":"http://yoursite.com/tags/EC2存储/"}]},{"title":"安全组","slug":"全组-1","date":"2018-12-06T06:46:00.000Z","updated":"2018-12-19T07:46:42.253Z","comments":true,"path":"2018/12/06/全组-1/","link":"","permalink":"http://yoursite.com/2018/12/06/全组-1/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[{"name":"安全组","slug":"安全组","permalink":"http://yoursite.com/tags/安全组/"}]},{"title":"EC2实例（计费类型）","slug":"EC2","date":"2018-12-04T08:37:00.000Z","updated":"2019-01-11T08:08:31.973Z","comments":true,"path":"2018/12/04/EC2/","link":"","permalink":"http://yoursite.com/2018/12/04/EC2/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[{"name":"EC2","slug":"EC2","permalink":"http://yoursite.com/tags/EC2/"}]},{"title":"EC2实例（特性）","slug":"EC2实例2","date":"2018-12-04T08:34:00.000Z","updated":"2018-12-19T07:48:31.369Z","comments":true,"path":"2018/12/04/EC2实例2/","link":"","permalink":"http://yoursite.com/2018/12/04/EC2实例2/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[{"name":"EC2","slug":"EC2","permalink":"http://yoursite.com/tags/EC2/"}]},{"title":"EC2实例（简介、运行平台、访问方式）","slug":"EC2实例","date":"2018-12-04T08:22:00.000Z","updated":"2019-01-11T08:07:43.021Z","comments":true,"path":"2018/12/04/EC2实例/","link":"","permalink":"http://yoursite.com/2018/12/04/EC2实例/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[{"name":"EC2","slug":"EC2","permalink":"http://yoursite.com/tags/EC2/"}]},{"title":"IAM服务","slug":"IAM","date":"2018-11-30T06:48:00.000Z","updated":"2018-12-19T07:49:59.573Z","comments":true,"path":"2018/11/30/IAM/","link":"","permalink":"http://yoursite.com/2018/11/30/IAM/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[{"name":"IAM","slug":"IAM","permalink":"http://yoursite.com/tags/IAM/"}]},{"title":"申请AWS免费套餐","slug":"申请AWS免费套餐","date":"2018-11-30T03:23:00.000Z","updated":"2018-12-19T07:51:01.450Z","comments":true,"path":"2018/11/30/申请AWS免费套餐/","link":"","permalink":"http://yoursite.com/2018/11/30/申请AWS免费套餐/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[{"name":"AWS免费套餐","slug":"AWS免费套餐","permalink":"http://yoursite.com/tags/AWS免费套餐/"}]},{"title":"AWS分区","slug":"AWS分区","date":"2018-11-30T03:21:00.000Z","updated":"2018-12-19T07:53:20.050Z","comments":true,"path":"2018/11/30/AWS分区/","link":"","permalink":"http://yoursite.com/2018/11/30/AWS分区/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[{"name":"AWS分区","slug":"AWS分区","permalink":"http://yoursite.com/tags/AWS分区/"}]},{"title":"云计算技术","slug":"云计算","date":"2018-11-30T03:20:00.000Z","updated":"2018-12-19T07:54:17.274Z","comments":true,"path":"2018/11/30/云计算/","link":"","permalink":"http://yoursite.com/2018/11/30/云计算/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"http://yoursite.com/tags/云计算/"}]},{"title":"AWS服务","slug":"Untitled","date":"2018-11-30T03:17:00.000Z","updated":"2018-12-19T07:54:55.094Z","comments":true,"path":"2018/11/30/Untitled/","link":"","permalink":"http://yoursite.com/2018/11/30/Untitled/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[{"name":"AWS服务","slug":"AWS服务","permalink":"http://yoursite.com/tags/AWS服务/"}]},{"title":"源码安装puppet服务端","slug":"Untitled-1","date":"2018-11-22T03:11:00.000Z","updated":"2018-11-22T07:27:30.901Z","comments":true,"path":"2018/11/22/Untitled-1/","link":"","permalink":"http://yoursite.com/2018/11/22/Untitled-1/","excerpt":"","text":"1、安装ruby(版本：1.8.7)wget http://ftp.ruby-lang.org/pub/ruby/ruby-1.8.7-p358.zipunzip ruby-1.8.7cd ruby-1.8.7./configure –prefix=/usr/local/puppetmake &amp;&amp; make install因为安装ruby的位置不在系统环境变量中，所以需要手动导入系统环境变量export PATH=$PATH:/usr/local/puppet/bin/:/usr/local/puppet/sbin/ 2、安装ruby-shadowgit clone https://github.com/apalmblad/ruby-shadow.gitcd ruby-shadowruby extconf.rbmake &amp;&amp; make install 3、安装facter(版本：1.7.4)wget http://downloads.puppetlabs.com/facter/facter-1.7.4.tar.gztar zxvf facter-1.7.4.tar.gzcd facter-1.7.4ruby install.rb 4、安装puppet(版本：2.7.25)wget http://downloads.puppetlabs.com/puppet/puppet-2.7.25.tar.gzcd puppet-2.7.25ruby install.rb –full 有坑:到这一步，提示不能加载openssl，因此先安装openssl：apt-get install opensslapt-get install libssl-devel安装libssl-devel的时候，提示”apt-get install E: 无法定位软件包问题”尝试更新apt源，在/etc/apt的sources.list 添加镜像源deb http://archive.ubuntu.com/ubuntu/ trusty main universe restricted multiverse，然后apt-get update对apt-get进行更新，再次执行apt-get install libssl-devel，还是同样的报错。这时候尝试使用aptitude软件包管理器安装libssl-dev包:(1)安装aptitudeapt-get install aptitude(2)使用aptitude安装 libssl-dev包aptitude install libssl-dev安装完openssl之后，重新运行puppet安装命令”ruby install.rb –full”，依然提示无法load openssl，这时候需要进入到ruby的源码解压目录cd ruby-1.8.7-p358/ext/openssl,执行ruby extconf.rb可以生成编译openssl扩展的Makefile，然后make &amp;&amp; make install，这时候再运行puppet安装命令”ruby install.rb –full”就可以安装上puppet了。","categories":[{"name":"安装篇","slug":"安装篇","permalink":"http://yoursite.com/categories/安装篇/"}],"tags":[{"name":"puppet","slug":"puppet","permalink":"http://yoursite.com/tags/puppet/"}]},{"title":"挂载和卸载","slug":"挂载和卸载","date":"2018-11-13T01:39:00.000Z","updated":"2018-11-13T02:23:10.815Z","comments":true,"path":"2018/11/13/挂载和卸载/","link":"","permalink":"http://yoursite.com/2018/11/13/挂载和卸载/","excerpt":"","text":"挂载:将新的文件系统关联至当前根文件系统卸载:将某文件系统从当前根文件系统的关联关系移除 mount:挂载mount 设备 挂载点备注:1、设备可以是设备文件(/dev/sda5)、卷标(LABEL=”XXX”)、UUID(UUID=”XXX”)2、挂载点必须是目录，要求如下:(1)此目录没有被其他进程使用(2)此目录得事先存在(3)目录中的原有文件将会暂时隐藏3、挂载完成后，通过挂载点访问对应文件系统上的文件4、mount不带任何选项，会显示当前系统中已经挂载的设备以及挂载点可选参数:-a:表示/etc/fstab文件中定义的所有文件系统-n:挂载设备时，不把信息写入mtab文件(默认情况下，mount每挂载一个设备，会把挂载的设备信息保存至/etc/mtab文件)备注:mtab是mount table的简称，直接mount显示的信息就是mtab文件中的信息-t:指定挂载设备上的文件系统类型。不使用此选项时，mount会调用blkid获取对应文件系统类型-r:只读挂载，挂载光盘时常用此选项-w:读写挂载-o:指定额外的挂载选项，也即指定文件系统启用的属性额外的挂载选项有:remount:重新挂载当前文件系统(mount -o remount /dev/sda5 [/mnt/test] 备注:重新挂载的时候，可以省略挂载点)ro:只读挂载(等于-r)rw:读写挂载(等于-w) umount:卸载umount 设备 or umount 挂载点备注:卸载的时候，需要切换到跟挂载点无关的目录上去。如果你在挂载点上运行umount命令，会提示”device is busy”","categories":[{"name":"linux磁盘管理","slug":"linux磁盘管理","permalink":"http://yoursite.com/categories/linux磁盘管理/"}],"tags":[{"name":"挂载","slug":"挂载","permalink":"http://yoursite.com/tags/挂载/"},{"name":"卸载","slug":"卸载","permalink":"http://yoursite.com/tags/卸载/"}]},{"title":"设备文件管理","slug":"设备文件管理","date":"2018-11-12T09:12:00.000Z","updated":"2018-11-12T09:13:40.359Z","comments":true,"path":"2018/11/12/设备文件管理/","link":"","permalink":"http://yoursite.com/2018/11/12/设备文件管理/","excerpt":"","text":"设备文件:设备文件作为设备的访问入口，被内核识别，分两种1、b:块设备，以块为单位进行随机访问，例如硬盘2、c:字符设备，以字符为单位进行线性访问，例如键盘 创建设备文件:mknod -m 权限 文件名 文件类型(b或c) 主设备号 次设备号其中，1、设备文件名:IDE、ATA:hd开头的文件名SATA、SCSI、USB:sd开头的文件名(a、b、c…区分同一类型下的不同设备)2、设备号:/dev目录下的文件有两个数字属性:主设备号:major number，标识设备类型次设备号:minor number，标识同一类型下的不同设备(这种文件没有大小，有点类似于链接文件。因为大小指的是它真正占用磁盘块的大小，而设备文件只是作为设备的一个访问入口，因此没有大小)","categories":[{"name":"linux磁盘管理","slug":"linux磁盘管理","permalink":"http://yoursite.com/categories/linux磁盘管理/"}],"tags":[{"name":"设备文件","slug":"设备文件","permalink":"http://yoursite.com/tags/设备文件/"}]},{"title":"磁盘和分区管理","slug":"磁盘和分区管理","date":"2018-11-12T09:06:00.000Z","updated":"2018-11-13T03:15:52.888Z","comments":true,"path":"2018/11/12/磁盘和分区管理/","link":"","permalink":"http://yoursite.com/2018/11/12/磁盘和分区管理/","excerpt":"","text":"磁盘:真空的，需要防尘，磁盘主要分两种(1)机械硬盘:目前主流，比较遗憾(2)固态硬盘:性能相对好一点的磁盘 磁盘基本术语(硬件方面):(1)盘片(2)盘面:每一块盘片有两块盘面(3)磁头(4)磁道(5)扇区:512字节(6)机械臂(7)柱面:磁道组成的逻辑分区柱面具有以下特点:1、存储数据就是按照柱面来存储的，读取数据也是2、划分分区也是按照柱面来划分3、从外到内，柱面的编号从0开始4、同一个转轴，越靠外面的磁道，转速越快(这也是我们大多数操作系统安装在C盘的原因) 磁盘基本术语(软件方面):磁盘出厂前，需要低级格式化，划分磁道分区1、MBR:master boot record，主引导记录(0盘片0磁道0扇区的那一块地方就是MBR，属于磁盘，是全局的存储空间，独立于操作系统之外)MBR的大小为512字节，分为3个部分，446字节叫做BootLoader，叫做引导加载器，是一段程序代码，作用是引导操作系统正确启动起来；接下来的64字节，每16字节标识一个主分区，因此操作系统最多可以划分4个主分区；剩下的2个字节叫做魔数，标识MBR是否有效。2、分区:partition，划分分区的作用是创建文件系统，每一个分区就是一个文件系统。 要正常使用一块磁盘，需要经过:低级格式化（由硬盘厂商来完成）–做分区–高级格式化（创建文件系统）–挂载 磁盘分区命令:查看当前系统识别了多少块硬盘：fdisk -l查看当前系统某块硬盘的具体信息：fdisk -l /dev/sda管理磁盘分区：fdisk /dev/sda （启动一个交互式界面）m：for helpp：显示当前分区，包括没保存的改动n：创建新的分区e：创建新的扩展分区p：创建新的主分区d：删除一个分区w：保存退出q：不保存退出t：修改分区类型L：修改的时候查看分区类型（以确定某种类型对应的编号）创建完分区之后需要内核识别才能够格式化。查看内核已经识别的分区：cat /proc/partitions通知内核重读分区表：partprobe #Redhat6上使用了新命令:partx备注:partprobe是默认重读所有磁盘上的分区表，当然我们也可以指定内核重读哪一块磁盘，比如说partprobe /dev/sda 创建分区例子:1、创建3个逻辑分区(得先创建扩展分区，在扩展分区的基础上创建逻辑分区。主分区不能创建逻辑分区；扩展分区不能使用，只能使用在扩展分区上划分出来的逻辑分区)(1)fdisk /dev/sda #会进入一个交互界面，备注:进入交互界面后，如果在创建分区的过程中敲错命令，直接删除键是删不掉的，需要按住ctrl+删除键来删除(2)p #查看分区(3)n(4)e #创建扩展分区(5)n(6)+2G #创建第一个逻辑分区，大小为2G(7)n(8)+5G #创建第二个逻辑分区，大小为5G(9)n(10)+1G #创建第三个逻辑分区，大小为1G(11)p #查看分区(12)w #保存退出(13)cat /proc/partitions #查看内核是否识别新创建的分区(14)partprobe /dev/sda #指定内核重读/dev/sda分区表 2、创建SWAP分区(备注:SWAP分区是磁盘上的空间，允许内存过载使用。一旦内存耗尽，可以临时拿硬盘上的SWAP来应急，防止系统崩溃甚至宕机。SWAP分区必须是一个单独的分区)(1)首先新建一个新的分区:fdisk #准备新建分区p #查看已有分区n #新建分区+1G #新建1G的分区L #查看分区类型t #调整分区类型8 #对第几块磁盘调整类型L #查看分区类型82 #linux swap的分区编码p #查看是否已经建好swap分区w #保存退出partprobe /dev/sda #通知内核重读分区表(2)创建好分区之后，需要创建文件系统(swap分区也是有自己的文件系统的)mkswap /dev/sda8(3)启用和关闭交换分区的交换空间(类似于mount，但是有专门的命令，不用mount)启用:swapon /dev/sda8可选参数:-a:启用所有定义在/etc/fstab文件中的交换设备关闭:swapoff /dev/sda8 其他命令:1、blkid:block id，查看磁盘设备的相关属性UUID:用于唯一标识磁盘设备TYPE:用于标识文件系统类型LABEL:显示卷标 2、e2label:专门用于查看或者定义卷标e2label /dev/sda5 查看卷标e2label /dev/sda5 labelname 设定卷标 3、free:查看系统上物理内存和交换分区的使用情况(默认单位是字节)-m:以MB为单位显示内存使用情况buffer:缓冲，保存的是元数据cache:缓存，保存的是数据(这两段空间可以清除数据，不会影响到数据的完整性，对系统性能会有影响) 4、df:显示整个磁盘分区的使用情况(以磁盘块个数来显示大小)可选参数:-h:人性化显示-i:以inode个数显示大小-P:不换行显示备注:与du的区别:du显示目录或者目录的子目录所占用的大小可选参数:-h:人性化显示-s:显示目录所占据的整体的大小 5、dd:复制可选参数:if= #指定数据来源of= #指定数据存储目标bs=1 #以一个字节为单位count=2 #复制2次，跟bs=1结合使用就是复制2个字节的数据例子:1、创建1M的数据:dd if=/dev/zero of=/var/swapfile bs=1 count=10242、拿一个文件，哪怕你没有分区，没有多余的空间可以创建分区，我们照样可以找个文件来暂时性的当做交换分区来使用(性能差，但可以临时救急)(1)dd if=/dev/zero of=/var/swapfile bs=1M count=1024(2)mkswap /var/swapfile(3)swapon /var/swapfile与cp的区别:(1)cp是以文件为单位的，dd是以数据流为单位的(数据流就是01代码)(2)dd可以复制不完整的数据","categories":[{"name":"linux磁盘管理","slug":"linux磁盘管理","permalink":"http://yoursite.com/categories/linux磁盘管理/"}],"tags":[{"name":"磁盘","slug":"磁盘","permalink":"http://yoursite.com/tags/磁盘/"},{"name":"分区","slug":"分区","permalink":"http://yoursite.com/tags/分区/"}]},{"title":"文件系统管理","slug":"ntitled","date":"2018-11-12T09:01:00.000Z","updated":"2018-11-13T03:29:02.942Z","comments":true,"path":"2018/11/12/ntitled/","link":"","permalink":"http://yoursite.com/2018/11/12/ntitled/","excerpt":"","text":"文件系统:1、创建分区之后，要实现快速存储文件和查询文件，需要在这个分区上创建文件系统2、文件系统是一个管理软件，也是存储在磁盘的某个位置上的，但并不是在分区上，文件系统的数据在分区上3、文件系统把分区分为两部分，元数据区域(类似索引)和存储真正数据的区域新增、删除、复制、剪切文件的原理都跟文件系统的原理相关，比如说:(1)为什么剪切文件比复制文件的速度要快答:因为剪切的时候数据内容不变，变的是inode(2)为什么有些文件删除了还可以通过文件恢复器找回来？文件粉碎机的原理是什么？答:删除就是删除inode对应的磁盘块，原来的数据原封不动；粉碎就是用一堆随机数去覆盖原来的数据4、linux支持的文件系统:ext2、ext3、ext4、xfs、reiserfs、jfs、nfs…备注:(1)linux的vfs(虚拟文件系统)使得linux可以支持不同类型的文件系统(2)linux也支持fat32格式(windows平台)文件系统，但是本身不叫fat32，而叫做vfat；同样支持NTFS(windows平台)文件系统,但是支持不太好，写入速度慢，甚至严重的话会导致系统崩溃(3)要留意内核支持哪些文件系统，比如ext2，ext3等。只有内核中具有某种文件系统的模块，它才能支持这种文件系统。cat /proc/filesystems:查看当前内核所支持的文件系统类型(4)ext3和ext2的区别:ext3:日志文件系统，分为3个区域，元数据区、数据区、日志区。对数据进行读写操作的时候，先把inode放到日志区进行操作，操作完成之后再放到元数据区。如果这时候断电或者系统崩溃，下次开机的时候直接查找日志区有哪些inode文件就可以知道有哪些文件是损坏的，而不用从头到尾扫描所有的文件。ext3最大的功能在于能够加快文件系统修复的速度。ext2:就是采取从头到尾的扫描方式，如果存储数据很大的话这样扫描查找会导致机器崩溃，修复速度很慢。ext2是linux上唯一的非日志文件系统。有些情况下，对于安全性、完整性要求不高并且会频繁的大量读写小文件的时候，使用ext2尤佳。 创建完分区，下面就可以创建文件系统commands:1、mkfs:make file system，创建文件系统-t 指定文件系统类型mkfs -t ext2 = mkfs.ext2mkfs -t ext3 = mkfs.ext3mkfs -t vfat = mkfs.vfat2、mke2fs:专门创建或者管理ext系列文件系统:-j journal，直接创建ext3系列的文件系统(默认是创建ext2系列的文件系统)-b 指定block size(块大小)，默认是4096，可以取值为1024,2048-L 指定分区label(卷标)-m # 指定预留给超级用户的块数百分比(直接指定数字即可，不用加%。防止空间填满管理员也无法进入，因此预留一些空间出来，默认应该是20%)-i # 指定为多少字节的空间创建一个inode(默认是8192，这里给出的数值应该是块大小的2^n倍。块大小默认是4096字节)-F #强制创建文件系统(少用)-E #用户指定额外的文件系统属性(少用) 3、tune2fs:调整文件系统相关属性(例如:tune2fs -j /dev/sda2)可选参数:-j:不损坏原有数据，将ext2升级为ext3-L labelname:设定或修改卷标-m #:调整预留百分比-r #:指定预留块数-c #:指定挂载次数达到#次之后进行自检，0或者-1表示关闭此功能-i #:每挂载使用多少天之后进行自检，0或者-1表示关闭此功能(因为系统默认是挂载达到多少次或者多少天之后进行自检，如果文件很大而自检次数hen频繁的话，系统的IO会很高，有时会影响到系统的性能。所以通过设定-c和-i来修改默认的自检次数或者天数)-l /dev/sda5:显示超级块的信息(所有块组的信息都存储在超级块中)-o:设定默认挂载选项 4、dumpe2fs:显示文件系统属性信息可选参数:-h:只显示超级块中的信息 5、fsck:filesystem check，检查并修复linux文件系统可选参数:-t:指定文件系统类型(不指定也没关系，fsck会自动调用blkid来查看类型)-a:自动修复(不与用户交互) 6、e2fsck:专门用于检查并修复ext2、ext的文件系统可选参数:-f:强制检查-p:自动修复(也可以使用-a) 文件系统配置文件:/etc/fstabOS在初始化时，会自动挂载此文件中定义的每个文件系统配置文件格式:第一列:要挂载的设备，/dev/sda5第二列:挂载点，/mnt/test第三列:文件系列类型，ext3第四列:挂载选项，默认是defaults第五列:转储频率，跟文件系统备份相关，每多少天做一次完全备份第六列:文件系统检测次序，只有根文件系统为1，可以多个文件系统为2。0标识不检测注意事项:(1)以上设置可以让/dev/sda5在开机之后自动挂载到/mnt/test上(2)如果挂载设备时一个swap分区的话，它的挂载点也是swap(3)伪文件系统:tmpfs、devpts、sysfs、proc，用来实现特定功能的，不得不挂载(2)转储频率:0表示不备份，1表示每天都要备份，2表示每2天备份一次等等","categories":[{"name":"linux磁盘管理","slug":"linux磁盘管理","permalink":"http://yoursite.com/categories/linux磁盘管理/"}],"tags":[{"name":"文件系统","slug":"文件系统","permalink":"http://yoursite.com/tags/文件系统/"}]},{"title":"IP、TCP、UDP","slug":"IP报文和TCP报文","date":"2018-10-31T01:47:00.000Z","updated":"2018-10-31T02:42:22.783Z","comments":true,"path":"2018/10/31/IP报文和TCP报文/","link":"","permalink":"http://yoursite.com/2018/10/31/IP报文和TCP报文/","excerpt":"","text":"1、IP报文(1)IP VERSION:IP版本号(2)HEAD LEN:报文首部长度(3)TYPE OF SERVICE(TOS):服务类型(在现实生活中比如快递中的加急快件等)(4)TOTAL LEN:整个数据报文的长度(5)FRAGMENT ID:标识分片之后的报文;FRAGMENT OFFSET:标识分片之后的报文组合 #其中MF(MORE FRAGMENT)值为1表示报文分片;DF值为1表示报文没有分片(6)TTL:定义最大跳数(7)PROTOCOL:定义IP网络层上一层的协议(8)HEADER CHECKSUM:校验和，判断数据前后是否一致(9)源IP(10)目的IP(11)OPTION:可选选项(12)要传输的数据 2、TCP报文(1)TCP HEADER:TCP首部(2)SOURCE PORT:源端口(3)DESTINATION PORT:目标端口(4)SEQUENCE NUMBER:序列号(5)ACKNOWLEDGEMENT NUMBER:确认号(6)HEADER LENGTH:首部长度(7)URG:紧急位(8)URGENT POINTER:紧急指针(URG值为1表示指针有效，否则指针无效)(9)ACK:确认位(确认位为1，确认号有效；确认位为0，确认号无效)(10)PUSH值为1表示有优先传输的特权(因为数据传输都是通过网卡来传输的，不同的进程数据，在发送之前，会放置发送缓冲区当中再逐个的往外发送；同样的接收数据也会先保存到接收缓冲区当中。PUSH为1表示不再先保存至缓冲区当中，而是直接往外发送或者接收)(11)RST:重置位(12)SYN:三次握手发的包(13)FIN:四次关闭发的包(14)WINDOW SIZE:窗口大小(当发送方发送数据的速率和接收方接收数据的速率不一致的时候需要用到，其实发送速率和接收速率取决于发送缓冲区和接收缓冲区可容纳的数据)(15)TCP CHECKSUM:TCP校验和(16)OPTION:可选选项(17)DATA:数据 3、TCP与UDP的区别:TCP，transmission control protocol，传输控制协议(相当于打电话，特点是可靠，但是效率低)UDP，user datagram protocol，用户数据报协议(相当于发短信，特点是不靠谱，但是速度快)备注:对于即时通讯都是采用UDP协议，比如QQ，它是在应用层来保证通讯的可靠性 4、三次握手和四次关闭:(1)三次握手A:SYN=1,sn=100(sn即seq num，序列号，随机生成)B:SYN=1,ACK=1,an=101(an即ack num，确认号，序列号加1)，sn=300(随机生成)A:ACK=1,an=301(2)四次关闭A:FIN=1B:ACK=1B:FIN=1A:ACK=1","categories":[{"name":"linux网络管理","slug":"linux网络管理","permalink":"http://yoursite.com/categories/linux网络管理/"}],"tags":[{"name":"IP","slug":"IP","permalink":"http://yoursite.com/tags/IP/"},{"name":"TCP","slug":"TCP","permalink":"http://yoursite.com/tags/TCP/"},{"name":"UDP","slug":"UDP","permalink":"http://yoursite.com/tags/UDP/"}]},{"title":"linux软件编译安装","slug":"inux软件编译安装","date":"2018-10-30T06:09:00.000Z","updated":"2018-10-30T06:37:31.958Z","comments":true,"path":"2018/10/30/inux软件编译安装/","link":"","permalink":"http://yoursite.com/2018/10/30/inux软件编译安装/","excerpt":"","text":"首先，程序运行过程：源程序–&gt;编译–&gt;链接–&gt;运行c语言是将源代码编译成二进制格式，编译需要编译环境(开发环境)、编译工具等(跟C语言相比，脚本语言是解释器直接解释成二进制格式，不需要编译) 编译环境:因为linux的内核是使用c语言开发的，有部分跟平台相关的代码是用汇编语言写的。linux上运行的众多gnu软件，大多数也是用c开发的。因此最流行的的开发环境：C、C++、PERL、JAVA、PYTHON等。 编译工具:gcc:C的编译工具，全称是GNU complier cg++:C++的编译工具make:C或者C++的项目管理工具makefile:定义了make按什么顺序去编译这些源程序文件中的源程序automake:–&gt;makefile.in–&gt;makefileautoconf:–&gt;configure 编译安装三步骤:(注意要在源程序的目录下操作)前提:准备开发环境(编译环境)，最简单的就是安装两个组”Development tools”和”Development libraries”1、configure–help #获取帮助–prefix= #指定软件安装路径(会自动生成/bin和/sbin目录)–sysconfdir= #指定配置文件安装目录(如果不指定的话，默认安装在软件安装路径下的conf目录或者etc目录)–conf-path= #指定配置文件安装文件configure功能:(1)让用户选择编译特性(通过参数赋值)(2)检查编译环境2、make3、make install 编译安装之后的一些环境变量的问题:1、修改PATH环境变量，以能够识别此程序的二进制文件路径(提示找不到命令，大多是原因是命令的路径没有包含在$PATH中)在/etc/profile.d/目录下建立一个以.sh为名称后缀的文件，在里面定义export PATH=$PATH:/path/to/somewhere然后重新登录一下终端，比如克隆一个终端，配置即可生效 2、默认情况下，系统搜索库文件的路径是/lib，/usr/lib，要增加额外的搜索路径在/etc/ld.so.conf.d/目录下创建以.conf为后缀名的文件，然后把要增添的路径写到此文件中(例如apache的库文件路径/usr/local/apache/lib)然后运行ldconfig，通知系统重新搜索库文件-v则显示重新搜索库文件的过程 3、增加头文件的搜索路径，默认是/usr/include增加搜索路径的方式有两种:(使用链接)ln -s /usr/local/apache/include/* /usr/include(这会创建一堆链接，对将来管理这些链接的时候不方便)ln -s /usr/local/apache/include /usr/include/apache(推荐使用这种方式) 4、man文件路径默认安装在–prefix指定的目录下的man目录","categories":[{"name":"linux软件管理","slug":"linux软件管理","permalink":"http://yoursite.com/categories/linux软件管理/"}],"tags":[{"name":"编译安装","slug":"编译安装","permalink":"http://yoursite.com/tags/编译安装/"}]},{"title":"rpm包的前端工具--yum","slug":"rpm包的前端工具-yum","date":"2018-10-30T03:45:00.000Z","updated":"2018-10-30T06:04:32.012Z","comments":true,"path":"2018/10/30/rpm包的前端工具-yum/","link":"","permalink":"http://yoursite.com/2018/10/30/rpm包的前端工具-yum/","excerpt":"","text":"why–为什么是yumyum依赖于rpm，功能比rpm强大因为rpm有一个很大的缺陷就是依赖关系，yum的出现就是用来解决依赖关系的 what–什么是yum(1)yum架构:C/S架构(2)yum仓库:yum的工作依赖于server端的yum仓库(yum repository)yum仓库中的元数据文件(位于repodata目录下):primary.xml.gz:所有rpm包的列表、各种包的依赖关系、每个rpm包安装生成的文件列表(局部概念)filelists.xml.gz:当前仓库中所有rpm包的文件列表(全局概念)other.xml.gz:额外信息，rpm包的修改日志(单个软件包各个发行版的发行时间、作者等)repomd.xml:记录的是上面三个文件的时间戳和校验和comps*-.xml:rpm分组信息(3)yum配置:/etc/yum.confyum仓库的配置文件:/etc/yum.repos.d/目录下面的各个文件就是各个仓库文件(文件名格式:file.repo，必须是以repo结尾)定义repo文件:(for example)[Repo_ID]name=Descriptionbaseurl= #有三种路径，ftp、http、file(本地)ftp://http://file:///(第3个/表示根路径)enable={1|0} #1表示启用gpgcheck={1|0} #1表示校验gpgkey= #如果设置gpgcheck=1必须有此项，否则不需要此项 how–怎么使用yum备注:要注意跟rpm命令对比下，很多命令的功能是差不多的(1)yum clean:清缓存(2)yum list [all|available|installed]:查看所有的安装包，包括安装的和未安装的(已安装的最后一个字段显示install，未安装的显示[Repo_ID]，也就是仓库文件里面的第一行定义的那个ID)yum list all:显示所有的软件包(直接yum list默认也是显示所有的软件包)yum list available:可用的，仓库中有但是未安装的yum list installed:已经安装的yum list updates:可用的升级yum list all +通配符的包名:查看匹配的软件包(3)yum repolist [all|enabled|disabled]:查看库的信息yum repolist all:显示所有repo列表及其简要信息yun repolist enabled:显示可用的repo列表及其简要信息(直接yum repolist默认就是显示enabled的repo表)yum repolist disabled:显示不可用的repo列表及其简要信息(4)yum install:安装软件包(5)yum update:默认升级到最新版本yum update-to:指定升级到特定版本(6)yum remove/rease:卸载(7)yum info:查看软件包的简要信息(8)yum provide/whatprovides:查看指定的文件或特性是由哪个包生成的(9)软件包组groupyum groupinfoyum grouplistyum groupremoveyum groupupdateyum groupinstallyum grouplocalinstall备注:groupinstall和grouplocalinstall的区别在于，install只需要指定包名，localinstall则必须指定包文件，也就是以rpm包结尾的文件。用yum相比用rpm安装的好处在于，如果仓库中刚好包有依赖包，yumlocalinstall可以解决依赖关系 创建yum仓库:createrepo命令","categories":[{"name":"linux软件管理","slug":"linux软件管理","permalink":"http://yoursite.com/categories/linux软件管理/"}],"tags":[{"name":"yum","slug":"yum","permalink":"http://yoursite.com/tags/yum/"}]},{"title":"ubuntu16.04安装MongoDB","slug":"MongoDB","date":"2018-10-24T07:30:00.000Z","updated":"2018-10-24T08:05:13.425Z","comments":true,"path":"2018/10/24/MongoDB/","link":"","permalink":"http://yoursite.com/2018/10/24/MongoDB/","excerpt":"","text":"1、通过tgz压缩包安装:(1)wget https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-ubuntu1604-4.0.3.tgz(2)tar zxvf mongodb-linux-x86_64-ubuntu1604-4.0.3.tgz(3)cp -pr mongodb-linux-x86_64-ubuntu1604-4.0.3 /usr/local/mongodb #-p表示保留源文件的属性，-r表示递归复制(4)bin/mongod &amp; #会报错，因为不指定数据目录的时候，默认会以/data/db目录作为数据目录，因此不存在/data/db目录时会报错，可以创建一个/data/db目录，也可以在启动mongod的时候指定dbpath为自定义的数据目录，像这样:bin/mongod –dbpath= ~/db(5)可以通过bin/mongod –help来查看mongod的帮助选项备注:通过这样的方式安装的mongod，默认没有配置文件，需要自己创建配置文件。一般不建议通过这种方式安装mongod 2、通过apt-get安装:(1)导入软件源公钥sudo apt-key adv –keyserver hkp://keyserver.ubuntu.com:80 –recv EA312927(2)为mongodb创建软件源list文件ubuntu16.04:echo “deb http://repo.mongodb.org/apt/ubuntu xenial/mongodb-org/3.4 multiverse” | sudo tee /etc/apt/sources.list.d/mongodb-org-3.4.list #mongodb-org/3.4 的3.4 为版本号，可更换为你想要安装的版本(3)更新软件源sudo apt-get update #更新的时候可能会报错，提示由于没有公钥，无法验证下列签名： NO_PUBKEY 3EE66BD3F599ACE3这时候，只需要重新运行第一步，软件源公钥替换成错误提示中的key，然后重新运行sudo apt-get update(4)安装mongodbapt-get install -y mongodb-org #如果想要安装指定的版本，使用下面的命令:sudo apt-get install -y mongodb-org=3.2.9 mongodb-org-server=3.2.9 mongodb-org-shell=3.2.9 mongodb-org-mongos=3.2.9 mongodb-org-tools=3.2.9(上面的命令需要把3.4改为3.2)(5)开机启动systemctl enable mongod(6)启动、停止mongod和查看mongod服务状态systemctl start mongod.servicesystemctl stop mongod.servicesystemctl status mongod.service备注:mongodb启动报错，其中大量提到WiredTiger error，主要报错提示如下txn-recover: unsupported WiredTiger file version WiredTiger error这时候，把/data/db目录下的文件清空，再重新启动就可以了(亲测有效)，但是如果数据库中有重要数据, 不建议采取此方法。安装参考链接:https://github.com/cgDeepLearn/LinuxSetups/blob/master/docs/databases/mongodb.md 补充mongodb图形化工具:NoSQLBooster for MongoDB(windows)下载链接:https://nosqlbooster.com/downloads工具截图:","categories":[{"name":"安装篇","slug":"安装篇","permalink":"http://yoursite.com/categories/安装篇/"}],"tags":[{"name":"mongodb","slug":"mongodb","permalink":"http://yoursite.com/tags/mongodb/"}]},{"title":"QA","slug":"QA","date":"2018-10-22T03:29:00.000Z","updated":"2018-10-29T04:07:10.034Z","comments":true,"path":"2018/10/22/QA/","link":"","permalink":"http://yoursite.com/2018/10/22/QA/","excerpt":"","text":"1、mysql max_allowed_packet自动重置为1024 最后发现是被人搞了。发现过程:打开general.log记录日志，查找日志(1)grep “SET GLOBAL” ubuntu.log，日志截图，发现有改动痕迹 (2)选择某一个query ID，例如188592 (3)把这个链接的文件下载下来，360马上就提示这是一个病毒文件 因此，被人搞是确定无疑了。。 然后，赶紧把mysql的密码改了(原密码是mysql…因为这个服务器还没上线，所以密码也设置得很简单…)","categories":[{"name":"QA","slug":"QA","permalink":"http://yoursite.com/categories/QA/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/tags/mysql/"}]},{"title":"NFS入门","slug":"NFS","date":"2018-10-19T05:39:00.000Z","updated":"2018-10-19T07:57:16.806Z","comments":true,"path":"2018/10/19/NFS/","link":"","permalink":"http://yoursite.com/2018/10/19/NFS/","excerpt":"","text":"1、NFS介绍NFS是”Network File system”的缩写，即网络文件系统网络文件系统是应用层的一种应用服务，它主要应用于linux与linux系统，linux与unix系统之间的文件或目录的共享。当用户想要使用远程文件的时候，只要用mount命令就可以把远程文件系统挂载到本地的文件系统上，操作远程文件就跟操作自己本地操作系统的文件一样。采用NFS之后省去了登录的过程，方便了用户访问系统资源。一言以蔽之，NFS的主要功能就是通过网络让不同的主机系统之间可以彼此共享文件或目录。 2、NFS原理对于linux而言，文件系统是在内核空间实现的，即文件系统比如ext3、ext4等是在kernel启动时，以内核模块的身份加载运行的。类似的，NFS(网络文件系统)也是工作在内核空间。NFS本身的服务没有提供数据传递的协议，而是通过使用RPC(Remote Procedure Call)来实现。具体实现过程如下:(1)本地用户要使用NFS服务器中的文件，先向内核发起请求，内核调用NFS模块以及rpc client(2)rpc client向rpc server发起连接(3)在连接之前，NFS服务除了启动nfsd本身监听的端口2049/tcp和2049/udp，还会启动其他进程(如mount，statd,rquotad等)已完成文件共享，这些进程的端口是不固定的，是每次NFS服务启动时向RPC服务注册的，RPC服务会随机分配未使用的端口(4)完成连接，接受访问请求(5)NFS应用程序向内核发起请求(6)内核调用文件系统然后client端通过获取的NFS端口来建立和server端的NFS连接并进行数据的传输简单来说，NFS客户端与服务端的通信过程:(1)先与rpc服务通信(tcp和udp的111端口)(2)再根据rpc提供的mounted监听端口，与mounted通信；mounted进程会对用户进行验证，验证通过返回用户一个通行证(3)最后客户端与nfsd进程建立联系进行通信 3、NFS服务器端组件:nfs-utilsrpm -ql nfs-utils #查看nfs-utils程序所生成的文件NFS服务端将启动3个主进程:(1)nfsd，跟NFS文件传输相关，工作在tcp和udp的2049端口(2)mounted，跟客户端挂载相关，随机端口(3)quotad，跟磁盘配额相关，随机端口备注:mounted和quotad的端口是随机产生的，不是固定的，每次重启nfs端口会发生变化。由此我们最好自定义端口。定义mounted和quotad进程监听固定端口:编辑/etc/sysconfig/nfs文件 #MOUNTED_PORT= #QUOTAD_PORT= #LOCKED_TCPPORT= #LOCKED_UDPPORT= 4、rpc介绍(1)rpc，远程过程调用，是一种编程技术，主要是用于简化分布式应用程序的开发。因为如果需要在两台主机上的进程进行通信，那么客户端、服务器端必须要处理网络传输中的网络请求、网络响应等等。这时候就大大增加了程序员开发的难度。因此就出现了rpc的框架。由此，程序员在开发客户端和服务端的时候，不需要再下功夫去处理网络协议报文的封装，因为rpc在底层就完成了这种观功能。(2)NFS是基于rpc来进行网络传输的，使得本地主机访问远程主机的时候，就好像本地主机访问本地一样。网络通讯过程对于本地主机来说是透明的。(3)在linux提供rpc服务的程序，叫做portmap，自身监听在tcp和udp的111端口。rpc与portmap的关系是，rpc是协议，portmap是实现，相当于http协议和apache、nginx、lightted的关系(4)rpc实现数据交换，可以基于二进制格式，也可以基于文本格式，基于文本格式比较常见的叫做XLRPC，后来又发展为SOAP 5、NFS介绍NFS是由SUN公司开发的，NFS版本有:NFSV1(SUN公司内部使用)NFSV2(早期公开版)NFSV3(在RHEL5上使用)NFSV4(在RHEL6上使用)NFS的缺点:(1)NFS可以基于认证，但是在认证这一块的功能是非常弱的，只认ID号，不认用户名举例子:假如在一台主机上有一个用户名叫做tom，通过NFS在另外一台主机上创建了一个目录，那么a.如果另外一台主机上没有tom这个用户，那么创建的目录的属主和属组是tom对应的uid和gidb.如果另外一台主机上有一个叫做jerry的用户，他的uid跟tom的uid一样，那么在另外一台主机上创建的这个目录的属主和属组就是jerry正是因为NFS不支持用户名认证，所以NFS一般不支持在互联网上使用，多用于在内网中各主机之间实现文件共享服务(2)NFS只支持在linux/unix上进行通信，不支持在windows主机上通信(linux上的NFS其实就相当于windows上的网上邻居，所以windows网上邻居的功能也是基于类似于rpc的协议来实现的) 6、NFS配置文件:/etc/exports只需要在这个文件中定义共享哪个目录出去，并且能够让客户端挂载，就能够让客户端像使用本地目录那样来使用这个共享出去的目录查看NFS的exports配置帮助的相关文档:man export 7、export文件格式:共享目录 客户端列表备注:(1)如果有多个客户端，客户端之间用空白字符分隔；而且每个客户端必须跟上一个小括号，里面定义了此客户端的访问特性，比如访问权限等(2)编辑保存之后需要重启nfs服务(3)文件系统访问特性有:ro:只读rw:只写sync:同步async:异步root_squash:将root用户映射为来宾用户，默认开启此功能no_root_squash:一台主机上的root用户访问另外一台主机的文件系统，是以另外一台主机的文件系统的root用户身份来访问的all_squash:将所有访问的用户映射为来宾用户anonuid,anongid:指定映射的来宾用户的uid和gid 8、命令相关(1)showmount命令:这个命令在客户端和服务端都可以使用-a:列出所有的客户端地址以及挂载的目录 #showmount -a 服务端IP，这条命令在客户端和服务端都可以实现-e:显示服务器共享了哪些目录 #showmount -e 服务端IP-d:显示NFS服务器共享出来的目录有哪些是被客户端挂载了的 #showmount -d 服务端IP (2)exportfs命令:-a:一般是跟-r或者-u选项同时使用，表示重新挂载(或者说导出，export)所有目录(或者说文件系统)或者取消挂载(导出)所有目录(文件系统)-r:重新导出-u:取消导出(这时候export下的所有文件系统或者目录都不能被客户端访问) #exportfs -uav-v:显示详细信息备注:当我们修改export文件的时候，需要重启nfs服务配置才会生效。使用exportfs就可以不用重启nfs服务，相当于reload (3)rpcinfo命令rpcinfo -p IP #查看mount或者quotad监听的端口号rpcinfo -p localhost #查看本机上rpc程序所监听的端口 (4)mount命令客户端使用mount命令挂载:mount -t nfs NFS_SERVER:/PATH /PATH #需要指定类型为nfsmount -t nfs 172.16.100.7:/shared /mnt/nfs #把172.16.100.7的shared目录共享出去，客户端挂载该目录即可使用 9、NFS开机自启动chkconfig nfs on 10、客户端开机自动挂载nfs目录编辑/etc/fstab文件，格式如下:172.16.100.1:/shared /mnt/nfs nfs defaults 0 0172.16.100.1:/shared /mnt/nfs nfs defaults,_rnetdev 0 0备注:man mount有一个挂载选项需要关注，_rnetdev:如果文件系统挂不上，就自动忽略掉 参考链接:https://www.cnblogs.com/whych/p/9196537.html","categories":[{"name":"linux共享服务","slug":"linux共享服务","permalink":"http://yoursite.com/categories/linux共享服务/"}],"tags":[{"name":"NFS","slug":"NFS","permalink":"http://yoursite.com/tags/NFS/"}]},{"title":"HTML基础","slug":"Untitled-3","date":"2018-10-17T07:14:00.000Z","updated":"2018-12-19T08:02:50.231Z","comments":true,"path":"2018/10/17/Untitled-3/","link":"","permalink":"http://yoursite.com/2018/10/17/Untitled-3/","excerpt":"","text":"HTML:HyperText Markup Language,超文本标记语言 1、HTML特点(1)HTML不需要编译，直接由浏览器执行(2)HTML文件是一个文本文件(3)HTML文件必须使用html或者xml为文件名后缀(4)HTML大小写不敏感 2、HTML基本结构 3、HTML标签(1)&lt;&gt;括起来(2)一般成对出现，分开始标签和结束标签。结束标签比开始标签多一个/(3)单标签:没有结束标签(4)标签属性 4、HTML标签类型(1)标题标签:h1到h6 (2)段落标签 段落标签align属性left:多对齐right:右对齐center:居中对齐justify:对行进行伸展，这样每行都可以有相等的长度(3)文字标签 (4)换行标签 (5)水平线标签 水平线标签属性width:设置水平线宽度，可以是像素或者是百分比color:设置水平线颜色align:设置水平线对齐方式noshade:设置水平线无阴影(6)列表标签之无序列表 无序列表标签type属性disc:圆点square:正方形circle:空心圆(7)列表标签之有序列表 有序列表标签type属性1:数字1,2…a:小写字母a,b..A:大写字母A,B..i:小写罗马数字iI:大写罗马数字I(8)列表标签之定义列表 (9)图像标签 图像标签属性 (10)超链接标签 超链接标签属性 5、HTML元素在开始标签和结束标签中的所有代码，称为HTML元素 6、HTML注释 7、DOCTYPE文档类型声明 8、网页编码设置","categories":[{"name":"HTML","slug":"HTML","permalink":"http://yoursite.com/categories/HTML/"}],"tags":[{"name":"html","slug":"html","permalink":"http://yoursite.com/tags/html/"}]},{"title":"grep入门","slug":"grep","date":"2018-10-17T06:08:00.000Z","updated":"2018-10-17T06:23:13.109Z","comments":true,"path":"2018/10/17/grep/","link":"","permalink":"http://yoursite.com/2018/10/17/grep/","excerpt":"","text":"grep:根据模式搜索文本，并将符合模式的文本行显示出来 模式(pattern)的概念:文本字符和正则表达式的元字符组合而成的匹配条件 grep版本:(1)grep(2)egrep(3)fgrep grep用法:grep [option] pattern [file…]备注:(1)模式(pattern)要用引号引起来。在shell中，单引号是强引用，双引号是弱引用。(2)强引用指的是单引号里面的内容会原封不动(3)弱引用指的是引用变量，变量会被赋值为对应的值(4)在模式引用中，只要不涉及到变量的引用，单引号和双引号都可以；如果模式中没有包含正则表达式的元字符的时候，实际上不加引号也可以 option:-i 忽略大小写–color 匹配的字符高亮显示(可以通过别名，用alias grep=’grep –color’将grep的高亮显示作为默认显示)-v 反向grep-o 只显示被模式匹配到的字符串(默认会显示包含模式匹配到的整行文本)-E 支持扩展的正则表达式(相当于egrep)-A n 显示匹配到的字符串所在行及向下的n行-B n 显示匹配到的字符串所在行及向上的n行-C n 显示匹配到的字符串所在行及其上和其下的n行","categories":[{"name":"linux文本处理","slug":"linux文本处理","permalink":"http://yoursite.com/categories/linux文本处理/"}],"tags":[{"name":"grep","slug":"grep","permalink":"http://yoursite.com/tags/grep/"}]},{"title":"正则表达式","slug":"正则表达式","date":"2018-10-17T03:45:00.000Z","updated":"2018-12-10T09:36:46.354Z","comments":true,"path":"2018/10/17/正则表达式/","link":"","permalink":"http://yoursite.com/2018/10/17/正则表达式/","excerpt":"","text":"regular expression，简写REGEXP主要关注正则表达式里面的一些元字符，这些字符不表示本身的意义，而表示一些通配的意义(正则表达式默认工作在贪婪模式下，即尽可能长的匹配) 模式的概念:字符和正则表达式的元字符组合起来过滤文本的过滤条件 正则表达式分两类:basic regexp:基本正则表达式extended regexp:扩展正则表达式 基本正则表达式:(1)字符匹配. 匹配任意单个字符[] 匹配指定范围之内的任意单个字符[^] 匹配指定范围之外的任意单个字符也可以字符集合的方法来表示匹配字符集合里面的任意单个字符[:digit:] 数字[:alpha:] 所有字母[:alnum:] 数字和字母[:lower:] 小写字母[:upper:] 大写字母[:punct:] 标点符号[:space:] 空白字符注意:使用字符集合的时候，还要使用一个方括号括起来，就是要用到两个方括号 (2)次数匹配:* 匹配其前面的字符任意次.* 匹配任意长度的任意字符(跟通配符中的*表示的一样)\\? 匹配其前面的字符0次或1次\\{m,n\\} 匹配其前面的字符最少m次，最多n次(反斜线是用来转义的，因为在bash shell中，花括号会被理解成命令行展开)\\{m\\} 匹配其前面的字符最少m次举栗子:a.*b 表示a开头，b结尾，中间是任意长度的任意字符\\{1,\\} 最少1次\\{0,3\\} 最多3次 (3)位置锚定^ 锚定行首，此字符后面的任意内容必须出现在行首$ 锚定行尾，此字符前面的任意内容必须出现在行尾^$ 表示空白行\\&lt;或者\\b:锚定词首，其后面的任意字符必须作为单词的首部出现>或者\\b:锚定词尾，其前面的任意字符必须作为单词的尾部出现举栗子:\\&lt;root\\&gt; 匹配单词root(root既是词首，也是词尾) (4)分组\\(..\\)\\(ab\\) ab作为一个整体，ab可以出现0次、1次或者多次分组的主要目的是:后向引用，在后面引用前面括号括起来的内容\\1 引用第一个小括号分组中的内容\\2 引用第二个小括号分组中的内容\\3 引用第三个小括号分组中的内容举栗子:grep ‘\\(l..e\\).\\1’ test.txt可以匹配到以下两行:He love his lover.He like his liker. 扩展正则表达式:(1)字符匹配. 匹配任意单个字符[] 匹配指定范围之内的任意单个字符[^] 匹配指定范围之外的任意单个字符 (2)次数匹配* 匹配其前面的字符任意次.* 匹配任意长度的任意字符(跟通配符中的*表示的一样)?:匹配其前面的字符0次或1次+:匹配其前面的字符至少1次，相当于{1,}{m,n} 匹配其前面的字符最少m次，最多n次(在扩展正则表达式中，不需要加反斜线){m} 匹配其前面的字符最少m次 (3)位置锚定^ 锚定行首，此字符后面的任意内容必须出现在行首$ 锚定行尾，此字符前面的任意内容必须出现在行尾\\&lt;或者\\b:锚定词首，其后面的任意字符必须作为单词的首部出现>或者\\b:锚定词尾，其前面的任意字符必须作为单词的尾部出现 (4)分组() #不需要加反斜线\\1 引用第一个小括号分组中的内容\\2 引用第二个小括号分组中的内容\\3… (5)竖线| 表示或者的意思C|cat 匹配C或者cat(C|c)at 匹配Cat或者cat 总结:1、基本正则表达式和扩展正则表达式的区别:(1)扩展正则表达式中，表示分组的括号和表示次数匹配的花括号和问号，前面都不需要加反斜线(2)扩展正则表达式中，次数匹配多了一个”+”号，表示匹配一次或者多次(3)扩展正则表达式中，多了一个竖线的符号，表示或者的意思 2、正则表达式和通配符的区别:在文本过滤工具里面，都是用正则表达式，比如像awk、sed、grep等，都是针对文件内容的；而通配符是linux系统本身就支持的，多用在文件名上，比如像find、ls、cp，等等 通配符:* 任意长度的任意字符? 任意单个字符[] 指定范围内[^] 指定范围外","categories":[{"name":"linux文本处理","slug":"linux文本处理","permalink":"http://yoursite.com/categories/linux文本处理/"}],"tags":[{"name":"正则","slug":"正则","permalink":"http://yoursite.com/tags/正则/"}]},{"title":"awk入门","slug":"awk入门","date":"2018-10-17T03:37:00.000Z","updated":"2018-10-17T06:11:15.695Z","comments":true,"path":"2018/10/17/awk入门/","link":"","permalink":"http://yoursite.com/2018/10/17/awk入门/","excerpt":"","text":"awk:报告生成器，根据输入信息，将输入信息格式化之后再显示出来 awk版本:(1)awk(2)nwe awk,简称nawk(3)gnome awk,简称gwak awk使用格式:awk [options] ‘PATTERN { action }’ file2,file2… options:-F 指定分隔符BEGIN{OFS=””} 指定输出分隔符 在options中使用的内置变量(1)awk内置变量之记录变量:FS:读取文本时所使用的字段分隔符，默认是空白字符RS:输入文本信息所使用的换行符OFS:输出分隔符ORS:输出行分隔符 (2)awk内置变量之数据变量:NR:awk命令所处理的记录数。如果有多个文件，这个数目会把处理的多个文件中的行统一计数FNR:记录正处理的行是当前这一文件中被总共处理的行中是第几行NF:用于统计正在处理的行中的字段总数($NF:正在被处理的行中的最后一个字段) 常见的PATTERN类型:1.regexp，正则表达式，格式为/reglar expression/示例：awk -F: ‘/^r/{print $1}’ /etc/passwd #显示passwd文件中以r开头的用户名2.expression，表达式，比如$1 ~ /foo/ 或$1 == “magedu”等示例：awk -F: ‘$3&gt;=500{print $1,$3}’ /etc/passwd #显示passwd文件中uid大于300的用户及其uidawk -F: ‘$7~”bash$”{print $1,$7}’ /etc/passwd #显示passwd文件中以bash shell为shell的用户名及其对应的shell3.BEGIN/END,特殊模式，在awk命令执行之前运行一次货结束之前运行一次BEGIN:在awk处理文本第一行之前执行END:在awk处理文本最后一行之前执行实例：awk -F: ‘BEGIN{print “Username ID Shell”}{printf “%-10s%-10s%-20s\\n”,$1,$3,$7}END{print “end of report”}’ /etc/passwd #在第一行打印”Username ID Shell”，在最后一行打印”end of report” 常见的actions类型:控制语句：1.if-else实例：awk -F: ‘{if ($1==”root”) print $1,”admin”;else print $1,”common user”}’ /etc/passwd2.while实例：awk -F: ‘{i=1;while (i&lt;=3) {print $i;i++}}’ /etc/passwd3.do-whileawk -F: ‘{i=1;do {print $i;i++}while(i&lt;=3)}’ /etc/passwd4.forawk -F: ‘{for(i=1;i&lt;=3;i++)print $i}’ /etc/passwd5.case6.break,continue(跳过本字段)7.next(跳过本行) awk使用数组：示例：awk -F: ‘{shell[$NF]++}END{for(A in shell){print A,shell[A]}}’ /etc/passwd #生成一个shell数组，并统计passwd文件中各种shell的个数，A指的是下标netstat -tan | awk ‘/^tcp/{STATE{$NF}++}END{for (S IN STATE){print S,STATE[S]}}’ #生成一个STATE数组，并统计各种程序状态的个数，S指的是下标awk ‘{counts[$1]++}END{for(ip in counts){printf “%-20s:%d\\n”,ip,count[ip]}}’ /var/log/httpd/access.log #统计web日志文件中IP地址的访问量备注：awk中的下标很独特，可以是任意字符串","categories":[{"name":"linux文本处理","slug":"linux文本处理","permalink":"http://yoursite.com/categories/linux文本处理/"}],"tags":[{"name":"awk","slug":"awk","permalink":"http://yoursite.com/tags/awk/"}]},{"title":"初步认识docker","slug":"docker入门","date":"2018-10-12T01:26:00.000Z","updated":"2018-12-19T07:24:19.329Z","comments":true,"path":"2018/10/12/docker入门/","link":"","permalink":"http://yoursite.com/2018/10/12/docker入门/","excerpt":"","text":"什么是dockerdocker是一个开源的应用容器引擎，让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的linux机器中，也可以实现虚拟化。docker的目标是实现轻量级操作系统虚拟化的解决方案。(基于Go语言开发) docker简单原理docker的基础是linux容器(LXC)、Cgroup技术。docker是在LXC的基础上进行了进一步的封装，让用户不再需要去关心容器的管理，使得操作更加简便。用户操作docker的容器就像操作一个快速轻量级的虚拟机一样简单。与传统虚拟户(KVM、XEN等)相比较：(1)docker是在操作系统层面上实现虚拟化，直接复用本地主机的操作系统(由下往上:硬件-&gt;host操作系统-&gt;docker engine-&gt;应用库-&gt;应用app) (2)传统的虚拟化方式是在硬件的基础上，虚拟出自己的系统，再在系统上部署相关的APP应用(由下往上:硬件-&gt;host操作系统-&gt;hypervisor-&gt;guest操作系统-&gt;应用库-&gt;应用app) docker组件(1)镜像:其实就是模板，跟我们常见的ISO镜像类似，是一个样板(2)容器:使用镜像常见的应用或系统，我们称之为一个容器(容器相当于启动之后的镜像)(3)仓库:仓库就是存放镜像的地方，分为公开仓库(public)和私有仓库(private)两种形式 docker技术组件linux内核的命名空间(namespace)，用于隔离文件系统、进程和网络(1)文件系统隔离:每个容器都有自己的root文件系统(2)进程隔离:每个容器都运行在自己的进程环境中(3)网络隔离:容器间的虚拟网络接口和IP地址都是分开的(4)资源隔离和分组:使用Cgroups(即control group，linux内核特性之一)将cpu和内存之类的资源独立分配给每个docker容器(5)写时复制:文件系统都是通过写时复制创建的(6)日志:容器产生的STDOUT、STDIN和STDERR这些IO流都会被收集并记入日志(7)交互式shell:用户可以创建一个伪tty终端，为容器提供一个交互式shell docker虚拟化特点(1)操作启动快运行时的性能获得极大的提升，管理操作(开始、停止、重启等)都是以秒或者毫秒为单位的(2)轻量级虚拟化你会拥有足够的”操作系统”，仅需添加或减少镜像即可。在一台服务器上可以部署100~1000个container容器，但是传统虚拟化虚拟出10~20个虚拟机就已经很好了(3)开源免费(4)前景及云支持 使用docker的优势(1)提供一个简单、轻量的建模方式用户上手docker非常快，只需要几分钟就可以将自己的程序”docker化”,docker依赖于”写时复制”(copy-on-write)模型，使得修改应用程序也非常迅速。(2)职责的逻辑分离使用docker，开发人员只需要关心容器中运行的应用程序，运维人员只需要关心如何管理容器，从而降低”开发时一切正常，肯定是运维问题”的风险。(3)快速、高效的开发生命周期docker的目标之一就是缩短代码从开发、测试到部署、上线运行的周期，让你的应用程序具备可移植性、易于构建、易于协作。(4)鼓励使用面向服务的架构docker推荐单个容器只运行一个应用程序，这样就形成了一个分布式的应用程序模型。在这种模型下，应用程序或服务都可以表示为一系列内部互联的容器，从而使分布式部署应用程序或者扩展应用程序变得简单。 docker安装先决条件(1)运行64位CPU架构的计算机，不支持32位的CPU(2)运行linux3.8或更高版本的内核查看内核版本:uname -a目前3.8内核已经可以通过apt-get来安装，内核更新步骤:apt-get updateapt-get install linux-headers-3.8.0-27-genericupdate-grubreboot(3)内核必须支持一种适合的存储驱动，默认是Device Mapper检查主机是否安装Device-mapper:grep device-mapper /proc/devices如果没有出现device-mapper的相关信息，可以尝试加载dm_mod模块:modprobe dm_mod(4)内核必须支持并开启cgroup和namespace(命名空间)的功能cgroup和namespace自2.6版本就已经集成到linux内核中，目前为止功能非常稳定 docker安装默认docker只能在centos6.5以上机器才能使用yum直接安装，如果是其他版本的话需要安装centos扩展源epel。docker官方要求linux kernel至少要3.8以上。在centos6.5系统上安装docker:(1)关闭selinux(2)安装epel源wget http://ftp.riken.jp/Linux/fedora/epel/6/x86_64/epel-release-6-8.noarch.rpmrpm -ivh epel-release-6-8.noarch.rpm(3)安装依赖yum install lxc libcgroup device-mapper-event-libsdevice-mapper* -y(4)安装dockeryum install docker-io(5)docker启动/etc/init.d/docker start在ubuntu 16.04安装docker:(1)安装wget -qO- https://get.docker.com/ | sh(2)启动/etc/init.d/docker start备注:在ubuntu中，如果使用UFW，需要在UFW中启用数据报文转发，才能让docker正常工作。因为UFW默认情况下会丢弃所有转发的数据包。修改/etc/default/ufw，将DEFAULT_FORWARD_POLICY=”DROP”修改为DEFAULT_FORWARD_POLICY=”ACCEPT”，保存修改内容并通过ufw reload重启UFW即可 docker常用命令docker version #查看docker版本docker images #查看当前的docker所有镜像docker info #检查docker是否已经正确安装并运行docker search centos #搜索可用的docker镜像docker pull centos #从公有仓库中下载镜像cat centos.tar | docker import - centos6 #导入镜像，导入centos.tar镜像并重命名为centos6docker export id &gt; centos6.tar #导出镜像，根据id导出镜像并重命名为centos6.tardocker ps -l #查看最后一个容器的iddocker ps -a #查看所有容器docker run centos echo “hello world” #在容器中运行”hello world”docker run centos yum install ntpdate #在容器中安装ntpdate程序docker run -i -t centos /bin/bash #在容器中启动一个/bin/bash shell环境，可以登入操作，-t表示打开一个终端，-i表示交互式输入docker run -d centos:v1 /bin/bash #在后台启动一个/bin/bash shell环境，-d表示在后台以daemon方式启动docker run -d -p 80:80 -p 8022:22 centos:v2 #-p指定容器启动后docker上运行的端口映射为容器里运行的端口，80:80中第一个80表示docker系统(本机)的80端口，第二个80表示docker虚拟机(docker容器)里面的端口。用户默认访问本机80端口，自动映射到容器里面的80端口docker commit 2313132 centos:v1 #提交刚修改的容器docker stop id #关闭容器docker start id #启动容器docker rm id #删除容器","categories":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/categories/docker/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/tags/docker/"}]},{"title":"初识java","slug":"初识java","date":"2018-10-10T08:33:00.000Z","updated":"2018-12-07T06:34:55.897Z","comments":true,"path":"2018/10/10/初识java/","link":"","permalink":"http://yoursite.com/2018/10/10/初识java/","excerpt":"","text":"1、先了解一下PHP(1)PHP是开发语言，也是运行环境作为开发语言，PHP属于脚本语言，也属于动态语言 (2)PHP编译过程:为简化编译过程，引入Zend Engine，编译成opcode，第一次编译第二次就不用编译；但是像Apache，每一个进程都使用一个独立的进程空间，因此第一个进程编译的结果第二个进程无法使用，因此又引入了缓存，像Xcache、APC、eAccelerator。 (3)PHP与C(面向过程)、C++(面向对象)相比较:PHP具有动态语言和脚本语言的灵活性、便捷性、移植性好C和C++移植困难、维护成本高，但是高速、性能好，一般用来开发驱动和底层程序等 插入介绍一些linux系统知识:(1)最底层:System call，系统调用上一层:API(application programming interface)，应用编程接口，有windows api和linux api再上一层:POSIX(POS全称portable operation system)，可移植操作系统，后面的IX是为了兼容linux操作系统的叫法。POSIX可以实现跨平台编译，POSIX是一种规范。(2)程序可以跨平台编译，但是不能跨平台运行(因为windows和linux的动态库不一样，windows系统是.so文件，linux系统是.dll文件)。因此，又出现一种叫做ABI的接口，ABI全称是application binary interface，可以拟合不同操作系统的二进制格式。在linux中，二进制格式是ELF；在windows中，二进制格式是EXE 最后引入java，java的出现就是为了能够在不同的操作系统上运行应用程序java包含四个独立又彼此相关的技术:(1)java程序设计语言(2)jvm(java virtual machine)，又叫java虚拟机(3)java class文件格式(4)java api彼此相关:java编程语言结合java api，编译成java class文件格式(字节码)，在jvm上运行(name.java–&gt;name.class,还有各种公有类和私有类跑在jvm上) 2、java apijava ee包含多个独立的api，servlet(硬编码)和jsp(.jsp-&gt;.java-&gt;.class)就是其中的两个，而java ee中著名的api还还包含以下几个:java ee api:(1)ehj(enterprise javabeans):java相关的诸多高级功能的实现，如rmi(remote method invocation)，对象/关系映射，跨越多个数据源的分布式事务等(2)jms(java message service):高性能异步消息服务，实现java ee应用程序与非java程序的透明通信(3)jmx(java management extensions):在程序运行时对其进行交互式监控和管理的机制(4)jta(java transaction api):允许应用程序在自身的一个或多个组件中平滑的处理错误的机制(5)javamail:通过工业标准的POP/SMTP/IMAP协议发送和接收邮件的机制 java se api:jndi(java naming and directory interface):用于与ldap服务交互的apijaxp(java api for xml processing):用于分析和转换xml 3、介绍jvmjvm最大的特点:一次编译，到处运行(once for all)jvm实现方式:(1)一次性解释器，解释字节码并执行(2)即时编译器(just-in-time complier)，依赖于更多内存缓存解释后的结果(3)自适应编译器，监控执行频率较高的代码，并将结果缓存下来(二八法则，缓存20%左右的代码，提高80%左右的速度) jvm分类:(1)hotspot，sum公司自己的jvm，hotspot又分为两类:jre:java运行环境，运行(编译)所需；jre=java语言+java se apijdk:java开发环境(包含jre，是jre的超集)，运行(编译)+开发所需；jdk=java语言+java api+jvm，jdk是实现java程序开发的最小环境(2)openjdk，开源界的jvm开发+运行的开源实现 java分类(根据java应用领域的不同):(1)java se:standard edition，标准版本，早期也叫做J2SE(2)java ee:enterprise edition，企业版本，早期也叫做J2EE(3)java me:mobile edition，移动版本，早期也叫做J2ME(用的很少) #2指的是第二版 4、介绍jdk:(1)jdk包格式jdk 1.6 update 32(jdk1.6的第32次升级，软件包名称是jdk-1.6.32)jdk 1.7 update 9(jdk1.7的第9次升级，软件包名称是jdk-1.7.9)(2)jdk安装方式rmp包通用二进制格式源码编译(3)命令yum list all|grep java #查看操作系统自身提供的jdk软件包java -version #查看java版本 5、介绍jsp(1)早期的时候，出现了applet这种小程序，用于开发动态网站；applet是开发在客户端运行的应用程序，基于web技术(2)接着，出现一种叫做CGI(common gateway interface)规范，能够让用户访问某种资源的时候，触发web服务器，调用额外的程序执行。除了CGI规范，java还提供了一种叫做servlet的规范，用来兼容applet和CGI；servlet是开发运行在服务器端的应用程序，基于CGI技术(3)在servlet的基础上进行升级改造，又引入了jsp(java server page)，用来嵌入java语言；jsp将servlet简化，开发者只需要将java程序嵌入到html代码中 #虽然说jsp拜托了servlet的束缚，但是jsp还是要通过Jasper先转换成servlet；jsp框架能够让java以嵌入式代码的方式嵌入到html代码中，从而实现基于java的动态网站开发 6、介绍java类(类库)有三类:(1)applet(2)servlet(3)jsp.jsp通过Jasper转换为.java.java通过jvm转换为.class 7、垃圾回收机制java程序可以实现自动内存回收，通过GC(gabbage collect)来完成(1)垃圾回收器:cms(Concurrent Mark-Sweep)，cms是以牺牲吞吐量为代价来获得最短回收停顿时间的垃圾回收器。对于要求服务器响应速度的应用上，这种垃圾回收器非常适合。在启动JVM参数加上-XX:+UseConcMarkSweepGC ，这个参数表示对于老年代的回收采用CMS。CMS采用的基础算法是：标记—清除。(2)cms过程:初始标记、并发标记、并发预处理、重新标记、并发清理、并发重置(3)cms优缺点:优点:并发收集、低停顿缺点:无法收集浮动垃圾，由于基于标记-清除算法，可能会产生碎片 8、java配置参数-XX:+ #开启此参数指定的功能-XX:- #关闭此参数指定的功能-XX:= #给option指定的选项赋值示例:java -XX:+PrintFlagsFinal #查看java配置所支持的参数 9、java工具sun jdk免费提供给用户监控和故障处理工具:(在jdk安装目录的bin目录下有很多java工具和命令)(1)jps:java process status tool，显示指定系统内的所有hotspot虚拟机进程的列表信息(2)jstat:jvm staticstics monitoring tool，收集并显示hotspot虚拟机各方面的运行数据(3)jinfo:显示正在运行的某hotspot虚拟机配置信息(4)jmap:生成某hotspot虚拟机的内存转储快照 可视化工具:(1)jconsole:java的监控和管理控制台(2)jvisualvm:java虚拟机控制台 #java工具除了sun开源的工具，还有很多商业的工具","categories":[{"name":"tomcat","slug":"tomcat","permalink":"http://yoursite.com/categories/tomcat/"}],"tags":[{"name":"java","slug":"java","permalink":"http://yoursite.com/tags/java/"}]},{"title":"redis高级功能","slug":"redis高级功能","date":"2018-10-08T09:20:00.000Z","updated":"2018-12-19T07:21:52.861Z","comments":true,"path":"2018/10/08/redis高级功能/","link":"","permalink":"http://yoursite.com/2018/10/08/redis高级功能/","excerpt":"","text":"1、redis认证实现方法:(1)通过配置文件redis.conf修改requirepass PASSWORD #定义连接redis时的密码(2)通过客户端redis-cli修改auth PASSWORD #验证密码，PASSWORD为配置文件中requirepass定义的密码 2、redis事务(1)通过MULTI、EXEC、WATCH等命令实现事务功能:将一个命令或多个命令归并为一个操作提请服务器按顺序执行的机制举栗子:multi #启动(开始)一个事务……exec #执行(结束)一个事务 (2)watch:乐观锁在exec命令执行之前，用于监视指定键；如果监视中的某任意键数据被修改，则服务器拒绝执行事务(因为watch是监视数据是否被修改，一旦确认数据被修改，则放弃使用数据，而不是拒绝对方使用数据，所以叫乐观锁) (3)redis事务与传统关系型数据库的事务最大区别在于:redis不支持回滚 3、redis持久化:本质上是内存数据库redis持久化有两种机制:(1)RDB:快照机制，按事先制定的策略，周期性的将数据保存至磁盘，数据文件默认为dunp.rdb客户端也可以显式使用save或bgsave命令启动快照保存机制save:同步，在主线中保存快照，此时会阻塞所有客户端请求bgsave:异步，bg表示back-ground，后台运行，不会阻塞客户端请求 与rdb相关的配置文件参数:stop-write-on-bgsave-error yes #出错时停止写入rdbcompression yes #rdb文件是否执行压缩来节省磁盘空间rdbchecksum yes #是否对rdb的镜像文件做校验码检测dbfilename dump.rdb #指明文件名dir /var/lib/redis #指明rdb文件保存的目录 (2)AOF：append only file的缩写，把redis的每一个操作命令以附加的形式，附加到指定文件的尾部，会导致文件很大。记录每一次写操作至指定的文件尾部实现持久化，当redis重启时，可以通过重新执行文件中的命令在内存中重建数据库。通过bgrewriteaof来实现aof文件重写，不会读取正在使用的aof文件，而是通过将内存中的数据以命令的方式保存到临时文件中，完成之后替换原来的aof文件 与aof相关的配置文件参数:appendonly no #没有开启aof功能appendfilename “appendonly.aof” #文件名appendfsync always #每次收到写命令就立即写到aof文件appendfsync everysec #每秒钟写一次(折中的方式)appendfsync no #不通知内核，内核爱怎么写就怎么写no-appendfsync-on-write no #重写的时候对新写的操作不做sync操作，而是暂存在内存当中auto-aof-rewrite-percentage 100auto-aof-rewrite-min-size 64m aof重写过程:a.redis主进程通过fork创建子进程b.子进程根据redis内存中的数据创建数据库重建命令序列于临时文件中c.父进程继承client的请求，并会把这些请求中的写操作继续追加至原来的aof文件中；额外的，这些新的写请求还会被放置于一个缓冲队列中d.子进程重写完成，会通知父进程；父进程把缓冲中的命令写到临时文件中e.父进程用临时文件替换老的aof文件 使用子进程进行AOF重写的问题：子进程在进行AOF重写期间，服务器进程还要继续处理命令请求，而新的命令可能对现有的数据进行修改，这会让当前数据库的数据和重写后的AOF文件中的数据不一致如何修正:为了解决这种数据不一致的问题，Redis增加了一个AOF重写缓存，这个缓存在fork出子进程之后开始启用，Redis服务器主进程在执行完写命令之后，会同时将这个写命令追加到AOF缓冲区和AOF重写缓冲区即子进程在执行AOF重写时，主进程需要执行以下三个工作：执行client发来的命令请求；将写命令追加到现有的AOF文件中；将写命令追加到AOF重写缓存中。参考链接:https://blog.csdn.net/hezhiqiang1314/article/details/69396887 备注:重写本身不能取代备份，还应该指定备份策略，对redis数据库进行定期备份rdb与aof同时启用的时候:a.bgsave和bgrewriteaof不会同时执行b.在redis服务器启动数据恢复时，会优先使用aof 4、复制功能(1)特点:a.一个master可以有多个slaveb.支持链式复制c.master以非阻塞的方式同步数据至salve(2)主从(配置):slave slaveof master_ip master_port(3)认证如果master使用requirepass开启了认证功能，从服务器要使用masterauth 来连入服务请求来使用此密码进行验证 5、HA高可用通过sentinel来管理多个redis服务器实现HAsentinel作用:(1)用于监视主服务器(2)实现通知功能(notification)(3)实现自动故障转移 sentinel协议:(1)流言协议:接收主服务器是否下线的通知(2)投票协议:决定哪个服务器成为新的主服务器 sentinel启动:(1)redis-sentinel /path/to/file.conf(2)redis-server /path/to/file.conf –sentinel启动过程:(1)服务器自身初始化，运行redis-server中专用于sentinel功能的代码(2)初始化sentinel状态，根据给定的配置文件，初始化监控的master服务器列表(3)创建指向master的连接 sentinel下线:(1)主观下线:一个sentinel实例判断出某节点下线(2)客观下线:多个sentinel节点协商好判断出某节点下线 sentinel专用配置文件:/etc/redis-sentinel.conf(1)sentinel monitor mymaster 127.0.0.1 6379 2(2代表投票数) #多个sentinel的情况下，有2票投票从服务器成为主服务器的话，从服务器就会成为新的主服务器(2)sentinel down-after-milliseconds mymaster 30000 #30秒找不到主服务器就判断离线(3)sentinel parallel-syncs mymaster 2 #允许多少个从服务器向主服务器发起同步请求(4)sentinel failover-timeout mymaster 20 #主服务器发生故障，故障转移超时时间(故障转移超过这个时间，判断故障转移失败) sentinel专用命令(都以sentinel开头):sentinel masters:列出所有监视的主服务器sentinel slaves master_name:获取指定主服务器的从节点sentinel get-master-addr-by-name master_name:根据name获取master地址sentinel reset:重置操作sentinel failover &lt;master_name&gt;:手动执行故障转移操作 sentinel连接:(1)客户端连接sentinel示例redis-cli -h ipaddr -p 26379(sentinel默认端口)(2)客户端连接从节点示例redis-cli -h ipaddr -p 6380(自定义redis端口) 6、集群clustering:redis3.0以后支持分布式数据库，通过分片机制进行数据分析，clustering内的每个节点仅存数据库的一部分数据，也被称作去中心化(每一个节点都可以接入客户请求)。这样，每个节点都持有全局元数据，但仅持有一部分数据优点:(1)无中心化，gossip分散式模式(2)更少的来回次数并降低延迟(3)自动于多个redis节点进行分片(4)不需要第三方软件支持协调机制缺点:(1)依赖于redis3.0或更高版本(2)需要时间验证其稳定性(3)没有后台界面(4)需要智能客户端(5)redis客户端必须支持redis cluster架构","categories":[{"name":"redis","slug":"redis","permalink":"http://yoursite.com/categories/redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://yoursite.com/tags/redis/"}]},{"title":"redis安装、配置及基本命令操作","slug":"redis配置及基本命令操作","date":"2018-10-08T08:19:00.000Z","updated":"2018-12-19T07:19:56.057Z","comments":true,"path":"2018/10/08/redis配置及基本命令操作/","link":"","permalink":"http://yoursite.com/2018/10/08/redis配置及基本命令操作/","excerpt":"","text":"1、redis特点:(1)原子性:要么全部执行，要么全部不执行(2)一致性:支持事务(3)隔离性:单线程(4)持久性:异步写入磁盘，避免雪崩效应 2、首先介绍一下redis3.0特性:(1)支持redis cluster(2)支持新的”embedded string”(3)LRU算法的改进改进如下:a.预设随机抽取5个样本，插入并排序至一个pool，移除最佳者，如此反复，直到内存用量小于maxmemory的设定b.样本5比先前的3多c.从局部最优趋向全局最优 3、redis组件:(1)redis-server(服务端)(2)redis-cli(客户端)(3)redis-benchmark(压测工具)(4)redis-check-dump &amp; redis-check-aof(检查持久化文件是否完整，分别对应rdb和aof格式) 4、redis官方站点:www.redis.ioyum info redis #查看epel源是否含有redis的安装包yum localinstall redis-3.0.2-1.el6.reml.x86_64.rpm #本地安装redisrpm -ql redis #查看安装redis时安装了哪些文件redis-server –help #查看帮助 5、redis配置文件(常用配置):(1)tcp-backlog #指等待队列。当并发量大的时候，redis可能会忙不过来。这时候需要额外找一个地方，将新的请求缓存下来，这个位置就叫backlog(2)redis.sock #服务端和客户端在同一台机器的时候，建议以sock文件的方式进行通信。好处是在内存当中直接交换，而不需要经过tcp/ip协议栈进行封装和解封装(3)timeout 0 #0表示连接不会超时(4)snapshotting配置:save 900 1 表示在900秒内有一个键发生变化，就做一次快照(5)replication配置:主从(6)daemonize yes #启动程序时，程序在后台运行 6、redis基本命令:(1)通过redis-cli客户端连接redis之后，可以通过help命令查看帮助help +tab键 #查看redis支持哪些类型help @STRING #查看字符串帮助help append #查看append命令的用法 (2)连接(connection)命令:help @connection #查看连接相关命令AUTH #验证PING #测试服务器是否在线，在线的话会返回PONGECHO #显示命令，例如ECHO ‘hello’QUIT #退出命令SELECT #选择数据库 (3)服务器(server)命令:help @server #查看服务器相关命令CLIENT SETNAME connection-name #设定连接名CLIENT GETNAME #查看连接名CLIENT KILL ip:port kill #关闭client (4)配置(config)命令:INFO #查看redis信息，信息包含很多段，例如INFO memory可以查看内存段的信息CONFIG RESETSTAT #重置INFO中所统计的数据CONFIG SET #运行中修改，也就是在内存中修改，不会同步到硬盘中CONFIG REWRITE #将配置写到硬盘当中CONFIG GET (如dir) #查看配置 7、redis支持的数据结构:(1)string #help @string，查看string支持的命令string支持的命令:set #help set，查看set帮助getappendstrlen (2)integer #help @integer，查看integer支持的命令integer支持的命令:incr #help incr，查看incr帮助decr (3)list [a,b,c,d] #help @list，查看list支持的命令list支持的命令:rpush #help rpush，查看rpush帮助lpushrpoplpoplindexlsetllen (4)set {a,b,c,d} #help @set，查看set支持的命令set支持的命令:sadd #help sadd，查看sadd帮助sinter #求交集sunion #求并集spop #随机弹出，set无序sismember #成员运算符 (5)sorted set {a:1,b:2,c:3} #help @sorten_set，查看sorten_set支持的命令sorten_set支持的命令:zadd #help zadd，查看zadd帮助zrangezcardzrank (6)hash {field1:”a”,field2:”b”}，说白了就是映射，也称为关联数组 #help @hash，查看hash支持的命令hash支持的命令:hset #help hset，查看set帮助hsetnxhgethkeyshvalshlenhdel (7)bitmaps #help @bitmaps，查看bitmaps支持的命令(8)hyperloglog #help @hyperloglog，查看hyperloglog支持的命令 …. 8、清空数据库:FLUSHDB:清空当前库FLUSHALL:清空所有库","categories":[{"name":"redis","slug":"redis","permalink":"http://yoursite.com/categories/redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://yoursite.com/tags/redis/"}]},{"title":"开始认识redis","slug":"初识redis","date":"2018-10-08T06:59:00.000Z","updated":"2018-12-19T07:18:59.620Z","comments":true,"path":"2018/10/08/初识redis/","link":"","permalink":"http://yoursite.com/2018/10/08/初识redis/","excerpt":"","text":"redis属于nosql的一种。首先介绍一下nosql的分类:1、key-value nosql，比如redis，memcached2、column family nosql(列式存储)，比如hbase3、documentation nosql(文档存储)，比如mongodb4、graph nosql(图形存储) redis特性:1、key-value cache and store2、in-memory3、single threaded(单线程，因为redis占用cpu的消耗很低，因此cpu一般不会成为瓶颈)4、支持持久化(snapshotting，快照方式，异步写入到磁盘:AOF，append only file)5、支持主从(借助于sentinel实现一定意义上的HA:高可用)6、支持分布式集群(clustering)7、支持string、list、hash(关联数组)、set、sorted set(有序集合)、bitmap、hyperloglog redis与memcached比较:redis优势:1、支持的数据类型丰富，包括hash、lists、sets、sorted set、hyperloglog2、内建replication及cluster3、就地更新操作(in-place update)4、支持持久化(异步写入磁盘，避免雪崩效应)memcached优势:1、多线程(善用多核CPU，更少的阻塞操作)2、更少的内存开销3、更少的内存分配压力4、可能有更少的内存碎片","categories":[{"name":"redis","slug":"redis","permalink":"http://yoursite.com/categories/redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://yoursite.com/tags/redis/"}]},{"title":"解决rabbitmq的web管理界面无法使用guest用户登录的问题","slug":"解决rabbitmq的web管理界面无法使用guest用户登录的问题","date":"2018-09-29T09:26:00.000Z","updated":"2018-09-29T09:27:15.108Z","comments":true,"path":"2018/09/29/解决rabbitmq的web管理界面无法使用guest用户登录的问题/","link":"","permalink":"http://yoursite.com/2018/09/29/解决rabbitmq的web管理界面无法使用guest用户登录的问题/","excerpt":"","text":"为了解决这个问题，需要在rabbitmq的配置文件中将loopback_users配置设置为空，如编写配置文件:/etc/rabbitmq/rabbitmq.config，并在其中添加以下内容： [{rabbit, [{loopback_users, []}]}]. 保存后重启rabbitmq-server即可随意使用guest用户名和密码来登录了(当然这个做法非常不安全)。","categories":[],"tags":[{"name":"rabbitmq","slug":"rabbitmq","permalink":"http://yoursite.com/tags/rabbitmq/"}]},{"title":"iptables删除已有的规则","slug":"iptables删除已有的规则","date":"2018-09-29T09:21:00.000Z","updated":"2018-12-10T09:31:44.817Z","comments":true,"path":"2018/09/29/iptables删除已有的规则/","link":"","permalink":"http://yoursite.com/2018/09/29/iptables删除已有的规则/","excerpt":"","text":"比如要删除input链上的某条规则，先要查询input链的所有规则iptables -L INPUT –line-numbers 查看你所要删除的规则是第几条，比如要删除第3条iptables -D INPUT 3","categories":[{"name":"iptables","slug":"iptables","permalink":"http://yoursite.com/categories/iptables/"}],"tags":[{"name":"iptables","slug":"iptables","permalink":"http://yoursite.com/tags/iptables/"}]},{"title":"mysql启动报错:\"[ERROR] Table 'mysql.user' doesn't exist\"","slug":"mysql启动报错","date":"2018-09-29T09:16:00.000Z","updated":"2018-12-19T07:29:31.466Z","comments":true,"path":"2018/09/29/mysql启动报错/","link":"","permalink":"http://yoursite.com/2018/09/29/mysql启动报错/","excerpt":"","text":"这是因为编译安装mysql时指定了”–datadir=/usr/local/mysql/data”,所以在新增加一个/etc/my.cnf文件的时候，需要在my.cnf里面指定datadir=/usr/local/mysql/data 然后重启mysql就可以正常启动了","categories":[{"name":"QA","slug":"QA","permalink":"http://yoursite.com/categories/QA/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/tags/mysql/"}]},{"title":"ubuntu安装ansible","slug":"ubuntu安装ansible","date":"2018-09-26T08:13:00.000Z","updated":"2018-10-08T05:50:39.916Z","comments":true,"path":"2018/09/26/ubuntu安装ansible/","link":"","permalink":"http://yoursite.com/2018/09/26/ubuntu安装ansible/","excerpt":"","text":"1、安装add-apt-repository必要套件apt-get install -y python-software-properties software-properties-common 2、使用ansible官方的PPA套件来源add-apt-repository -y ppa:ansible/ansible 3、升级apt-getapt-get update 4、安装ansibleapt-get install -y ansible","categories":[{"name":"安装篇","slug":"安装篇","permalink":"http://yoursite.com/categories/安装篇/"}],"tags":[{"name":"ansible","slug":"ansible","permalink":"http://yoursite.com/tags/ansible/"}]},{"title":"集群的概念","slug":"集群的概念","date":"2018-09-23T10:31:00.000Z","updated":"2018-09-23T10:42:13.270Z","comments":true,"path":"2018/09/23/集群的概念/","link":"","permalink":"http://yoursite.com/2018/09/23/集群的概念/","excerpt":"","text":"1、LB集群:lvs,nginx(lvs,nginx也可以实现高可用，但是相对来说在高可用中keepalived比较常见)2、HA集群:keepalived,heartbeat,corosync3、HP集群:高性能集群、超算集群，在互联网公司中很少见，一般在国家级实验室或者超算实验室中比较常见(HP集群一般可以用分布式计算来替换) 延伸:分布式计算中的一些概念分布式存储:HDFS分布式计算:YARNbatch:mapreducein-memory:sparkstream:storm HA cluster配置前提:1、本机的主机名与host中定义的主机名保持一致，要与hostname(uname -n)获得的名称保持一致 #根据主机名彼此通信配置主机名:在centos6中,/etc/sysconfig/networks在centos7中，hostnamectl set-hostname HOSTNAME #各节点要能相互解析主机名:一般建议通过host文件进行解析(配置文件/etc/hosts)2、各节点时间同步3、确保iptables及selinux不会成为服务的阻碍iptables -L -n #查看iptables规则getenforce #查看selinux状态","categories":[{"name":"高可用web","slug":"高可用web","permalink":"http://yoursite.com/categories/高可用web/"}],"tags":[{"name":"集群","slug":"集群","permalink":"http://yoursite.com/tags/集群/"}]},{"title":"keepalived配置实例","slug":"keepalived配置实例","date":"2018-09-23T09:53:00.000Z","updated":"2018-12-07T06:39:29.278Z","comments":true,"path":"2018/09/23/keepalived配置实例/","link":"","permalink":"http://yoursite.com/2018/09/23/keepalived配置实例/","excerpt":"","text":"实例一启动keepalived之后找不到配置文件:1、编辑/etc/rsyslog.conf #指明各类日志文件中的信息加上一句，local3.* /var/log/keepalived.log 2、编辑/etc/sysconfig/keepalived,加上一句，KEEPALIVED_OPTIONS=”-D -S 3” #指明keepalived日志文件的facility(等级)为3 3、重启rsyslog,keepalived服务在centos7中，systemctl restart rsyslog.servicesystemctl restart keepalived.service 实例二手动调度vip在两台主机中转移在配置文件中，1、vrrp实例之外加上一个函数vrrp_script chk_maintainnance{ script “[[ -f /etc/keepalived/down]] &amp;&amp; exit 1 || exit 0” interval 1 weight -2} 2、vrrp实例之内调用这个函数track_script{ chk_maintainnance}用法:只需要touch /etc/keepalived/down,vip就会转移；删除down文件又会转移到另一台主机 实例三配置虚拟路由器组vrrp_sync_group VG_1{ group { VI_1 VI_2 }} vrrp_instance VI_1{ eth0 vip #对外部客户} vrrp_instance VI_2{ eth1 dip #对内部主机} 实例四主机状态发生改变时发送通知:在vrrp实例中定义 #notify scripts,alert as above –自定义脚本 notify_master | #当前节点转换为master时，发送相应消息 notify_backup | #当前节点转换为backup时，发送相应消息 notify_fault |&lt;QUOTED_STRING&gt; #当前节点转换为fault(发生故障)时，发送相应消息 notify | smtp_alert实例:””括起来的内容就是表示QUOTED_STRINGnotify_master “/etc/keepalived/notify.sh master”notify_backup “/etc/keepalived/notify.sh backup”notify_fault “/etc/keepalived/notify.sh fault” 下面是一个notify脚本的简单示例: #!/bin/bashvip=172.16.100.1contact=‘root@localhost’ notify(){ mailsubject=”hostname to be $1:$vip floating” mailbody=”date &#39;+%F %H:%M:%S&#39;:vrrp transtion,hostname change to be $1” echo $mailbody|mail -s “$mailsubject” $contact} case “$1” in master) notify master #/etc/rc.d/init.d/haproxy start exit 0 ;; backup) notify backup #/etc/rc.d/init.d/haproxy stop exit 0 ;; fault) notify fault #/etc/rc.d/init.d/haproxy stop exit 0 ;; *) echo “Usage:basename $0 {master|backup|fault}” exit 1 ;;esac","categories":[{"name":"keepalived","slug":"keepalived","permalink":"http://yoursite.com/categories/keepalived/"}],"tags":[{"name":"keepalived","slug":"keepalived","permalink":"http://yoursite.com/tags/keepalived/"}]},{"title":"初步认识Keepalived","slug":"eepalived简介、组件及配置文件","date":"2018-09-22T08:16:00.000Z","updated":"2018-12-19T07:27:54.750Z","comments":true,"path":"2018/09/22/eepalived简介、组件及配置文件/","link":"","permalink":"http://yoursite.com/2018/09/22/eepalived简介、组件及配置文件/","excerpt":"","text":"keepalived是vrrp协议在linux主机上的实现，能够根据配置文件自动生成ipvs规则，对各RS做健康状态检查。1、特点(1)轻量级(2)以守护进程的形式(3)节点类型分为active/passive 2、组件(1)vrrp stack(2)checkers(3)ipvs wrapper 3、keepalived涉及的协议(1)组播:主服务器发送hello信息给从服务器，证明”I am alive”配置同进退vrrp实例时，要注意多播地址，每一组实例默认会分配一个组播地址。如果是在配置文件中指定一个组播地址，则只能配置一组实例；如果需要配置多组实例(不让其中一台主机有空闲)，则需要在各组实例的配置中配置上组播地址 (2)ntp:network time protocol格式:ntpdate timeserver_ip，以这个时间服务器的时间为准，同步自己的时间date命令调整时间的格式:”date 月日时分年.秒” (3)vrrp:virtual routing redundent protocol，虚拟路由冗余协议(vrrp是路由交换协议，keepalived是vrrp在linux上的实现)vrrp是一种容错协议，保证当主机的下一跳路由出现故障时，由另一台路由器来代替出故障的路由器进行工作，从而保障网络通信的连续性和可靠性。在vrrp协议中，分为master和backup两种角色。 vrrp中的一些概念: vrid:虚拟路由器标识，有相同vrid的一组路由器构成一个虚拟路由器 虚拟Mac:一个虚拟路由器拥有一个虚拟Mac，通常情况下虚拟路由器回应arp请求使用的是虚拟Mac 优先级:vrrp根据优先级来确定虚拟路由器中每台路由器的地位 非抢占模式:即使backup路由器的优先级比master高，也不会抢占master的地位 抢占模式:根据优先级的大小来确定谁是master vrrp工作原理: a.虚拟路由器中的路由器根据优先级选举出master，master路由器通过发送免费arp报文，将自己的虚拟Mac地址通知给其他与其连接的设备或主机，从而承担报文转发任务 b.master路由器周期性发送vrrp报文，以公布其配置信息(优先级)和工作状况 c.如果master路由器出现故障，虚拟路由器中的backup路由器将根据优先级重新选举新的master d.虚拟路由器切换时，master路由器由一台设备切换成另外一台设备，新的master路由器只是简单的发送一个携带虚拟路由器的Mac地址和虚拟ip地址信息的免费arp报文，这样就可以更新与之连接的设备或主机的arp信息 e.backup路由器优先级高于master的时候，由backup路由器的工作方式(抢占或非抢占)来决定是否重新选举master vrrp认证方式: a.无认证 b.简单字符认证(将认证字符插入到vrrp报文中) c.md5认证(利用认证字符和MD5算法对vrrp报文进行加密)","categories":[{"name":"keepalived","slug":"keepalived","permalink":"http://yoursite.com/categories/keepalived/"}],"tags":[{"name":"keepalived","slug":"keepalived","permalink":"http://yoursite.com/tags/keepalived/"}]},{"title":"ubuntu 16.04搭建Hexo博客后台管理系统","slug":"ubuntu-16-04搭建Hexo博客后台管理系统","date":"2018-09-20T06:40:00.000Z","updated":"2018-09-20T07:00:40.481Z","comments":true,"path":"2018/09/20/ubuntu-16-04搭建Hexo博客后台管理系统/","link":"","permalink":"http://yoursite.com/2018/09/20/ubuntu-16-04搭建Hexo博客后台管理系统/","excerpt":"","text":"1、安装Hexo-adminnpm install –save hexo-admin #之前已经介绍安装Hexo,参考链接:https://leungzj.github.io/2018/09/19/ubuntu16-04-%E6%90%AD%E5%BB%BAHexo%E5%8D%9A%E5%AE%A2/ 2、启动服务hexo s &amp; 3、访问后台http://你的ip地址:4000/admin 4、后台启用密码登录(默认无密码)点击”Setup authentification here” 弹出设置窗口，按要求填入登录用户名和密码，然后将”admin config section”下面那一段代码复制到Hexo的配置文件_config.yml即可 5、重启Hexokillall hexohexo s &amp; 6、更换Hexo主题先切换到Hexo所在安装目录，通过git下载主题文件到本地文件夹git clone https://github.com/BosenY/Lap.git theme/lap #Hexo主题汇总链接:https://hexo.io/themes/ 7、修改Hexo配置文件_config.yml 8、保存配置文件，重新生成并重启Hexo服务hexo ghexo dkillall hexohexo s &amp;","categories":[{"name":"搭建篇","slug":"搭建篇","permalink":"http://yoursite.com/categories/搭建篇/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://yoursite.com/tags/Hexo/"}]},{"title":"secureCRT连接ubuntu显示中文乱码的解决方法","slug":"secureCRT显示中文乱码","date":"2018-09-20T05:33:00.000Z","updated":"2018-09-20T05:52:17.443Z","comments":true,"path":"2018/09/20/secureCRT显示中文乱码/","link":"","permalink":"http://yoursite.com/2018/09/20/secureCRT显示中文乱码/","excerpt":"","text":"一、ubuntu设置1、在/var/lib/locales/supported.d/local文件中添加一行:zh_CN.UTF-8 UTF-8 执行sudo locale-gen下载文件 2、在/etc/environment文件中添加两行:LANG=”zh_CN.UTF-8”LC_ALL=”zh_CN.UTF-8” 3、在~/.profile文件中添加两行:export LANG=”zh_CN.UTF-8”export LC_ALL=”zh_CN.UTF-8 执行source ~/.profile 二、secureCRT设置1、选择options – session options，弹出设置窗口2、选择terminal – emulation，terminal下拉表选择linux，并在”ansi color”前面方框打上勾 3、选择terminal – appearance，”current color scheme”选择traditional font字体选择fangsong，script选择”Chinese GB2312” character encoding下拉表选择utf-8 退出当前crt窗口，重新登录试试！","categories":[{"name":"工具篇","slug":"工具篇","permalink":"http://yoursite.com/categories/工具篇/"}],"tags":[{"name":"secureCRT","slug":"secureCRT","permalink":"http://yoursite.com/tags/secureCRT/"}]},{"title":"ubuntu16.04 源码编译安装boost1_59_0","slug":"ubuntu16-04-源码编译安装boost1-59-0","date":"2018-09-19T08:31:00.000Z","updated":"2018-09-19T08:38:34.285Z","comments":true,"path":"2018/09/19/ubuntu16-04-源码编译安装boost1-59-0/","link":"","permalink":"http://yoursite.com/2018/09/19/ubuntu16-04-源码编译安装boost1-59-0/","excerpt":"","text":"1、下载源码包wget https://iweb.dl.sourceforge.net/project/boost/boost/1.59.0/boost_1_59_0.tar.gz 2、解压缩tar zxvf boost_1_59_0.tar.gz 3、进入解压缩目录cd boost_1_59_0/ 4、运行bootstrap.sh脚本./bootstrap.sh –with-libraries=all –with-toolset=gcc参数解释:–with-libraries指定编译哪些boost库，all的话就是全部编译，只想编译部分库的话就把库的名称写上，用逗号分隔即可–with-toolset指定编译时使用哪种编译器，Linux下使用gcc即可，如果系统中安装了多个版本的gcc，在这里可以指定gcc的版本，比如–with-toolset=gcc-4.4 5、编译boost./b2 toolset=gcc 6、安装boost./b2 install可以加–prefix参数:用来指定boost的安装目录，不加此参数的话默认的头文件在/usr/local/include/boost目录下，库文件在/usr/local/lib/目录下 7、更新系统的动态链接库ldconfig","categories":[{"name":"安装篇","slug":"安装篇","permalink":"http://yoursite.com/categories/安装篇/"}],"tags":[{"name":"boost","slug":"boost","permalink":"http://yoursite.com/tags/boost/"}]},{"title":"ubuntu16.04 搭建Hexo博客","slug":"ubuntu16-04-搭建Hexo博客","date":"2018-09-19T06:56:00.000Z","updated":"2018-09-19T09:09:42.422Z","comments":true,"path":"2018/09/19/ubuntu16-04-搭建Hexo博客/","link":"","permalink":"http://yoursite.com/2018/09/19/ubuntu16-04-搭建Hexo博客/","excerpt":"","text":"一、安装Node.js1、安装curlapt install curl 2、安装node.jscurl -sL https://deb.nodesource.com/setup_8.x | sudo -E bash -apt install -y nodejs 3、检查版本(有版本号输出表示安装完成)node -vnpm -v 二、安装Hexo1、npm install -g hexo-cli 2、进入你希望建站的文件夹(必须是一个空的文件夹)，执行初始化命令:hexo init 3、安装依赖包:npm install 至此，Hexo本地博客搭建完成。 三、Hexo常用命令hexo help:查看帮助hexo init:初始化一个目录hexo generate:生成网页，在public目录查看整个网站的文件，简写为hexo ghexo server:用来启动本地站点，执行后即可在浏览器中输localhost:4000查看，简写为hexo shexo deploy:部署.deploy目录，可以简化为hexo dhexo clean:清除缓存，强烈建议每次部署deploy之前先清理缓存 四、使用github pages服务部署hexoGiuhub Page介绍:我们用来托管博客的服务叫做 Github Pages，它是 Github 用来提供给个人/组织或者项目的网页服务，只需要部署到你的 Github Repository，推送代码，便可以实时呈现。 1、首先要使用邮箱注册Github账号 2、设置gitgit config –global user.email “you@example.com“git config –global user.name “Your Name” 3、安装插件npm install hexo-deployer-git –save #为了部署到Github上，需要安装hexo-deployer-git插件 4、生成ssh秘钥ssh-keygen -t rsa -C you@example.com #-C后面跟住你在github的用户名邮箱，这样公钥才会被github认可 5、查看你的公钥，添加到Github账户的sshkey中less ~/.ssh/id_rsa.pub 6、Github上新建项目，项目名称为”用户名.github.io”，例如我的用户名是leungzj，则创建的项目名为leungzj.github.io 7、在setting–SSH and GPG keys中，添加生成的公钥，也就是将~/.ssh/id_rsa.pub的内容添加到这里 8、修改Hexo配置文件 9、编译并上传部署到Githubhexo generate #编译hexo deploy #将hexo部署到Github io上 10、访问Hexo博客通过用户名.github.io就可以Hexo博客啦！例如我的博客:https://leungzj.github.io/","categories":[{"name":"搭建篇","slug":"搭建篇","permalink":"http://yoursite.com/categories/搭建篇/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://yoursite.com/tags/Hexo/"}]},{"title":"ubuntu16.04 源码编译安装mysql5.7","slug":"安装篇-ubuntu16-04-安装mysql5-7","date":"2018-09-19T05:36:00.000Z","updated":"2019-01-09T07:07:07.173Z","comments":true,"path":"2018/09/19/安装篇-ubuntu16-04-安装mysql5-7/","link":"","permalink":"http://yoursite.com/2018/09/19/安装篇-ubuntu16-04-安装mysql5-7/","excerpt":"","text":"1、安装依赖sudo apt-get install make cmake gcc g++ bison libncurses5-dev build-essential 2、下载mysql 5.7源码包下载地址：https://dev.mysql.com/downloads/mysql/在”select operating system”中选择”source code”，我下载的版本是mysql-5.7.23 3、解压缩tar zxvf mysql-5.7.23.tar.gz -C /usr/localcd /usr/local/mysql-5.7.23/ 4、编译安装cmake . -DCMAKE_INSTALL_PREFIX=/usr/local/mysql -DMYSQL_DATADIR=/usr/local/mysql/data -DSYSCONFDIR=/etc -DWITH_INNOBASE_STORAGE_ENGINE=1 -DWITH_ARCHIVE_STORAGE_ENGINE=1 -DWITH_BLACKHOLE_STORAGE_ENGINE=1 -DWITH_PARTITION_STORAGE_ENGINE=1 -DWITH_PERFSCHEMA_STORAGE_ENGINE=1 -DWITHOUT_EXAMPLE_STORAGE_ENGINE=1 -DWITHOUT_FEDERATED_STORAGE_ENGINE=1 -DDEFAULT_CHARSET=utf8 -DDEFAULT_COLLATION=utf8_general_ci -DWITH_EXTRA_CHARSETS=all -DENABLED_LOCAL_INFILE=1 -DWITH_READLINE=1 -DMYSQL_UNIX_ADDR=/usr/local/mysql/mysql.sock -DMYSQL_TCP_PORT=3306 -DMYSQL_USER=mysql -DCOMPILATION_COMMENT=”lq-edition” -DENABLE_DTRACE=0 -DOPTIMIZER_TRACE=1 -DWITH_DEBUG=1 运行到这一步，出现报错信息:“CMake Error at cmake/boost.cmake:81 (MESSAGE): You can download it with -DDOWNLOAD_BOOST=1 -DWITH_BOOST=“提示需要安装boost库，安装参考链接:https://leungzj.github.io/2018/09/19/ubuntu16-04-%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85boost1-59-0/ makemake install 5、配置mysql(1)创建用户和用户组groupadd mysqluseradd -g mysql mysql (2)设置mysql安装目录的权限cd /usr/local/mysqlchown -R mysql:mysql ./ (3)mysql初始化 #这里会生成一个mysql临时登录密码，需要记下来，稍后登录mysql会用到bin/mysqld –initialize –user=mysql (4)启动mysqlsupport-files/mysql.server start (5)修改mysql登录密码bin/mysql -u root -pSET PASSWORD FOR ‘root‘@’localhost’ = PASSWORD(‘newpassword’); 6、远程连接mysql用类似navicat的客户端连接mysql，如果出现提示”is not allowed to connect”，需要在mysql命令行上设置远程连接权限，检查iptables是否开放3306端口(1)GRANT ALL ON . TO ‘root‘@’%’ IDENTIFIED BY ‘password’ WITH GRANT OPTION;(2)iptables -A INPUT -P tcp –dport 3306 -j ACCEPT","categories":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/categories/mysql/"}],"tags":[]}]}