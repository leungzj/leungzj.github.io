{"meta":{"title":"Jim's Blog","subtitle":null,"description":null,"author":"Jim","url":"http://yoursite.com"},"pages":[{"title":"","date":"2018-10-30T03:17:12.022Z","updated":"2018-10-30T03:17:12.022Z","comments":true,"path":"baidu_verify_HCnRC8FAR2.html","permalink":"http://yoursite.com/baidu_verify_HCnRC8FAR2.html","excerpt":"","text":"HCnRC8FAR2"},{"title":"","date":"2018-11-23T02:53:13.907Z","updated":"2018-11-23T02:53:13.907Z","comments":true,"path":"google6067bd16d98499cd.html","permalink":"http://yoursite.com/google6067bd16d98499cd.html","excerpt":"","text":"google-site-verification: google6067bd16d98499cd.html"},{"title":"","date":"2018-10-17T02:15:56.847Z","updated":"2018-10-17T02:15:56.843Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":"关于运维工程师，熟悉网络、运维、数据库、自学前端、python，志向于全栈认证：CCNA,SAA,PMP,中级网络工程师，目前在考高级项目管理师 { name: ‘jim’ age: ‘28’ gender: ‘男’ profession: ‘Operation’ experience: ‘3年’ address: ‘广东省广州市’ education: ‘本科’ github: ‘https://github.com/leungzj&#39; email: &#39;18826400669@163.com‘ blog: ‘leungzj.github.io’ description: ‘技术改变世界’ skills: [ 网络、运维、SQL、python...(持续更新中) ] }"},{"title":"","date":"2018-12-17T02:52:24.170Z","updated":"2018-12-17T02:52:24.170Z","comments":true,"path":"books/index.html","permalink":"http://yoursite.com/books/index.html","excerpt":"","text":"docker:《第一本docker书》 python:《python编程:从入门到实践》 mongodb:《MongoDB权威指南》 shell:《linux与Unix_shell编程指南》 puppet:《puppet权威指南》 jenkins:《jenkins权威指南》"},{"title":"categories","date":"2018-09-19T09:02:45.000Z","updated":"2018-09-19T09:06:58.378Z","comments":true,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2018-10-17T03:21:43.737Z","updated":"2018-10-17T03:21:43.733Z","comments":false,"path":"links/index.html","permalink":"http://yoursite.com/links/index.html","excerpt":"","text":""},{"title":"标签","date":"2018-10-17T02:54:58.153Z","updated":"2018-10-17T02:54:58.153Z","comments":false,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"rpm包安装详解","slug":"rpm包安装详解","date":"2019-03-28T09:07:00.000Z","updated":"2019-03-28T09:08:15.004Z","comments":true,"path":"2019/03/28/rpm包安装详解/","link":"","permalink":"http://yoursite.com/2019/03/28/rpm包安装详解/","excerpt":"","text":"rpm包：rpm命令：(1)rpm: 数据库在/var/lib/rpm下(2)rpmbuildrpm功能：安装，查询，卸载，升级，校验，数据库的重建，验证数据等工作 rpm命名：包：组成部分 主包：bind-9.7.1-1.i586.el5.rpm 子包：bind-libs-9.7.1-1.i586.el5.rpm bind-utils-9.7.1-1.i586.el5.rpm包名格式： name-version-release.arch.rpm bind-major.minor.release-release.arch.rpm(第一个release是制作者的发行号，第二个release是下载之后改良之后的发行号)比如下面的例子，第一个1是发行者的修正号，第二个1是修改者的修正号:bind-9.7.1-1.noarch.rpm(既可以在32位平台上运行，又可以在64位平台上运行。表示跟平台没有关系，什么平台上安装都可以运行)bind-9.7.1-1.ppc.rpm(这表明在powerPC平台上运行) 总结：(1)name-version-release.arch(版本号，发行号，平台)(2)版本号又可以分为主版本号（mahor）和次版本号（minor）(3)主版本号：重大改进 次版本号：某个子功能发生重大改变 发行号（又叫修正号）：修改了部分bug，调整了一点功能 rpm包分类：两种格式：(1)二进制格式：已经编译好的(2)源码格式：未编译的 各有优劣：(1)二进制格式已经编译好，简便快捷(2)源码格式需要在自己的主机上编译，能够更好地依赖主机的硬件性能 下面主要讲二进制格式的rpm包：rpm包作者下载源程序，编译配置完成后，制作出rpm包 1.安装：rpm -i 路径/包文件-h:以#显示进度，每个#表示2%-v:显示详细过程-vv:显示更加详细的过程 –nodeps:忽略依赖关系 –replacepkgs:重新安装，替换原有安装 –oldpackage:降级，就是升级了新版本之后发现跟其他软件包有冲突然后做降级处理 –force:强制安装，可以实现重装或者降级（’–’表示二级参数） 常用选项：-ivh 2.查询rpm -q 包名(不是文件，文件是以.rpm结尾) ==》注：上面包名格式中的name字段就是包名例如：zsh-4.2.6-6.el5.i386.rpm ==》这是包文件zsh ==&gt;这才是包名 ===包名-q:查询指定的包是否已经安装-qa:查询已经安装的所有包（其后不需要指定包名）-qi:查询指定包的说明信息（比如说rpm包的功能，什么时候安装的，谁制作的，rpm包的大小等等）-ql:查询指定包安装后生成的文件列表-qc:查询指定包安装的配置文件-qd:查询指定包安装的帮助文件-q –script：查询指定包中包含的脚本（包含四类脚本：安装前，安装后，卸载前，卸载后） ===文件名-qf 路径/文件名:查询指定的文件是由哪个rpm包生成的 注意：如果某rpm包尚未安装而我们需要查询其说明信息、安装后会产生的文件等：(在-p参数就可以)rpm -qpi 路径/包文件（包文件跟文件名又不一样）rpm -qpl 路径/包文件rpm -qpc 路径/包文件rpm -qpd 路径/包文件 3.升级rpm -Uvh 路径/新的包文件 #如果装有老版本的，则升级；否则，则安装rpm -Fvh 路径/新的包文件 #如果装有老版本的，则升级；否则，则退出 –oldpackage:降级 4.卸载rpm -e 包名 –nodeps 忽略依赖关系 5.校验rpm -V 包名 6.重建数据库：rpm的数据库在：/var/lib/rpm下rpm –rebuild:重建数据库。一定会重新建立，不管有还是没有 –initdb：初始化数据库。没有才建立，有就不用建立 7.检验来源合法性及软件完整性rpm –import /etc/pki/rpm-gpg/RPM-GPG-KEY-redhat-release（先导入密钥，不然运行下一步-K会报错）rpm -K 包文件dsa,gpg：验证来源合法性，也就是验证签名，可以使用–nosignature，略过此项sha1,md5：验证软件包完整性，可以使用–nodigest，略过此项","categories":[{"name":"linux软件管理","slug":"linux软件管理","permalink":"http://yoursite.com/categories/linux软件管理/"}],"tags":[]},{"title":"软件包管理背景知识","slug":"软件包管理背景知识","date":"2019-03-28T08:11:00.000Z","updated":"2019-03-28T08:57:15.999Z","comments":true,"path":"2019/03/28/软件包管理背景知识/","link":"","permalink":"http://yoursite.com/2019/03/28/软件包管理背景知识/","excerpt":"","text":"1、程序运行过程：源程序-编译-链接-运行例如：C语言：源代码-（编译）二进制格式脚本语言：不需要编译，直接由解释器解析 2、程序简单来说，程序=指令+数据具体来说，程序组成部分：(1)二进制程序(2)库（作用有两个：提供接口，就是供别人调用的接口；调用接口，就是程序需要依赖于库提供的某些功能才能运行）(3)配置文件(4)帮助文件备注：常用的最底层的核心库：glibc，全称是gnu library c(c语言库) 3、linux下的目录一级目录：/boot/etc/usr/var/dev/lib/tmp/bin/sbin/proc/sys/mnt/media/home/root/misc/opt/svr备注：(1)/mnt、/media主要用于挂载(2)/proc、/sys是伪文件系统(3)/dev是设备文件，2.4内核之前所有的设备文件都是预先提供的，以确保不时之需，不能根据文件识别设备；2.6内核之后，udev出现，能够根据内核提供的信息识别并动态的创建设备文件，能够判定文件设备类型创建具备见名知义的文件名(4)/boot是内核相关，是操作系统启动完之后才会看到的目录文件，所以boot目录跟操作系统启动无关 程序涉及到的目录：/etc 放置配置文件/bin 放置二进制文件/sbin 放置二进制文件/lib 放置库文件/usr/share/man 放置帮助文档 /usr： /bin /sin /lib备注：/usr下的配置文件也是放在/etc下，帮助文档也是放在/usr/share/man下 /usr/local： /bin /sbin /lib /etc /usr/local/man备注：/usr/lcoa/相当于一个独立的王国，有自己的一套完整的体系 这3套路径的区别在于：(1)/etc、/bin、/sbin、/lib是操作系统自身启动就需要用到的程序；这些目录不能挂载其他额外的分区，必须在根文件系统的分区上(2)/usr/bin、/usr/sbin、/usr/lib是提供操作系统的核心功能，可以单独分区(3)/usr/local/bin、/usr/local/sbin、/usr/local/lib、/usr/lcoal/etc、/usr/local/man主要是用于安装第三方软件。早期的时候，第三方软件都是安装在/opt下，现在才是安装在/usr/local下 4、操作系统启动过程(1)POST（加电自检）(2)BIOS（根据BIOS的配置去找启动的次序，例如从硬盘HD启动）(3)BIOS加载MBR(4)MBR根据其上面的bootloader去找出内核存放的分区，然后加载内核(5)找出根分区，加载/boot目录（内核相关） 5、软件包管理器核心功能：(1)打包成一文件：包含二进制程序、库文件、配置文件、帮助文件（制作软件包）(2)生成数据库：追踪所安装的每一个文件（例如将来卸载的时候就到各自的目录去移除就可以了），方便操作（包括安装、卸载、升级、查询、校验）分类：(1)对redhat、suse来说，有rpm软件包管理器(2)对debian来说，有dpt软件包管理器备注：rpm和dpt是后端工具，yum(yellowdog update modifier)和apt-get是前端工具 #前端工具可以更方便的解决依赖关系","categories":[{"name":"linux软件管理","slug":"linux软件管理","permalink":"http://yoursite.com/categories/linux软件管理/"}],"tags":[]},{"title":"软件包分类（rpm包、二进制包、源码包）","slug":"软件包分类","date":"2019-03-28T07:06:00.000Z","updated":"2019-03-28T07:38:30.757Z","comments":true,"path":"2019/03/28/软件包分类/","link":"","permalink":"http://yoursite.com/2019/03/28/软件包分类/","excerpt":"","text":"1、安装软件的方法1）源码安装（一般软件包格式为xx.tar.gz）2）rpm包安装（一个软件包格式为xx.rpm）3）通过软件包管理器安装（比如RHEL和Centos的yum，ubuntu的apt等） 2、软件包类型1）二进制包定义：二进制包是已经经过编译，只需要下载、解包安装即可使用。格式1：xxxx-devel-6b-33.x86_64.rpm格式（rpm -ivh安装之后能直接使用） #二进制包其实默认指的是rpm包，也就是二进制包包含rpm包，rpm包时二进制包的一个子集格式2：mysql-5.5.32-linux2.6-x86_64.tar.gz格式（tar -zxvf解压之后就能直接使用） #在格式2中，软件包的包名很长，一般带有版本号、适应平台、适应的硬件类型等。 2）rpm包定义：rpm包是二进制包的一种，以rpm结尾的一般都是rpm包。而yum(Yellowdog Update Manager)是RPM的前端工具，是基于RPM的一个管理工具，他能自动的解决安装rpm包产生的依赖关系。格式1：name-version-release.arch.rpm #对于已经编译成二进制的rpm包，由于操作系统环境不同，一般不能混用格式2：name-version-release.arch.src.rpm #以src.rpm形式发行的软件包，由于需要安装时进行本地编译，所以通常可以在不同系统下安装。 备注：name-version-release.arch.rpmname:包名称，分为主包名和分包名version:包的版本信息release:用于标识rpm包的发行号arch:主机平台，noarch表示软件包与硬件架构无关，可以通用；i386表示软件包适用于intel 80386以上的x86架构的计算机；i686表示软件包适用于intel 80686以上(奔腾pro以上)的x86架构的计算机总结下就是说i686软件包不能在i386平台上运行，而i386的软件包没有限制，可以在任何平台上运行使用 src.rpm的安装：示例：（以SUSE系统安装setarch-1.3-1.src.rpm为例）：1）cp setarch-1.3-1.src.rpm /usr/src/packages/SRPMS/2）cd /usr/src/packages/SRPMS/3）rpmbuild –rebuild –clean setarch-1.3-1.src.rpm #将源代码直接编译成普通的二进制rpm包.执行之后可以到/usr/src/packages/RPMS/x86_64目录下找到可用的二进制rpm包setarch-1.3-1.x86_64.rpm进行安装4）cd ../RPMS/x86_645）rpm -ivh setarch-1.3-1.x86_64.rpm 3）源码包定义：源码包是Linux中软件包的另一种形式，需要在计算机上进行编译以后才可以产生可以直接运行的二进制程序。源代码包里面包括了程序的程序代码，一般就是我们能认识的C语言文件,因此在安装源码包的时候通常会检索系统中是否正确安装gcc编译器，并且源代码安装的时间会比较长。格式：*.tar.gz、*.tgz、*.bz2源码包的格式一般是一个版本号的tar包，例如httpd-2.4.25.tar.gz，文件名包含信息没有二进制包多 源码包一般的安装过程是：(1)解压(2)./config(3)make(4)make install(5)ln -sv /usr/local/xxx/lib/xxx /usr/lib64/xxx 或者vim /etc/ld.so.conf ，在文件末尾追加/usr/local/xxxx/lib，保存退出后执行ldconfig 【建议这种方式】(6)vim /etc/profile,文件末尾添加PATH=/usr/local/xxx/bin:$PATH，然后 source /etc/profile","categories":[{"name":"linux软件管理","slug":"linux软件管理","permalink":"http://yoursite.com/categories/linux软件管理/"}],"tags":[]},{"title":"linux系统调优","slug":"linux系统调优","date":"2019-03-28T02:24:00.000Z","updated":"2019-03-28T02:59:45.519Z","comments":true,"path":"2019/03/28/linux系统调优/","link":"","permalink":"http://yoursite.com/2019/03/28/linux系统调优/","excerpt":"","text":"1、网络故障排查思路1）网络硬件传输问题2）检查网卡是否能正常工作，网卡ip是否设置正确3）检查dns是否设置正确4）服务是否正常打开5）访问权限是否打开 2、网络硬件资源1）cpu2）内存3）磁盘io4）网络带宽 3、文件系统1）ext2：linux标准文件系统，无日志记录（inode）功能2）ext3：在ext2的基础上增加了日志记录功能，仅支持32000个目录3）ext4：无限目录支持，快速fsck4）xfs：高性能文件系统建议：读操作频繁，同时小文件众多：首选ext4，然后是xfs，ext3写操作频繁：首选xfs，然后是ext4，ext3对性能要求不高、数据安全性不高的业务：ext3是比较好的选择 4、cpu性能评估工具1）vmstat（Virtual Memory Statistics 虚拟内存统计）：对操作系统的内存信息、进程状态、cpu活动等进行监视vmstat 2 3:每2秒更新一次输出信息，统计3次之后停止输出 #-a：显示活跃和非活跃内存 #-s：显示内存相关统计信息及多种系统活动数量 #-d：显示磁盘相关统计信息 #-p：显示指定磁盘分区读写信息 2）iostat：用法跟vmstat一样，主要是对系统磁盘io进行监视iostat -c 3 5 #-c：显示cpu的使用情况 #-d：显示磁盘的使用情况 #-k：强制使用Kilobytes为单位 #-x：输出更多详细信息 3）uptime输出如下：当前时间 04:03:58系统已运行的时间 10 days, 13:19当前在线用户 1 user平均负载：0.54, 0.40, 0.20，最近1分钟、5分钟、15分钟系统的负载 5、内存性能评估工具1）free -m2）sar/pidstat主要用于监控占用系统资源的情况-u:获取cpu状态-r:获取内存状态-d:获取磁盘状态 sar -u 3 #获取cpu3秒内的状态pidstat -r -p 1 3 #获取内存3秒内的状态 6、磁盘性能评估工具1）iostat -d 2 32）pidstat -d -p 1 3 #统计pid为1的进程所占用的磁盘io资源，3秒统计一次备注：-p：针对特定进程统计3）sar -d 2 3 #每隔2秒钟统计一次，统计3次 7、网络性能评估工具1）ping2）netstatnetstat -i：查看路由情况netstat -r：查看网络接口状态3）mtr/traceroute","categories":[{"name":"linux系统调优","slug":"linux系统调优","permalink":"http://yoursite.com/categories/linux系统调优/"}],"tags":[]},{"title":"Raid详解","slug":"Raid详解","date":"2019-03-27T09:23:18.000Z","updated":"2019-03-28T02:22:27.177Z","comments":true,"path":"2019/03/27/Raid详解/","link":"","permalink":"http://yoursite.com/2019/03/27/Raid详解/","excerpt":"","text":"1、Raid0 1）定义：Raid0可以提高存储性能，代表了Raid级别中最高的存储性能。2）原理：Raid0把连续的数据分散到多个磁盘上存取，这样当系统有数据请求的时候，就可以被多个磁盘并行的执行，每个磁盘执行属于它自己的那部分数据请求。比如说，系统向三个磁盘组成的逻辑硬盘（Raid0磁盘组）发出的I/O数据请求转化为3项操作，其中的每一项操作都对应一块物理硬盘。通过建立Raid0，原先顺序的数据请求被分散到三块硬盘中同时执行。从理论上说，三块硬盘的并行操作使得同一时间内磁盘读写速度提高了3倍。但是实际中由于总线带宽等多种因素的影响，实际的提升速度会低于理论值。3）优缺点：优点是空间使用率100%，成本低。而且读写性能是所有Raid级别中最高的读性能：N*单块磁盘的读性能写性能：N*单块磁盘的写性能缺点是不提供冗余，一旦用户数据损坏，损坏的数据将无法得到恢复。 2、Raid1 1）定义：通过磁盘数据镜像实现数据冗余，互为主备。当原始数据繁忙时，可以直接从镜像拷贝中读取数据，因此Raid1可以提高读取性能。2）原理：Raid1是两块硬盘所构成的Raid磁盘阵列，其容量仅等于一块硬盘的容量，另一块只是当做数据镜像。它的读取性能没有Raid0磁盘阵列那么好，但是其读取速度较单一硬盘块，因为数据会从两块硬盘中较快的一块读出。写入速度通常比单块硬盘要慢，因为虽然是并行写，即对两块硬盘的写入是同时进行的，但因为要比较两块硬盘中的数据，所以性能比单块磁盘慢。3）优缺点：优点是实现数据冗余，提供了很高的数据安全性和可用性缺点是空间使用率50%，成本高 3、Raid5 1）定义：Raid5是Raid0和Raid1的折中方案。Raid5具有和Raid0相近似的读取速度，只是多了一个奇偶校验信息，写入数据的速度比单个磁盘写入要慢。2）原理：Raid5把数据和相应的奇偶校验信息存储到组成Raid5的各个磁盘上，并且奇偶校验信息和相对应的数据分别存储于不同的磁盘上，其中任意N-1块磁盘都存储完整的数据，也就是说有相当于一块磁盘容量的空间用于存储奇偶校验信息。当磁盘损坏被替换后，Raid5会自动利用剩下的奇偶校验信息去重建此磁盘上的数据。做Raid5阵列所有磁盘容量必须一样大，当容量不同时，会以最小的容量为准。最好转速也一样，否则会影响性能。3）优缺点：磁盘空间利用率(N-1)/N，即只浪费一块磁盘用于奇偶校验。读性能也不赖，可以实现冗余（只允许一块硬盘损坏）读性能：(N-1)*单块磁盘的读性能，接近Raid0的读性能写性能：比单块磁盘的写性能要差 4、Raid10 1）定义：Raid10的另一种说法是Raid1+0，也就是Raid1和Raid0的组合。2）原理：Raid10其实结构非常简单，首先创建2个独立的Raid1，然后将这两个独立的Raid1组成一个Raid0。虽然Raid10方案造成了50%的磁盘浪费，但是它提供了200%的速度和单磁盘损坏的数据安全性，并且当同时损坏的磁盘不在同一Raid1中，就能保证数据安全性。3）优缺点：磁盘空间利用率是50%，读写性能：读性能：N/2*单块硬盘的读性能写性能：N/2*单块硬盘的写性能冗余：只要同时损坏的磁盘不在同一Raid1中，就能保证数据安全性","categories":[],"tags":[]},{"title":"mongoDB基础","slug":"mongoDB笔记（1）","date":"2019-03-27T02:07:00.000Z","updated":"2019-03-27T03:41:20.334Z","comments":true,"path":"2019/03/27/mongoDB笔记（1）/","link":"","permalink":"http://yoursite.com/2019/03/27/mongoDB笔记（1）/","excerpt":"","text":"一、数据库操作 1、创建数据库如果想创建一个数据库名称为:use mydb #use会创建一个新的数据库，如果该数据库存在，则切换到这个数据库 2、检查当前的数据库db返回mydb 3、查询数据库列表show dbs #创建的数据库（mydb）不存在于列表中如果想要显示刚创建的数据库，需要至少插入一个文档进去db.movie.insert({“name”:”yiibai tutorials”})show dbs 4、删除数据库db.dropDatabase() #D大写，用于删除当前的数据库 二、集合操作 1、创建集合db.createCollection(name,options)db.createCollection(‘mycollection’) #创建集合时可指定选项，选项是可选的选项列表：1）capped:Boolean类型，如果为true，它启用上限集合。上限集合是一个固定大小的集合，当它达到其最大尺寸会自动覆盖最小的条目。如果指定true，还需要指定参数的大小2）autoIndexID:Boolean类型，如果为true，自动创建索引_id字段。默认值为False3）size:number类型，指定的上限集合字节的最大尺寸。如果capped为true，那么还需要指定这个字段4）max:number类型，指定上限集合允许的最大文件数 db.createCollection(‘mycol’,{capped:true,autoIndexID:true,size:6142800,max:10000});#autoIndexID严格按照大小写，不然会报错备注：在mongoDB中并不需要创建集合。当插入一些文档mongoDB会自动创建集合db.yiibai.insert({“name”:”yiibai”});#会创建一个名称为yiibai的集合 2、查看当前集合show collections; 3、删除集合db.mycollection.drop(); #mycollection是集合名 三、文档操作1、插入文档db.mycol.insert({ _id: ObjectId(7df78ad8902c), #如果我们不指定_id参数插入的文档，那么 MongoDB 将为文档分配一个唯一的ObjectId title: ‘MongoDB Overview’, description: ‘MongoDB is no sql database’, by: ‘yiibai tutorials’, url: ‘http://www.yiibai.com&#39;, tags: [‘mongodb’, ‘database’, ‘NoSQL’], likes: 100})备注：插入多个文档，可以通过insert()命令的数组方式（也就是通过中括号定义一个数组）其他插入文档的方法：db.collection.insertOne():将单个文档插入到集合中db.collection.insertMany():将多个文档插入到集合中db.collection.save() 2、查询文档db.collection_name.find() #find()方法将以非结构化的方式显示所有的文件如果显示结果是格式化的，那么可以用pretty()方法:db.mycol.find().pretty()除了find()方法还有findOne()方法，仅返回一个文档:db.mycol.findOne().pretty() 1）投影:当执行find()方法时，默认会显示一个文档的所有字段。投影的意思就是只选择必要的字段显示。要做到这一点，需要设置字段的值为0或1。1用来显示字段而0用来隐藏字段。语法格式:db.collection_name.find({},{key:1})db.mycol.find({“title”:”MongoDB Overview”},{“_id”:1,”title”:1}) #显示匹配title是MongoDB Overview的行，并且显示_id和title两个字段 投影概念参考链接:https://www.cnblogs.com/wangjing666/p/6837157.html 2）限制记录数:limit()db.mycol.find({},{‘_id’:1,’title’:1}).limit(2);#只显示两个记录3）跳过记录:skip()db.mycol.find({},{‘_id’:1,’title’:1}).limit(1).skip(2);#跳过前2个，只显示一个记录(显示第三个记录) limit和skip详细介绍:http://www.runoob.com/mongodb/mongodb-limit-skip.html 4）排序:db.mycol.find({},{“title”:1,”_id”:0}).sort({“title”:-1});#按title降序排序db.mycol.find({},{“title”:1,”_id”:1}).sort({“_id”:1});#按”_id”升序排序备注：1用于升序，而-1用于降序 排序参考链接：http://www.runoob.com/mongodb/mongodb-sort.html 5）mongoDB的where:等于:db.mycol.find({“by”:”yiibai tutorials”}).pretty()等效于:where by = ‘yiibai tutorials’小于:db.mycol.find({“likes”:{$lt:50}}).pretty()等效于:where likes &lt; 50小于等于:db.mycol.find({“likes”:{$lte:50}}).pretty()等效于:where likes &lt;= 50大于:db.mycol.find({“likes”:{$gt:50}}).pretty等效于:where likes &gt; 50大于等于:db.mycol.find({“likes”:{$gte:50}}).pretty()等效于:where likes &gt;= 50不等于:db.mycol.find({“likes”:{$ne:50}).pretty()等效于:where likes != 50 6）mongoDB的and操作符$anddb.mycol.find({$and:[{“by”:”yiibai tutorials”},{“likes”:100}]}).pretty()等效于:where by=”yiibai tutorials” and likes=100也可以通过使用’,’来传递多个键，mongoDB也将其视为and条件：db.mycol.find({“by”:”yiibai tutorials”,”likes”:100}).pretty(); 7）mongoDB的or操作符$ordb.mycol.find({$or:[{“by”:”yiibai tutorials”},{“likes”:100}]}).pretty()等效于:where by=”yiibai tutorials” or likes=100 8）查询嵌套文档（使用点符号）db.inventory.insertMany( [ { item: “journal”, qty: 25, size: { h: 14, w: 21, uom: “cm” }, status: “A” }, { item: “notebook”, qty: 50, size: { h: 8.5, w: 11, uom: “in” }, status: “A” }, { item: “paper”, qty: 100, size: { h: 8.5, w: 11, uom: “in” }, status: “D” }, { item: “planner”, qty: 75, size: { h: 22.85, w: 30, uom: “cm” }, status: “D” }, { item: “postcard”, qty: 45, size: { h: 10, w: 15.25, uom: “cm” }, status: “A” }]);查询选择字段size等于{ h: 14, w: 21, uom: “cm” }的所有文档：db.inventory.find( { size: { h: 14, w: 21, uom: “cm” } } )备注：嵌入式文档中的相等匹配需要精确匹配指定的文档，包括字段顺序(顺序不对不匹配) 查询嵌套字段：使用点符号db.inventory.find({“size.uom”:”in”}); 9）更新文档updatedb.mycol.update({“_id”:100},{$set:{“title”:”update the MongoDB Overview”}}); #将”_id”为100的那一行的title更新为update the MongoDB Overview备注:默认情况下，mongoDB只会更新一个文档。要更新多个文档，需要将参数”multi”设置为truedb.mycol.update({“title”:”MongoDB Overview”},{$set:{“title”:”New Update MongoDB Overview”}},{multi:true}) savedb.mycol.save({“_id”:100,”title”:”New MongoDB Overview”}) #语法跟insert类似,将_id值为100的title设置为’New MongoDB Overview’ 10）删除文档db.mycol.remove({‘_id’:103});#删除_id为103的文档如果有多条记录，并且只想删除第一条记录，则在remove()方法中设置justOne参数:justOne的值设置为true或1，则只删除一个文档db.mycol.remove({‘_id’:101},1);如果不指定删除条件，MongoDB 将删除集合中的所有文档，相当于sql中的truncate:db.mycol.remove() 四、索引操作索引可以有效的提高查询效率。没有索引，mongoDB必须扫描集合的每个文档，以选择与查询语句匹配的文档。这种扫描效率很低，需要mongoDB处理大量的数据。索引是特殊的数据结构，以易于遍历的形式存储数据集的一小部分。索引存储特定字段或一组字段的值，按照索引中指定的字段值排序。 1）创建索引db.mycol.ensureIndex({“title”:1});#1是升序。要按降序创建索引，需要使用-1可以在多个字段上创建索引：db.mycol.ensureIndex({“title”:1,”description”:-1}) ensureIndex()可接受的参数:background:Boolean类型，在后台构建索引，以便构建索引不会阻止其他数据库活动，则指定background的值为true。默认值为falseunique:Boolean类型，创建一个唯一的索引name:String类型，索引的名称。如果未指定，则MongoDB通过连接索引字段的名称和排序顺序来生成索引名称。 2）查看索引db.mycol.getIndexes() 3）查看索引大小db.mycol.getIndexSize() 4）删除所有索引db.mycol.dropIndexes() 5）删除指定索引db.mycol.dropIndex(“索引名称”) 五、聚合操作聚合操作处理数据记录并返回计算结果。聚合操作将多个文档中的值组合在一起，并可对分组数据执行各种操作，以返回单个结果。在SQL中的 count(*)与group by组合相当于mongodb 中的聚合功能。 集合中插入如下数据：db.article.insert([{_id:100,title:’MongoDB Overview’,description:’MongoDB is no sql atabase’,by_user:’Maxsu’,url:’http://www.yiibai.com&#39;,tags: [‘mongodb’, ‘database’, ‘NoSQL’],likes: 100},{_id:101,title:’NoSQL Overview’,description:’No sql database is very fast’,by_user:’Maxsu’,url:’http://www.yiibai.com&#39;,tags:[&#39;mongodb&#39;, ‘database’, ‘NoSQL’],likes: 10},{_id:102,title:’Neo4j Overview’,description:’Neo4j is no sql database’,by_user:’Kuber’,url:’http://www.neo4j.com&#39;,tags:[&#39;neo4j&#39;, ‘database’, ‘NoSQL’],likes: 750},{_id:103,title:’MySQL Overview’,description:’MySQL is sql database’,by_user:’Curry’,url:’http://www.yiibai.com/mysql/&#39;,tags:[&#39;MySQL&#39;, ‘database’, ‘SQL’],likes: 350}]) 查询每个用户写入多少个教程：#_id代表你想聚合的数据的主键db.article.aggregate([{$group:{_id:”$by_user”,num_tutrial:{$sum:1}}}])等效于：select by_user, count(*) as num_tutorial from ‘article’ group by by_user; 其他聚合函数(除了$sum以外)：1）$avg:求给定值的平均值db.article.aggregate([{$group:{_id:”$by_user”,num_total:{$avg:”$likes”}}}])2）$min:求给定值的最小值db.article.aggregate([{$group:{_id:”$by_user”,num_min:{$min:”$likes”}}}])3）$max:求给定值的最大值db.article.aggregate([{$group:{_id:”$by_user”,num_max:{$max:”$likes”}}}])4）$push:将值插入到生成的文档的数组中db.article.aggregate([{$group:{_id:”$by_user”,url:{$push:”$url”}}}])5）$addToSet:将值插入生成的文档中的数组，但不会创建重复项db.article.aggregate([{$group:{_id:”$by_user”,url:{$addToSet:”$url”}}}]);6）$first:从源文档获取第一个文档db.article.aggregate([{$group:{_id:”$by_user”,first_url:{$first:”$url”}}}]);7）$last:从源文档获取最后一个文档db.article.aggregate([{$group:{_id:”$by_user”,last_url:{$last:”$url”}}}]); 除了group之外，聚合框架中其他的几个操作：1）$project：修改输入文档的结构。可以用来重命名、增加或删除域，也可以用于创建计算结果以及嵌套文档。db.article.aggregate({$project:{title:1,by_user:1}});#显示title和by_user字段，默认_id也会显示，如果不想显示_id，设置_id:0即可2）$match：用于过滤数据，只输出符合条件的文档db.articles.aggregate([{$match :{score:{$gt:70,$lte:90}}},{$group:{_id:null,count:{$sum:1}}}]); #$match用于获取分数大于70小于或等于90记录，然后将符合条件的记录送到下一阶段$group管道操作符进行处理。3）$skip：在聚合管道中跳过指定数量的文档，并返回余下的文档。db.article.aggregate({ $skip : 5 });#经过$skip管道操作符处理后，前五个文档被”过滤”掉。4）$limit：用来限制MongoDB聚合管道返回的文档数。5）$unwind：将文档中的某一个数组类型字段拆分成多条，每条包含数组中的一个值。6）$sort：将输入文档排序后输出。","categories":[{"name":"mongoDB","slug":"mongoDB","permalink":"http://yoursite.com/categories/mongoDB/"}],"tags":[]},{"title":"shell编程--4","slug":"python编程（5）","date":"2019-03-26T02:32:00.000Z","updated":"2019-03-26T03:59:06.619Z","comments":true,"path":"2019/03/26/python编程（5）/","link":"","permalink":"http://yoursite.com/2019/03/26/python编程（5）/","excerpt":"","text":"1、tar-c:创建文件-f:后接文件名-r:向已存在的归档文件再添加一些文件-u:一般来说，如果存在同名文件，会一并更新到归档文件中。-u选项指定只有比归档文件中的同名文件更新时才会被添加 例子：1）归档:tar -cf output.tar file1 file2 file3 …2）列出归档文件中所包含的文件:tar -tf archive.tar3）如果想要显示更加详细的信息:tar -tvf archive.tar #-v或者-vv4）向已存在的归档文件再添加一些文件:tar -rvf archive.tar new_file5）提取归档文件到当前目录:tar -xf archive.tar #-C可以指定提取到某个特定目录6）提取特定的文件:tar -xf archive.tar file1 file4 #只提取file1和file4，忽略其他文件7）从归档文件中删除特定文件:tar -f archive.tar –delete file1 file2 … #删除file1，file2…8）拼接两个归档文件:tar -Af file.tar file2.tar #将file2.tar的内容合并到file1.tar中9）归档时排除部分文件:tar -cf archive.tar –exclude “*.txt” #排除txt结尾的文件，也可以将需要排除的文件列表放入文件，同时配合使用选项-Xtar -cf archive.tar -X list #list是需要排除文件的列表10）排除版本控制目录（如.svn和.git）:tar –exclude-vcs -czvvf archive.tar.gz svn11）归档完成后打印出总共字节数:tar -cf archive.tar –exclude “*.txt” –total 对归档文件压缩：不同的tar选项可以用来指定不同的压缩格式-j:指定bunzip2格式-z:指定gzip格式–lzma:指定lzma格式也可以不明确指定使用上面特定的选项来使用压缩功能。tar可以通过压缩文件名来判断使用哪个选项，也就是通过使用-a来让tar支持根据扩展名自动压缩:tar -acvf archive.tar file1 file2 file3 2、cpio另一种类似于tar的归档格式（不像tar那么常用，多用于rpm软件包）1）归档:echo file1 file2 file3 |cpio -ov &gt;archive.tar #-o指定输出，-v用来打印归档文件列表2）列出归档文件中的内容:cpio -it &lt;archive.tar3）从归档文件中提取文件:cpio -id &lt;archive.tar 3、gzipgzip只能压缩单个文件或数据流，而无法对目录或多个文件进行压缩。因此我们先要创建tar归档文件，然后再用gzip进行压缩1）压缩:gzip filename2）解压缩:gunzip filename.gz3）列出压缩文件的属性信息:gzip -l filename.gz还可以指定gzip的压缩级别:–fast:提供最低的压缩比–best:提供最高的压缩比 通常将gzip与归档文件结合使用:4）tar -czvvf archive.tar.gz files或者tar -cavvf archive.tar.gz files #选项-a表明从文件扩展名自动判断压缩格式5）如果有大量的文件需要被压缩归档，可以在循环中使用追加选项-r来逐个添加文件:示例：FILE_LISTS=”file1 file2 file3 file4 file5”for f in $FILE_LISTS;do tar -rvf archive.tar $fdonegzip archive.tar6）提取由gzip压缩的归档文件中的内容tar -xavvf archive.tar.gz -C /PATH7）压缩率:1-9级1级的压缩率最低，但是压缩速度最快9级的压缩率最高，但是压缩速度最慢可以指定压缩比:gzip -5 test.img #在压缩率和压缩速度之间取一个平衡 4、zcat无需事先提取，直接查看gzip压缩过的压缩包内容zcat test.gz 5、bzip2与gzip类似，但是bzip2的压缩效率比gzip更高，但花费的时间比gzip更长1）压缩:bzip2 filename2）解压缩:bunzip2 filename.bz23）与tar搭配使用:tar -jxvf archive.tar.bz2 #-j表示该归档文件是bzip2格式 6、lzmalzma是另一种压缩工具，压缩率比gzip和bzip2更好1）压缩:lzma filename2）解压缩:unlzma filename.lzma3）解压缩（与tar搭配使用）:tar -xvvf –lzma archive.tar.lzma -C /PATH #-x用于提取内容4）与tar搭配使用:tar -cvvf –lzma archive.tar.lzma files或者tar -cavvf archive.tar.lzma files 7、zip用zip来压缩，在linux上应用不如gzip和bzip2那么广泛，但是Internet上的文件通常都是采用这种格式1）采用zip格式压缩:zip file.zip file2）从zip文件中提取内容:unzip file.zip3）更新压缩文件中的内容:zip file.zip -u new_file #-u表示更新4）从压缩文件中删除内容:zip -d archive.zip file.txt #删除file.txt5）列出压缩文件中的内容:unzip -l archive.zip 8、git非常流行的版本控制系统（使用场景:基于版本控制的备份）使用git进行数据备份:1）进入需要备份的目录cd /home/data/source2）设置并初始化远端备份目录。在远程主机上创建备份目录:$ mkdir -p /home/backups/backup.git$ cd /home/backups/backup.git$ git init –bare3）在源主机中执行以下步骤：a、在源主机中将用户详细信息添加到git:git config –global user.name “jim”git config –global user.email xx@163.com b、初始化主机中需要备份的源目录:git initgit commit –allow-empty -am “Init” #–allow-empty:commit提交，但是在这里检查到暂存区并未修改，提交失败。可以使用–allow-empty参数放弃检查 #-a表示add，添加 #-m表示message，这里指”Init” c、在源目录中执行以下命令来添加远程git目录并同步备份:git remote add origin user@remotehost:/home/backups/backup.git d、将当前目录下的所有文件和文件夹添加到备份目录中git add *也可以有条件的添加特定类型的文件:git add *.txtgit add *.py e、删除不需要跟踪的文件和文件夹:git rm file f、查看所有版本的备份:git log g、要恢复到之前的某个状态或版本，需要查看一个由32位十六进制串组成的提交ID（假设提交ID为3131f9661ec1739f72c213ec5769bc0abefa85a9）git checkout 3131f9661ec1739f72c213ec5769bc0abefa85a9 h、从远端备份下载:git clone user@remotehost:/home/backups/backup.git 9、fsarchiver创建全盘镜像（fsarchiver默认并没有安装在大多数发布版中。你得用软件包管理器自行安装）1）创建文件系统分区备份:使用savefs选项fsarchiver savefs backup.fsa /dev/sda1 #backup.fsa是最终的备份文件，/dev/sda1是要备份的分区2）同时备份多个分区:fsarchiver savefs backup.fsa /dev/sda1 /dev/sda23）从备份中恢复分区:fsarchiver restfs backup.fsa id=0,dest=/dev/sda1 ##id=0表明我们希望从备份中提取第一个分区的内容，将其恢复到由dest=/dev/sda1所指定的分区中4）从备份中恢复多个分区:fsarchiver restfs backup.fsa id=0,dest=/dev/sda1 id=1,dest=/dev/sdb1 #我们使用了两组id,dest告诉fsarchiver从备份中将前两个分区的内容恢复到指定的物理分区中","categories":[{"name":"shell编程","slug":"shell编程","permalink":"http://yoursite.com/categories/shell编程/"}],"tags":[]},{"title":"python编程（4）","slug":"ython编程（4）","date":"2019-03-25T07:45:00.000Z","updated":"2019-03-25T09:53:10.778Z","comments":true,"path":"2019/03/25/ython编程（4）/","link":"","permalink":"http://yoursite.com/2019/03/25/ython编程（4）/","excerpt":"","text":"1、列表连接和列表复制 2、用del语句从列表中删除值 3、多重赋值 4、增强的赋值操作 5、","categories":[{"name":"python编程","slug":"python编程","permalink":"http://yoursite.com/categories/python编程/"}],"tags":[]},{"title":"python编程（1）","slug":"python编程（1）","date":"2019-03-25T07:32:00.000Z","updated":"2019-03-25T07:35:35.287Z","comments":true,"path":"2019/03/25/python编程（1）/","link":"","permalink":"http://yoursite.com/2019/03/25/python编程（1）/","excerpt":"","text":"1、数学操作符 2、字符串连接和复制 3、变量名 4、print()函数 5、input()函数 6、len()函数 7、str()、int()、float()函数","categories":[{"name":"python编程","slug":"python编程","permalink":"http://yoursite.com/categories/python编程/"}],"tags":[]},{"title":"python编程（3）","slug":"python编程（3）","date":"2019-03-25T07:23:00.000Z","updated":"2019-03-25T07:29:59.338Z","comments":true,"path":"2019/03/25/python编程（3）/","link":"","permalink":"http://yoursite.com/2019/03/25/python编程（3）/","excerpt":"","text":"1、def语句和参数 2、返回值和return语句 3、关键字参数和print() 4、作用域全局作用域 局部作用域 作用 四条法则 5、global语句 6、异常处理","categories":[{"name":"python编程","slug":"python编程","permalink":"http://yoursite.com/categories/python编程/"}],"tags":[]},{"title":"python编程（2）","slug":"python","date":"2019-03-25T06:44:00.000Z","updated":"2019-03-25T07:31:07.414Z","comments":true,"path":"2019/03/25/python/","link":"","permalink":"http://yoursite.com/2019/03/25/python/","excerpt":"","text":"1、比较操作符 2、布尔操作符 3、not操作符 4、elif语句 5、while循环语句 6、break语句 7、continue语句 8、类真与类假 9、for循环与range()函数 10、导入模块 11、用sys.exit()提前结束程序","categories":[{"name":"python编程","slug":"python编程","permalink":"http://yoursite.com/categories/python编程/"}],"tags":[]},{"title":"shell编程--3","slug":"shell编程-3","date":"2019-03-25T06:00:43.000Z","updated":"2019-03-25T06:00:57.371Z","comments":true,"path":"2019/03/25/shell编程-3/","link":"","permalink":"http://yoursite.com/2019/03/25/shell编程-3/","excerpt":"","text":"1、ip1）当前网络接口配置：ifconfig2）显示ip地址信息：ifconfig wlan03）手动设置网络接口的ip地址：ifconfig wlan0 192.168.1.14）手动设置网络接口的ip地址和掩码：ifconfig wlan0 192.168.1.1 netmask 255.255.255.05）如果你连接到一个支持自动分配ip地址的有线网络中，以下命令可以主动配置网络接口：dhclient eth06）打印网络接口列表：ifconfig|cut -c -10|tr -d ‘ ‘|tr -s ‘\\n’ #cut -c -10 提取每一行的前10个字符 #tr -d ‘ ‘ 删除每一行的所有空格 #tr -s ‘\\n’ 压缩重复的换行符7）提取ip地址：ifconfig eth0|egrep -o “inet 地址:[^ ]*“|egrep -o “[0-9.]*“ #模式以inet 地址:作为起始，以非空格字符序列（由[^ ]*指定）作为结束。然后在接下来的管道操作中，打印出数字与点号的组合8）重写mac地址：ifconfig eth0 hw ether 00:1c:bf:87:25:d5 #重启之后会失效 2、dnsdns设置：/etc/resolv.confdns查找：1）host：列出某个域名的所有ip地址host google.com2）nslookup：列出dns资源记录nslookup google.com #server是dns解析的默认名字服务器3）如果不使用dns，可以向/etc/hosts加入ip和要解析成的名称即可echo 192.168.1.1 backupserver &gt;&gt;/etc/hosts #添加条目之后，任何时候解析backupserver，都会返回192.168.1.1 3、路由表1）显示路由表：route -n #使用-n会以数字形式的ip地址显示每一个条目，否则如果ip地址有对应的dns条目，直接使用route会显示主机名而不是ip地址2）网关：route add default gw 192.168.1.1 wlan0 4、ping1）获取往返时间rtt：网络上两台主机之间的往返时间（round trip time，rtt），它是分组从源主机到目的主机的一来一回的时间，单位是毫秒2）限制发送的分组数量：-cping 192.168.1.1 -c 2 #只发送2个分组 5、fping可以同时ping一组ip地址，而且响应速度非常快。有以下选项：-a 指定打印出所有活动主机的ip地址-u 指定打印出所有无法到达的主机-g 指定ip/掩码或者ip地址范围的形式来确定一组ip例子：fping -a 192.168.1.1/24 -g或者：fping -a 192.168.1.1 192.168.1.255 -g还可以使用命令行参数的形式指定一组ip地址：fping -a 192.168.1.1 192.168.1.5 192.168.1.6 #ip地址以参数传递fping -a ip.list #ip.list是一组ip地址，表示从文件中传递一组ip地址备注：fping默认并没有安装在linux发行版中，需要手动安装 6、traceroute显示分组途经的所有网关地址（如今linux发行版还包含了一个mtr命令，类似于traceroute，但是能够显示实时刷新的数据） 7、sshsecure shell，使用加密通道来传输网络数据ssh username@ip -p port1）要想在远程主机执行命令，并将命令输出显示到本地shell中：ssh username@ip ‘command’ #单条命令ssh username@ip ‘command1;command2;command3’ #多条命令，命令之间用分号分隔例子：ssh root@192.168.1.1 “echo user:$(whoami);echo OS:$(uname)”ssh -C username@ip ‘command’ #-C支持对数据进行压缩传输2）在远程主机上执行图形化命令，然后图形化输出到本地主机：设置变量display:ssh username@ip “export DISPLAY=:0;command1;command2” #将会启用远程主机上的图形化输出使用ssh的x11转发选项：ssh -x username@ip “command1;command2” #该命令将在远程主机上执行，但图形化输出会显示在本地主机上3）ssh实现无密码登录：原理：ssh采用了非对称加密技术，认证密钥包含两部分：一个公钥和一个私钥。我们必须通过ssh-keygen命令创建认证密钥。要想实现自动化认证，公钥必须放在服务器中（将其加入文件~/.ssh/authorized_keys），与公钥对应的私钥放在客户机的~/.ssh目录中。关于ssh相关的配置信息，可以通过修改/etc/ssh/sshd_config进行配置（比如修改authorized_keys文件的路径与名称）步骤：a、创建ssh密钥ssh-keygen -t rsa #指定加密类型为rsa在创建期间，会提示你输入口令，当然不输入口令，也可以生成公钥和私钥。id_rsa.pub是生成的公钥，id_rsa是生成的私钥b、添加公钥到远程主机上ssh username@ip “cat &gt;&gt;~/.ssh/authorized_keys” &lt; ~/.ssh/id_rsa_Pubpassword:在上面的命令中提供登录密码备注：多数linux发行版中提供了一个叫做ssh-copy-id的工具，可以自动将公钥加入到远程服务器的authorized_key文件中ssh-copy-id username@ip4）ssh实现交互式端口转发：a、将本地主机端口8000上的流量转发到www.kernel.org的端口80上：ssh -L 8000:www.kernel.org:80 username@ip #将上述命令的username替换成本地主机上的用户名b、将远程主机上的8000端口上的流量转发到www.kernel.org的端口80上：ssh -L 8000:www.kernel.org:80 username@remote_machine #将上述命令的remote_machine替换成远程主机的主机名或者ip，username替换成进行ssh访问的用户名备注：在进行转发的过程中，这个shell必须保持打开状态，什么时候想停止端口转发，只需要退出shell即可c、非交互式端口转发：ssh -fL 8000:www.kernel.org:80 username@localhost -N #只想设置端口转发，而不希望总是保持一个打开状态的shell。-f指定ssh在执行命令前转入后台运行，-N告诉ssh无需执行命令，只进行端口转发d、反向端口转发：适用场景：如果你有一台无法通过互联网进行访问的主机，但是又希望其他用户可以访问到这台主机上的服务，这时候就需要使用到反向端口转发ssh -R 8000:localhost:80 username@remote_machine #上述命令将远程主机端口8000上的流量转发到本地主机的端口80上 8、sshfs将位于远程主机上的文件系统挂载到本地挂载点上：（linux发行版默认不包含sshfs，需要使用软件包管理器来自行安装）sshfs -o allow_other username@remote_machine:/path /mnt/mountpoint #会提示输入密码，输入完成后就可以通过本地挂载点/mnt/mountpoint来访问/path中的数据了卸载：umount /mnt/mountpoint 9、网络传输文件1）ftp：文件传输协议，是一个古老的用于在网络主机之间传输文件的文件传输协议。只有在远程主机上安装有ftp服务器才能使用ftplftp username@ftphost备注：也可以使用ftp命令用于ftp文件传输。相比较而言，lftp的用法更加灵活。ftp自动传输：ftp -i -n $HOST &lt;&lt;EOF....EOF2）sftp：secure ftp，是一个类似于ftp的文件传输系统，运行在ssh连接之上。不需要远端运行ftp服务器来进行文件传输，但是必须安装并运行openssh服务器。进入sftp会话之后，命令跟ftp都是一样的，比如get下载文件，put上传文件，quit退出会话等。备注：有时候ssh并不运行在22端口上，我们可以通过-oPort来指定端口例如：sftp -oPort=422 username@hostname3）rsync：利用差异计算以及压缩技术来最小化数据传输量。相对于cp而言，rsync的优势在于使用了高效的差异算法。另外，它还支持网络数据传输，在进行复制的同时，rsync会比较源文件和目的端的文件，只有当文件有更新时才进行复制。rsync也支持压缩、加密等多种特性。用法：rsync -av source destination #-a表示归档 #-v表示在stdout上打印出细节信息和进度例子：a、rsync -av username@ip:/path destination #rsync命令用于ssh连接远程主机，因此必须使用username@ip这种形式来设定远程主机的地址b、rsync -av /home/test/ /home/backups #将源目录中的内容（不包含目录本身）复制到现有的backup目录中c、rsync -av /home/test /home/backups #将包括源目录本身在内的内容复制到现有的backup目录中（会在backup目录中创建一个test同名目录）d、还可以排除部分文件：–exclude：排除特定文件$ rsync -avz /home/code/some_code /mnt/disk/backup/code –exclude “*.txt”–exclude-from：通过一个列表文件指定需要排除的文件e、在更新时，删除源端已不存在的文件：默认情况下，rsync不会在目的端删除那些在源端已不存在的文件。使用–delete选项可以删除这些已经不存在的文件rsync -avz source destination –deletef、-z选项可以指定在网络传输时压缩数据：rsync -avz source destinationg、定期备份：创建一个定时任务即可0 */10 * * * rsync -avz /home/codeuser@IP_ADDRESS:/home/backups4）scp语法格式：scp user@hostname:/path filename #表示将远程主机上的文件复制到当前目录，并指定文件名备注：如果ssh没有运行在22端口，使用-oPort指定特定端口选项：-r 递归复制-p 复制文件的同时保留文件的权限和模式5）lsof-i:列出系统中的开放端口以及运行在端口上的服务的详细信息（列出本地主机和对应端口以及远程主机和对应端口）只列出本地主机当前的开放端口：lsof -i|grep -o “:[0-9]+-&gt;”|grep -o “[0-9]+“|sort|uniq另外一个查看端口服务的命令：netstat -tnp #列出开放端口与服务 10、创建套接字：1）设置侦听套接字：nc -l 1234 #在本机的端口1234上创建一个侦听套接字2）连接到该套接字：nc HOST 1234 #如果是在运行着侦听套接字的主机上执行该命令，那么需要将HOST更换成localhost，否则更换成其他主机的ip或者主机名3）要想发送消息，只需要在执行第2步操作的主机终端输入信息并按回车键即可：消息会出现在执行第一步操作的主机终端中nc除了创建套接字，还可以在网络上进行快速文件复制：1）在接收端执行以下命令：nc -l 1234 &gt;destination_filename2）在发送端执行以下命令：nc HOST 1234 &lt;source_filename 11、iptables:阻塞发送到特定ip地址的流量：iptables -A OUTPUT -d 8.8.8.8 -j DROP阻塞发送到特定端口的流量：iptables -A OUTPUT -p tcp -dport 21 -j DROP","categories":[],"tags":[]},{"title":"shell编程--2","slug":"22","date":"2019-03-19T05:53:07.000Z","updated":"2019-03-25T01:16:30.605Z","comments":true,"path":"2019/03/19/22/","link":"","permalink":"http://yoursite.com/2019/03/19/22/","excerpt":"","text":"1、dudu:显示磁盘使用情况（disk usage）df:显示磁盘可用空间（disk usage） du directory:只显示子目录使用的磁盘空间du -a directory:递归显示目录中各个文件的磁盘占用情况 -h:人性化显示-c:会在输出结果末尾加上一行总计，输出作为命令行参数的所有文件和目录的磁盘使用情况-s:只输出合计数据 还可以指定使用特定的单位：以字节为单位：单位是bytesdu -b file(s)以KB为单位：1KB等于1024字节，单位是KB或者Kdu -k file(s)以MB为单位：du -m file(s)以块为单位du -B block_size file(s) 还可以排除指定文件：du –exclude “*.txt” file(s)排除所有的.txt文件 排除列表：–exclude-fromdu –exclude-from exclude.txt file(s)exclude.txt包含了需要排除的文件列表 指定遍历目录层次的最大深度：–max-depth，将深度指定为1表示统计当前目录下的所有文件的占用情况，指定为2表示统计当前目录以及下一级子目录下的文件占用 限制只能对单个文件系统进行遍历：-x:将所有挂载点排除在磁盘使用统计之外假设有这样一种情况，递归遍历的目录层次中的某个子目录可能就是一个挂载点。例如，/mnt/sda1是/mnt的子目录，同时也是设备/dev/sda1的挂载点 常用例子：1)du -ak|sort -nrk 1|headsort对第一列依数值逆序排序，head显示前10行输出（缺点是输出结果中包含了目录）2)find . -type f exec du -k {} \\; | sort -nrk 1|head只输出最大的10个文件 2、timetime:测试运行时间time COMMAND 显示COMMAND命令的运行时间输出三个时间：real、user、sys备注：当运行time时，默认调用的是shell的内建命令time，内建的time命令选项有限。如果想要使用另外的功能，应该使用/usr/bin/time这个可执行二进制文件 /usr/bin/time:1）-o:将相关的时间统计信息写入文件/usr/bin/time -o output.txt COMMAND2）-f:格式化时间输出/usr/bin/time -f “Time:%U” -a -o timing.log uname3）使用错误重定向操作符(2&gt;)对时间信息重定向（因为time命令会将命令的执行时间输出到stderr中）/usr/bin/time -f “Time:%U” uname &gt; command.output.txt 2&gt;timing.log 3、登录用户相关命令1）当前用户登录信息：who显示出登录名、用户所使用的tty、登录时间以及登录用户的远程主机名（或ip）说明：tty是与终端相关联的设备文件，对应的设备文件目录在/dev/pts目录，执行tty可以获取当前终端的设备路径 2）更加详细的用户登录信息：w 3）当前登录主机的用户列表：users排除重复用户最简单的方法是：users|tr ‘ ‘ ‘\\n’|sort |uniq 4）查看系统运行了多长时间：uptimeuptime|grep -Po “\\d{2}:\\d{2}:\\d{2}” 5）查看登录会话信息：lastlast USER 获取单个用户登录会话的信息last reboot 获取重启会话的信息lastb 获取登录失败的会话信息 ps -eo comm,pcpu|tail -n +2 获取cpu的统计数据，tail -n +2用来将ps输出中COMMAND %CPU去掉 $$:表示当前脚本的进程id 4、watch用来在终端以固定的时间间隔监视命令输出例如watch ‘ls -l|grep “^d”‘ 只列出目录，默认每2秒更新一次输出也可以用-n seconds指定更新输出的时间间隔例如watch -n 5 ‘ls -l’ 以5秒为间隔，监视ls -l的输出 5、inotifywait可以收集有关文件访问的信息。linux发行版默认没有包含这个命令，要用软件管理器自行安装inotify-tools。安装：apt install inotify-tools inotifywait -m -r -e create,move,delete $path -q选项说明：-m:表示要持续监视变化-r:表示以递归形式监视命令（忽略符号链接）-e:指定要监视的事件列表-q:减少冗余信息 -e可以指定的监视事件列表有：access 读取文件modify 修改文件attrib 文件元数据被修改move 移动文件create 创建文件open 打开文件close 关闭文件delete 删除文件 6、logrotate用于管理日志文件：rotation（轮替）例如，logrotate在保留日志文件中最新添加的100KB内容（假设指定SIZE = 100k）的同时，将剩下的数据（较旧的日志数据）移入新文件logfile_name.1。随着该日志文件（logfile_name.1）中的内容越来越多，逐渐超出了SIZE规定的定额，logrotate就会再用最近的内容更新日志文件，然后用较旧的内容创建logfile_name.2。整个过程可以轻松地使用logrotate进行配置。logrotate还可以将旧的日志文件压缩成logfile_name.1. gz、logfile_name.2.gz等。是否选择压缩旧日志文件也可以通过logrotate来配置。 logrotate的配置目录位于/etc/logrotate.d。假如我们的程序会生成这样一个日志/var/log/program.log，我们可以为这个日志编写一个特定的配置：cat /etc/logrotate.d/program/var/log/program.log { #/var/log/program.log指定了日志文件路径missingok #如果日志文件丢失，则忽略（不对日志文件轮替）notifempty #仅当源日志文件非空时才对其进行轮替size 30K #限制轮替日志的大小，可以用1M表示1MBcompress #允许用gzip压缩较旧的日志weekly #指定进行轮替的时间间隔，可以是daily、weekly、yearlyrotate 5 #这是需要保留的旧日志文件的归档数量。这里指定为5，所以日志文件名会是program.log.1.gz、program.log.2.gz一直到program.log.5.gzcreate 0600 root root #指定所创建归档文件的权限、用户和用户组}说明：以上选项都是可选的 7、syslog在linux系统中，由守护进程syslogd使用syslog协议负责在/var/log中创建并写入日志信息。每一个标准应用进程都可以利用syslog记录日志信息 用logger创建和管理日志信息：1）向系统日志文件/var/log/message写入日志信息：#logger默认将日志信息记录到/var/log/messagelogger this is a test然后执行命令：[root@host ~]# tail -n 1 /var/log/messagesMar 14 15:01:41 host root: this is a test 2）将另一个日志文件的最后一行记录到系统日志中：logger -f /var/log/program.log #系统日志是message","categories":[],"tags":[]},{"title":"shell编程--1","slug":"shell编程（笔记1）","date":"2019-03-19T03:48:00.000Z","updated":"2019-03-25T01:15:34.201Z","comments":true,"path":"2019/03/19/shell编程（笔记1）/","link":"","permalink":"http://yoursite.com/2019/03/19/shell编程（笔记1）/","excerpt":"","text":"1、psps -eo comm,pcpu|head其中comm表示command,pcpu表示cpu占用率-o可以用来指定想要显示的列。选项-o可以使用不同的参数，如下所示：pcpu:cpu占用率pmem:内存使用率comm:可执行文件名cmd:简单命令user:启动进程的用户nice:优先级time:累计的cpu时间etime:进程启动后流逝的时间tty:所关联的tty设备euid:有效用户idstat:进程状态pid:进程idppid:父进程id 可以用–sort将ps命令的输出根据特定的列进行排序列出占用cpu最多的10个进程：ps -eo comm,pcpu –sort -pcpu|head 10 找出给定命令名所对应的进程id：假设某个命令有多个实例正在运行，我们可能需要识别这些进程的pidps -C command_nameps -C command_name -o pid=说明：-o指定输出特定pid列，在pid后面加上=，可以去掉pid那一列的列名举例：ps -C bash -o pid= 2、pgrep除了使用ps -C,还可以用pgrep，获得特定命令的进程id列表：$ pgrep bash12551680pgrep还可以指定定界符：（默认使用换行符作为定界符）$ pgrep bash -d “:”1255:1680 可以用选项-L在ps的输出中显示线程的相关信息。NLWP是进程的线程数量查看线程数最多的10个进程：ps -eLf –sort -nlwp | head 3、which、whereis、file、uptime1）which:找出某个命令的位置2）whereis:与which类似，但它不仅返回命令的路径，还能够打印出其对应的命令手册的位置以及命令源代码的路径3）file:确定文件的类型4）uptime:查看平均负载。平均负载由三个值来指定，第一个值指明了1分钟内的平均值，第二个值指明了5分钟内的平均值，第三个值指明了15分钟内的平均值 3、信号定义：信号是linux中一种进程间通信机制kill -l:列出所有可用的信号kill pid:终止进程。kill命令默认发出一个TERM信号kill -s SIGNAL pid:通过kill命令向进程发送指定的信号（参数SIGNAL可以是信号名称，也可以是信号编号） 尽管有很多信号可用于，但是常用的其实就那么几个：SIGHUP 1:挂起SIGINT 2:当按下ctrl-c时发送该信号SIGKILL 9:用于强行杀死进程SIGTERM 15:用于终止进程SIGTSTP 20:当按下ctrl-z时发送该信号所以，我们要强行杀死进程，可以使用：$ kill -s SIGKILL PROCESS_ID或者：$ kill -9 PROCESS_ID kill命令以进程id作为参数，killall命令可以通过进程名终止进程：killall process_name1)通过名称向进程发送信号:killall -s SIGNAL process_name2)通过名称以及所属用户名指定进程:killall -u USERNAME process_name3)在杀死进程前进行确认，可以使用killall的-i选项 pkill命令和kill命令类似，不过默认情况下pkill接受的是进程名，而非进程ID trap:kill命令用来向进程发送信号，而trap是用来捕捉并响应信号一旦使用trap将某个函数分配给一个信号，那么当脚本运行收到该信号时，其对应的函数就会开始执行语法格式：trap function_name SIGNAL例子：trap ‘handler’ SIGINT说明：handler是信号SIGINT的信号处理程序的名称。如果按Ctrl-C，就会执行’handler’函数 $$是一个特殊变量，它可以返回当前脚本的进程id 4、采集系统信息1）打印当前系统的主机名：hostname或者uname -n 2）打印linux内核版本、硬件架构等详细信息uname -a 3）打印linux内核发行版本uname -r 4）打印主机类型uname -m 5）打印cpu相关信息cat /proc/cpuinfo 6）获取处理器名称cat /proc/cpuinfo | sed -n 5p 7）打印内存的详细信息cat /proc/meminfo 8）打印系统可用内存总量cat /proc/meminfo |head -1 9）查看系统的分区信息cat /proc/partitions或者fdisk -l 备注：/proc是一个在内存中的伪文件系统，提供了一个可以从用户空间读取系统参数的接口。系统中每一个运行的进程在/proc中都有一个对应的目录，目录名和进程id相同。比如某进程id是9527，那么就会有一个对应的目录/proc/9527。对应的目录中包含了大量有关进程的信息，比方说exviron:包含与进程相关的环境变量exe:是一个到当前进程所对应的可执行文件的符号链接（可以用readlink查看）readlink /proc/9527/exe 5、定时任务除了使用crontab -e编辑，还有另外两种方法可供使用：1）创建文本文件（例如task.cron），写入定时任务，通过crontab task.cron来运行crontab2）无需单独创建文本文件，例如：crontab &lt;&lt;EOF02 /home/slynux/script.shEOF 可以使用选项-u来查看其它用户的cron表：crontab -l -u slynux说明：使用选项-u时，你必须作为root用户以获得最高的权限 可以使用选项-r来删除当前用户的cron表：crontab -r 要删除其它用户的cron表，可以使用：crontab -u slynux -r 6、用户管理相关命令1）useradd：添加用户语法格式：useradd USER -p PASSWORD使用-m可以用来创建home目录 2）deluser：删除用户语法格式：deluser USER使用–remove-all-files用来删除与用户相关的所有文件，包括home目录 3）chsh：修改用户默认shell语法格式：chsh USER -s SHELL 4）usermod：用来处理和用户账户相关的若干属性信息usermod -L 锁定账户usermod -U 解锁账户 5）change：用来处理用户账户的过期信息chage -l：查看账户过期信息chage -E DATE：设置过期时间chage -m：设置两次改变密码之间相距的最小天数chage -M：设置两次改变密码之间相距的最大天数chage -W：设置在前几天提醒需要更改密码 6）addgroup：为系统添加一个新的用户组用法格式：addgroup GROUP将已有的用户添加到一个组：addgroup USER GROUP 7）delgroup：删除一个用户组语法格式：delgroup GROUP 8）finger：显示用户信息figer USER：用户信息包括用户的home目录、上一次登录的时间、默认shell等 7、shift使用场景：shift命令每执行一次，就将命令行参数向左移动一个位置，这样我们就不需要使用变量$1、$2、$3等，而只用一个$1就可以对命令参数逐个访问了 8、截图工具可以使用ImageMagick中的import工具进行截图取整个屏幕：import -window root screenshot.png 9、screen作用：获得多个shell用法：1）创建新的screen窗口：从shell中运行screen来创建一个新的screen。也可以使用Ctrl+A+C（区分大小写）2）在窗口之间切换：可以使用Ctrl+A和Ctrl+N切换到下一个窗口，使用Ctrl+A和Ctrl+P切换到前一个窗口3）脱离会话：使用Ctrl+A和Ctrl+D脱离当前screen会话4）关联会话：screen –r –d该命令告诉screen关联到上一个screen会话。如果已脱离的会话不止一个，screen会打印出会话列表，这时候就可以使用screen –r –d PID 关联相关会话","categories":[{"name":"shell编程","slug":"shell编程","permalink":"http://yoursite.com/categories/shell编程/"}],"tags":[]},{"title":"检查硬件","slug":"检查硬件","date":"2019-03-18T07:31:00.000Z","updated":"2019-03-18T08:32:07.796Z","comments":true,"path":"2019/03/18/检查硬件/","link":"","permalink":"http://yoursite.com/2019/03/18/检查硬件/","excerpt":"","text":"主板：1、查询服务器型号dmidecode -t 1 2、查询主板信息dmidecode -t 2 cpu：3、查看cpu型号cat /proc/cpuinfo |grep name|cut -d: -f2|uniq -c 4、查看cpu物理个数cat /proc/cpuinfo |grep “physical id”|sort|wc -l 5、查看单个物理cpu核数cat /proc/cpuinfo |grep “cpu cores”|uniq 6、查看cpu逻辑个数cat /proc/cpuinfo |grep “processor”|wc -l 7、查看cpu的相关信息lscpu 8、查看cpu支持32位还是64位getconf LONG_BIT 备注：cpu总核数=cpu物理个数 单个物理cpu核数cpu总逻辑个数=cpu物理个数 单个物理cpu核数 * 超线程数如果cpu总核数和cpu总逻辑个数相同，说明cpu没有超线程，反之则有 内存：9、查看内存型号dmidecode -t 17 10、查看内存大小dmidecode |grep -A5 “Memory Device”|grep Size 硬盘：11、查看硬盘和分区分布lsblk 12、查看硬盘和分区的详细信息fdisk -l 网卡：13、查看网卡硬件信息lspci|grep -i “eth” 14、查看系统所有网络接口ipconfig -a 15、查看某个网络接口的详细信息（比如eth0的详细参数和指标）ethtool eth0 PCI：列出所有pci设备信息lspci -tv","categories":[],"tags":[]},{"title":"ulimit命令","slug":"ulimit命令","date":"2019-03-18T02:26:00.000Z","updated":"2019-03-18T03:23:09.303Z","comments":true,"path":"2019/03/18/ulimit命令/","link":"","permalink":"http://yoursite.com/2019/03/18/ulimit命令/","excerpt":"","text":"1、定义在linux系统中对于进程会有一些限制，这就是所谓的limit，在实际应用中比较常见的就是对打开文件（open files）的限制，在配置nginx服务器会用到。 2、分类这些限制分为软限制（soft limit）和硬限制（hard limit）。它们的区别就是软限制可以在程序的进程中自行改变（突破限制），而硬限制不行（除非程序进程有root权限）。使用ulimit命令可以分别查看软限制和硬限制，只要在查看的参数前面加S(软限制)和H(硬限制)即可。 3、参数-a:显示当前所有的资源限制-c size:设置core文件的最大值（单位:blocks）-d size:设置数据段的最大值（单位:kbytes）-f size:设置创建文件的最大值（单位:blocks）-l size:设置在内存中锁定进程的最大值（单位:kbytes）-m size:设置可以使用的常驻内存的最大值（单位:kbytes）-n size:设置内核可以同时打开的文件描述符的最大值（单位:n）-p size:设置管道缓冲区的最大值（单位:kbytes）-s size:设置堆栈的最大值（单位:kbytes）-t size:设置CPU使用时间的最大上限（单位:seconds）-v size:设置虚拟内存的最大值（单位:kbytes）-u size:设置最大进程数 4、建议设置成unlimited的一些重要设置数据段长度：ulimit -d unlimited最大内存大小：ulimit -m unlimited堆栈大小：ulimit -s unlimitedCPU时间：ulimit -t unlimited虚拟内存：ulimit -v unlimited 5、举例通过ulimit -n命令可以查看linux系统打开文件描述符的最大值，一般缺省值是1024，对一台繁忙的服务器来讲，这个值偏小，所以有必要重新设置这个值。1）临时生效：这个值可以用ulimit命令来修改。如:ulimit -n 65535。但是这样设置之后，只会对当前登录shell有效，系统重启或者用户退出后就会失效。2）永久生效：编辑/etc/security/limits.conf，追加以下内容 其中 * 代表所有用户重新登录，通过ulimit -a或者ulimit -n 查看是否生效","categories":[{"name":"linux内核调优","slug":"linux内核调优","permalink":"http://yoursite.com/categories/linux内核调优/"}],"tags":[]},{"title":"linux进入安全模式","slug":"linux进入安全模式","date":"2019-03-15T09:23:00.000Z","updated":"2019-03-15T09:35:38.898Z","comments":true,"path":"2019/03/15/linux进入安全模式/","link":"","permalink":"http://yoursite.com/2019/03/15/linux进入安全模式/","excerpt":"","text":"linux其实没有安全模式。所谓的安全模式，其实就是单用户模式。在此模式下，linux以最小化模式运行，也不能进行远程登录，大部分非核心服务也不会在启动阶段加载，而且是以root用户登录。进入安全模式：1、启动服务器，进入grub引导菜单： 2、根据上图的下方提示，敲击e键进入编辑模式： 3、显示的内容可能会因为linux的发行版本而会有所不同，但可以找到类似上图红框的代码（可以查找vmlinuz所在行），在行的最后加上single（有空格隔开），然后敲击ctrl+x确认，以单模式启动linux。","categories":[{"name":"QA","slug":"QA","permalink":"http://yoursite.com/categories/QA/"}],"tags":[]},{"title":"linux内核参数配置","slug":"linux内核参数配置","date":"2019-03-15T08:05:00.000Z","updated":"2019-03-15T08:37:42.440Z","comments":true,"path":"2019/03/15/linux内核参数配置/","link":"","permalink":"http://yoursite.com/2019/03/15/linux内核参数配置/","excerpt":"","text":"linux在系统运行时修改内核参数（/proc/sys与/etc/sysctl.conf），而不需要重启系统，这个功能是通过/proc虚拟文件系统实现的。 1）临时变更：在/proc/sys目录下存放着大多数的内核参数，并且可以在系统运行时修改。通过修改/proc/sys中内核参数对应的文件而达到修改内核参数的目睹（修改过后，保存配置文件马上自动生效），不过重启机器后会失效。所以是一种临时的变更方案（适合调试内核参数优化值的时候使用，如果设置值有问题，重启服务器就可以还原原来的参数值了） 2）永久变更：通过修改/etc/sysctl.conf文件内的内核参数，修改后的参数值不会马上生效。如果想要马上生效，并且不重启服务器，可以执行命令：sysctl -p 3）/proc/sys与/etc/sysctl.conf的对应关系：即将/proc/sys中的文件转换成sysctl中的变量可以依据以下两个简单的规则：1、去掉前面部分/proc/sys2、将文件名中的斜杠变为点这两条规则可以将/proc/sys中的任一文件转换成sysctl.conf文件中的变量名 例如：/proc/sys/net/ipv4/ip_forward ==&gt; net.ipv4.ip_forward/proc/sys/kernel/hostname ==&gt; kernel.hostname 可以使用下面命令查询所有可修改的变量名:sysctl –a 总结：两种修改内核参数的方法：1）使用echo value的方式直接追加到文件中。如echo “1”》&gt;/proc/sys/net/ipv4/tcp_syn_retries，但这种方法设备重启后又会恢复为默认值2）把参数添加到/etc/sysctl.conf中，然后执行sysctl -p使参数生效，永久生效 内核参数解析参考：https://www.cnblogs.com/bodhitree/p/5756719.html","categories":[{"name":"linux内核调优","slug":"linux内核调优","permalink":"http://yoursite.com/categories/linux内核调优/"}],"tags":[]},{"title":"进程状态与进程信号","slug":"进程状态与进程信号","date":"2019-03-12T10:04:00.000Z","updated":"2019-03-12T10:13:41.377Z","comments":true,"path":"2019/03/12/进程状态与进程信号/","link":"","permalink":"http://yoursite.com/2019/03/12/进程状态与进程信号/","excerpt":"","text":"进程状态： 平时在查看linux进程状态时，查看最多的三个状态是R S DR状态，不必多说，R就是running的缩写，即运行中的进程。S 即 sleep进程，休眠进程。其又分为两种：1）Interruptible Sleep（可中断睡眠，在ps命令中显示“S”）。处在这种睡眠状态的进程是可以通过给它发送signal来唤醒的，比如发HUP信号给nginx的master进程可以让nginx重新加载配置文件而不需要重新启动nginx进程；2）Uninterruptible Sleep（不可中断睡眠，在ps命令中显示“D”）。处在这种状态的进程不接受外来的任何signal，无论是“kill”, “kill -9”还是“kill -15”，都无法杀掉这些处于D状态的进程。D状态的进程通常是在等待IO，比如磁盘IO，网络IO，其他外设IO，可能也就意味着很有可能有IO出了问题。比如从远程挂载的NFS卷不可访问导致进程进入uninterruptible sleep状态的，那么可以通过恢复该NFS卷的连接来使进程的IO请求得到满足，除此之外，要想干掉处在D状态进程就只能重启整个Linux系统。 进程信号：kill -l可以查看所有信号： 但其实常用的也就几个：","categories":[{"name":"linux进程管理","slug":"linux进程管理","permalink":"http://yoursite.com/categories/linux进程管理/"}],"tags":[]},{"title":"mysql5.7忘记root密码","slug":"mysql5-7忘记root密码","date":"2019-03-12T08:44:00.000Z","updated":"2019-03-12T08:50:48.155Z","comments":true,"path":"2019/03/12/mysql5-7忘记root密码/","link":"","permalink":"http://yoursite.com/2019/03/12/mysql5-7忘记root密码/","excerpt":"","text":"1、编辑mysql配置文件/etc/my.cnf，在[mysqld]中添加skip-grant-tables 2、重启mysql服务/etc/init.d/mysqld restart 3、用户无密码登录mysql -uroot -p (直接点击回车，密码为空) 4、选择数据库use mysql; 5、修改root密码update user set authentication_string=password(‘root’) where user=’root’;到这里，提示报错：ERROR 1175 (HY000): You are using safe update mode and you tried to update a table without a WHERE that uses a KEY column备注：mysql 5.7版本及以后的版本的password字段更改成了authentication_string，5.7之前的版本是password 6、根据提示，是因为MySql运行在safe-updates模式下，该模式会导致非主键条件下无法执行update或者delete命令。查看开关状态：show variables like ‘SQL_SAFE_UPDATES’; 7、修改数据库模式SET SQL_SAFE_UPDATES = 0; 8、再次执行update修改密码：update user set authentication_string=password(‘root’) where user=’root’; 9、刷新flush privileges; 10、在配置文件中删除skip-grant-tables，重启mysql服务","categories":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/categories/mysql/"}],"tags":[]},{"title":"lvm","slug":"vm","date":"2019-03-12T07:26:00.000Z","updated":"2019-03-12T08:42:30.206Z","comments":true,"path":"2019/03/12/vm/","link":"","permalink":"http://yoursite.com/2019/03/12/vm/","excerpt":"","text":"1、安装lvmyum -y install lvm2 安装的时候遇到报错： 由提示可知，是由于device-mapper的版本问题导致。于是更新device-mapper-libs：yum install -y device-mapper-*再次执行安装命令：yum -y install lvm2此时可以成功安装。 2、创建和管理lvm1）创建一个lvm分区fdisk /dev/sda 由上图，保存分区的时候有一个报错：The partition table has been altered! Calling ioctl() to re-read partition table. WARNING: Re-reading the partition table failed with error 16: Device or resource busy.The kernel still uses the old table. The new table will be used atthe next reboot or after you run partprobe(8) or kpartx(8)Syncing disks. 意思是内核还用的旧的分区表信息，新的分区表会在重启或者执行partprobe或者kpartx之后使用。然后我运行了一下partprobe命令，无任何提示。再去看内核分区表：cat /proc/partitions，看到分区已经成功加载进去 备注：lvm的分区编号是8e 2）创建PV","categories":[{"name":"linux磁盘管理","slug":"linux磁盘管理","permalink":"http://yoursite.com/categories/linux磁盘管理/"}],"tags":[]},{"title":"lvm分区概念","slug":"lvm分区","date":"2019-03-12T06:48:00.000Z","updated":"2019-03-12T07:25:06.905Z","comments":true,"path":"2019/03/12/lvm分区/","link":"","permalink":"http://yoursite.com/2019/03/12/lvm分区/","excerpt":"","text":"1、简介lvm是逻辑卷管理（logical volume manager）的简称，它是linux环境下对磁盘分区进行管理的一种机制。lvm是建立在硬盘和分区之上的逻辑层，来提高磁盘分区管理的灵活性。 lvm的工作原理很简单，就是通过将底层的物理磁盘抽象的封装起来，然后以逻辑卷的方式呈现给上层应用。在传统的磁盘管理机制中，我们的上层应用是直接访问文件系统，从而对底层的物理硬盘进行读取。而在lvm中，其通过对底层的硬盘进行封装，当我们对底层的物理硬盘进行操作时，其不再是针对分区进行操作，而是通过逻辑卷来对其进行底层的磁盘管理操作。比如说我增加一个物理硬盘，这个时候上层的服务是感觉不到的，因为呈现给上层服务的是以逻辑卷的方式。 lvm最大的特点是可以对磁盘进行动态管理。因为逻辑卷的大小是可以动态调整的，而且不会丢失现有的数据。如果我们新增加了硬盘，其也不会改变现有上层的逻辑卷。作为一个动态磁盘管理机制，逻辑卷技术大大提高了磁盘管理的灵活性。 2、lvm基本术语1）物理存储介质：指的是系统的存储设备：硬盘，如/dev/sda等，是存储系统最底层的存储单元。2）PV(physical volume)–物理卷：物理卷在逻辑卷管理中处于最底层，它可以是实际物理硬盘上的分区，也可以是整个物理硬盘3）VG(volume group)–卷组：卷组建立在物理卷之上，一个卷组至少要包括一个物理卷，在卷组建立之后可以动态添加物理卷到卷组中。一个逻辑卷管理系统中可以只有一个卷组，也可以拥有多个卷组。4)LV(logical volume)–逻辑卷：逻辑卷建立在卷组之上，卷组中未分配的空间可以用于建立新的逻辑卷，逻辑卷建立后可以动态的扩展和缩小空间。系统中的多个逻辑卷可以属于同一个卷组，也可以属于不同的多个卷组。 3、lvm分层结构","categories":[{"name":"linux磁盘管理","slug":"linux磁盘管理","permalink":"http://yoursite.com/categories/linux磁盘管理/"}],"tags":[]},{"title":"linux分区（笔记）","slug":"linux分区（笔记）","date":"2019-03-12T05:36:00.000Z","updated":"2019-03-12T06:45:26.091Z","comments":true,"path":"2019/03/12/linux分区（笔记）/","link":"","permalink":"http://yoursite.com/2019/03/12/linux分区（笔记）/","excerpt":"","text":"1、主分区、扩展分区与逻辑分区的区别1）一个硬盘可以有1到3个主分区和1个扩展分区，也可以只有主分区没有扩展分区，但主分区必须至少有1个，扩展分区则最多只有一个。而且主分区+扩展分区总共不能超过4个。 2）一个硬盘的主分区也就是包含操作系统启动所必需的文件和数据的硬盘分区，要在硬盘上安装操作系统，则该硬盘必需要有一个主分区。3）扩展分区也就是除了主分区以外的分区，但它不能直接使用，必须要将它划分为若干个逻辑分区才行。4）逻辑分区也就是我们平常在操作系统上所看到的的D、E、F等盘。 2、几个比较重要的命令1）fdisk 磁盘分区相关操作2）df 系统分区挂载信息3）mount 挂载分区4）umount 卸载分区5）mkfs.ext4 格式化分区 3、查看当前磁盘信息1）fdisk -l 看到系统有sda, sdb 两块硬盘，其中sdb里面是没有任何分区的 2）df -lh 4、创建分区 重复同样的方法再建立——2G大小的主分区sdb2——500M大小的扩展分区大小sdb3——100M大小的逻辑分区sdb5, sdb6 将sdb已经做了5个分区（实际上4个有效，因为sdb3是扩展分区，sdb5 是第一个逻辑分区所以起始柱面和sdb3一样从395开始）备注：1）建立好分区后，先不要急着去挂载，否则提示必须知道文件系统类型 ,需要先格式化分区 2）可以直接使用partprobe使分区表立刻生效, 如果不行的话就重启partprobe 5、格式化分区这里我使用ext4 filesystem type 6、挂载分区新建4个文件夹用来挂载分区, sdb3是扩展分区不能用来挂载，他的逻辑分区sdb5和sdb6是可以挂载的 执行df，可以看到新建的4个分区都挂载好了 7、自动挂载打开/etc/fstab在最后添加挂载配置 添加权限，如果是挂载空间要给普通用户使用，给相应的目录添加访问权限[root@freeman /]# chmod 777 /my_mount1 8、卸载分区umount[root@freeman /]# umount /dev/sdb1 9、删除分区备注：删除分区之前，可以先umount卸载分区，以免出现不必要的问题 如果要删除一个硬盘的所有分区，更简单的做法是格式化硬盘 10、修改分区类型把sdb2分区系统类型id修改为 Linux LVM 备注：L可以查看分区类型 总结：创建分区–partprobe–格式化分区–挂载分区–自动挂载","categories":[{"name":"linux磁盘管理","slug":"linux磁盘管理","permalink":"http://yoursite.com/categories/linux磁盘管理/"}],"tags":[]},{"title":"mysql备份与恢复（mysqldump）","slug":"mysql备份与恢复（mysqldump）","date":"2019-03-12T03:24:00.000Z","updated":"2019-03-12T03:52:57.415Z","comments":true,"path":"2019/03/12/mysql备份与恢复（mysqldump）/","link":"","permalink":"http://yoursite.com/2019/03/12/mysql备份与恢复（mysqldump）/","excerpt":"","text":"mysqldump：用来温备，所以我们得为所有库加读锁,并且滚动一下二进制日志，并记录当前二进制文件位置备注：温备是可读但不可写状态下进行的备份 步骤：1、全备份mysqldump -uroot -p –all-databases –lock-all-tables –routines –triggers –master-data=2 –flush-logs &gt;/opt/date +%F-full.sql备注：–all-databases 备份所有库–lock-all-tables 为所有表加读锁–routines 存储过程与函数–triggers 触发器–master-data=2 在备份文件中记录当前二进制日志的位置，并且为注释的，1是不注释掉在主从复制中才有意义–flush-logs 日志滚动一次 2、在mysql命令行查看当前的二进制日志 3、备份二进制日志cp /mybinlog/mysql-bin.000001 /opt/000001.sql 4、模拟一种场景，往linux表中新添加数据，然后不小心将这个表删了，我们要恢复到删除之前的状态，并且新加的数据还存在 5、先恢复完整备份，恢复过程不要记录日志编辑mysql配置文件/etc/mysql/mysql.conf.d/mysqld.cnf 在server-id和log_bin前面注释掉，然后重启mysql：/etc/init.d/mysql restart 6、先执行全恢复mysql -uroot -proot &lt;/opt/2019-03-12-full.sql 7、查看删除表时的记录位置mysqlbinlog /var/log/mysql/mysql-bin.000002 |grep -C 20 DROP 8、由上图可知删除是在25751时做的，将二进制文件中完整备份到删除表之前的记录导出mysqlbinlog –stop-position=25751 /var/log/mysql/mysql-bin.000002 &gt; /opt/000002.sql备注：–start-position 指定从哪开始导出二进制日志–stop-position 指定到哪结束–start-datetime 从哪个时间开始格式如”2005-12-25 11:25:56”–stop-datetime 到哪个时间结束 9、将这段二进制记录应用到mysql的库中mysql -uroot -proot &lt;/opt/000002.sql 10、进入数据库验证数据是否恢复 11、重新打开二进制日志（参考第5个步骤） 总结：基于mysqldump通常我们就是完整备份+二进制日志来进行恢复的。","categories":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/categories/mysql/"}],"tags":[]},{"title":"iptables条件匹配","slug":"iptables条件匹配","date":"2019-03-08T02:30:00.000Z","updated":"2019-03-08T02:56:35.786Z","comments":true,"path":"2019/03/08/iptables条件匹配/","link":"","permalink":"http://yoursite.com/2019/03/08/iptables条件匹配/","excerpt":"","text":"1、基本匹配[!] -s #检查报文中源IP地址是否符合此处指定的地址范围，!表示取反[!] -d #检查报文中目的IP地址是否符合此处指定的地址范围，!表示取反-p #检查报文中的协议，即ip首部的protocol所标识的协议-i #报文的流入接口，仅能用于input、prerouting、forward链上-o #报文的流出接口，仅能用于output、postrouting、forward链上 2、扩展匹配格式为-m match_name –spec_options，其中match_name为扩展名，–spec_options为扩展的选项，有隐式扩展和显式扩展两类 3、显式扩展1）multiportiptables -I INPUT -d 172.16.100.7 -p tcp -m multiport –dports 22,80 -j ACCEPT;iptables -I OUTPUT -s 172.16.100.7 -p tcp -m multiport –sports 22,80 -j ACCEPT备注：规则管理-A，追加新规则于指定链的尾部-I，插入新规则于指定链的指定位置，默认为首部-D，根据规则编号删除规则 2）iprangeiptables -I INPUT 2 -d 172.16.8.20 -p tcp –dport 22 -m iprange –src-range 172.16.8.10-172.16.8.19 -j DROP禁止172.16.8.10-172.16.8.19这些ip远程登录172.16.8.20主机 3）stringiptables -A OUTPUT -p tcp –dport 80 -m string -algo kmp –string ‘sex’ -j DROP当服务端返回数据报文检查到有关键字’sex’时，则丢弃该报文，可用于web敏感词过滤备注：–algo {bm|kmp}：字符匹配查找时使用算法 4）timeiptables -A FORWARD -m time –timestart 09:00 –timestop 18:00 -j DROP每天固定时间段匹配 iptables -A FORWARD -m time –timestart 09:00 –timestop 18:00 –weekdays Mon,Tue,Wed -j DROP按周固定时间段匹配 iptables -A FORWARD -m time –datestart 2017-10-01T00:00:00 –datestop 2017-10-31T23:59:59 -j DROP按固定日期匹配 5）connlimitiptables -I FORWARD -p tcp –syn –dport 80 -m connlimit –connlimit-above 10 –connlimit-mask 24 -j DROP只允许每组C类ip同时10个80端口转发 6）limitiptables -I INPUT -d 172.16.8.20 -p icmp –icmp-type 8 -m limit –limit-burst 3 –limit 20/minute -j ACCEPT;iptables -A INPUT -d 172.16.8.20 -p icmp -j REJECT其结果为： 备注：–icmp-type，常用数字表示其类型：0：echo-reply（回显应答，即ping应答）8：echo-request（回显请求，即ping请求） 7）state iptables -I INPUT -m state –state ESTABLISHED,RELATED -j ACCEPT;iptbales -A INPUT -d 172.16.8.20 -p tcp -m multiport –dports 21:22,80 -m state –state NEW -j ACCEPT;iptables -I OUTPUT -m state –state ESTABLISHED -j ACCEPT放行SSH，FTP（被动模式）,WEB服务（INPUT，OUTPUT，FORWARD默认策略均为DROP）","categories":[{"name":"iptables","slug":"iptables","permalink":"http://yoursite.com/categories/iptables/"}],"tags":[]},{"title":"iptables配置","slug":"iptables配置","date":"2019-03-07T09:35:00.000Z","updated":"2019-03-08T02:10:44.703Z","comments":true,"path":"2019/03/07/iptables配置/","link":"","permalink":"http://yoursite.com/2019/03/07/iptables配置/","excerpt":"","text":"1、配置一个filter表的防火墙1）查看本机关于iptables的设置情况iptables -L -nChain INPUT (policy ACCEPT)target prot opt source destinationChain FORWARD (policy ACCEPT)target prot opt source destinationChain OUTPUT (policy ACCEPT)target prot opt source destination 可以看到什么规则都没有。如果你在安装linux时没有选择启动防火墙，查看iptables时就是这样的。 2）清除原有规则不管你在安装linux时是否启动了防火墙，如果你想设置属于自己的防火墙，那就清除现在filter的所有规则。 iptables -F #清除filter中所有规则链的规则iptables -X #清除filter中使用者自定链中的规则/etc/rc.d/init.d/iptables save #保存规则，这样就可以写到/etc/sysconfig/iptables文件service iptables restart #重启才会生效 3）指定预设规则iptables -P INPUT DROPiptables -P OUTPUT ACCEPTiptables -P FORWARD DROP备注：上面的预设规则是要控制流入的数据包，但是流出的包不需要做太多限制，而是采取accept 4）添加规则首先添加INPUT链，INPUT的默认规则是drop，所以我们就写需要accept（通过）的链为了能采用远程SSH登录，我们要开启22端口。iptables -A INPUT -p tcp –dport 22 -j ACCEPTiptables -A OUTPUT -p tcp –sport 22 -j ACCEPT（如果你把OUTPUT链设置成drop的话，也要写上这一条，否则无法SSH） 其他的端口也一样，如果开启了web服务器，OUTPUT设置成drop的话，同样也要添加一条链：iptables -A OUTPUT -p tcp –sport 80 -j ACCEPT如果做了web服务器，开启80端口：iptables -A INPUT -p tcp –dport 80 -j ACCEPT 如果做了tp服务器，开启20、21端口：iptables -A INPUT -p tcp –dport 21 -j ACCEPTiptables -A INPUT -p tcp –dport 20 -j ACCEPT 如果做了邮件服务器，开启25、110端口：iptables -A INPUT -p tcp –dport 25 -j ACCEPTiptables -A INPUT -p tcp –dport 110 -j ACCEPT 如果做了DNS服务器，开启53端口：iptables -A INPIT -p tcp –dport 53 -j ACCEPT 允许icmp包通过，也就是允许pingiptables -A INPUT -p icmp -j ACCEPT（OUTPUT设置成drop的话）iptables -A OUTPUT -p icmp -j ACCEPT（INPUT设置成drop的话） 备注：处于更安全的方式考虑，如果你把OUTPUT链也设置成drop的话，那么你添加的规则就多一些，就像上边添加允许SSH登录一样，照着写就行。 下面写一下更加细致的规则，就是限制某台机器比如：我们只允许192.168.0.3的机器进行SSH连接iptables -A INPUT -s 192.168.0.3 -p tcp –dport 22 -j ACCEPT备注：a、如果要允许或限制一段ip地址，可用192.168.0.0/24表示192.168.0.1-255的所有ip。记得把/etc/sysconfig/iptables里的这一行删掉：iptables -A INPUT -p tcp -m tcp –dport 22 -j ACCEPT，因为它表示所有地址都可以登录b、凡是采用命令的方式，只在当时生效。所以需要保存，就要重启后才起作用：/etc/rc.d/init.d/iptables save","categories":[{"name":"iptables","slug":"iptables","permalink":"http://yoursite.com/categories/iptables/"}],"tags":[]},{"title":"iptables原理","slug":"iptables原理","date":"2019-03-07T09:16:00.000Z","updated":"2019-03-08T01:37:17.953Z","comments":true,"path":"2019/03/07/iptables原理/","link":"","permalink":"http://yoursite.com/2019/03/07/iptables原理/","excerpt":"","text":"1、组成linux防火墙是由netfilter和iptables组成。用户空间的iptables制定防火墙规则，内核空间的netfilter实现防火墙功能。 netfilter（内核空间）位于linux内核中的包过滤防火墙功能体系，称为linux防火墙”内核态”。 iptables（用户空间）位于/sbin/iptables，是用来管理防火墙的命令工具，称为linux防火墙的”用户态”。 四表五链：1）四表（其实是五表，是后来加进来的）优先级从低到高分别是： 2）五链 2、预设规则制作防火墙规则通常有两种基本预设策略。一是黑名单策略；二是白名单策略。白名单策略指没有被允许的流量都要拒绝，这种策略比较保守，根据需要，逐渐开放，目前一般都采用白名单策略，推荐。","categories":[{"name":"iptables","slug":"iptables","permalink":"http://yoursite.com/categories/iptables/"}],"tags":[]},{"title":"iptables简介","slug":"iptables","date":"2019-03-07T08:17:00.000Z","updated":"2019-03-07T09:13:37.387Z","comments":true,"path":"2019/03/07/iptables/","link":"","permalink":"http://yoursite.com/2019/03/07/iptables/","excerpt":"","text":"1、是什么iptables是隔离主机以及网络的工具，通过自己设定的规则以及处理动作对数据报文进行检测以及处理。 2、发展史iptables的发展史就是从墙到链再到表的过程，也就是从简单到复杂的过程。为什么规则越来越多，因为互联网越来越不安全，所有防火墙的规则也越来越复杂。防火墙工具的变化如下：ipfirewall(墙)–&gt;ipchains(链条)–&gt;iptables(表)2.0内核版本，包过滤机制是ipfw，管理工具是ipfwadm；2.2内核版本，包过滤机制是ipchain，管理工具是ipchains；2.4版及之后的版本，包过滤机制是netfilter，管理工具是iptables。 参考链接：https://www.cnblogs.com/frankb/p/7427944.html","categories":[{"name":"iptables","slug":"iptables","permalink":"http://yoursite.com/categories/iptables/"}],"tags":[]},{"title":"TCP四次挥手","slug":"TCP四次挥手","date":"2019-03-06T09:31:00.000Z","updated":"2019-03-06T09:40:28.509Z","comments":true,"path":"2019/03/06/TCP四次挥手/","link":"","permalink":"http://yoursite.com/2019/03/06/TCP四次挥手/","excerpt":"","text":"四次握手断开连接过程：第一次挥手：主动关闭方发送一个FIN，用来关闭主动方到被动关闭方的数据传送，也就是主动关闭方告诉被动关闭方：我已经不会再给你发数据了(当 然，在fin包之前发送出去的数据，如果没有收到对应的ack确认报文，主动关闭方依然会重发这些数据)，但此时主动关闭方还可以接受数据。 第二次挥手：被动关闭方收到FIN包后，发送一个ACK给对方，确认序号为收到序号+1(与SYN相同，一个FIN占用一个序号)。 第三次挥手：被动关闭方发送一个FIN，用来关闭被动关闭方到主动关闭方的数据传送，也就是告诉主动关闭方，我的数据也发送完了，不会再给你发数据了。 第四次挥手：主动关闭方收到FIN后，发送一个ACK给被动关闭方，确认序号为收到序号+1，至此，完成四次挥手。","categories":[{"name":"tcp/ip","slug":"tcp-ip","permalink":"http://yoursite.com/categories/tcp-ip/"}],"tags":[]},{"title":"TCP三次握手","slug":"TCP三次握手","date":"2019-03-06T09:01:00.000Z","updated":"2019-03-06T09:44:18.241Z","comments":true,"path":"2019/03/06/TCP三次握手/","link":"","permalink":"http://yoursite.com/2019/03/06/TCP三次握手/","excerpt":"","text":"1、三次握手建立连接过程：第一次握手：客户端发送syn包（seq=x）到服务器，并进入syn_sent状态，等待服务器确认；第二次握手：服务器收到syn包，必须确认客户的syn（ack=x+1）,同时自己发送一个syn（seq=y），即syn+ack包，此时服务器进入syn_rcvd状态；第三次握手：客户端收到服务器的syn+ack包，向服务器发送确认包ack（ack=y+1）,此包发送完毕，客户端和服务端进入establish状态，完成三次握手。 2、完成三次握手之后，就可以进行传输数据过程：tcp数据传输的特性：1）超时重传超时重传机制用来保证tcp传输的可靠性。每次发送数据包时，发送的数据包都有seq号，接收端收到数据后，会回复ack进行确认，表示某一seq包已经收到。发送端在发送了某个seq包之后，等待一段时间，如果没有收到对应ack的回复，就会认为报文丢失，会重传这个数据包。2）快速重传接收数据的一方发现有数据包丢掉了，就会发送ack报文告诉发送端重传丢失的报文。如果发送端连续收到标号相同的ack包，则会触发客户端的快速重传。比较超时重传和快速重传，可以发现超时重传是发送端在傻等超时，然后触发重传；而快速重传则是接收端主动告诉发送端数据没收到，然后触发发送端重传。3）流量控制主要是tcp滑动窗口流量控制。tcp头里有一个字段叫window，又叫advertised-window，这个字段是接收端告诉发送端自己还有多少缓冲区可以接收数据。于是发送端就可以根据接收端的处理能力来发送数据，而不会导致接收端处理不过来。4）拥塞控制比较流量控制和拥塞控制，流量控制是实现对发送流量的控制，拥塞控制则是基于整个网络来考虑的。拥塞控制算法主要包括：慢启动、拥塞避免、快速重传和快速恢复 为什么TCP客户端最后还要发送一次确认？","categories":[{"name":"tcp/ip","slug":"tcp-ip","permalink":"http://yoursite.com/categories/tcp-ip/"}],"tags":[]},{"title":"mysql","slug":"mysql笔记2","date":"2019-03-06T06:44:00.000Z","updated":"2019-03-07T03:34:51.916Z","comments":true,"path":"2019/03/06/mysql笔记2/","link":"","permalink":"http://yoursite.com/2019/03/06/mysql笔记2/","excerpt":"","text":"1、插入数据：insert语法：insert into customer(cust_name,cust_contact,cust_email) values(‘jim’,NULL,NULL)以上例子中，因为给出了列名，所以列的顺序在这里不重要，可以调换顺序备注：如果表的定义允许，可以在insert操作中省略某些列。省略的列必须满足以下条件：1）该列定义为允许null值（无值或空值）2）在表定义中给出默认值。表示如果不给出值，将使用默认值 插入多行：1）多条insert语句，每条语句用分号分隔2）单条insert语句，每一组值用一对圆括号括起来，用逗号分隔实例：insert into customers(cust_name,cust_age,cust_city) values(‘jim’,17,’guangzhou’),(‘jim’,18,’shenzhen’) 插入检索出的数据：insert selectinsert into customer(cust_name,cust_contact,cust_email) select name,contact,email from custnew;备注：1）不一定要求列名匹配，因为使用的是列的位置2）insert select中select语句中可以包含where子句以过滤插入的数据 2、更新数据：updateupdate语句由3部分组成：1）要更新的表2）列名与它们的新值3）确定要更新行的过滤条件实例：update customer set cust_email = &#39;18826400669@163.com‘ where cust_id = 10005;update customer set cust_name = ‘jim’,cust_email = &#39;18826400669@163.com‘ where cust_id = 10005;备注：1）即使发生错误，也继续进行更新，可以使用ignore关键字update ignore customer …2）删除某个列的值，可以设置为nullupdate customer set cust_email = NULL where cust_id = 10005; 3、删除数据1）从表中删除特定行2）从表中删除所有行实例：delete from customer where cust_id = 10006;备注：1）delete是删除行，update null是删除列2）更快的删除：truncate（truncate是整表删除，delete是逐行删除）3）更新和删除的指导原则：一定要使用where子句，否则就是整表删除或更新 3、创建表create table customer( cust_id int not null auto_increment, cust_name char(50) not null, cust_address char(50) not null， cust_city char(50) null, primary_key(cust_id))engine=innodeDB;备注：1）关键字not null会阻止插入没有值的列，null为默认设置，如果不指定not null，则认为指定的是null。null和空串的概念不一样，null不等同于’’（两个单引号，其间没有字符）2）auto_increment是自动增1，default是设置默认值，主键primary key可以是单值，也可以是多个值，engine可以设置使用哪个引擎3）如果表已经存在，创建表会报错；如果仅想在表不存在时创建它，可以在表名之后给出IF NOT EXISTS 4、mysql常见的引擎1）innodeDB是一个可靠地事务处理存储引擎，不支持全文搜索2）myisam是一个性能极高的引擎，支持全文搜索，但不支持事务处理3）memory的功能等同于myisam，但由于数据存储在内存（不是磁盘），所以速度极快（特别适用于临时表）备注：引擎可以混用，即同一个数据库不同表可以使用不同的存储引擎，但是外键不能跨引擎（即使用一个引擎的表不能引用具有不同引擎的表的外键） 5、更新表定义1）添加一个列：alter table vendors add vend_phone char(20);以上例子中，增加一个名为vend_phone的列，并声明其数据类型2）定义外键alter table orderitems add constraint fk_orderitems_orders foreign_key(order_num) reference orders(order_num);以上例子中，order_num是表orders中的一个列，fk_orderitems_orders 是orderitems的新增外键 6、删除和重命名表1）删除表drop table table_name2）重命名表rename table table_name1 to table_name2 7、创建视图create view view_name as …正确使用视图，可以极大的简化复杂的数据处理备注：1）视图可以被更新，但不是所有视图都是可更新的2）更新一个视图，将更新其基表（视图是一个虚拟的表，本身没有数据）3）如果视图定义中有以下操作，则不能进行视图的更新：a、分组（使用GROUP BY和HAVING）；b、联结；c、子查询；d、并；e、聚集函数（min、count、sum）；f、distinct；g、导出（计算）列4）一般来说，视图主要用于检索（select语句），而不用于更新（insert、update和delete） 8、存储过程简单来说，就是为以后的使用而保存的一条或者多条mysql语句的集合，类似于批文件。备注：mysql将编写存储过程与执行存储过程的权限分开，许多DBA允许用户使用存储过程，但不允许他们创建存储过程。 1）执行存储过程mysql将存储过程的执行称为调用，因此执行的语句为call。call接受存储过程的名字以及需要传递给它的任意参数。示例：call productpricing(@pricelow,@pricehigh,@priceaverage);以上例子中，执行名为productpricing的存储过程，它计算并返回产品的最低、最高和平均价格 2）创建存储过程示例：create procedure productpricing()begin select avg(prod_price) as priceaverage from products;end:以上例子中，此存储过程名为productpricing，在括号内可以接受参数。begin和end语句用来限定存储过程体，过程体本身仅是一个简单的select语句。如果你使用的是mysql命令行，因为存储过程自身内是使用分号作为分隔符，mysql命令行也是使用分号作为语句分隔符，这会出现语法错误。解决方法是临时更改命令行程序的语句分隔符：delimiter //create procedure productpricing()begin select avg(prod_price) as priceaverage from products;end //delimiter;以上例子中，delimiter //告诉命令行实用程序使用//作为新的语句结束分隔符，可以看到标志存储过程结束的end定义为end //而不是end;这样，存储过程体内的;仍然保持不动，并且正确地传递给数据库引擎。最后，恢复为原来的语句分隔符可以使用delimiter。除\\符号外，任何字符都可以用作语句分隔符。 3）删除存储过程drop procedure productpricing;备注：存储过程名后面没有使用()如果指定的过程不存在，则drop procedure将产生一个错误。当过程存在想删除它时（如果过程不存在也不产生错误）可使用DROP PROCEDURE IF EXISTS。 4）使用参数示例1：create procedure productpricing( out pl decimal(8,2), out ph decimal(8,2), out pa decimal(8,2))begin select min(prod_price) into pl from products; select max(prod_price) into ph from products; select avg(prod_price) into pa from products;end;a、以上例子中，存储过程接受3个参数：pl存储产品最低价格，ph存储产品最高价格，pa存储产品平均价格。b、关键字out指出相应的参数用来从存储过程传出一个值（返回给调用者）。mysql支持in（传递给存储过程），out（从存储过程传出）和inout（对存储过程传入和传出）类型的参数。c、通过指定into关键字把检索值保存到对应的变量。 示例2：create procedure ordertotal( in onumber int, out ototal decimal(8,2))begin select sum(item_price*quantity) from orderitems where order_num = onumber into ototal;end;以上例子中，a、onumber定义为in，因为订单号被传入存储过程。b、ototal定义为out，因为要从存储过程返回合计。c、into使用ototal存储计算出来的合计 调用：call ordertotal(20005,@total);备注：必须给ototal传递两个参数，第一个参数为订单号，第二个参数为包含计算出来的合计的变量名为了显示此合计，可如下进行：select @total; 为了得到另一个订单的合计显示，需要再次调用存储过程，然后重新显示变量：call ordertotal(20009,@total);select @total; 5）检查存储过程a、show create procedure ordertotal;显示用来创建一个存储过程的create语句b、show procedure status;显示包括何时、由谁创建等详细信息的存储过程列表备注：show procedure status会列出所有存储过程。为了限制其输出，可以使用like指定一个过滤模式，例如，show procedure status like ‘ordertotal’; 9、游标游标只能用于存储过程和函数 1）创建游标示例：定义名为ordernumbers的游标，使用了可以检索所有订单的select语句create procedure processorders()begin delare ordernumbers cursor for select order_num from orders;end; 2）打开或者关闭游标打开：open ordernumbers;关闭：close ordernumbers;备注：隐式关闭，如果你不明确关闭游标，mysql将会在到达end语句时自动关闭它示例：create procedure processorders()begin –declare the cursor declare ordernumbers cursor for select order_num from orders; –open the cursor open ordernumbers; –close the cursor close ordernumbers; end; 3）使用游标数据示例1：从游标中检索单个行（第一行）create procedure processorders()begin –declare local varibles declare o int; –declare the cursor declare ordernumbres cursor for select order_num from orders; –open the cursor open ordernumbers; –get order number fetch ordernumbers into o; –close the cursor close ordernumbers; end;以上例子中，fetch用来检索当前行的order_num列（第一行）到一个名为o的局部声明的变量中 示例2：循环检索数据，从第一行到最后一行create procedure processorders()begin –delare local variables delare done boolean default 0; delare o int; –delare the cursor delare ordernumbers cursor; for select order_num from orders; –delare continue handler delare continue handler for sqlstate ‘02000’ set done=1; –open the cursor open ordernumbers; –loop through all rows repeat –get order number fetch ordernumbers into o; –end of loop until done end repeat; –close the cursor close ordernumbers; end;","categories":[{"name":"mysql笔记","slug":"mysql笔记","permalink":"http://yoursite.com/categories/mysql笔记/"}],"tags":[]},{"title":"mysql笔记","slug":"mysql笔记","date":"2019-03-05T03:35:00.000Z","updated":"2019-03-06T06:42:07.446Z","comments":true,"path":"2019/03/05/mysql笔记/","link":"","permalink":"http://yoursite.com/2019/03/05/mysql笔记/","excerpt":"","text":"1、数据库（database）保存有组织的数据的容器 人们通常用户数据库这个术语来代表他们所使用的数据库软件，这是不正确的。确切来说，数据库软件应该称为DBMS（数据库管理系统）。数据库是通过DBMS创建和操纵的容器。你并不是直接访问数据库，你使用的是DBMS，它替你访问数据库。 2、表（table）某种特定类型数据的结构化清单 不应该将顾客的清单和订单的清单存储在同一个数据表当中。这样做会使以后的检索和访问很困难。应该创建两个表，每个清单一个表。数据库中的每个表都有一个名字，用来标识自己。表名字是唯一的。 表具有一些特性，这些特性定义了数据在数据表中如何存储，比如说可以存储什么样的数据。 3、模式（schema）关于数据库和表的布局及特性的信息 数据如何分解，各部分信息如何命名等等。描述表的这组信息就是模式。 4、列（column）表中的一个字段 所有表都是由一个或者多个列组成。每个列有相应的数据类型。 5、行（row）表中的一个记录 行有时也称为记录。 6、主键（primary key）列或一组列，其值能够唯一区分表中的每个行。也可以一起使用多个列作为主键 应该总是定义主键：1）任意两行都不具有相同的主键值2）每个行都应该具备一个主键值（主键值不允许null值） 7、sqlsql是结构化查询语言的缩写，是专门用来与数据库通信的语言 sql优点：1）sql不是某个特定数据库供应商专用的语言。几乎所有重要的DBMS都支持sql，但事实上任意两个DBMS实现的sql都不完全相同2）sql简单易学。它的语句全都是由描述性很强的英语单词组成3）sql是一种强有力的语言，可以进行非常复杂和高级的数据库操作 8、mysqlmysql、oracle和Microsoft sql server等数据库是基于客户机-服务器的数据库。 服务器部分是负责所有数据访问和处理的一个软件。关于数据添加、删除和更新的所有请求都是由服务器软件完成。客户机是与用户打交道的软件。这些请求或更改来自运行客户机软件的计算机。例如，客户机软件通过网络提交请求给服务器软件，服务器软件处理这个请求，根据需要过滤、丢弃和排序数据；然后把结果送回到你的客户机软件。 mysql优点：1）成本 – mysql是开放源代码的，一般可以免费使用（甚至可以免费修改）2）性能 – mysql执行很快3）可信赖 – 某些非常重要和声望很高的公司、站点使用mysql，这些公司和站点都用mysql来处理自己的重要数据4）简单 – mysql很容易安装和使用 9、mysql工具mysql客户机 1）mysql命令行实用程序应该使用mysql -u ben -p -h myserver -P 9999（指定用户名、主机、端口号），完整的命令行选项和参数列表可以用mysql –help获得也可以通过help获得特定命令的帮助，比如help select可以查看使用select语句的帮助 2）mysql administratormysql administrator（mysql管理器）是一个图形交互客户机，用来简化mysql服务器的管理 10、show命令mysql&gt;show databases; 显示可用的数据库列表use zabbix; 使用zabbix数据库show tables; 返回当前数据库内可用表的列表show columns from zabbix; 等价于describe zabbix，显示列show status; 显示服务器状态信息show create database; 查看创建特定数据库的mysql语句show create table; 查看创建特定表的mysql语句show grants; 显示用户（所有用户或特定用户）的安全权限show errors; 显示服务器错误信息show warnings; 显示服务器警告信息help show; 显示允许的show语句 11、查询数据1）查询特定列2）查询所有列（select *）3）去重（select distinct）4）限制结果跳数limit 5 指示mysql返回结果为5行数据limit 5,5 指示mysql返回从行5开始的5行。第一个5是开始位置（从0开始计数），第二个5是要检索的行数 12、排列数据order by1）order by子句可以是所检索的列，也可以是非检索的列2）可以是按照单个列排序，也可以是按照多个列排序3）默认是升序排列（或者显式指定asc），也可以通过desc指定降序排序 13、子句顺序1）select2）from3）where4）group by5）having6）order by7）limit 14、过滤数据where 操作符： 15、组合where and:where子句中使用的关键字，用来指示检索满足所有给定条件的行or:where子句中使用的关键字，用来检索匹配任一给定条件的行in:where子句中用来指定要匹配值的清单的关键字，功能与or相当not:where子句中用来否定后跟条件的关键字备注：sql(像大多数sql语言一样)在处理or操作符之前，优先处理and操作符。可以使用圆括号改变默认操作顺序。 16、通配过滤 like操作符：为在搜索子句中使用通配符，必须使用like操作符like指示mysql，后跟的搜索模式利用通配符匹配而不是直接相等匹配进行比较 搜索模式：由字面值、通配符或者两者组合构成的搜索条件通配符：用来匹配值的一部分的特殊字符1）百分号(%)通配符表示任意字符出现任意次数备注：虽然似乎%可以匹配任何东西，但是有一个例外，就是null。例如where prod_name like ‘%’不能匹配用值null作为产品名的行2）下划线(_)通配符下划线只匹配单个字符而不是多个字符 17、正则过滤关键字like被regexp替代，其他跟使用like很像 like与regexp的区别：1）like匹配整个列，如果被匹配的文本在列值中出现，like将不会找到它，相应的行也不会返回（除非使用通配符）2）regexp在列值内匹配，如果被匹配的文本在列值中出现，regexp将会找到它，相应的行将被返回例如，3）select prod_name from products where prod_name regexp ‘1000’ order by prod_name; 返回数据’jetpack 1000’，列值内匹配4）select prod_name from products where prod_name like ‘1000’order by prod_name; 不返回数据，要整个匹配才会返回数据 18、regexp用法1）匹配整个列值（使用^与$定位符，从而功能与like相同）2）默认不区分大小写（使用binary关键字可以区分大小写，例如select prod_name regexp binary ‘JetPack .000’）3）or匹配（使用符号’|’，表示匹配符号’|’左边或者右边的其中一个）4）匹配几个字符之一（使用中括号’[]’，比如[123]ab可以匹配1ab或2ab或3ab）5）匹配几个字符之一的否定写法（使用中括号，并在中括号里面的集合的开始处放置一个^，比如[^123]就是匹配除1、2、3之外的任何字符）6）匹配范围[1-9] 匹配1到9[a-d] 匹配a到d7）匹配特殊字符必须以\\为前导。比如\\-表示查找-，\\.表示查找.，\\\\表示查找\\备注：多数正则表达式实现使用单个反斜杠转义特殊字符，以便能使用这些字符本身。但mysql要求使用两个反斜杠（mysql自己解释一个，正则表达式库解释另一个）8）匹配字符类[:alnum:] 匹配任意数字和字母[:alpha:] 匹配任意字符[:digit:] 匹配任意数字[:lower:] 匹配小写字母[:upper:] 匹配大写字母[:punct:] 匹配标点符号[:space:] 匹配空白字符[::xdigit] 匹配十六进制数9）重复元字符（匹配其前面的字符多少次）* 匹配其前面的字符任意次+ 匹配其前面的字符至少1次? 匹配其前面的字符0次或1次{n} 匹配其前面的字符n次{n,} 匹配其前面的字符至少n次{n,m} 匹配其前面的字符至少n次，至多m次10）定位符^ 匹配文本的开始位置$ 匹配文本的结束位置[[:&lt;:]] 匹配词的开始位置[[:&gt;:]] 匹配词的结束位置备注：^有3种用法：a、用在集合[]中表示否定该集合b、用在字符串’’中指定串的开始位置c、如之前所知，like匹配整个串而regexp匹配子串。利用^的定位符功能，通过用^开始每个表达式，用$结束每个表达式，可以使regexp的作用与like一样11）可以在不使用数据库的情况下使用select来测试正则表达式。例如使用带文字字符串的regexp来测试正则表达式select ‘hello’ regexp ‘[0-9]’ 返回0，表示不匹配备注：返回0表示不匹配，返回1表示匹配 19、拼接字段concat()函数 多数的DBMS使用+或者||来实现拼接，mysql则使用concat()函数来实现。括号里面是要拼接的字符串，用逗号隔开 20、删除空格trim()函数，支持rtrim()和ltrim()trim() 删除左右两边的空格rtrim() 删除右侧多余空格ltrim() 删除左侧多余空格 21、使用别名使用关键字as 22、使用select计算（省略from语句）select 3*2 返回6select trim(‘ abc ‘) 返回abc，去掉空格select NOW() 返回当前日期和时间 23、sql函数分文本处理函数、日期和时间处理函数、数值处理函数、聚集函数、分组函数等 24、文本处理函数1）left() 从左边返回left(str,length) left()函数接受两个参数，str是要提取子字符串的字符串，length是一个正整数，指定将从左边返回的字符数例如，select left(‘example.com’,3); 返回exa2）right() 跟left相反，从右边返回3）length() 返回字符串长度4）locate()locate(substr,str) 返回子串substr在字串str中第一次出现的位置。如果子串substr在str中不存在，将返回05）lower() 转换为小写6）upper() 转换为大写7）ltrim() 删除左侧多余的空格8）rtrim() 删除右侧多余的空格9）substring()select substring(‘example.com’,4,2); 从字符串的第4个字符位置开始取，只取2个字符10）soundex() 返回类似发音的值where soundex(cust_contact) = soundex(‘Y Lie’) ‘cust_contact’的值中有’Y Lee’。因为’Y Lee’和’Y Lie’发音类似，所以它们的soundex值匹配，会返回’Y Lee’ 25、日期和时间函数1）curdate() 返回当前日期2）curtime() 返回当前时间3）date() 返回日期时间的日期部分4）datediff 计算两个日期之差5）date_format() 返回一个格式化的日期时间备注：可以使用的格式有，a、年%Y 年，4位%y 年，2位 b、月%b 缩写月名%M 月名%m 月，数值（00-12） c、日%D 带有英文前缀的月中的天%d 月的天，数值（00-31） d、时%H 小时（00-23）%h 小时（01-12） e、分%i 分钟（数值00-59） f、秒%S 秒（00-59）%s 秒（00-59） year() 返回一个日期的年部分month() 返回一个日期的月部分day() 返回一个日期的天数dayofweek() 返回一个日期对应的星期几time() 返回一个日期的时间部分hour() 返回一个日期的小时部分minute() 返回一个日期的分钟部分second() 返回一个日期的秒部分 26、数值处理函数1）abs() 返回一个数的绝对值2）exp() 返回一个数的指数值3）mod() 返回除操作的余数4）pi() 返回圆周率5）rand() 返回一个随机数6）sqrt() 返回一个数的平方根 27、聚集函数定义：运行在行组中，计算和返回单个值的函数 1）avg() 返回某列的平均值avg()只能用于单列，要获得多列的平均值必须使用多个avg()函数 2）count() 返回某列的行数count()函数有两种使用方式：count(*) 对表中的数目进行计数，不管包含的是空值还是非空值count(column) 对特定列中具有值的行进行计数，忽略空值 3）max() 返回某列中的最大值在用于文本数据时，如果数据按照相应的列排序，则max()返回最后一行 4）min() 返回某列的最小值在用于文本数据时，如果数据按照相应的列排序，则min()返回最前面的一行 5）sum() 返回某某列值之和 28、分组函数group by 1）group by子句中列出的每个列必须是检索列或有效的表达式（但不能是聚集函数）2）如果在select中使用表达式，则必须在group by子句中指定相同的表达式3）不能使用别名4）group by子句必须出现在order by子句之前5）在分组函数中，不能使用where来过滤，而是用having来过滤。因为where过滤的是行而不是分组。having用在group by之后 29、with rollup可以实现在分组统计数据的基础上再做统计（sum,avg，count…）用法示例：例如我们将数据表按照名字进行分组，再统计每个人登录的次数 30、子查询和相关子查询子查询：嵌套在其他查询中的查询相关子查询：涉及外部查询的子查询。可能会涉及到列名有多义性，这时候必须使用完全限定列名（表名和列名由一个句点分割）备注：子查询最常见的使用是在where子句的in操作符中 31、外键外键是某个表中的一列，它包含另一个表的主键值，定义了两个表之间的关系。可以用来连接两个表 32、连接关系1）内连接（等值连接）：inner joinselect vend_name,prod_name,prod_price from vendors,productswhere vendors.vend_id = products.vend_id order by vend_name,prod_name也可以用规范的语法：select vend_name,prod_name,prod_price from vendors inner join products on vendors.vend_id = products.vend_id备注：至于使用哪种语法，sql规范首选inner join语法 2）自连接select p1.prod_id,p1.prod_name from products as p1,products as p2 where p1.vend_id = p2.vend_id and p2.prod_id = ‘DTNTR’等同于子查询：select prod_id,prod_name from produtcs where vend_id = (select vend_id from products where prod_id = ‘DTNTR’)备注：有时候处理连接比处理子查询要快得多 3）左外连接：left join或left outer join包含左边表的所有行（不管右边的表中是否存在与它们匹配的行），以及右表中全部匹配的行 4）右外连接：right join或right outer join包含右边表的所有行（不管左边的表中是否存在与它们匹配的行），以及左表中全部匹配的行 5）全外连接：full join或full outer join包含左、右两个表的全部行，不管另外一边的表中是否存在与它们匹配的行 6）交叉连接：没有连接关系（没有where子句）生成笛卡尔积备注：笛卡尔积，是指由没有联结关系的表关系返回的结果称为笛卡尔积 33、组合查询union关键字 union规则：1）union必须有两条或者两条以上的select语句组成，语句之间用关键字union分隔2）union的每个查询必须包含相同的列、表达式或聚集函数（不过各个列不需要以相同的次序列出）3）列数据类型必须兼容：类型不必完全相同，但必须是DBMS可以隐含的转换的类型（例如，不同的数值类型或不同的日期类型）备注：1）union从查询结果集中自动的去除了重复的行；如果想返回所有行，可以使用union all而不是union2）union几乎总是完成与多个where条件相同的工作。union all为union的一种形式，它完成where子句完成不了的工作。如果确实需要每个条件的匹配行全部出现（包括重复行），则必须使用union all而不是where 34、全文本搜索功能mysql最常用的搜索引擎是myisam和innodeDB，但是只有myisam支持全文本搜索，innodeDB不支持 为什么需要全文本搜索功能：mysql支持使用like运算符和正则表达式进行文本搜索。但是，当文本列较大并且表中的行数增加时，使用这些方法有一些限制：1）性能问题：mysql必须扫描整个表以根据like或正则表达式的模式查找文本2）灵活搜索：使用like或者正则表达式搜索，很难进行灵活的搜索查询。例如，查找描述包含car但不是classic的产品3）没有办法指定结果集中的哪一行与搜索字词更相关 由于这些限制，mysql扩展了一个非常好的功能，叫做全文搜索。从技术上讲，mysql从启用的全文搜索列的单词中创建一个索引，并对该索引进行搜索。mysql使用复杂的算法来确定与搜索查询匹配的行。 35、全文本搜索示例1）启用全文本搜索支持：在创建表的时候通过fulltext子句启用create table productnotes( note_id int not null auto_increment, prod_id char(10) not null, note_date datetime not null, note_text text, primary_key(note_id), fulltext(note_text),)engine=myisam;以上例子中，mysql根据子句fulltext(note_text)对它进行索引。在定义之后，mysql自动维护该索引。在增加、更新、删除行时，索引随之更新。可以在创建的时候指定fulltext，也可以在稍后指定。 2）进行全文本搜索在索引之后，使用两个函数match()和against()执行全文本搜索，其中match()指定被搜索的列，against指定要使用的搜索表达式select note_text from productnotes where match(note_text) against(‘rabbit’)以上例子中，match(note_text)指示mysql针对指定的列进行搜索，against(‘rabbit’)指定词rabbit作为搜索文本备注：a、传递给match()的值必须与fulltext()定义中的相同。如果指定多个列，则必须列出它们（并且次序要相同）b、搜索不区分大小写（除非使用binary方式，否则全文本搜索不区分大小写）c、全文本搜索提供了简单like搜索不能提供的功能。而且，数据是索引的，全文本搜索还相当快 3）查询扩展使用全文本搜索，但是没有查询扩展：select note_text from productnotes where match(note_text) against(‘anvils’);使用全文本搜索，并且使用查询扩展：select note_text from productnotes where match(note_text) against(‘anvils’ with query expansion);这行返回的行数比较多。第一行包含词anvils，因此等级最高；第二行与anvils无关，但因为它包含第一行中的两个词（customer和recommend），所以也被检索出来第三行也包含这两个相同的词，但它们在文本中的位置更靠后且分开得更远，因此也包含这一行，但等级为三。 4）布尔文本搜索布尔文本搜索与全文本搜索不同的地方在于：1）可以排除指定的关键字2）即使没有定义fulltext索引，也可以使用它 select note_text from productnotes where match(note_text) against(‘heavy -rope*‘ in boolean mode);以上例子中，表示匹配词heavy，但-rope*指示mysql排除包含rope的行 select note_text from productnotes where match(note_text) against(‘rabbit bait’ in boolean mode);以上例子中，没有指定关键字，这个搜索匹配包含rabbit和bait中的至少一个词的行 备注：布尔操作符：","categories":[{"name":"mysql笔记","slug":"mysql笔记","permalink":"http://yoursite.com/categories/mysql笔记/"}],"tags":[]},{"title":"nginx（缓存）","slug":"nginx（缓存）","date":"2019-03-01T08:00:00.000Z","updated":"2019-03-01T09:53:44.995Z","comments":true,"path":"2019/03/01/nginx（缓存）/","link":"","permalink":"http://yoursite.com/2019/03/01/nginx（缓存）/","excerpt":"","text":"1、缓存的优点nginx缓存，可以在一定程度上减少源服务器的处理请求压力。因为静态文件（比如css、js、图片）中，很多都是不经常更新的。nginx使用proxy_cache将用户的请求缓存到本地一个目录，下一个相同的请求可以直接调取缓存文件，就不用去请求服务器了。 2、配置说明开启简单的缓存配置，只需要两个指令：proxy_cache_path和proxy_cache。proxy_cache_path：配置缓存的存放地址和其他的一些常用配置proxy_cache：启动缓存 3、proxy_cache_path配置例子：proxy_cache_path /path/to/cache levels=1:2 keys_zone=mycache:10m max_size=10g inactive=60m use_temp_path=off;相关配置说明如下：1）/path/to/cache，本地路径，用来设置nginx缓存资源的存放路径2）levels，默认所有的缓存文件都放在同一个/path/to/cache下，但是会影响缓存的性能，因此通常会在/path/to/cache下面建立子目录用来分别存放不同的文件。假设levels=1:2，nginx为将要缓存的资源生成的key是f4cd0fbc769e94925ec5540b6a4136d0，那么key的最后一位0，以及倒数第2-3位6d作为二级的子目录，也就是该资源最终会被缓存到/path/to/cache/0/6d目录中3）key_zone，在共享内存中设置一块存储区域来存放缓存的key和metadata（类似使用次数），这样nginx可以快速判断一个request是否命中或者未命中缓存。1m可以存储8000个key，10m可以存储80000个key。4）max_size：最大cache空间，如果不指定，会使用掉所有的disk space，当达到配额后，会删除最少使用的cache文件。5）inactive：未被访问文件在缓存中保留时间。本配置中如果60分钟未被访问则不论状态是否为expired，缓存控制程序会删掉文件。inactive默认是10分钟，需要注意的是，inactive和expired配置项的含义是不同的，expired只是缓存过期，但不会被删除，inactive是删除指定时间内未被访问的缓存文件。6）use_temp_path：如果为off，则nginx会将配置文件直接写入到指定的cache文件中，而不是用temp_path存储，官方建议为off，避免文件在不同文件系统中不必要的拷贝。 4、proxy_cache配置proxy_cache on启用proxy_cache，并指定key_zone。如果proxy_cache off表示关掉缓存功能。","categories":[{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/categories/nginx/"}],"tags":[]},{"title":"nginx（负载均衡调度状态）","slug":"nginx（负载均衡调度状态）","date":"2019-03-01T06:50:00.000Z","updated":"2019-03-01T06:54:50.036Z","comments":true,"path":"2019/03/01/nginx（负载均衡调度状态）/","link":"","permalink":"http://yoursite.com/2019/03/01/nginx（负载均衡调度状态）/","excerpt":"","text":"在nginx upstream模块中，可以设定每台后端服务器在负载均衡调度中的状态，常见的状态有：1）down：表示当前的server暂时不参与负载均衡2）backup：预留的备份机器。当其他所有的非backup机器出现故障或者忙的时候，才会请求backup机器，因此这台机器的访问压力最小3）max_fails：允许请求失败的最大次数，默认为1。当超过最大次数时，返回proxy_next_upstream模块定义的错误4）fail_timeout：请求失败超时时间，在经历了max_fails次失败之后，暂停服务的时间。max_fails和fail_timeout可以一起使用","categories":[{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/categories/nginx/"}],"tags":[]},{"title":"nginx（负载均衡算法实例）","slug":"nginx（负载均衡算法实例）","date":"2019-03-01T06:13:00.000Z","updated":"2019-03-01T06:22:00.142Z","comments":true,"path":"2019/03/01/nginx（负载均衡算法实例）/","link":"","permalink":"http://yoursite.com/2019/03/01/nginx（负载均衡算法实例）/","excerpt":"","text":"1、轮询（默认）每个请求按照时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。 2、weight指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。代码如下：upstream backend{ server 192.168.0.14 weight=10; server 192.168.0.15 weight=10;} 3、ip_hash每个请求按照访问ip的hash结果分配，这样每个访客固定访问一台后端服务器，可以解决session的问题。代码如下：upstream backend{ ip_hash; server 192.168.0.14:88; server 192.168.0.15:80;} 4、fair（第三方）按照后端服务器的响应时间来分配请求，响应时间短的优先分配。代码如下：upstream backend{ fair; server server1; server server2;} 5、url_hash（第三方）按照访问url的hash结果来分配请求，使同一个url定向到同一个后端服务器，后端服务器为缓存时比较有效。upstream backend { server squid1:3128; server squid2:3128; hash $request_uri; hash_method crc32;}备注：在upstream中加入hash语句，server语句中不能写入weight等其他的参数，hash_method是使用的hash算法","categories":[{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/categories/nginx/"}],"tags":[]},{"title":"nginx（负载均衡算法）","slug":"nginx（负载均衡算法）","date":"2019-03-01T06:01:31.000Z","updated":"2019-03-01T06:10:43.884Z","comments":true,"path":"2019/03/01/nginx（负载均衡算法）/","link":"","permalink":"http://yoursite.com/2019/03/01/nginx（负载均衡算法）/","excerpt":"","text":"1、nginx负载均衡算法1）轮询（默认）每个请求按照时间顺序逐一分配到不同的后端服务，如果后端某台服务器宕机，自动剔除故障主机，使用户访问不受影响。2）weight（轮询权值）weight的值越大，访问概率越高，主要用于后端每台服务器性能不均衡的情况下。或者仅仅为在主从的情况下设置不同的权值，达到合理有效的利用主机资源。3）ip_hash每个请求按照访问IP的哈希结果分配，使来自同一个IP的访客固定访问一台后端服务器，并且可以有效解决动态网页存在的session共享问题。4）fair比weight、ip_hash更加智能的负载均衡算法，fair算法可以根据页面大小和加载时间长短智能地进行负载均衡，也就是根据后端服务器的响应时间来分配请求，响应时间短的优先分配。nginx本身不支持fair，如果需要这种调度算法，则必须安装upstream_fair模块。 5）url_hash按照访问url的哈希结果来分配请求，使每个url定向到一台后端服务器，可以进一步提高后端缓存服务器的效率。nginx本身不支持url_hash，如果需要这种调度算法，则必须安装nginx的hash软件包。","categories":[],"tags":[]},{"title":"nginx（负载均衡配置）","slug":"nginx（负载均衡）","date":"2019-03-01T03:34:00.000Z","updated":"2019-03-01T06:11:16.184Z","comments":true,"path":"2019/03/01/nginx（负载均衡）/","link":"","permalink":"http://yoursite.com/2019/03/01/nginx（负载均衡）/","excerpt":"","text":"upstream模块：实现负载均衡，nginx把客户端请求加权论调到后端多个服务器。需要注意的是，upstream模块需要定义在server之外 语法格式：upstream websrvs{ server 172.16.100.1 weight=1 max_fails=2 fail_timeout=2; server 172.16.100.2 weight=2 max_fails=2 fail_timeout=2; server 127.0.0.1:8080 backup;}备注：1）172.16.100.1和172.16.100.2不能加http协议，直接指定服务器ip2）backup指定当前面定义的httpd服务down掉的时候，这时候会启用这个页面3）使用google浏览器验证负载均衡的时候，需要先清掉缓存；可以用IE浏览器验证 location / { proxy_pass http://websvrs/; 这里需要改成websvrs}","categories":[{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/categories/nginx/"}],"tags":[]},{"title":"nginx（反向代理）","slug":"nginx（反向代理）","date":"2019-03-01T03:16:00.000Z","updated":"2019-03-01T07:35:10.471Z","comments":true,"path":"2019/03/01/nginx（反向代理）/","link":"","permalink":"http://yoursite.com/2019/03/01/nginx（反向代理）/","excerpt":"","text":"1、什么是代理服务器代理服务器：客户端在发送请求时，不会直接发送给目的主机，而是先发送给代理服务器，代理服务器接受客户端请求之后，再向目的主机发出，并接收目的主机返回的数据，转发回给客户端。简单来说，就是一个”跳板”的作用。 2、为什么要使用代理服务器1）提高访问速度由于目的主机返回的数据会存放在代理服务器的硬盘中，因此下一次客户再访问相同的站点数据时，会直接从代理服务器的硬盘中读取，起到了缓存的作用，尤其是对于热门站点能够明显提高请求速度。2）防火墙作用由于所有客户端请求都必须通过代理服务器访问远程站点，因此可在代理服务器上设限，过滤不安全信息。 3、正向代理和反向代理正向代理：代理内部网络对Internet的连接请求，客户机必须指定代理服务器,并将本来要直接发送到Web服务器上的http请求发送到代理服务器中。正向代理的作用：1）访问原来无法访问的资源，比如google2）可以做缓存，加速访问资源3）对客户端访问授权，上网进行认证4）代理可以记录用户访问记录（上网行为管理），对外隐藏用户信息 反向代理：当一个代理服务器能够代理外部网络上的主机，访问内部网络时，这种代理服务的方式称为反向代理服务。反向代理的作用：1）保证内网的安全，阻止web攻击（大型网站，通常将反向代理作为公网访问地址，web服务器是内网）2）负载均衡，通过反向代理来优化网站的负载 server语法：server { listen 80; server_name www.magedu.com location / { 后端服务器; }} 1）location /forum/ { proxy_pass http://172.16.100.1:8080/bbs/; proxy_pass，反向代理}意味着用户访问http://www.magedu.com/forum/，这个访问请求会被转发至http://172.16.100.1:8080/bbs/备注：forum后面的斜线必须跟下面的bbs后面的斜线保持一致，意味着上面有斜线下面也必须有，上面没有斜线下面也必须没有 2）location ~* /forum/ { proxy_pass http://172.16.100.1:8080/;}意味着用户访问http://www.magedu.com/forum，这个访问请求会被转发至http://172.16.100.1:8080/forum/(如果是模式匹配正则表达式的形式，下面只要指定服务器即可，否则会报错) 3）proxy_set_header:location ~* /forum/ { proxy_pass http://172.16.100.1:8080/; proxy_set_header X-Real-IP $remote_addr;}说明：这可以使得传递给后端的ip是真正的客户端的ip地址，但是在记录日志的时候还不是真正客户端的地址，而是代理服务器的ip地址。如果向记录日志的时候记录的是真正客户端的ip地址，还需要编辑/etc/httpd/conf/httpd.conf配置文件：LogFormat “%h…” ==&gt; LogFormat “%{X-Real-IP}i…” ,后面加i表示的是引用这个变量的值，然后重启服务","categories":[{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/categories/nginx/"}],"tags":[]},{"title":"nginx（整合nginx和php）","slug":"nginx（整合nginx和php）","date":"2019-03-01T02:48:00.000Z","updated":"2019-03-01T02:57:40.683Z","comments":true,"path":"2019/03/01/nginx（整合nginx和php）/","link":"","permalink":"http://yoursite.com/2019/03/01/nginx（整合nginx和php）/","excerpt":"","text":"1、编辑/etc/nginx/nginx.conf，启动如下选项：location ~ .php${ root html;改为/web/htdocs，改为html主页所在目录 fastcgi_pass 127.0.0.1:9000; 127.0.0.1表示nginx和php是在同一台主机上，如果是不同主机，要改为部署php的主机 fastcgi_index index.php; fast_cgi_param SCRIPT_FILENAME; include fastcgi_params;} 2、编辑/etc/nginx/fastcgi_params，将其内容更改为如下内容：fastcgi_param GATEWAY_INTERFACE CGI/1.1;fastcgi_param SERVER_SOFTWARE nginx;fastcgi_param QUERY_STRING $query_string;fastcgi_param REQUEST_METHOD $request_methodfastcgi_param CONTENT_TYPE $content_type;fastcgi_param CONTENT_LENGTH $content_length;fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;fastcgi_param SCRIPT_NAME $fast_script_namefastcgi_param REQUEST_URI $request_uri;fastcgi_param DOCUMENT_URI $document_urifastcgi_param DOCUMENT_ROOT $document_rootfastcgi_param SERVER_PROTOCOL $server_protocolfastcgi_param REMOTE_ADDR $remote_addrfastcgi_param REMOTE_PORT $remote_portfastcgi_param SERVER_ADDR $server_addrfastcgi_param SERVER_PORT $server_portfastcgi_param SERVER_NAME $server_name 并在所支持的主页面格式中添加php格式的主页，类似如下:location / { root html; index index.php index.html index.htm;} 3、重新载入nginx配置文件:service nginx reload","categories":[{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/categories/nginx/"}],"tags":[]},{"title":"nginx（php安装）","slug":"nginx（php安装）","date":"2019-03-01T02:06:00.000Z","updated":"2019-03-01T02:47:15.625Z","comments":true,"path":"2019/03/01/nginx（php安装）/","link":"","permalink":"http://yoursite.com/2019/03/01/nginx（php安装）/","excerpt":"","text":"编译安装php解决依赖关系：yum -y groupinstall “X Software Development”如果要让编译的php支持mcrypt，mhash扩展和libevent，此处还需要下载几个rpm包:libmcrypt-2.5.8.4.e15.centos.i386.rpmlibmcrypt-devel-2.5.8.4.e15.centos.i386.rpmmhash-0.9.9-1.el5.centos.i386.rpmmhash-devel-0.9.9-1.el5.centos.i386.rpmmcrypt-2.6.8-1.e15.i386.rpm最好使用升级的方式安装上面的rpm包，命令格式如下：rpm -Uvh 另外，也可以根据需要安装libevent，系统一般会自带libevent，但版本有些低，因此可以升级安装。它包含以下两个rpm包：libevent-2.0.17-2.i386.rpmlibevent-devel-2.0.1702.i386.rpm备注：libevent是一个异步时间通知库文件，其API提供了在某文件描述上发生某事件时或其超时执行回调函数的机制，它主要是用来替换事件驱动的网络服务器上的event loop机制。目前来说，libevent支持/dev/poll,kqueue,select,poll,epoll以及solaris的event ports 1）tax xf php-5.4.13.tar.bz2）cd php-5.4.133）./configure –prefix=/usr/local/php –with-mysql=/usr/local/mysql –with-openssl –enable-sockets –enable-sysvshm –with-mysqli=/usr/local/mysql/bin/mysql_config –enable-mbstring –with-freetype-dir –with-jpeg-dir–with-png-dir –with-zlib-dir –with-libxml-dir=/usr –enable-xml –with-mhash –with-mcrrypt –with-config-file-path=/etc –with-config-file-scan-dir=/etc/php.d –with-bz2 –with-curl 说明：如果前面解决依赖关系时安装了mcrypt相关的两个rpm包，此处的./configure命令还可以带上–with-mcrypt选项让php支持mcrypt扩展，–with-snmp选项则用于实现php的snmp扩展，但此snmp功能要求提前安装net-snmp相关软件包 备注：./configure的时候如果提示某些安装包没有装，使用命令yum list all|grep 包名 可以查看哪些包没装，然后直接yum -y install 没安装的包的包名即可（直接是包名，不需要加上版本号之类。yum list all 的时候如果状态是bash表示没有安装） 4）make5）make install6）为php提供配置文件：cp php.ini-production /etc/php.ini7）为php-fpm提供Sysv init脚本，并将其添加到服务列表：cp sapi/fpm/init.d/php-fpm /etc/rc.d/init.d/php-fpmchmod +x /etc/rc.d/init.d/php-fpm8）chkconfig –add php-fpm9）chkconfig php-fpm on10）为php-fpm提供配置文件：cp /usr/local/php/etc/php-fpm.conf.default /usr/local/php/etc/php-fpm.conf11）编译php-fpm配置文件：vi /usr/local/php/etc/php-fpm.conf配置fpm相关选项为你所需要的值，并启用pid文件（如下最后一行）：pm.max_children = 50pm.start_servers = 5pm.min_spare_servers = 2pm.max_spare_servers = 8pid = /usr/local/php/var/run/php-fpm.pid12）接下来就可以启动php-fpm：service php-fpm start13）验证：使用如下命令，如果命令输出有几个fpm-php进程说明启动成功ps aux|grep php-fpm","categories":[{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/categories/nginx/"}],"tags":[]},{"title":"nginx配置（虚拟主机）","slug":"nginx配置（虚拟主机）","date":"2019-02-26T08:14:00.000Z","updated":"2019-03-21T02:58:10.680Z","comments":true,"path":"2019/02/26/nginx配置（虚拟主机）/","link":"","permalink":"http://yoursite.com/2019/02/26/nginx配置（虚拟主机）/","excerpt":"","text":"server { listen 80 server_name localhost } location /bbs { root html; 网页配置文件在/usr/html/bbs/下，访问时输入ip/bbs #安装时已通过prefix指定html根目录为/usr index index.html; allow xx.xx.xx.xx; 只允许特定地址访问 deny all; auth_basic “Restricted”; 指定名称 auth_basic_user_file htpasswd; 指定文件路径，通过auth_basic和auth_basic_user_file这两个选项可以实现基于用户认证的访问 } 备注: 1)要建立配置htpasswd文件，要借用httpd的htpasswd命令。 2)要使用htpasswd命令，确定你安装了httpd-tools（yum install httpd-tools -y） 3)创建授权用户和密码： htpasswd -c -d /path root #/path可以随意指定任一个目录，root是登录用户名 4)检查nginx配置：nginx -t 平滑重启nginx：nginx -s reload location /status { stub_status on; 显示状态信息，注意状态信息一般不会开放给所有人访问 allow xx.xx.xx.xx; deny all; } 备注: 1)显示的信息： active connection：活动连接数 server accept handled requests：服务器已经处理过的请求数 reading：nginx正在读首部的请求个数 writing：nginx正在读主体的请求个数或正处理着其请求内容的请求个数或者正在向客户端发送响应的个数 waiting：reading+writing} server里面的选项：location：1)location uri {}:花括号中的属性对当前路径及子路径下的所有对象都生效2)location = uri {}：花括号中的属性对当前路径生效（精确匹配指定路径，不包括子路径）3)location ~ uri {}：模式匹配uri，此处的uri可以使用正则表达式（区分字符大小写）4)location ~* uri {}：模式匹配uri，此处的uri可以使用正则表达式（不区分字符大小写）5)location ~~ uri {}：不使用正则表达式 备注：nginx语法检查：nginx -t","categories":[{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/categories/nginx/"}],"tags":[]},{"title":"nginx配置","slug":"nginx配置","date":"2019-02-22T09:19:00.000Z","updated":"2019-03-20T09:28:32.703Z","comments":true,"path":"2019/02/22/nginx配置/","link":"","permalink":"http://yoursite.com/2019/02/22/nginx配置/","excerpt":"","text":"nginx的配置文件:/etc/nginx1、大体配置:分为几个上下文（意思就是分段）:mainhttpserver（http子段）upstream（http子段，定义反向代理）location（相当于虚拟主机的DocumentRoot）mail（实现邮件的反向代理） 2、详细配置1）worker process 1（work进程数，与cpu个数相关）备注:如果负载是cpu密集型应用为主，如ssl或者压缩应用，则work个数与cpu个数相同；如果负载是io密集型为主，如响应大量内容给客户端，则worker的个数应该是cpu个数的1.5倍或2倍2）error_log logs/error.log（错误日志路径，如果是被注释掉，说明我们编译时候指定的错误日志路径已经生效）3）pid logs/nginx.pid（pid路径，如果是被注释掉，说明我们编译的时候指定的路径已经生效）4）event{ worker_connections 1024;}备注:worker_connection指定的是连接数5）keeplive_timeout 65; 使用长连接并指定超时时间gzip on; 先压缩再发送，可以节省带宽","categories":[{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/categories/nginx/"}],"tags":[]},{"title":"nginx安装","slug":"nginx安装","date":"2019-02-22T07:29:00.000Z","updated":"2019-03-20T09:30:33.903Z","comments":true,"path":"2019/02/22/nginx安装/","link":"","permalink":"http://yoursite.com/2019/02/22/nginx安装/","excerpt":"","text":"编译安装nginx（如果将来需要批量部署安装nginx，可以自己做成rpm包。官方也有提供rpm包）1、安装前准备1）yum grouplist（查看安装了哪些yum包组）2）yum -y groupinstall “Development Tools” （安装包组）3）yum install -y pcre-devel openssl-devel gd（安装依赖，pcre是perl扩展的正则表达式） 2、解压缩1）tar xf nginx-1.4.1.tar.gz（安装软件之前需要确认下时间，如果系统时间比软件包时间靠前的话，会认为软件包是来自未来的，因此软件包是无法使用的）2）groupadd -r -g 108 nginx3）useradd -r -g 108 -u 108 nginx（nginx应该要以普通用户的身份运行）备注:-r:创建系统账户-g:指定gid-u:指定uid 3、编译安装1）cd nginx-1.4.12）./configure –help|less（查看configure的帮助文档） 3）./configure \\–prefix=/usr \\–sbin-path=/usr/sbin/nginx \\–conf-path=/etc/nginx/nginx.conf \\–error-log-path=/var/log/nginx/error.log \\–htp-log-path=/var/log/nginx/access.log \\–pid-path=/var/run/nginx/nginx/pid \\–lock-path=/var/lock/nginx.lock \\–user=nginx \\–group=nginx \\–with-http_ssl-module \\–with-http_flv_module \\–with-http_stub_status_module \\–with-http_gzip_static_module \\–http-client-body-temp-path=/var/tmp/nginx/client/ \\–with-proxy-temp-path=/var/tmp/nginx/proxy/ \\–with-fastcgi-temp-path=/var/tmp/nginx/fcgi/ \\–withuwsgi-temp-path=/var/tmp/nginx/uwsgi/ \\–with-scgi-temp-path=/var/tmp/nginx/scgi/ \\–with-pcre\\–with-file-aio4）make5）make install备注:如果编译出错需要重新编译，要先make clean一下再configure以上编译选项都是两个横杠在前面 4、将nginx加入到服务列表chkconfig –add nginx（加到服务列表中去）chkconfig –list nginx（检查是否已经加入到服务列表）备注：两个横杠 5、启动nginx要想启用nginx，需要编辑一个启动脚本:/etc/rc.d/init.d/nginx #需要自己写，可以参考httpd的启动停止脚本(就是可以通过脚本来实现start|stop|reload等功能)。然后通过service nginx start来启动nginx 备注:会在默认安装目录下创建一个html目录，里面放的就是网页文件。如果是按照上面方法提供的路径来安装nginx的话，网页文件就放在/usr/html目录中.","categories":[{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/categories/nginx/"}],"tags":[]},{"title":"nginx功能","slug":"nginx功能","date":"2019-02-22T07:03:00.000Z","updated":"2019-02-22T07:20:34.623Z","comments":true,"path":"2019/02/22/nginx功能/","link":"","permalink":"http://yoursite.com/2019/02/22/nginx功能/","excerpt":"","text":"1、nginx官网:www.nginx.org 2、nginx功能:1）web服务器（具有基本web服务器所需要具备的绝大多数功能，除非需要apache提供的某些功能，否则nginx是我们选择web服务器的首选）2）反向代理（反向代理web和mail，反向代理mail一般很少用） 3、nginx进程:nginx会按需同时运行多个进程，一个主进程（master）和几个工作进程（worker），配置了缓存时还会有缓存加载器进程（cache loader）和缓存管理器（cache manager）等。所有进程均是只含有一个线程，并主要通过共享内存机制来实现进程间通信。主进程以root用户身份运行，而worker、cache loader、cache manager均以非特权用户身份运行。 4、进程详细作用1）主进程主要完成以下工作:a、读取并验证配置信息b、创建、绑定和关闭套接字c、启动、终止和维护worker进程的个数d、热部署、平滑升级，也就是重新加载配置以及在线升级时，不需要中断正在处理的请求e、重新打开日志文件，实现日志滚动f、编译嵌入式perl脚本 2）worker进程主要完成的任务包括:a、接收、传入并处理来自客户端的连接b、提供反向代理及过滤功能c、nginx任何能完成的其他任务 3）cache loader进程主要完成的任务包括:a、检查缓存存储中的缓存对象b、使用缓存元数据建立内存数据库 4）cache manager进程的主要任务包括:a、缓存的失效及过期检验","categories":[{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/categories/nginx/"}],"tags":[]},{"title":"httpd虚拟主机配置（Session 3）","slug":"httpd虚拟主机配置（Session-3）","date":"2019-02-22T06:29:00.000Z","updated":"2019-02-22T06:55:38.735Z","comments":true,"path":"2019/02/22/httpd虚拟主机配置（Session-3）/","link":"","permalink":"http://yoursite.com/2019/02/22/httpd虚拟主机配置（Session-3）/","excerpt":"","text":"虚拟主机:一个apache服务服务于多个不同的站点1）定义: 备注:要使用虚拟主机，首先要取消中心主机。取消方法，注释DocumentRoot 2）新建虚拟主机:两种方法第一种:在/etc/httpd/conf/httpd.conf里面定义虚拟主机第二种:新建虚拟主机定义文件/etc/httpd/conf.d/virtual.conf，在里面定义虚拟主机 3）示例:a、基于IP的虚拟主机 备注:httpd -t（可以检查httpd的配置或者语法是否正确） b、基于端口的虚拟主机如果是基于端口的虚拟主机，还需要在httpd.conf主配置文件中定义监听端口(默认是只监听了80端口) c、基于域名的虚拟主机 备注:默认所有的主机日志都在/var/log/httpd/access.log|error_log","categories":[{"name":"http","slug":"http","permalink":"http://yoursite.com/categories/http/"}],"tags":[]},{"title":"httpd属性配置（Session 2）","slug":"httpd属性配置（Session-2）","date":"2019-02-22T03:38:00.000Z","updated":"2019-02-22T06:53:39.582Z","comments":true,"path":"2019/02/22/httpd属性配置（Session-2）/","link":"","permalink":"http://yoursite.com/2019/02/22/httpd属性配置（Session-2）/","excerpt":"","text":"1、配置文件内容:1）ServerAdmin root@localhost（服务器管理员邮箱地址）2）ServerName www.example.com:80（主机名称，除了在定义虚拟主机这个选项必须开启之外，其他模式下可以注释）3）UserCanonicalName Off（正式名称，很少用，一般注释掉）4）DocumentRoot “/var/www/html”（文档根目录，就是网页文件存放的位置） 备注:Directory里面的内容是一个容器，这里面定义的是如何访问/var/www/html这个路径 2、容器里面的内容:1）options（定义访问属性，如果存在多个值，值与值之间用空格隔开）访问属性值:none:不支持任何选项indexes:允许索引目录，在生产环境中通常不允许（有一种情况例外，就是提供下载文件）FollowSymLinks:允许访问符号链接指向的源文件（通常不允许）ExecCGI:允许执行cgi脚本All:支持所有选项（在生产环境中一般没有人这样玩）2）AllowOverride支持的值:none:不支持任何选项Authconfig:需要提供账号密码才能访问站点3）AuthType Basic4）AuthName “Restricted Site”5）AuthUserFile “/etc/httpd/conf/htpasswd”（允许哪些用户访问）6）AuthGroupFile “/etc/httpd/conf/htgroup”（允许哪些组访问）7）Require user user_name（只允许某个用户登录）8）Require group group_name（只允许某个组登录）9）Require valid-user（允许/etc/httpd/conf/htpasswd中的所有用户登录） 3、htpasswd1）作用:创建htpasswd文件2）示例:第一次创建:htpasswd -c -m /etc/httpd/conf/htpasswd user_name第二次创建:htpasswd -m /etc/httpd/conf/htpasswd user_name备注:a、只在第一次创建的时候使用-c创建/etc/httpd/conf/htpasswd文件，第二次创建的时候不要使用-c，否则会覆盖原来的文件b、htpasswd -h 可以查看帮助","categories":[{"name":"http","slug":"http","permalink":"http://yoursite.com/categories/http/"}],"tags":[]},{"title":"httpd cgi","slug":"httpd-cgi","date":"2019-02-22T03:17:00.000Z","updated":"2019-02-22T06:18:52.956Z","comments":true,"path":"2019/02/22/httpd-cgi/","link":"","permalink":"http://yoursite.com/2019/02/22/httpd-cgi/","excerpt":"","text":"1、cgi由来httpd或者web服务器本身不处理动态内容，而是通过某种协议调用额外的应用程序来运行，并将处理后的结果响应给客户端。而cgi，全称是common gateway interface，翻译为通用网关接口，就是使web服务器能够跟其他应用程序通讯的一种机制（或者协议），能够调用额外的应用程序来处理动态内容。例如web服务器调用php解释器来解释php脚本。 2、fastcgiweb服务器与动态进程服务器通讯，动态进程不再归web服务器管理，而是统一由动态进程服务器进程管理。这个动态进程服务器进程同时生成了很多子进程，等待响应请求。也就是说，静态内容和动态内容分别由不同的主机处理（web服务器处理静态内容，动态进程服务器处理动态内容，然后返回html页面给web服务器） 3、动态网站分两种类型:1）客户端动态过程:用户过来请求，把服务器端的源码下载到本地，在本地执行程序安全性:如果有人恶意的在服务器端放了一个恶意脚本，用户下载到本地会对本地主机造成一定的危害适应性:如果服务器端的脚本是java写的，要运行这段脚本，就必须要求用户本地主机必须安装有java的执行环境，否则脚本无法执行2）服务器端动态过程:脚本放在服务器端，通过cgi协议调用相关的解释器来执行脚本，并把执行后的结果返回给客户端 4、php每一种程序开发语言都有其最适用的场景。比如，C,C++非常底层，执行效率很高，不适合开发那些多媒体，表现形式很丰富的程序，而适用于那些直接驱动硬件的程序。php是一种脚本语言，天生就是用来开发web页面的。 5、小于1024端口1）httpd:root,root(master process) – 这个主导进程是root用户，root组 #并不会处理用户请求，而是用来创建进程或者销毁多余的进程2）httpd:apache,apache(worker process) – 其他进程都是apache用户，apache组备注:a、在linux上，小于1024的端口只有管理员有权限使用，所以启动httpd的master进程的用户只有是管理员(httpd:80端口;如果是基于SSL:443端口)b、在/etc/rc.d/init.d下有一个脚本叫做httpd，因此httpd也可以通过service httpd start|stop来启动或者停止httpd进程","categories":[{"name":"http","slug":"http","permalink":"http://yoursite.com/categories/http/"}],"tags":[]},{"title":"httpd全局配置（Session 1）","slug":"httpd配置","date":"2019-02-22T01:22:00.000Z","updated":"2019-02-22T06:25:54.390Z","comments":true,"path":"2019/02/22/httpd配置/","link":"","permalink":"http://yoursite.com/2019/02/22/httpd配置/","excerpt":"","text":"1、httpd相关目录（1）/etc/httpd:工作的根目录（2）/etc/httpd/conf:配置文件目录（3）/etc/httpd/conf/httpd.conf:主配置文件（配置文件很大，在/etc/httpd/conf.d/*.conf的文件都属于httpd的配置文件的一部分，主配置文件通过include将这些配置文件包含进来）（4）/etc/httpd/modules:模块链接，指向/usr/lib/httpd/modules下的库文件（5）/etc/httpd/logs:目录文件，是一个链接文件，指向/var/log/httpd备注:a、httpd的日志分两类:访问日志:access_log错误日志:err_logb、/var/www/:（请求的资源所在的目录，一般包含两个目录）html:静态页面所在路径cgi-bin:动态内容所在路径 2、httpd主配置文件/etc/httpd/conf/httpd.conf（1）总体配置grep “Section” /etc/httpd/conf/httpd.conf，可以看到主配置文件分为3段:Section 1:Global Environment（全局环境）Section 2:Main server configuration（主服务器配置）Section 3:Virtual Hosts（虚拟主机）备注：a、第二段和第三段的配置不能同时生效，只能有一个生效b、第一段全局配置指的是如果你使用的是虚拟主机，就对全部的虚拟主机都生效（2）详细配置a、ServerTokens OS – 输出操作系统版本信息:当网页报错时，最底下的显示（示例:Apache/2.2.3 RedHat Server at 172.16.100.1 port 80）备注:ServerTokens的值除了OS，还有其他的值，比如Major|Minor|Min[imal]|Prod[uctonly]|Fullb、ServerRoot “/etc/httpd” – 服务器的根目录（不到万不得已不要修改这个配置）c、PidFile run/httpd.pid – run是相对路径，相对于/etc/httpd路径d、timeout 120 – 超时时间（跟tcp协议相关的超时时间）e、KeepAlive Off – 是否使用长连接f、KeepAliveRequest 100 –使用长连接的请求达到100个之后，就断开长连接g、KeepAliveTimeout 15 – 长连接耗时超过15s，就断开长连接 1)StartServer 8 – 定义web服务器启动时启动空闲进程的数量2)MinSpareServers 5 – 定义web服务器随时要保证的空闲进程的数量（至少要有的空间进程的个数）3)MaxSpareServers 20 – 定义的最大空闲进程数量（过多的空闲进程会浪费系统资源）4)ServerLimit 256 – MaxClinet的上限值，MaxClient的值不能超过ServerLimit定义的值。要修改该值，需要kill原进程，修改值之后再重启服务5)MaxClient 256 – 允许请求的最大客户端数量6)MaxRequestPerchild 4000 – 定义一个进程最多只能服务多少个用户请求（一旦超过该设定值，就会kill掉该进程） 1)StartServer 2 – 生成进程数2)MaxClient 1503)MinSpareThread 25 – 最小空闲线程（所有的进程加起来的线程数）4)MaxSpareThread 75 – 最大空闲线程（所有的进程加起来的线程数）5)ThreadPerChild 25 – 每个进程最多生成多少个线程6)MaxRequestPerChild 0 – 每个进程最多服务多少个用户请求。因为用户请求是由线程响应的，所以这里设置为0表示不做限定j、Listen 80（指定监听地址和端口，如果不带ip地址，表示监听当前主机上的所有地址）示例:监听多个地址:Listen 80Listen 8080监听某个地址上的某个端口:Listen 172.16.10.1:80k、LoadModule mod_name（装载模块）l、include conf.d/*.confm、User apachen、Group apache 3、本地查看httpd帮助文档yum install -y httpd-manual（这时候会在httpd的主配置目录里面生成一个manual的文件，重启httpd服务后只需要在你的主机ip后面加上/manual，就可以在浏览器中显示帮助文档）","categories":[{"name":"http","slug":"http","permalink":"http://yoursite.com/categories/http/"}],"tags":[]},{"title":"httpd安装","slug":"httpd安装","date":"2019-02-21T15:27:00.000Z","updated":"2019-02-22T07:23:17.455Z","comments":true,"path":"2019/02/21/httpd安装/","link":"","permalink":"http://yoursite.com/2019/02/21/httpd安装/","excerpt":"","text":"1、安装方式:（1）使用系统自带的rpm包（2）源码编译安装 2、通过rpm包的方式安装（1）缺点:有些功能可能不需要但是已经编译进来，或者是有些功能需要但是没有编译进来（2）安装步骤:（以红帽系统的rpm包安装为例）a、yum list all |grep httpd（查看系统自带的rpm包）输出内容:httpd.i386（服务器端的包）httpd-devel-i386（除非是针对httpd做二次开发，否则这个包用不上）httpd.manual-i386（帮助手册）备注:一般来说，系统自带的版本比较落后，或者是有漏洞，或者是某些特定的功能rpm包没有提供，所以很多时候我们是需要通过源码安装的方式来安装httpdb、getenforce（查看selinux状态）setenforce 0（设置selinux为permissive状态，临时生效）备注:因为红帽系统上httpd是受selinux控制的，所以需要先停止掉selinux。如果要使selinux关闭永久生效，需要编辑/etc/sysconfig/selinux或/etc/selinux/config(这两个文件是同一个文件)，设置SELINUX=permissivec、yum -y install httpd（安装httpd）d、rpm -ql httpd|less（查看httpd安装生成哪些文件）e、service httpd start（启动httpd）f、chkconfig httpd on（开机启动httpd）g、在浏览器输入服务器的ip地址即可访问httpdh、配置欢迎页面，编辑/etc/httpd/conf.d/welcome.conf，配置完成后通过service httpd restart重启服务使得配置生效。如果没有欢迎页面，默认页面在/var/www/html目录下定义:新建文件a.html, 不需要重启服务，刷新浏览器即可","categories":[{"name":"http","slug":"http","permalink":"http://yoursite.com/categories/http/"}],"tags":[]},{"title":"httpd","slug":"httpd","date":"2019-02-21T14:51:00.000Z","updated":"2019-02-22T03:37:01.693Z","comments":true,"path":"2019/02/21/httpd/","link":"","permalink":"http://yoursite.com/2019/02/21/httpd/","excerpt":"","text":"1、httpd由来httpd最初是由NCSA研发和维护的，后来这个机构解散之后，很多原来维护httpd的工程师觉得httpd这个软件很好用，所以就自愿通过互联网的方式继续维护httpd这个软件，其实也是打打补丁之类的工作。所以之后httpd被戏称为a patchy server(打满补丁的软件)，简称为apache。后来apache发展为一个软件基金会ASF(apache software foundation),ASF底下维护了很多著名的项目，比如httpd、tomcat、hadoop等备注:a、早期的httpd就叫做apache，但是其实apache是一个软件基金会，这个基金会维护着很多著名的软件，httpd只是其中的一种b、apache官方网站 www.apache.org，httpd官方网站 http://httpd.apache.org(apache的子网页) 2、httpd特性（1）事先创建进程（在用户请求之前已经创建好进程作为空闲进程，一旦有用户请求进来，就可以立刻把空闲进程分配给请求予以响应）（2）按需维持适当的进程（一旦空闲进程太多，会把空闲进程销毁）（3）模块化设计，核心比较小，各种功能模块化添加。支持运行时配置，单独编译模块即可。也可以在运行时启用，即装载响应的模块即可。（4）支持多种方式的虚拟主机配置（5）支持url重写（假如用户访问/a.jpg，可以通过转换使得用户去访问/b.jpg，这个过程对用户来说是不可见的）（6）支持https（通过模块mod_ssl实现）（7）支持用户认证（认证方式:简单认证、摘要认证、表单认证等）（8）支持基于ip或主机名的acl（acl:访问控制列表）（9）支持某目录的访问控制（访问网站不需要密码，但是访问特定目录的时候需要输入账号密码） 3、虚拟主机（1）定义:web物理服务器和web程序都只有一个，但可以服务不同的站点（2）种类:a、基于ip的虚拟主机（ipv4地址资源比较紧缺，使用互联网ip来定义基于ip的虚拟主机不太现实）b、基于端口的虚拟主机（在互联网上使用端口也不太现实，因为如果不使用标准端口的话，在互联网上很难知道web服务器到底是使用哪一个端口来提供web服务）c、基于域名的虚拟主机（常用） 4、httpd与nginx比较nginx是多进程响应n个用户请求的模型，使用有限的资源响应比httpd更多的用户请求，但是替代不了httpd原因是:（1）从提供众多特性这点来说，nginx是无法与httpd比较的（2）稳定性也无法跟httpd比较（3）一般nginx是用来做反向代理的，而httpd仍然是web服务的老大","categories":[{"name":"http","slug":"http","permalink":"http://yoursite.com/categories/http/"}],"tags":[]},{"title":"web server模型","slug":"web-server模型","date":"2019-02-21T08:14:00.000Z","updated":"2019-02-22T03:10:42.372Z","comments":true,"path":"2019/02/21/web-server模型/","link":"","permalink":"http://yoursite.com/2019/02/21/web-server模型/","excerpt":"","text":"1、web server主要操作:（不会处理动态内容，也就是不会执行脚本）（1）建立连接:接收或者拒绝客户端的连接请求（2）接收请求:通过网络读取http请求报文（3）处理请求:解析请求报文并做出相应的动作（4）访问资源:访问请求报文中的相关资源（5）构建响应:使用正确的首部生成http响应报文（6）发送响应:向客户端发送生成的响应报文（7）记录日志:已经完成http事务记录进日志 2、web server模型:mpm模型，也叫多道处理模块，定义apache服务器在响应多个用户请求时所采用的的模型。分三种:（1）prefork:在apache启动之初，就会预派生一些子进程，然后等待连接。每个子进程只有一个线程，可以兼容新老模块，也不需要担心线程安全问题。但是一个进程相对的占用更多的资源，消耗大量内存，不擅长处理高并发的场景。备注:a、查看当前使用的mpm:/usr/local/apache24/bin/httpd -V 或者apachectl -Vb、MaxClients的设置值:设定Apache可同时处理的请求数量，默认的150远远不能满足一般站点，超过这个数量的请求需要排队，直到前面的请求处理完毕。如果我们发现系统资源还剩很多，但是HTTP访问却很缓慢，大多数时候增加这个值可以得到缓解。c、MaxRequestsPerChild的设置值:设定处理多少个请求后该进程自动销毁，默认值为0表示永不销毁。当负载较高时，为了使每个进程处理更多的请求，避免销毁、创建进程的开销，一般建议设置为0或者较大的数字。但是也要注意可能会造成进程占用的内存不能得到释放，所以这个值不能设置得太大，也不能太小，大了会影响资源的释放，小了会导致apache不断fork进程。（2）worker:与prefork的工作模式相比，worker使用了多进程和多线程的混合模式，worker模式也会预派生一些子进程，然后每个子进程创建一些线程，同时包括一个监听线程，每个请求过来会被分配到一个线程来服务。线程比进程更加轻量级，因为线程通常会共享父进程的内存地址，因此内存占用会减少一些。缺点是必须考虑线程安全性，因为多个子进程是共享父进程的内存地址的，如果使用keep-alive的长连接方式，某个线程会被一直占据，需要等到超时才会被释放。如果过多的线程被这样占据，也会导致在高并发下的无服务线程可用。（3）event:和worker的工作模式很像，最大的区别是解决了在keep-alive场景下，长期线程被占用导致的资源浪费问题。在event模式下，会有一个专门的线程来管理keep-alive线程，当有真实请求过来的时候，将请求传递给服务进程，执行完毕后，又允许它释放，这样增强了在高并发场景下的请求处理能力。通过事件驱动机制和通知机制，大大加速响应请求的过程，请求所占用的服务器资源也大大减少。备注:a、httpd -l（可以查看当前所使用的工作模型）b、rpm -ql httpd|grep bin（可以查看httpd也支持worker模型和event模型，默认是prefork模型）c、prefork、worker、event模型分别对应的二进制程序是:/usr/sbin/httpd/usr/sbin/httpd.worker/usr/sbin/httpd.event如果要启用worker模型或者event模型，就通过httpd.worker或者httpd.event相对应的程序来启动httpd。或者修改/etc/sysconfig/httpd文件中的httpd = /usr/sbin/httpd.worker|httpd.event 3、web server架构:C/S架构C:client agent，客户端代理，就是常见的浏览器，包括ie、firefox、chrome、opera、sarafi（其他的诸如360浏览器、遨游等，都是假的浏览器，里面是ie的内核，只是外观不同而已）S:server，能够提供web服务的，包括httpd、iis、nginx、lightted、tomcat、jboss（tomcat的二次封装）、websphere、weblogic（最后两个是商业化产品）备注:www.netcraft.com #可以查看web服务器各种产品的市场占有率","categories":[{"name":"http","slug":"http","permalink":"http://yoursite.com/categories/http/"}],"tags":[]},{"title":"http报文","slug":"http报文","date":"2019-02-21T07:45:00.000Z","updated":"2019-02-21T08:06:25.434Z","comments":true,"path":"2019/02/21/http报文/","link":"","permalink":"http://yoursite.com/2019/02/21/http报文/","excerpt":"","text":"1、ip首部:主要是ip地址，包括源ip和目的ip2、tcp首部:主要是端口号，包括源端口和目的端口备注:ip和tcp主要是负责将报文传输到目标主机上，但是对应是目标主机的哪一个页面，tcp/ip协议并没有指定。因此，要正确访问一个web页面，还需要http首部。 3、http首部:GET /2.html #直接指定要访问的资源文件host:www.magedu.com #已经通过tcp/ip协议来确定了主机，为什么还需要通过host来指定主机呢？答:这是为虚拟主机准备的备注:一个http页面，通常包含多个资源。也就是说，客户端访问一个页面，要向服务端发起多个请求。http首部属于http报文的一部分。 4、http报文种类:请求报文和响应报文http报文组成:起始行、报文首部、主体(报文首部和主体之间需要空一行)(1)请求报文: 请求报文实例: (2)响应报文: 响应报文实例: 5、状态码(1)1xx:纯信息(用的很少)(2)2xx:成功类信息(请求资源获取正确的响应，200,201,202)(3)3xx:重定向信息(301:永久重定向，302:临时重定向，304:服务端告诉客户端所请求的内容没有发生任何改变，告知客户端用自己的缓存内容即可)备注:重定向:请求的资源已经挪到另外的位置，并返回对应位置的信息给客户端让客户端去访问新的资源地址(4)4xx:客户端错误类信息(例如请求的是一个不存在的内容，404 not found)(5)5xx:服务端错误信息","categories":[{"name":"http","slug":"http","permalink":"http://yoursite.com/categories/http/"}],"tags":[]},{"title":"web服务","slug":"web服务","date":"2019-02-20T14:49:00.000Z","updated":"2019-02-20T15:51:02.821Z","comments":true,"path":"2019/02/20/web服务/","link":"","permalink":"http://yoursite.com/2019/02/20/web服务/","excerpt":"","text":"1、http定义http:hypertext transfer protocol，超文本传输协议超文本:带有超级链接的文本，基于这些链接，能够使得文档之间相互跳转 2、http版本:（1）http 0.9版本:仅支持纯文本，仅支持GET方法（2）http 1.0版本:除了GET方法，还支持PUT、POST、DELETEGET:从远程服务器上直接获取文件到本地之后以浏览器的方式展示PUT:从远程服务器直接获取文件到本地POST:提交数据或表单到服务器上DELETE:从远程服务器上删除文件备注:http method有8种，分别是GET、PUT、POST、DELETE、HEAD（只返回首部，不返回主体内容）、TRACE、OPTIONS、CONNECTION，最常用的是前面4种 最大的改进是引进了MIMEMIME:Multipurpose Internet Mail Extension，多用途互联网邮件扩展，就是将非文本数据在传输前重新编码成文本格式，接收方能够用相反的将其还原成原来的格式，还能够调用相应的程序来打开此文件备注:a、通过协议首部告知接收方（也就是浏览器）自己的类型，然后浏览器在收到之后就会调用相关的插件来展示b、早期的传输邮件是通过SMTP协议来传输的，只能传输纯文本，所以叫做简单文件传输协议。后来SMTP引进了MIME，所以现在邮件可以传输的不仅仅是纯文本，还有图片、mp3等 还引进了缓存的机制缓存的意义:因为http是基于tcp传输的，tcp连接包含了3次握手、4次挥手，所以传输的时间会很久。此时缓存就可以加速你访问网页的速度，加速系统资源访问，还可以节省带宽。其实页面刷新就是清除缓存，也就是无论本地缓存是否存在，都重新去服务端下载一次文件（3）http 1.1版本:增强了缓存的功能，引进了长连接的功能长连接：连接不断开，直到超时好处:同一客户端发起第二个请求的时候，尽可能的缩短时间并降低服务端的资源利用率坏处:服务器并发量巨大的时候，后面来的请求就很难建立连接。但是绝大多数情况下，如果你的连接请求不是大到一定请求的时候，使用长连接的方式可以显著的提高服务器的性能 3、http概念（1）html:hypertext mark language，超文本标记语言（开发超文本的语言）（2）URI:Uniform Resource Indentifier，统一资源标识符（3）URL:Uniform Resource Locator，统一资源定位符（URI的子集）（4）web资源:多个资源很可能会被整合为一个html文档，也叫web对象（5）动态网页:服务端存储的文档非html格式，而是编程语言开发的脚本。客户端访问服务端的时候，会将自身浏览器的属性数据（比如ip、浏览器类型等）作为参数传给服务端的脚本，脚本接受参数之后在服务端执行一次。就动态语言来说，是什么类型的语言编写的脚本就调用相对应的解析器来解析。脚本执行完之后会生成html格式的文档发给客户端。不同的客户端获取的结果可能不一样。备注：a、动态网页不同于flash、java的applet所展示的动态效果（动态网页和动态效果不是同一个概念）b、动态网页包括:静态内容（不需要通过脚本执行，直接是一个文档或者是一张图片等等）；动态内容（需要脚本执行生成html文档之后返回客户端）web监听方式（web服务器怎么知道有客户端来访问资源）:以去饭馆吃饭举例a、阻塞:阻塞的方式就是一直盯着饭菜有没有做好，不能去干别的事b、非阻塞:非阻塞的方式就是在等菜的时候可以出去玩或者干别的事，过一段时间再回来看饭菜有没有做好，这种方式也叫轮询","categories":[{"name":"http","slug":"http","permalink":"http://yoursite.com/categories/http/"}],"tags":[]},{"title":"mysql管理视图","slug":"mysql管理视图","date":"2019-01-31T06:28:00.000Z","updated":"2019-01-31T06:35:36.366Z","comments":true,"path":"2019/01/31/mysql管理视图/","link":"","permalink":"http://yoursite.com/2019/01/31/mysql管理视图/","excerpt":"","text":"1、定义视图就是存储下来的select语句，基于基表的查询结果 2、管理视图（1）查看创建视图的帮助：help create view;（2）创建视图：create view view_name as select * from tb_name;说明：view_name的结果来自于select语句（3）删除视图：drop view view_name; 备注：1、视图一般在限定某个用户在查询数据表的时候，只能查看特定的字段的时候使用。其他情况下一般不建议使用视图。2、一种特殊的视图：物化视图，可以将select的结果，也就是select生成的视图缓存下来。好处：节省资源坏处：基表更新和虚表不一致因此，对于更新不频繁的数据表，可以使用物化视图。但是，mysql不支持物化视图，也不支持在视图上创建索引。3、查看之前的某个对象是怎样创建的：SHOW CREATE TABLE tb_name;4、mysql -e “SHOW DATABASES”;说明：在命令行中执行sql语句，并返回sql语句执行的结果","categories":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/categories/mysql/"}],"tags":[]},{"title":"mysql管理数据库、数据表和索引","slug":"mysql管理数据库、数据表和索引","date":"2019-01-30T14:16:00.000Z","updated":"2019-01-30T14:45:48.152Z","comments":true,"path":"2019/01/30/mysql管理数据库、数据表和索引/","link":"","permalink":"http://yoursite.com/2019/01/30/mysql管理数据库、数据表和索引/","excerpt":"","text":"1、数据库操作（1）查看创建数据库的帮助：help create database（2）创建数据库：CREATE SCHEMA students CHARACTER SET ‘gbk’ COLLATE ‘gbk_chinese_ci’说明：CHARACTER定义字符集，COLLATE定义排序规则，SCHEMA跟DATABASE意思一样。在mysql的students数据库目录中会生成db.opt文件，里面保存着字符集和排序规则的相关信息。 （3）修改数据库：针对数据库修改的就只有两项，字符集和排序规则alter schema character set=’xxx’alter schema collate=’xxx’（4）删除数据库：drop schema db_name 2、数据表操作（1）查看创建数据表的帮助：help create table（2）创建数据表：（有三种方法）方法一、直接定义一张空表：CREATE TABLE tb1(id INT UNSIGNED NOT NULL AUTO_INCREMENT PRIMARY KEY,name CHAR(20),age TINYINT NOT NULL)说明：使用AUTO_INCREMENT的字段必须使用定义为主键类似于下面这种写法：CREATE TABLE tb2(id INT UNSIGNED NOT NULL AUTO_INCREMENT,name CHAR(20),age TINYINT NOT NULL,PRIMARY KEY(id))说明：PRIMARY_KEY可以单独定义，然后在括号中指明是作用在哪个字段上即可。如果是多个字段定义为键的话必须使用这种方法方法二、从其他表中查询出数据，并以之创建新表CREATE TABLE tb3 SELECT * FROM tb1 WHERE id &lt;=2;方法三、以其他表为模板创建一个空表CREATE TABLE tb4 LIKE tb1;（3）修改数据表：alter table添加、删除、修改字段 说明：修改是modify、change添加、删除、修改索引例子：ALTER TABLE tb1 ADD PRIMARY KEY(id) REFERENCE tb2(id);说明：外键约束只能用于支持事务的存储引擎上，也就是InodeDB上，Myisam不支持事务，因此不支持外键的使用。外键约束可以防止误删，但是外键约束在一定程度上也会消耗系统资源修改表引擎：ALTER TABLE tb1 ENGINE=InnodeDB;（4）删除数据表DROP TABLE tb_name [RESTRICT|CASCADE];说明：restrict：如果想要删除父表的记录时，而在子表中有关联该父表的记录，则不允许删除父表中的记录cascade：表示级联，会同时删除与之有外键约束关系的表 3、索引操作（1）查看创建索引的帮助：HELP CREATE INDEX;（2）创建索引：CREATE INDEX index_name ON tb_name(col_name); #用于哪张表的哪个字段CREATE INDEX index_name ON tb_name(col_name(#num));用于哪张表的哪个字段的前num个字符上（3）查看索引：SHOW INDEXES FROM tb_name;（4）删除索引：DROP INDEX index_name ON tb_name(col_name);说明：索引不能修改，要修改只能先删除再创建即可 备注：1、键和索引的区别：键也称作约束，可用作索引，属于特殊索引2、主键和唯一键的区别：主键和唯一键都是唯一标识字段的；每张表只能有一个主键，但是每张表可以有多个唯一键；主键不能为空，唯一键可以为空；","categories":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/categories/mysql/"}],"tags":[]},{"title":"mysql单表查询、多表查询和子查询","slug":"mysql单表查询、多表查询和子查询","date":"2019-01-30T09:41:00.000Z","updated":"2019-01-30T09:42:18.447Z","comments":true,"path":"2019/01/30/mysql单表查询、多表查询和子查询/","link":"","permalink":"http://yoursite.com/2019/01/30/mysql单表查询、多表查询和子查询/","excerpt":"","text":"1、单表查询例子：SELECT FROM tb_name;SELECT field1,field2 FROM tb_nmae； –投影SELECT [DISTINCT] FROM tb_name WHERE condition; –选择,WHERE子句后面接的字段不一定是SELECT接的字段 where子句：（1）符号匹配=，!=，&gt;,&gt;=,&lt;,&lt;=说明：等号也可以用来比较字符串，字符串需要加引号（2）组合条件&amp;&amp;：and||：or!：not（3）模糊匹配使用通配符百分号(%)：匹配任意长度的任意字符下划线：匹配任意单个字符（4）正则表达式regexp ‘正则表达式’（5）离散取值和连续取值离散取值：in连续取值：between..and..（6）比较空值is null、is not null select扩展：（1）order by filed_name {asc|desc}说明：排序，asc是正序，默认也是正序，desc是逆序（2）as取别名，as可以省略，后面可以直接引用别名（3）limit：只显示某些行例子：limit 2：最终结果只显示2个limit 2，3：最终结果偏移2个，然后显示接下来的3个（4）聚合计算sum()，求总和avg()，求平均值min()，求最小值max()，求最大值count()，求数量（5）group by分组，主要是做聚合计算（一般来说，不是求聚合函数的就不要分组）（6）having对分组后的结果过滤，也就是说，对group by后的结果进行过滤必须用having，不能用where 2、多表查询（1）交叉连接select * from tb1,tb2说明：tb1和tb2做笛卡尔乘积（2）自然连接：对应字段必须保持等值关系select tb1.xxx,tb2.xxx from tb1,tb2 where tb1.xxx=tb2.xxx说明：可以加别名（3）外连接左外连接：（左表）left join （右表）on (条件)右外连接：（右表）right join (左表) on (条件)例子：比如说，左表是课程表，右表是学生信息如果以课程表为标准，如果课程表有学生选择，就显示出来，课程没人选就显示为null。这就叫做左外连接；如果以学生为标准，如果学生有选课，就显示出来，没选课就显示为null。这就叫做右外连接。（4）自连接要连接的两个数据表在同一张表中，from tb1 as name1,tb1 as name2同一张表，起两个别名 3、子查询一个查询中嵌套另一个查询（1）在where子句中使用SELECT NAME FROM student WHERE Age &gt; (SELECT AVG(age) FROM student);说明：查询出大于平均年龄的学生不能这样写：SELECT NAME FROM student WHERE Age &gt; AVG(Age)SELECT NAME FROM student WHERE Age IN (SELECT age FROM tutor)说明：in的使用（2）在from子句中使用这种情况下一般可以使用联合查询(UNION)例子：(SELECT col1,col2 FROM tb1) UNION (SELECT col1,col2 FROM tb2)","categories":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/categories/mysql/"}],"tags":[]},{"title":"MySQL数据类型和sqlmode","slug":"sqlmode","date":"2019-01-30T03:25:00.000Z","updated":"2019-01-30T03:42:30.029Z","comments":true,"path":"2019/01/30/sqlmode/","link":"","permalink":"http://yoursite.com/2019/01/30/sqlmode/","excerpt":"","text":"一些比较特殊的数据类型：float（m,n） #整数占m位，小数点后占n位enum和set:enum：枚举列出的值set：可以随意组合列出的值例子：ENUM(‘A’,’B’) #’A’,’B’SET(‘A’,’B’) #’A’,’B’,’AA’,’BB’,’AB’,’BA’备注：set存储的方式比较特殊，不是存储字符，而是存储每个字符的索引下标 查看sql模式：show global variables like ‘sql_mode’;或者：select @@global.sql_mode;备注：1、@@变量名：表示显示服务器变量2、如果是一个@，表示显示自定义变量3、如果是设置变量，set global|session sql_mode=’xxx’ MYSQL的服务器变量：按作用域区分，分为两类：1.全局变量(对所有用户生效) #SHOW GLOBAL VARIABLES2.会话变量(只对会话生效) #SHOW [SESSION] VARIABLES AUTO_INCREMENT:(自动加1)修饰的字段必须满足以下几个条件：整型、无符号、非空、主键或者唯一键例子：CREATE TABLE test(ID INT UNSIGNED AUTO_INCREATEMENT NOT NULL PRIMARY KEY,name CHAR(20)) 存储引擎：1、mysql默认的是myisam和innodeDB两种存储引擎(通用引擎，除这两种之外的其他都是辅助的存储引擎)；2、存储引擎是表类型，是表级别的概念，不是数据库级的概念，一个数据库中的不同表可以使用不同的存储引擎。3、显示当前数据库所支持的所有存储引擎：show engines4、显示当前表所用的存储引擎：SHOW TABLE STATUS LIKE ‘TABLE_NAME’\\G;（显示一个表的属性信息）","categories":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/categories/mysql/"}],"tags":[]},{"title":"docker存储篇","slug":"docker存储篇","date":"2019-01-29T07:33:00.000Z","updated":"2019-01-29T08:45:45.448Z","comments":true,"path":"2019/01/29/docker存储篇/","link":"","permalink":"http://yoursite.com/2019/01/29/docker存储篇/","excerpt":"","text":"主题一、存储数据（1）storage driver定义：docker支持多种storage driver，有AUFS、Device Mapper、Btrfs、OverlayFS、VFS和ZFS。它们都能实现分层的架构，同时又有各自的特性。优选：对于选择哪种storage driver，docker官方给出了一个简单的答案，就是优先使用linux发行版默认的storage driver。查看：可以通过docker info查看driver 由上图可以看出，Centos用的是overlay2，底层文件系统是extfs，各层数据存放在/var/lib/docker优缺点：优点是对于某些容器，直接将数据放在由 storage driver 维护的层中是很好的选择，比如那些无状态的应用。无状态意味着容器没有需要持久化的数据，随时可以从镜像直接创建。比如 busybox，它是一个工具箱，我们启动 busybox 是为了执行诸如 wget，ping 之类的命令，不需要保存数据供以后使用，使用完直接退出，容器删除时存放在容器层中的工作数据也一起被删除；缺点是对于有持久化数据的需求，容器启动时需要加载已有的数据，容器销毁时希望保留产生的新数据，也就是说，这类容器是有状态的。这就要用到 Docker 的另一种存储机制：Data Volume。 （2）data volume定义：Data Volume 本质上是 Docker Host 文件系统中的目录或文件，能够直接被 mount 到容器的文件系统中。特点：Data Volume 是目录或文件，而非没有格式化的磁盘（块设备）；容器可以读写 volume 中的数据；volume 数据可以被永久的保存，即使使用它的容器已经销毁。类型：bind mount：定义：将host上已存在的目录或文件mount到容器例子：1、docker host上有目录$HOME/htdocs： 2、通过-v将其 mount 到 httpd 容器： -v的格式为:。/usr/local/apache2/htdocs 就是 apache server 存放静态文件的地方。由于 /usr/local/apache2/htdocs 已经存在，原有数据会被隐藏起来，取而代之的是 host $HOME/htdocs/ 中的数据，这与 linux mount命令的行为是一致的。3、查看httpd容器的ip： 4、在docker host上用curl验证： curl 显示当前主页确实是 $HOME/htdocs/index.html 中的内容5、更新一下，看是否能生效： 6、将容器删除，验证对bind mount的影响： 结论：数据依然存在。说明bind mount是docker host系统中的数据，只是借给容器使用7、设置权限： ro设置了只读权限，在容器中是无法对bind mount数据进行修改的。只有host有权修改数据，提高了安全性。8、除了mount目录，bind mount还可以单独指定一个文件： 使用 bind mount 单个文件的场景是：只需要向容器添加文件，不希望覆盖整个目录。在上面的例子中，我们将 html 文件加到 apache 中，同时也保留了容器原有的数据。使用单一文件有一点要注意：host 中的源文件必须要存在。 docker managed volume：定义：使用bind mount指定的时候有一个缺点，就是bind mount 需要指定 host 文件系统的特定路径，这就限制了容器的可移植性，当需要将容器迁移到其他 host，而该 host 没有要 mount 的数据或者数据不在相同的路径时，操作会失败。因此引出来docker managed volume，移植性更好的方式是 docker managed volume。例子：1、docker managed volume 与 bind mount 在使用上的最大区别是不需要指定 mount 源，指明 mount point 就行了： 通过 -v 告诉 docker 需要一个 data volume，并将其 mount 到 /usr/local/apache2/htdocs。2、查看data volume的位置：docker inspect 28534a2a1452ce(这是容器的短ID)，主要关心mount部分： 这里会显示容器当前使用的所有 data volume，Source 就是该 volume 在 host 上的目录3、查看volume里面的内容： volume 的内容跟容器原有 /usr/local/apache2/htdocs 完全一样。这是因为如果 mount point 指向的是已有目录，原有数据会被复制到 volume 中。我们可以像 bind mount 一样对数据进行操作，例如更新数据。4、通过docker volume查看volume： 备注：总结docker managed volume 的创建过程1、容器启动时，简单的告诉 docker “我需要一个 volume 存放数据，帮我 mount 到目录 /abc”。2、docker 在 /var/lib/docker/volumes 中生成一个随机目录作为 mount 源。 两种类型的比较：相同点：两者都是host文件系统中的某个路径不同点： 两种类型的使用场景：数据层，或者说镜像层和容器层（storage driver）和volume（data volume）都可以用来存放数据，各自的使用场景：1、Database软件vs Database数据2、web应用 vs web应用产生的日志3、数据分析软件 vs input/output数据4、Apache server vs 静态html文件结论：1、这四种场景中，前者都应该放在数据层，因为这部分内容是无状态的，应该作为镜像的一部分；2、后者放在data volume。因为这是需要持久化的数据，并且应该与镜像分开存放。 主题二：共享数据（1）容器与host共享数据我们有两种类型的 data volume，它们均可实现在容器与 host 之间共享数据，但方式有所区别。bind mount：直接将要共享的目录 mount 到容器。docker managed volume：由于 volume 位于 host 中的目录，是在容器启动时才生成，所以需要将共享数据拷贝到 volume 中。 备注：docker cp 可以在容器和 host 之间拷贝数据，当然我们也可以直接通过 Linux 的 cp 命令复制到 /var/lib/docker/volumes/xxx（2）容器与容器共享数据方法一：原理：将共享数据放在 bind mount 中，然后将其 mount 到多个容器。例子：1、我们要创建由三个 httpd 容器组成的 web server 集群，它们使用相同的 html 文件： 2、修改 volume 中的主页文件，再次查看并确认所有容器都使用了新的主页： 方法二：原理：用 volume container 共享数据特点：1、与 bind mount 相比，不必为每一个容器指定 host path，所有 path 都在 volume container 中定义好了，容器只需与 volume container 关联，实现了容器与 host 的解耦。2、使用 volume container 的容器其 mount point 是一致的，有利于配置的规范和标准化，但也带来一定的局限，使用时需要综合考虑。 例子：1、volume container 是专门为其他容器提供 volume 的容器。它提供的卷可以是 bind mount，也可以是 docker managed volume 我们将容器命名为 vc_data（vc 是 volume container 的缩写）。注意这里执行的是 docker create 命令，这是因为 volume container 的作用只是提供数据，它本身不需要处于运行状态。容器 mount 了两个 volume：（1）bind mount，存放 web server 的静态文件。（2）docker managed volume，存放一些实用工具。2、通过docker inspect vc_data可以查看到这两个volume： 3、其他容器通过 –volumes-from 使用 vc_data 这个 volume container 4、以webapp4为例 webapp4 容器使用的就是 vc_data 的 volume，而且连 mount point 都是一样的。5、验证数据共享 结论：三个容器已经成功共享了volume container中的volume。 方法三：原理：使用data-packed volume container。其原理是将数据打包到镜像中，然后通过 docker managed volume 共享。例子：1、通过Dockerfile创建镜像 ADD将静态文件添加到容器目录 /usr/local/apache2/htdocs。VOLUME的作用与-v等效，用来创建docker managed volume，mount point 为/usr/local/apache2/htdocs，因为这个目录就是ADD添加的目录，所以会将已有数据拷贝到volume中。2、build 新镜像 datapacked 备注：htdocs要在当前目录下事先存在3、用新镜像创建 data-packed volume container 4、因为在 Dockerfile 中已经使用了 VOLUME 指令，这里就不需要指定 volume 的 mount point 了。启动 httpd 容器并使用 data-packed volume container data-packed volume container 和 volume container 的区别是：前者共享的数据是在image中的，不需要修改，任何host上的容器都能用；后者共享的是某个特定host上的数据，只有同一个host上的容器才能用。也就是说， data-packed volume 可以在任何host中使用，这就是区别。这样的方式迁移起来相当方便，但是如果数据有变动的话，只能通过重新构建image的方式来修改。用来做data-packed volume container的base image是越小越好，比如busybox 主题三、volume生命周期管理1、备份定义：因为 volume 实际上是 host 文件系统中的目录和文件，所以 volume 的备份实际上是对文件系统的备份。操作：搭建本地registry 所有的本地镜像都存在 host 的 /myregistry 目录中，我们要做的就是定期备份这个目录。2、恢复定义：volume 的恢复也很简单，如果数据损坏了，直接用之前备份的数据拷贝到 /myregistry 就可以了。3、迁移如果我们想使用更新版本的 Registry，这就涉及到数据迁移，方法是：（1）docker stop 当前 Registry 容器。（2）启动新版本容器并 mount 原有 volumedocker run -d -p 5000:5000 -v /myregistry:/var/lib/registry registry:latest4、销毁对于bind mount，docker 不会销毁 bind mount，删除数据的工作只能由 host 负责。对于 docker managed volume，在执行 docker rm 删除容器时可以带上 -v 参数，docker 会将容器使用到的 volume 一并删除，但前提是没有其他容器 mount 该 volume，目的是保护数据。如果没有带上-v参数，这样会产生孤立volume。例子：（1）使用docker managed volume 可以创建一个容器bbox （2）删除bbox （3）因为没有使用 -v，volume 遗留了下来。对于这样的孤儿 volume，可以用 docker volume rm 删除 （4）也可以这样删除孤儿 volume： docker volume prune如果想批量删除孤儿 volume，可以执行：docker volume rm $(docker volume ls -q) 最后总结：1、docker 为容器提供了两种存储资源：数据层和 Data Volume。2、数据层包括镜像层和容器层，由 storage driver 管理。3、Data Volume 有两种类型：bind mount 和 docker managed volume。4、bind mount 可实现容器与 host 之间，容器与容器之间共享数据。5、volume container 是一种具有更好移植性的容器间数据共享方案，特别是 data-packed volume container。6、备份、恢复、迁移和销毁 Data Volume。","categories":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/categories/docker/"}],"tags":[]},{"title":"docker网络篇","slug":"docker网络篇","date":"2019-01-29T01:36:00.000Z","updated":"2019-01-29T02:56:27.454Z","comments":true,"path":"2019/01/29/docker网络篇/","link":"","permalink":"http://yoursite.com/2019/01/29/docker网络篇/","excerpt":"","text":"1、四个网络定义：docker安装时会自动在host上创建三个网络，可以通过docker network ls命令查看 （1）none网络定义：顾名思义，none网络就是什么都没有的网络。挂在这个网络下的容器除了lo，没有其他任何网卡。容器创建时，可以通过–network=none指定使用none网络。 应用场景：封闭意味着隔离，一些对安全性要求高并且不需要联网的应用可以使用none网络。比如某个容器的唯一用途就是生成随机密码，就可以放到none网络中避免密码被窃取。 命令：指定使用none网络 （2）host网络定义：连接到host网络的容器共享docker host的网络栈，容器的网络配置与host完全一样。可以通过–network=host来指定使用host网络。 应用场景：直接使用docker host网络的最大好处就是性能，如果容器对网络传输效率有较高要求，则可以选择host网络。当然不便之处就是牺牲一些灵活性，比如要考虑端口冲突问题，docker host上已经使用的端口就不能再使用了。 命令：指定使用host网络 容器的hostname也跟宿主机一样 （3）bridge网络（默认）定义：docker安装时会创建一个命名为docker0的linux bridge。如果不指定–network，创建的容器默认都会挂到docker0上。 命令：一个新的网络接口vethad723e1被挂到了docker0上，vethad723e1就是新创建容器的虚拟网卡。 查看容器的网络配置 对比docker0和容器的interface，实际上vethad723e1和eth0@if109是一对veth pair。veth pair是一种成对出现的特殊网络设备，可以把它们想象成由一根虚拟网线连接起来的一对网卡，网卡的一头（eth0@if109）在容器中，另一头（vethad723e1）挂在网桥docker0上，其效果就是将eth0@if109 也挂在了 docker0 上。其中，eth0@if109的ip地址是172.17.0.3/16，这个网段的ip是由bridge网络的配置决定的。查看bridge网络的配置信息 （4）自定义网络定义：除了none、host、bridge这三个自动创建的网络，用户也可以根据业务需要创建user-defined网络。docker提供了三种user-defined网络驱动：bridge、overlay和macvlan。 命令：新增了一个网桥br-30ff061f03ca 查看my_net的配置信息 除了可以自动分配，还可以自定义ip网段 容器使用新的网络，使用自动分配的ip 除了可以自动分配，还可以指定ip地址 备注：只有使用–subnet创建的网络才能指定静态ip。如果容器使用不是–subnet创建的网络，指定ip地址时会返回错误。 2、容器与容器的相互访问同一网络之间的容器通信：有三种通信方式（1）IP两个容器要能通信，必须要有属于同一网络的网卡。具体做法是在创建容器时通过–network指定相应的网络，或者通过docker network connect将现有网络加入到指定网络。参考之前的章节。（2）docker dns server通过ip访问会有一个问题：我们在部署应用之前有可能无法确定ip，部署之后再指定要访问的ip会比较麻烦。针对这个问题，可以通过docker自带的dns服务来解决。原理：从docker1.10版本开始，docker daemon实现了一个内嵌的dns server，使容器可以直接通过容器名通信。方法很简单，只要在启动时使用–name为容器命名就可以了。实验一：启动两个容器：docker run -it –network=my_net2 –name=bbox1 busyboxdocker run -it –network=my_net2 –name=bbox2 busybox验证ping测试： 结论：可以ping通。 实验二：创建两个bridge网络下的容器：docker run -it –name=bbox3 busyboxdocker run -it –name=bbox4 busybox验证ping测试： 结论：使用dns有限制，只能在自定义网络（my_net2就是自定义网络）中使用。也就是说，默认的bridge网络是无法使用dns的。（3）joined原理：可以使两个或多个容器共享一个网络栈、网卡和配置信息，joined容器之间可以通过127.0.0.1直接通信适用场景：不同容器中的程序希望通过loopback高效快速的通信，比如web server与app server；希望监控其他容器的网络流量，比如运行在独立容器中的网络监控程序。验证：先创建一个httpd容器，名字为web1：docker run -d -it –name=web1 httpd然后创建busybox容器并通过–network=container:web1指定joined容器为web1 查看web1容器的网络配置信息： 结论：busybox与web1的网卡mac地址与ip地址完全一样，它们共享了相同的网络栈。 不同网络之间的容器通信：首先，由常识可知，同一网络中的容器、网关之间都是可以相互通信的。也可以通过实验验证。但是，自定义网络（my_net2）与默认bridge网络之间默认不能相互通信。针对这个问题，我们可以通过添加路由来达到不同网络之间的同期也能相互通信的目的。也就是说，如果host上针对每个网络都有一条路由，同时操作系统上打开了ip forwarding，host就成了一个路由器，挂接在不同网桥上的网络就能够相互通信。验证：首先，定义172.17.0.0/16和172.22.16.0/24两个网络的路由： 确认打开了ip转发功能：sysctl net.ipv4.ip_forward或者cat /proc/sys/net/ipv4/ip_forward，值为1表示打开了ip转发功能为httpd容器（位于bridge网络）添加一块my_net2的网卡，添加命令： 在httpd容器中查看网络配置（红框中为新加的网卡，ip地址是my_net2端随机分配的ip，这时候就可以在位于my_net2的容器ping通httpd容器）： 容器与外部的相互访问：（1）容器访问外部定义：容器默认就能访问外网（外网指的是容器网络以外的网络环境，并非特指Internet）原理：最关键的就是NAT技术验证首先，查看一下host的iptables规则： 这条iptables规则的含义：如果网桥 docker0 收到来自 172.17.0.0/16 网段的外出包，把它交给 MASQUERADE 处理。而 MASQUERADE 的处理方式是将包的源地址替换成 host 的地址发送出去，即做了一次网络地址转换（NAT）。通过tcpdump查看地址转换：首先，查看host的路由表：默认路由通过eth0发送出去，所以我们可以通过tcpdump来监控docker0和eth0上的icmp数据包 然后，在busybox容器上ping外网（比如www.bing.com），tcpdump输出如图：docker0 收到 busybox 的 ping 包，源地址为容器 IP 172.17.0.4，然后交给 MASQUERADE 处理。 这时在eth0上查（发现ping包的源地址变成了144.34.204.150） （2）外部访问容器原理：端口映射验证首先，docker可以将容器对外提供服务的端口映射到host的某个端口，外网通过该端口访问容器。 容器启动后，可以通过docker ps或者docker port查看到host映射的端口。在上面的例子中，httpd容器的80端口被映射到host 32769上，这样就可以通过 : 访问容器的 web 服务了。也可以指定映射到host的某个特定端口： 每一个映射的端口，host都会启动一个docker-proxy进程来处理访问容器的流量： 最后，过程总结：docke-proxy监听host的32769端口；当访问宿主机的web服务的时候（宿主机的ip:port），docker-proxy 转发给容器(容器ip:容器port）；httpd 容器响应请求并返回结果。","categories":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/categories/docker/"}],"tags":[]},{"title":"广域网技术","slug":"广域网技术","date":"2019-01-25T08:06:00.000Z","updated":"2019-01-25T08:28:37.989Z","comments":true,"path":"2019/01/25/广域网技术/","link":"","permalink":"http://yoursite.com/2019/01/25/广域网技术/","excerpt":"","text":"1、基础概述（1）定义WAN–广义网，大范围网络，常常是一个国家或者一个州（2）设备路由器–支持不同类型的网络接口，实现不同网络类型互联 2、基础术语（1）上行/下行 （2）同步/异步 （3）串行/并行 3、连接类型（1）专线连接 E1：2MT1：1.544M优点：线缆专用，带宽恒定缺点：价格昂贵（2）电路连接 （3）分组交换 （4）信元交换固定长度的分组就是信元 4、WAN协议（1）HDLC定义：高级数据链路控制协议–Cisco私有 概念：DTE：数据终端设备DCE：数据通信设备配置：第一步，首先确定DTE与DCE的时钟频率一致：查看时钟频率 配置时钟频率 第二步，进行协议配置：配置端口协议 查看端口协议 （2）PPP定义：point-to-point协议 配置： 认证：PAP认证（明文）：PAP认证过程： PAP认证配置： CHAP认证（密文）：分为双向CHAP和单向CHAP双向CHAP认证过程： 双向CHAP认证配置： 单向CHAP认证过程： 单向CHAP认证配置： 链路捆绑：定义： 配置： 查看： （3）frame-relayWHYframe-relay出现之前:拓扑复杂： 查询复杂： frame-relay出现之后：拓扑简洁： 查询简单： WHAT术语：DLCI：数字链路连接标识符标签：tag接口类型：DTE、DCE、NNI信令类型：cisco、q933a、ansi(同一线缆上信令类型必须一致)电路类型：VC(虚拟电路)、PVC(永久虚电路)、SVC(短暂虚电路)HOW拓扑图： 静态配置： R1： R2： R3： 动态配置： 查看配置：","categories":[{"name":"网络基础","slug":"网络基础","permalink":"http://yoursite.com/categories/网络基础/"}],"tags":[]},{"title":"NAT技术","slug":"NAT技术","date":"2019-01-25T07:56:00.000Z","updated":"2019-01-25T08:04:28.457Z","comments":true,"path":"2019/01/25/NAT技术/","link":"","permalink":"http://yoursite.com/2019/01/25/NAT技术/","excerpt":"","text":"1、WHY为什么需要NAT？私网设备与公网设备不会运行任何路由协议上网流量：默认路由出去，精细路由回来 2、WHATNAT类型：（1）静态NAT：一对一映射 （2）动态NAT：多对多映射 （3）PAT：端口复用 3、HOW配置：（1）静态NAT （2）动态NAT （3）PAT","categories":[{"name":"网络基础","slug":"网络基础","permalink":"http://yoursite.com/categories/网络基础/"}],"tags":[]},{"title":"ACL技术","slug":"ACL技术","date":"2019-01-25T07:35:00.000Z","updated":"2019-01-25T07:53:51.736Z","comments":true,"path":"2019/01/25/ACL技术/","link":"","permalink":"http://yoursite.com/2019/01/25/ACL技术/","excerpt":"","text":"1、ACL定义访问控制列表–定义感兴趣流量 2、ACL规则（1）编号：条目编号默认以10递增，方便ACL后期修改（2）查看：从上到下查看，一旦匹配规则，立即执行，后面规则不再查看（3）特性：条目最后隐藏一条拒绝所有语句；本地流量不过滤 3、ACL分类按编号分类：（1）标准ACL：编号1到99，只能定义源IP （2）扩展ACL：编号100到199，能定义源IP、目的IP、协议、端口号 按功能分类：（1）时间ACL概念：绝对时间（absolute）–即这个时间只生效一次，比如 2010年1 月1 月15:00周期时间（periodic）–即这个时间是会多次重复的，比如每周一需求： 配置： 查看： （2）自反ACL需求： 过程： 配置： （3）lock&amp;key ACL需求： 过程： 配置： 4、ACL命令（1）调用 （2）命名 （3）插入 （4）删除 （5）查看","categories":[{"name":"网络基础","slug":"网络基础","permalink":"http://yoursite.com/categories/网络基础/"}],"tags":[]},{"title":"Centos7安装mongoDB","slug":"Centos7安装mongoDB","date":"2019-01-24T09:04:00.000Z","updated":"2019-01-24T09:06:44.414Z","comments":true,"path":"2019/01/24/Centos7安装mongoDB/","link":"","permalink":"http://yoursite.com/2019/01/24/Centos7安装mongoDB/","excerpt":"","text":"1、配置mongoDB的yum源vim /etc/yum.repos.d/mongodb-org-3.4.repo #添加以下内容：[mongodb-org-3.4]name=MongoDB Repositorybaseurl=https://repo.mongodb.org/yum/redhat/$releasever/mongodb-org/3.4/x86_64/gpgcheck=1enabled=1gpgkey=https://www.mongodb.org/static/pgp/server-3.4.asc #这里可以修改 gpgcheck=0, 省去gpg验证[root@localhost ~]# yum makecache 2、安装MongoDB安装命令：yum -y install mongodb-org 3、查看mongo安装位置whereis mongod 4、启动mongoDBsystemctl start mongod.service","categories":[{"name":"安装篇","slug":"安装篇","permalink":"http://yoursite.com/categories/安装篇/"}],"tags":[]},{"title":"mongoDB的图形化软件","slug":"mongoDB的图形化软件","date":"2019-01-23T02:18:00.000Z","updated":"2019-01-23T02:18:53.104Z","comments":true,"path":"2019/01/23/mongoDB的图形化软件/","link":"","permalink":"http://yoursite.com/2019/01/23/mongoDB的图形化软件/","excerpt":"","text":"nosqlbooster for mongodb:","categories":[{"name":"QA","slug":"QA","permalink":"http://yoursite.com/categories/QA/"}],"tags":[]},{"title":"telnet mongod端口连接失败","slug":"telnet-mongod端口连接失败","date":"2019-01-23T01:34:00.000Z","updated":"2019-01-23T01:40:26.902Z","comments":true,"path":"2019/01/23/telnet-mongod端口连接失败/","link":"","permalink":"http://yoursite.com/2019/01/23/telnet-mongod端口连接失败/","excerpt":"","text":"mongodDB端口号27017，已在防火墙上放行27017端口，但是在本地telnet端口提示连接失败，如图： 解决方法：在mongoDB的配置文件有一个bind_ip的配置，默认值为127.0.0.1，默认只有本机可以连接。此时，需要将bind_ip配置为0.0.0.0，表示接受任何IP的连接。 然后重启mongoDB:service mongod restart这时候再telnet 27017就可以了","categories":[{"name":"QA","slug":"QA","permalink":"http://yoursite.com/categories/QA/"}],"tags":[]},{"title":"ECS（容器代理、安全性）","slug":"ECS（容器代理、安全性）","date":"2019-01-14T06:18:00.000Z","updated":"2019-01-14T06:18:32.237Z","comments":true,"path":"2019/01/14/ECS（容器代理、安全性）/","link":"","permalink":"http://yoursite.com/2019/01/14/ECS（容器代理、安全性）/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[]},{"title":"ECS（调度、集群）","slug":"ECS（调度、集群）","date":"2019-01-14T06:17:00.000Z","updated":"2019-01-14T06:17:22.956Z","comments":true,"path":"2019/01/14/ECS（调度、集群）/","link":"","permalink":"http://yoursite.com/2019/01/14/ECS（调度、集群）/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[]},{"title":"ECS（fargate、两种模式）","slug":"ECS（fargate、两种模式）","date":"2019-01-14T06:15:00.000Z","updated":"2019-01-14T06:15:55.492Z","comments":true,"path":"2019/01/14/ECS（fargate、两种模式）/","link":"","permalink":"http://yoursite.com/2019/01/14/ECS（fargate、两种模式）/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[]},{"title":"ECS（任务定义）","slug":"ECS（任务定义）","date":"2019-01-14T06:13:00.000Z","updated":"2019-01-14T06:14:18.488Z","comments":true,"path":"2019/01/14/ECS（任务定义）/","link":"","permalink":"http://yoursite.com/2019/01/14/ECS（任务定义）/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[]},{"title":"ECS（定义、特点）","slug":"ECS（定义、特点）","date":"2019-01-14T06:12:00.000Z","updated":"2019-01-14T06:12:29.260Z","comments":true,"path":"2019/01/14/ECS（定义、特点）/","link":"","permalink":"http://yoursite.com/2019/01/14/ECS（定义、特点）/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[]},{"title":"docker（容器与虚拟化的区别）","slug":"docker（容器与虚拟化的区别）","date":"2019-01-14T03:17:00.000Z","updated":"2019-01-14T03:18:06.343Z","comments":true,"path":"2019/01/14/docker（容器与虚拟化的区别）/","link":"","permalink":"http://yoursite.com/2019/01/14/docker（容器与虚拟化的区别）/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[]},{"title":"docker（特点、优点）","slug":"docker（特点、优点）","date":"2019-01-14T03:15:00.000Z","updated":"2019-01-14T03:16:08.327Z","comments":true,"path":"2019/01/14/docker（特点、优点）/","link":"","permalink":"http://yoursite.com/2019/01/14/docker（特点、优点）/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[]},{"title":"docker（组件）","slug":"docker（组件）","date":"2019-01-14T03:14:00.000Z","updated":"2019-01-14T03:15:03.354Z","comments":true,"path":"2019/01/14/docker（组件）/","link":"","permalink":"http://yoursite.com/2019/01/14/docker（组件）/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[]},{"title":"docker（起源、定义）","slug":"docker（起源、定义）","date":"2019-01-14T03:13:00.000Z","updated":"2019-01-14T03:13:47.242Z","comments":true,"path":"2019/01/14/docker（起源、定义）/","link":"","permalink":"http://yoursite.com/2019/01/14/docker（起源、定义）/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[]},{"title":"EC2置放群组（特点）","slug":"EC2置放群组（特点）","date":"2019-01-14T02:58:03.000Z","updated":"2019-01-14T02:58:10.336Z","comments":true,"path":"2019/01/14/EC2置放群组（特点）/","link":"","permalink":"http://yoursite.com/2019/01/14/EC2置放群组（特点）/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"EC2置放群组（定义、最佳实践）","slug":"EC2置放群组（定义、最佳实践）","date":"2019-01-14T02:56:00.000Z","updated":"2019-01-14T02:57:05.256Z","comments":true,"path":"2019/01/14/EC2置放群组（定义、最佳实践）/","link":"","permalink":"http://yoursite.com/2019/01/14/EC2置放群组（定义、最佳实践）/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[]},{"title":"弹性伸缩（扩展选项、默认的实例终止策略、与ELB搭配使用）","slug":"弹性伸缩（扩展选项、默认的实例终止策略、与ELB搭配使用）","date":"2019-01-11T09:10:00.000Z","updated":"2019-01-11T09:12:22.268Z","comments":true,"path":"2019/01/11/弹性伸缩（扩展选项、默认的实例终止策略、与ELB搭配使用）/","link":"","permalink":"http://yoursite.com/2019/01/11/弹性伸缩（扩展选项、默认的实例终止策略、与ELB搭配使用）/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[]},{"title":"弹性伸缩（启动配置、弹性伸缩组）","slug":"弹性伸缩（启动配置、弹性伸缩组）","date":"2019-01-11T09:08:00.000Z","updated":"2019-01-11T09:08:57.803Z","comments":true,"path":"2019/01/11/弹性伸缩（启动配置、弹性伸缩组）/","link":"","permalink":"http://yoursite.com/2019/01/11/弹性伸缩（启动配置、弹性伸缩组）/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[]},{"title":"弹性伸缩（定义、功能、参数）","slug":"弹性伸缩（定义、功能、参数）","date":"2019-01-11T09:04:00.000Z","updated":"2019-01-11T09:05:16.106Z","comments":true,"path":"2019/01/11/弹性伸缩（定义、功能、参数）/","link":"","permalink":"http://yoursite.com/2019/01/11/弹性伸缩（定义、功能、参数）/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[]},{"title":"bootstrap开机脚本","slug":"bootstrap开机脚本","date":"2019-01-11T08:19:00.000Z","updated":"2019-01-11T08:20:21.507Z","comments":true,"path":"2019/01/11/bootstrap开机脚本/","link":"","permalink":"http://yoursite.com/2019/01/11/bootstrap开机脚本/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[]},{"title":"EC2实例（数据类型）","slug":"EC2实例（数据类型）","date":"2019-01-11T08:11:00.000Z","updated":"2019-01-11T08:12:04.902Z","comments":true,"path":"2019/01/11/EC2实例（数据类型）/","link":"","permalink":"http://yoursite.com/2019/01/11/EC2实例（数据类型）/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[]},{"title":"vmware虚拟机：Exception 0xc000001d  has occurred.","slug":"vmware虚拟机：Exception-0xc000001d-has-occurred","date":"2019-01-11T07:39:00.000Z","updated":"2019-01-11T07:41:17.320Z","comments":true,"path":"2019/01/11/vmware虚拟机：Exception-0xc000001d-has-occurred/","link":"","permalink":"http://yoursite.com/2019/01/11/vmware虚拟机：Exception-0xc000001d-has-occurred/","excerpt":"","text":"解决方案：虚拟机设置，点击显示器，加速3D图形前面的打勾去掉即可。","categories":[{"name":"QA","slug":"QA","permalink":"http://yoursite.com/categories/QA/"}],"tags":[]},{"title":"docker容器篇","slug":"docker容器","date":"2019-01-10T07:10:00.000Z","updated":"2019-01-10T08:58:21.178Z","comments":true,"path":"2019/01/10/docker容器/","link":"","permalink":"http://yoursite.com/2019/01/10/docker容器/","excerpt":"","text":"1、运行容器指定容器启动时执行的命令的三种方法：（1）CMD命令（2）ENTRYPOINT命令（3）在docker run命令行中指定举例：（1）在容器启动时执行pwd，返回的/是容器中的当前目录 （2）执行docker ps或者docker container ls查看当前运行的容器 （3）执行docker ps -a或者docker container ls -a查看所有容器（-a会显示所有状态的容器） 可以看到容器已经退出，状态为exited 让容器保持运行状态的两种方法：（1）通过执行一个长期运行的命令来保持容器的运行状态（例如循环） 打开另外一个终端查看容器的状态缺点是：这种方法始终会占用一个终端（2）加上参数-d以后台方式启动容器 通过docker ps看到的container id是短id，短id是长id的前12个字符 停止容器：docker stop “短id” 指定容器名称：docker run –name “my_httpd_server” -d httpd docker ps可以看到容器运行的命令是httpd-foreground docker history可以知道这个命令是通过CMD指定的 2、进入容器两种进入容器的方法：（1）docker attach 通过id attach到容器的启动命令终端，然后可以看到echo每隔1秒打印hello-world（2）docker exec -it就是以交互模式打开，执行bash，其结果就是打开一个bash终端，就可以像在普通的linux中一样执行命令了。执行exit会退出容器，回到docker host（3）两者的区别attach直接进入容器启动命令的终端，不会启动新的进程；exec则是在容器中打开新的终端，并且可以启动新的进程；如果想直接在终端中查看启动命令的输出，用attach。其他情况用exec。通过docker log -f也可以查看启动命令的输出（-f与tail -f类似，能够持续打印输出） 指定容器的三种方法：（1）短ID（2）长ID（3）容器名称（通过–name为容器命名。重命名容器可以执行docker rename） 3、常用命令create：创建容器run：运行容器pause：暂停容器unpause：取消暂停stop：发送SIGTERM停止容器kill：发送SIGKILL快速停止容器start：启动容器restart：重新启动容器attach：attach到容器启动进程的终端exec：在容器中启动新进程，通常使用”-it”参数logs：显示容器启动进程的控制台输出，用”-f”持续打印rm：从磁盘中删除容器 4、资源限额内存限额：（1）内存定义：内存包含两部分，物理内存和swap（2）设置命令：-m或–memory：设置内存的使用限额，例如100M，2G–memory-swap：设置内存+swap的使用限额（备注：不单单是指swap，而是内存和swap的总和）（3）举例：例子1docker run -m 200M –memory-swap=300M ubuntu这条指令的意思是该容器最多允许使用200M的内存和100M的swap。默认上面两组参数的值为1，即对该容器内存和swap的使用没有限制 例子2docker run -it -m 200M –memory-swap=300M progrium/stress –vm 1 –vm-bytes 280M备注：–vm 1是指启动一个内存工作线程；–vm-bytes 280M是指每个线程分配280M内存运行结果： 结论：可以正常工作工作过程：分配 280M 内存。释放 280M 内存。再分配 280M 内存。再释放 280M 内存。一直循环…… 例子3docker run -it -m 200M –memory-swap=300M progrium/stress –vm 1 –vm-bytes 310M运行结果： 结论：不能正常工作工作过程：分配的内存超过限额，stress 线程报错，容器退出 备注：如果在启动容器时只指定 -m 而不指定 –memory-swap，那么 –memory-swap 默认为 -m 的两倍，比如：docker run -it -m 200M ubuntu容器最多使用 200M 物理内存和 200M swap。 CPU限额：设置命令：-c或者–cpu-shares：设置容器使用cpu的权重备注：（1）与内存限额不同，通过 -c 设置的 cpu share 并不是 CPU 资源的绝对数量，而是一个相对的权重值。也就是说，某个容器最终能分配到的 CPU 资源取决于它的 cpu share 占所有容器 cpu share 总和的比例。（2）比如说，在docker host中启动了两个容器docker run –name “container_A” -c 1024 ubuntudocker run –name “container_A” -c 512 ubuntucontainer_A 的 cpu share 1024，是 container_B 的两倍。当两个容器都需要 CPU 资源时，container_A 可以得到的 CPU 是 container_B 的两倍。（3）这种按权重分配cpu只会发生在cpu资源紧张的时候。如果 container_A 处于空闲状态，这时，为了充分利用 CPU 资源，container_B 也可以分配到全部可用的 CPU。 举例：（1）启动container_a 备注：–cpu是用来设置工作线程的数量。因为当前host只有一颗cpu，所以一个工作线程就能将cpu压满。如果host有多颗cpu，则需要相应增加–cpu的数量。（2）打开另一个终端，启动container_b （3）再打开一个终端，执行top命令 结论：container_a消耗的cpu是container_d的2倍（4）暂停container_a （5）container_b在container_a空闲的情况下可以用满整颗CPU IO限额：（1）IO定义：block io指的是磁盘的读写，docker可以通过设置权重、限制bps和iops的方式控制容器读写磁盘的带宽（2）限制IO的两种方式：设置权重：通过设置–blkio-weight参数来修改权重，默认值是500举例：container_a读写磁盘的带宽是container_b的两倍docker run -it –name container_a –blkio-weight 600 ubuntudocker run -it –name container_b –blkio-weight 300 ubuntu 限制bps和iops：（1）定义：bps：byte per second，每秒读写的数据量iops：io per second，每秒io的次数（2）可以通过以下参数控制容器的bps和iops：–device-read-bps：限制读某个设备的bps；–device-write-bps：限制写某个设备的bps；–device-read-iops：限制读某个设备的iops；–device-write-iops：限制写某个设备的iops。（3）举例：限制容器写/dev/sda的速率为30MB/sdocker run -it –device-write-bps /dev/sda:30MB ubuntu限速情况下的运行结果： 对比不限速情况下的运行结果： 备注：oflag=direct 指定用 direct IO 方式写文件，这样 –device-write-bps 才能生效 5、底层技术cgroup（1）作用：实现资源限额（2）定义：全称control group。Linux 操作系统通过 cgroup 可以设置进程使用 CPU、内存 和 IO 资源的限额。之前设置的–cpu-shares、-m、–device-write-bps 实际上就是在配置 cgroup（3）举例：启动一个容器： 查看容器ID： 查看cgroup目录： 在 /sys/fs/cgroup/cpu/docker 目录中，Linux 会为每个容器创建一个 cgroup 目录，以容器长ID 命名备注：目录中包含所有与 cpu 相关的 cgroup 配置，文件 cpu.shares 保存的就是 –cpu-shares 的配置，值为 512；同样的，/sys/fs/cgroup/memory/docker 和 /sys/fs/cgroup/blkio/docker 中保存的是内存以及 Block IO 的 cgroup 配置。 namespace（1）作用：实现资源隔离（2）定义：在每个容器中，我们都可以看到文件系统，网卡等资源，这些资源看上去是容器自己的。拿网卡来说，每个容器都会认为自己有一块独立的网卡，即使 host 上只有一块物理网卡。这种方式非常好，它使得容器更像一个独立的计算机。Linux 实现这种方式的技术是 namespace。namespace 管理着 host 中全局唯一的资源，并可以让每个容器都觉得只有自己在使用它。（3）六种namespace：六种namespace分别对应六种资源：Mount、UTS、IPC、PID、Network和User（4）六种资源：Mount namespace：Mount namespace 让容器看上去拥有整个文件系统。容器有自己的 / 目录，可以执行 mount 和 umount 命令。当然我们知道这些操作只在当前容器中生效，不会影响到 host 和其他容器； UTS namespace：UTS namespace 让容器有自己的 hostname。 默认情况下，容器的 hostname 是它的短ID，可以通过 -h 或 –hostname 参数设置； IPC namespace：IPC namespace 让容器拥有自己的共享内存和信号量（semaphore）来实现进程间通信，而不会与 host 和其他容器的 IPC 混在一起； PID namespace：容器在 host 中以进程的形式运行。例如当前 host 中运行了两个容器； Network namespace：Network namespace 让容器拥有自己独立的网卡、IP、路由等资源； User namespace：User namespace 让容器能够管理自己的用户，host 不能看到容器中创建的用户。","categories":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/categories/docker/"}],"tags":[]},{"title":"mysql基本使用","slug":"mysql数据库基础","date":"2019-01-09T07:12:00.000Z","updated":"2019-01-09T09:50:49.070Z","comments":true,"path":"2019/01/09/mysql数据库基础/","link":"","permalink":"http://yoursite.com/2019/01/09/mysql数据库基础/","excerpt":"","text":"1、mysql安装（1）专用软件包管理器：deb（ubuntu系统）和rpm(Redhat、centos、Fedora、suse系统)备注：rpm包可以由两种组织制作，一种是操作系统发行商（Redhat）制作，一种是mysql官方制作（2）通用二进制格式包gcc:x86（32位），x64（64位）（3）源代码包5.5、5.6之后的mysql不再用make编译，而是改用cmake（跨平台）；5.5、5.6本身没有提供cmake，需要自定义安装；mysql 6之后就已经集成了cmake备注：源代码方式和二进制包方式的区分（1）二进制包里面包括了已经经过编译,可以马上运行的程序。你只需要下载和解包(安装)它们以后,就马上可以使用；源代码包里面包括了程序原始的程序代码,需要在你的计算机上进行编译以后才可以产生可以运行程序，所以从源代码安装的时间会比较长。（2）二进制格式的包名字很长,都带有版本号、适应平台、适应的硬件类型等,而源码格式仅仅就是一个版本号的tar包：mysql-5.0.45.tar.gz 是源码包mysql-5.0.45-linux-x86_64-glibc23.tar.gz 是二进制包（3）源代码包里的文件往往会含有种种源代码文件,头文件.h、c代码源文件.c、C++代码源文件.cc/.cpp等;而二进制包里的文件则会有可执行文件(与软件同名的往往是主执行文件),标志是其所在路径含有名为bin的目录(仅有少数例外) 2、mysql版本alpha：内测版beta：公测版rc：发行候选版ga：通用发行版 3、进程间通信对于mysql客户端和服务端在同一主机的，不同进程间通过mysql.sock进行通信；对于mysql客户端和服务端不在同一主机的，不同进程间基于TCP/IP协议栈进行通信 4、mysql工具客户端工具（1）mysql：交互式输入SQL语句或从文件以批处理模式执行它们的命令行工具（2）mysqlaccess：检查访问主机名、用户名和数据库组合的权限的脚本（3）mysqladmin：管理工具，执行管理操作的客户程序，例如创建或删除数据库，重载授权表，将表刷新到硬盘上，以及重新打开日志文件。mysqladmin还可以用来检索版本、进程，以及服务器的状态信息。（4）mysqlbinlog：从二进制日志读取语句的工具。在二进制日志文件中包含执行过的语句，可用来帮助系统从崩溃中恢复（5）mysqlcheck：检查工具，检查、修复、分析以及优化表的表维护客户程序（6）mysqldump：备份工具，将mysql数据库转储到一个文件（7）mysqlhotcopy：当服务器在运行时，快速备份的工具（8）mysql import：导入工具，使用load data infile将文本文件导入相关表的客户程序（9）mysqlshow：显示数据库、表、列以及索引相关信息的客户程序 （1）\\d:定义语句结束符（2）\\c:提前终止语句执行(直接在后面加上\\c即可，但是加在结束符后面语句依然会执行)（3）\\r:重新连接到服务器（4）\\g:无论语句结束符是什么，直接将此语句送至服务端去执行（5）\\G:无论语句结束符是什么，直接将此语句送至服务端去执行，而且是以竖排的方式来显示(纵向显示，这对于横排显示不下一张表的时候，\\G是一种非常好的显示手段)（6）\\p:print,显示正在执行的命令（7）! COMMAND:执行shell命令(或者用system)（8）\\W:大写W表示语句执行之后显示警告信息（9）\\w:小写w表示语句执行之后不显示警告信息 服务端工具（1）mysqld：SQL后台程序（即mysql服务器进程）。该程序必须运行之后，客户端才能通过连接服务来访问数据库（2）mysqld_safe：服务器启动脚本。在Unix中推荐使用mysqld_safe来启动mysqld服务器。mysqld_safe增加了一些安全特性，例如当出现错误时重启服务器并向错误日志写入运行时间信息（3）mysql.server：服务器启动脚本。它调用mysqld_safe来启动mysql服务（4）mysql_multi：服务器启动脚本。用于启动或者停止系统上安装的多个mysql服务（5）myisampack：压缩myisam表以产生更小的只读表的一个工具（6）myisamchk：用来描述、检查、优化和维护myisam表的实用工具（7）mysql_install_db：该脚本用默认权限创建mysql授权表。通常只是在系统上首次安装mysql时执行一次备注：mysqld工具可能不在bin目录下，可能在{mysql安装目录}/mysql/libexec下 图形化工具mysql官方提供的图形化管理工具MySQL WorkbenchMySQL Workbenck也有两个版本：（1）MySQL Workbench Community Edition，也就是社区版本。（2）MySQL Workbench Standard Edition，也就是商业版本，是按年收取费用的。 其他工具mysql_configmysql在安装完后，一般在${MYSQL_HOME}/bin目录下有mysql_config工具，它不是一个二进制文件，是一个脚本工具。当我们在编译自己的mysql客户端时，可用通过mysql_config工具获取很多的有用的编译参数，例如使用mysql_config –include可以获取mysql的mysql在安装时的一些头文件位置，或者mysql_config–libs可以获取mysql的头文件及共享库等编译参数。例如：mysql_config–include #得到-I/usr/include/mysqlmysql_config –libs #得到-L/usr/lib/mysql-lmysqlclient -lz -lcrypt -lnsl -lm -L/usr/lib -lssl -lcrypto 备注：（1）修改用户密码：mysqladmin -u username -h hostname password ‘new_password’ -p ‘old_password’也可以这样修改：set password for ‘username‘@’host’=password(‘new_password’)（2）SELECT DATABASE();#查看当前使用的默认数据库连入数据库的时候，还可以通过–database db_name(或者-D db_name)来指定默认的数据库 5、mysqladmin工具mysqladmin create hellodb #不用连上数据库直接在linux命令行下创建(会读取my.cnf下的数据库的定义)mysqladmin -uroot -p password -h host_name create hellodb还有其他一些子命令，比如：mysqladmin drop db_name:删除dbmysqladmin ping:测试对方mysql服务器是否在线：mysqladmin -uroot -p -hhostname(或主机ip) pingmysqladmin processlist:显示正在执行的进程(线程列表)(相当于连上mysql之后执行的SHOW PROCESSES)mysqladmin status:显示mysql服务器的状态status的高级用法：mysqladmin status –sleep 2 #定义多久显示一次mysqladmin status –count 2 #定义显示次数mysqladmin extended-status:显示状态变量(状态变量对于查询mysql服务器状态和排除故障至关重要)mysqladmin variables:显示服务器变量(跟状态变量区分)mysqladmin flush-privileges(等同于reload):让mysql重读授权表mysqladmin flush-status:重置大多数的服务器状态变量mysqladmin flush-threads:重置线程缓存mysqladmin flush-logs:中继日志滚动mysqladmin flush-hosts:重置连接的hostmysqladmin refresh:相当于mysqladmin flush-logs和mysqladmin flush-hostsmysqladmin shutdown:关闭mysql服务器mysqladmin version:显示当前服务器版本及状态信息mysqladmin start-slave:启动复制，启动从服务器复制线程mysqladmin stop-slave:关闭复制 6、表文件（1）对于myisam存储引擎来说.frm：表结构.MYD：表空间.MYI：表索引 （2）对于innodeDB存储引擎来说（默认所有表共享一个表空间文件，建议每个表单独一个表空间文件）.frm：表结构.ibd：表空间（表数据和表索引）.opt：定义字符集和排列规则（是一个文本文件，排列规则collation）","categories":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/categories/mysql/"}],"tags":[]},{"title":"关系型数据库基础理论","slug":"关系型数据库基础理论","date":"2019-01-09T06:20:00.000Z","updated":"2019-01-09T07:04:13.452Z","comments":true,"path":"2019/01/09/关系型数据库基础理论/","link":"","permalink":"http://yoursite.com/2019/01/09/关系型数据库基础理论/","excerpt":"","text":"1、关系模型和关系型数据库之间的联系关系模型：也叫结构化数据模型关系模型分类：（1）关系模型：最基本的（2）关系-实体模型：将数据拆分为多个不同实体（数据表），通过实体之间建立关联关系，也叫E-R模型（3）对象关系模型：基于对象的数据模型（比如图片）（4）半结构化数据模型：比如XML（扩展标记语言），存储数据的同时也存储数据的属性 关系型数据库能够处理以上的4种关系型数据模型 2、SQL语句分类（1）DML：数据操作语言（增删改查）insertdeleteupdateselect（2）DDL：数据定义语言（针对操作对象）createdropalter（3）DCL：数据控制语言（针对访问权限）grantrevoke 关系型数据库的对象有：库、表、索引、视图、用户、约束、存储过程、存储函数、触发器、事件调度器（类似于cron） 3、约束分类（1）域约束：数据类型约束（2）外键约束：引用完整性约束（使本表与另外的表关联起来的字段）（3）主键约束：某字段能唯一标识此字段所属的实体，并且不能为空（唯一标识本表）（4）唯一约束：跟主键约束类似，但是唯一约束可以为空，主键约束不能为空，而且一张表可以有多个唯一约束，但是只能有一个主键约束（5）检查性约束：除了用域约束来规定数据的类型之外，检查性约束可以规定数据不违反常理（比如规定一个人的年龄不超过150岁） 4、关系型数据分层表示层：表逻辑层：存储引擎物理层：数据文件 5、关键组件（1）查询管理器DDL解释器、DML解释器、查询执行引擎（2）存储管理器缓冲区管理器、文件管理器、事务管理器、权限和完整性管理器备注：因为对数据操作都是需要把数据从磁盘中读到内存，而内存往往比硬盘小得多，因此需要缓冲区管理器提供一种缓冲置换策略，将不常用的或者是已过期很久的一些操作置换出去，以此来腾出内存空间 6、进程与线程mysql是属于单进程多线程。线程分为守护线程和用户线程两种。守护线程：mysql内部的线程用户线程：比如连进来的用户（每一个用户连进来都建立一个线程，一个线程不能同时为多个用户服务，因为这涉及到权限交叉的问题）备注：在32位系统中，mysql只能使用到2.7G的内存（因此在生产环境中应该上64位的系统） 7、mysql与Oracle的区别最大的区别在于mysql支持插件式的存储引擎（也就是用户可以自行选择使用哪个存储引擎）备注：5.5.8之前，mysql默认的存储引擎是myisam，myisam不支持事务（myisam适用于查询比较多而修改比较少的场景，特别适用于数据仓库）；5.5.8之后，也就是mysql被Oracle收购之后，mysql的默认存储引擎变为innodeDB（innodeDB适用于在线事务管理系统，比如在线论坛等等） 8、SQL语句执行过程连接管理器–&gt;线程管理器–&gt;用户模块（验证身份）–&gt;命令分发模块–&gt;解析器–&gt;优化器（select）、表定义模块（update、delete、insert）、表维护模块（repair，检查、修改、备份、修复、优化等）、复制模块、状态报告模块–&gt;访问控制模块（检查用户是否有权限操作相关数据表）–&gt;表管理器（完成SQL操作，负责创建、读取或修改表结构定义文件，维护表描述符高速缓存，管理表锁）–&gt;存储引擎（数据库跟磁盘上的数据打交道的接口） 9、定长和变长对于定长的数据来说，查询的效率高，但是很容易造成空间浪费；对于变长的数据来说，查询效率慢，但是可以节省存储空间备注：在选择使用定长还是变长的时候，应该选择折中的方案 10、数据字典定义：存储元数据的表（在mysql初始化的时候，默认会生成一个叫做mysql的数据表，这个数据表就是用来存储数据库的相关元数据的，也就是数据字典）","categories":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/categories/mysql/"}],"tags":[]},{"title":"bash: ifconfig: command not found","slug":"bash-ifconfig-command-not-found","date":"2019-01-08T02:34:00.000Z","updated":"2019-01-08T02:37:08.948Z","comments":true,"path":"2019/01/08/bash-ifconfig-command-not-found/","link":"","permalink":"http://yoursite.com/2019/01/08/bash-ifconfig-command-not-found/","excerpt":"","text":"root@37e20725f95d:/usr/local/apache2# ifconfigbash: ifconfig: command not found 备注：debian默认没有安装ifconfig查看redhat（Centos）版本：cat /etc/redhat-release查看debian（ubuntu）版本：cat /etc/issue Debian系统：apt-get install net-tools","categories":[{"name":"QA","slug":"QA","permalink":"http://yoursite.com/categories/QA/"}],"tags":[{"name":"ifconfig","slug":"ifconfig","permalink":"http://yoursite.com/tags/ifconfig/"}]},{"title":" bash: ip: command not found","slug":"bash-ip-command-not-found","date":"2019-01-08T02:31:00.000Z","updated":"2019-01-08T02:32:05.155Z","comments":true,"path":"2019/01/08/bash-ip-command-not-found/","link":"","permalink":"http://yoursite.com/2019/01/08/bash-ip-command-not-found/","excerpt":"","text":"Centos安装:yum install iproute iproute-doc Ubuntu安装:apt-get install iproute iproute-doc","categories":[{"name":"QA","slug":"QA","permalink":"http://yoursite.com/categories/QA/"}],"tags":[{"name":"ip","slug":"ip","permalink":"http://yoursite.com/tags/ip/"}]},{"title":"Centos:brctl command not found","slug":"linux-brctl-command-not-found","date":"2019-01-08T02:27:00.000Z","updated":"2019-01-08T02:28:53.007Z","comments":true,"path":"2019/01/08/linux-brctl-command-not-found/","link":"","permalink":"http://yoursite.com/2019/01/08/linux-brctl-command-not-found/","excerpt":"","text":"[root@localhost ~]# brctl-bash: brctl: command not found 解决方法： [root@localhost ~]# yum install bridge-utils","categories":[{"name":"QA","slug":"QA","permalink":"http://yoursite.com/categories/QA/"}],"tags":[{"name":"brctl","slug":"brctl","permalink":"http://yoursite.com/tags/brctl/"}]},{"title":"docker镜像篇","slug":"docker镜像篇","date":"2019-01-07T01:28:00.000Z","updated":"2019-01-10T06:17:00.284Z","comments":true,"path":"2019/01/07/docker镜像篇/","link":"","permalink":"http://yoursite.com/2019/01/07/docker镜像篇/","excerpt":"","text":"1、最小镜像（1）定义hello-world是Docker官方提供的一个镜像，通常用来验证Docker是否安装成功（2）Dockerfile查看地址：https://github.com/docker-library/hello-world/blob/master/Dockerfile-linux.template 解释指令：FROM scratch：此镜像是从白手起家，从0开始构建的COPY hello /：将文件”hello”复制到镜像的根目录CMD [“/hello”]：容器启动时，执行/hello 2、base镜像（1）定义base镜像提供的是最小安装的linux发行版。能称作base镜像的通常都是各种linux发行版的Docker镜像，比如Ubuntu、Debian、Centos等（2）Dockerfile查看地址：https://github.com/CentOS/sig-cloud-instance-images/blob/a77b36c6c55559b0db5bf9e74e61d32ea709a179/docker/Dockerfile 解释指令：FROM、COPY、CMD这几个指令的作用跟hello-world镜像中的作用是一样的；ADD指令添加到镜像的tar包就是Centos7的rootfs。在制作镜像时，这个tar包会自动解压到/目录下，生成/dev、/proc、/bin等目录（3）含义不依赖其他镜像，从scratch构建；其他镜像可以以之为基础进行扩展（4）以Cenots为例下载镜像：docker pull centos查看镜像信息：docker images centos（备注：平时我们安装一个Centos至少都有几个GB，这里只有200MB。这是因为内核空间kernel的文件系统是bootfs，linux刚启动时会加载bootfs文件系统，之后bootfs会被卸载掉。而用户空间的文件系统是rootfs，包含我们熟悉的/dev、/proc、/bin等目录。对于base镜像来说，底层用host的kernel，自己只需要提供rootfs就行。对于一个精简的OS，rootfs可以很小，只需要包括最基本的命令、工具和程序库等）支持多种操作系统类型（备注：除Centos之外，base镜像可以模拟出多种操作系统环境。base镜像只是用户空间与发行版一致，kernel版本与发行版是不同的。因为所有容器共用host的kernel，因此在容器中无法对kernel升级。如果容器对kernel的版本有要求，比如说应用只能在某个kernel版本下运行，则不建议用容器，这种场景虚拟机可能更合适） 3、分层结构（1）定义通过扩展现有镜像，创建新的镜像（实际上，Docker Hub中99%的镜像都是通过在base镜像中安装和配置需要的软件构建出来的）（2）Dockerfile 解释指令：新镜像不再是从scratch开始，而是直接在Debian base镜像上构建；安装emacs编辑器；安装Apache2；容器启动时运行bash（3）好处：共享资源比如，有多个镜像都从相同的base镜像构建而来，那么Docker Hub只需要在磁盘上保存一份base镜像即可；同时内存中也只需要加载一份base镜像，就可以为所有容器服务了（4）copy-on-write特性定义：当需要修改时，才复制一份数据原理：当容器启动时，一个新的可写层被加载到镜像的顶部，这一层通常被称作”容器层”，”容器层”之下都叫”镜像层”；所有对容器的改动（无论是添加、删除或者是修改文件）都只会发生在容器层中；只有容器层是可写的，容器层下面的所有镜像层都是只读的，不会被容器修改，所以镜像可以被多个容器共享。（5）查看分层结构docker history：会显示镜像的构建历史，也就是Dockerfile的执行过程。ubuntu-with-vi-dockerfile与ubuntu镜像相比，确实只是多了顶部的一层 备注：docker history输出中IMAGE列出现，表示无法获取IMAGE ID，通常从Docker Hub下载的镜像会有这个问题 4、构建镜像（1）docker commit步骤：a、运行容器 -it参数的作用是以交互模式进入容器，并打开终端b、确认vim确实没有安装 c、安装vim（如果没有找到vim软件包，先apt-get update一下） d、打开一个新的窗口，查看当前运行的容器 silly_goldberg 是 Docker 为我们的容器随机分配的名字e、执行docker commit命令将容器保存为镜像 新镜像命名为ubuntu-with-vif、查看新镜像属性 从size上看到镜像因为安装了软件而变大了g、从新镜像启动容器，验证vi已经可以使用 总结：Docker并不建议用户通过这种方式构建镜像原因：这是一种手工创建镜像的方式，容易出错，效率低且可重复性弱；使用者并不知道镜像是如何创建出来的，里面是否有恶意程序。也就是说无法对镜像进行审计，存在安全隐患。（2）Dockerfile构建文件步骤：a、新建一个Dockerfile文件，内容如下：FROM ubuntuRUN apt-get update &amp;&amp; apt-get install -y vimb、运行docker build命令docker build -t ubuntu-with-vi-dockerfile .命令解释：-t将新镜像命名为ubuntu-with-vi-dockerfile；命令末尾的点号(.)，指明了build context为当前目录。目录下的所有文件和子目录都会被发送给Docker daemon。所以，不要将多余文件放到build context，特别不要把/、/usr作为build context，否则构建过程会相当缓慢甚至失败；我们也可以通过-f参数指定Dockerfile的位置。c、构建完成后，通过docker images查看镜像信息 5、缓存特性（1）定义缓存已有镜像的镜像层，构建新镜像时，如果某镜像层已经存在，就直接使用，无需重新创建（2）举例在前面的Dockerfile中添加一点新内容，往镜像中复制一个文件 （3）不使用缓存如果我们希望在构建镜像的时候不使用缓存，可以在docker build命令上加上–no-cache参数（4）缓存失效Dockerfile中每一个指令都会创建一个镜像层，上层是依赖下层的。无论什么时候，只要某一层发生变化，其上面所有层的缓存都会失效。也就是说，如果我们改变Dockerfile指令的执行顺序，或者修改或添加指令，都会使缓存失效。比如，交换前面的RUN和COPY的顺序，也会导致缓存失效。（5）使用场景构建镜像 &amp;&amp; 下载镜像 6、调试Dockerfile（1）定义如果Dockerfile由于某种原因执行到某个指令失败了，我们能够得到前一个指令成功执行构建出的镜像，这对调试Dockerfile非常有帮助（2）举例 运行在第三步的时候报错，我们可以利用第二部创建的镜像ba6402b1298d进行调试，方式是通过 docker run -it 启动镜像的一个容器。手工执行 RUN 指令很容易定位失败的原因是 busybox 镜像中没有 bash。 7、Dockerfile常用指令（1）FROM指定base镜像（2）MAINTAINER设置镜像的作者，可以是任意字符串（3）COPY将文件从build context复制到镜像（build context默认是当前目录，也可以通过-f来指定）COPY支持两种形式：COPY src destCOPY [“src”,”dest”]备注：src只能指定build context中的文件或目录（4）ADD与COPY类似，从build context复制文件到镜像。不同的是，如果src是归档文件（tar、zip、tgz、xz等），文件会被自动解压到dest（5）ENV设置环境变量，环境变量可以被后面的指令使用举例：…ENV MY_VERSION 1.3RUN apt-get install -y mypackage=$MY_VERSION…（6）EXPOSE指定容器中的进程会监听某个端口（7）VOLUME将文件或目录声明为volume（8）WORKDIR设置镜像中的当前工作目录（9）RUN在容器中运行指定的命令。通常用于安装应用和软件包两种格式：shell格式：RUN apt-get install python3Exec格式：RUN [“apt-get”,”install”,”python3”]举例：RUN apt-get update &amp;&amp; apt-get install -y \\bzr \\cvs \\git \\mercurial \\subversion备注：apt-get update和apt-get install被放在一个RUN指令中执行，这样能够保证每次安装的是最新的包。如果apt-get install在单独的RUN中执行，则会使用apt-get update创建的镜像层，而这一层可能是很久以前缓存的。（10）CMD设置容器启动时运行指定的指令，此命令会在容器启动且docker run没有指定其他指令时运行备注：如果docker run指定了其他命令，CMD指定的默认命令将会被忽略；如果Dockerfile中有多个CMD指令，只有最后一个CMD有效三种格式：shell格式：CMD echo “hello world”Exec格式：CMD [“/bin/echo”,”hello world”]与ENTRYPOINT搭配使用：CMD [“param1”,”param2”] ,此时ENTRYPOINT必须使用Exec格式，其用途是为ENTRYPOINT设置默认的参数举例：Dockerfile 片段如下：CMD echo “Hello world”运行容器 docker run -it [image] 将输出：Hello world但当后面加上一个命令，比如 docker run -it [image] /bin/bash，CMD 会被忽略掉，命令 bash 将被执行（11）ENTRYPOINT设置容器启动时运行的指令，看上去与CMD很像备注：与CMD不同的地方在于，ENTRYPOINT不会被忽略，一定会被执行，即使运行docker run时指定了其他指令；Dockerfile中有多个ENTRYPOINT命令，但是只有最后一个生效两种格式：shell格式：ENTRYPOINT echo “hello world”Exec格式：ENTRYPOINT [“/bin/echo”,”hello world”]举例：Dockerfile 片段如下：ENTRYPOINT [“/bin/echo”, “Hello”]CMD [“world”]当容器通过 docker run -it [image] 启动时，输出为：Hello world而如果通过 docker run -it [image] CloudMan 启动，则输出为：Hello CloudMan 8、镜像命名（1）组成实际上一个特定镜像的名字由两部分组成：repository和tag。格式为：[imagename]=[reposity]:[tag]默认如果docker build没有指定tag，会使用默认值latesttag的作用：常用于描述镜像的版本信息，比如httpd镜像 也可以是任意字符串，比如ubuntu镜像 打tag：docker tag myimage-v1.9.2 myimage:1docker tag myimage-v1.9.2 myimage:1.9docker tag myimage-v1.9.2 myimage:1.9.2docker tag myimage-v1.9.2 myimage:latest 9、搭建Registry（1）搭建公共Registry步骤：a、首先在docker hub上面注册一个账号b、命令行登录（用户名密码是你注册时提供的用户名和密码） c、修改镜像的repository使之与docker hub账号匹配 d、通过docker push将镜像上传到Docker Hub 备注：Docker 会上传镜像的每一层。如果是在官方镜像的基础上做了一点修改而得到新的镜像，Docker Hub 上已经有了全部的镜像层，所以真正上传的数据很少。同样的，如果我们的镜像是基于 base 镜像的，也只有新增加的镜像层会被上传。如果想上传同一 repository 中所有镜像，省略 tag 部分就可以了，例如：docker push liangzj/ubuntu-with-vi-dockerfilee、登录 https://hub.docker.com，在repository就可以看到上传的镜像 f、这个镜像就可以被下载使用了docker pull liangzj/ubuntu-with-vi-dockerfile:v1（2）搭建本地Registrywhy：Docker Hub虽然非常方便，但还是有些限制，比如，需要Internet连接，而且上传和下载的速度慢；上传到Docker Hub的镜像任何人都能够访问，虽然可以用私有repository，但不是免费的；安全原因很多组织不允许将镜像放到外网；解决方案就是搭建本地的Registry。步骤：a、启动registry容器 备注：使用的镜像是 registry:2-d是后台启动容器；-p是将容器的5000端口映射到host的5000端口。5000 是 registry 服务端口。-v是将容器的/var/lib/registry目录映射到host的/myregistry，用于存放镜像数据b、通过docker tag重命名镜像，使之与registry匹配 备注：localhost是文件/etc/hosts里面定义的主机名我们在镜像的前面加上了运行 registry 的主机名称和端口。c、通过docker push上传镜像 d、通过docker pull从本地registry下载镜像 10、常用操作子命令（1）images：显示镜像列表（2）history：显示镜像构建历史（3）commit：从容器创建新镜像（4）build：从Dockerfile构建镜像（5）tag：给镜像打tag（6）pull：从registry下载镜像（7）push：将镜像上传到registry（8）rmi：删除镜像（如果一个镜像对应了多个 tag，只有当最后一个 tag 被删除时，镜像才被真正删除）（9）search：搜索docker hub中的镜像（search 让我们无需打开浏览器，在命令行中就可以搜索 Docker Hub 中的镜像）","categories":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/categories/docker/"}],"tags":[]},{"title":"docker配置允许远程服务器的连接请求","slug":"docker配置允许远程服务器的连接请求","date":"2019-01-02T02:20:00.000Z","updated":"2019-01-02T02:23:42.864Z","comments":true,"path":"2019/01/02/docker配置允许远程服务器的连接请求/","link":"","permalink":"http://yoursite.com/2019/01/02/docker配置允许远程服务器的连接请求/","excerpt":"","text":"默认配置下，docker daemon只能响应来自本地host的客户端请求。如果要允许远程服务端请求，需要在配置文件中打开TCP监听。步骤如下：1、在环境变量 ExecStart 后面添加 -H tcp://0.0.0.0，允许来自任意 IP 的客户端连接（服务端） 2、重启 Docker daemon（服务端） 3、服务器 IP 为 120.79.244.203，客户端在命令行里加上 -H 参数，即可与远程服务器通信（客户端） 备注：info 子命令用于查看 Docker 服务器的信息。","categories":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/categories/docker/"}],"tags":[]},{"title":"docker架构与组件","slug":"docker架构与组件","date":"2019-01-02T02:01:00.000Z","updated":"2019-01-02T02:16:21.247Z","comments":true,"path":"2019/01/02/docker架构与组件/","link":"","permalink":"http://yoursite.com/2019/01/02/docker架构与组件/","excerpt":"","text":"1、why–为什么需要容器（1）背景今天，开发人员通常使用多种服务（比如 MQ，Cache，DB）构建和组装应用，而且应用很可能会部署到不同的环境，比如虚拟服务器，私有云和公有云。一方面应用包含多种服务，这些服务有自己所依赖的库和软件包；另一方面存在多种部署环境，服务在运行时可能需要动态迁移到不同的环境中。这就产生了一个问题：如何让每种服务能够在所有的部署环境中顺利运行？（2）引入docker的理由简要的答案是：容器使软件具备了超强的可移植能力。（3）docker的优势对于开发人员来说–Build Once, Run Anywhere容器意味着环境隔离和可重复性。开发人员只需为应用创建一次运行环境，然后打包成容器便可在其他机器上运行。另外，容器环境与所在的 Host 环境是隔离的，就像虚拟机一样，但更快更简单。 对于运维人员来说–Configure Once, Run Anything只需要配置好标准的 runtime 环境，服务器就可以运行任何容器。这使得运维人员的工作变得更高效，一致和可重复。容器消除了开发、测试、生产环境的不一致性。 2、what–什么是容器（1）定义容器是一种轻量级、可移植、自包含的软件打包技术，使应用程序可以在几乎任何地方以相同的方式运行。开发人员在自己笔记本上创建并测试好的容器，无需任何修改就能够在生产系统的虚拟机、物理服务器或公有云主机上运行。（2）组成应用程序本身；依赖：比如应用程序所需要的库或者其他软件（3）对比容器与虚拟机相同点：两者都是为应用提供封装何隔离不同点：a、容器在Host操作系统的用户空间中运行，与操作系统的其他进程隔离。这一点显著区别于虚拟机。b、由于所有的容器共享同一个Host OS，这使得容器在体积上要比虚拟机小很多。另外，启动容器不需要启动整个操作系统，所以容器部署和启动速度更快，开销更小，也更容易迁移。 3、how–容器是如何工作的（1）docker架构docker采用的是Client/Server架构。客户端向服务端发送请求，服务端负责构建、运行和分发容器。客户端和服务端可以运行在同一个Host上，客户端也可以通过socket或REST API与远程的服务器通信 （2）核心组件a、docker客户端定义：通过docker客户端我们可以方便地在Host上构建和运行容器。相关命令：最常用的Docker客户端是docker命令；直接输入docker可以查看docker支持的子命令。 b、docker服务端定义：Docker daemon以后台服务的方式运行在Docker host上，负责创建、运行、监控容器，构建、存储镜像。默认配置：默认配置下，Docker daemon只能响应来自本地Host的客户端请求。（也可以配置允许远程客户端请求） c、docker镜像定义：可将Docker镜像看着只读模板，通过它可以创建Docker容器。例如某个镜像可能包含一个Ubuntu操作系统、一个Apache HTTP Server以及用户开发的Web应用。生成镜像：可以从无到有开始创建镜像（可以将镜像的内容和创建步骤描述在一个文本文件中，这个文件被称作 Dockerfile，通过执行 docker build 命令可以构建出 Docker 镜像）；也可以下载并使用别人创建好的现成的镜像；还可以在现有镜像上创建新的镜像。 d、docker容器定义：Docker容器就是Docker镜像的运行实例。通俗理解：可以这么认为，对于应用软件，镜像是软件生命周期的构建和打包阶段，而容器则是启动和运行阶段。 e、registry定义：Registry 是存放 Docker 镜像的仓库。分类：公有：Docker Hub（https://hub.docker.com/） 是默认的 Registry，由 Docker 公司维护，上面有数以万计的镜像，用户可以自由下载和使用；私有：出于对速度或安全的考虑，用户也可以创建自己的私有 Registry。相关命令：docker pull：命令可以从 Registry 下载镜像。docker run：命令则是先下载镜像（如果本地没有），然后再启动容器。","categories":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/categories/docker/"}],"tags":[]},{"title":"docker基本安装","slug":"docker基本安装","date":"2018-12-29T03:16:00.000Z","updated":"2018-12-29T07:19:13.330Z","comments":true,"path":"2018/12/29/docker基本安装/","link":"","permalink":"http://yoursite.com/2018/12/29/docker基本安装/","excerpt":"","text":"1、docker安装在ubuntu下安装：（1）允许apt命令HTTPS访问docker源$ sudo apt-get install \\ apt-transport-https \\ ca-certificates \\ curl \\ software-properties-common （2）添加docker官方的GPGcurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - （3）将docker的源添加到/etc/apt/sources.list$ sudo add-apt-repository \\“deb [arch=amd64] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) \\ stable” （4）安装docker$ sudo apt-get update$ sudo apt-get install docker-ce 在centos7下安装：（1）更新yum源yum update（2）脚本安装curl -sSL https://get.docker.com/ | sh（3）启动dockerservice docker start 2、docker加速背景：由于 Docker Hub 的服务器在国外，下载镜像会比较慢。幸好 DaoCloud 为我们提供了免费的国内镜像服务。步骤：（1）在 daocloud.io 免费注册一个用户。登录后，点击顶部菜单“加速器”。 （2）点击之后，复制”配置Docker加速器”框中给出的命令，在你的服务器上执行我的是curl -sSL https://get.daocloud.io/daotools/set_mirror.sh | sh -s http://f1361db2.m.daocloud.io （3）重启docker$sudo systemctl restart docker.service 3、docker启动（1）容器启动过程（httpd为例）a、Docker daemon 发现本地没有 httpd 镜像b、daemon 从 Docker Hub 下载镜像c、下载完成，镜像 httpd 被保存到本地d、Docker daemon 启动容器（2）容器基本命令docker images：查看镜像docker ps：查看容器","categories":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/categories/docker/"}],"tags":[]},{"title":"apt-get update报错","slug":"apt-get-update报错","date":"2018-12-28T08:57:00.000Z","updated":"2018-12-28T09:05:09.096Z","comments":true,"path":"2018/12/28/apt-get-update报错/","link":"","permalink":"http://yoursite.com/2018/12/28/apt-get-update报错/","excerpt":"","text":"apt安装docker的时候，遇到apt-get update报错：下列签名无效：KEYEXPIRED 1544811256 处理步骤：1、用apt-key list 命令看一下，发现是mongoDB的gpg过期了，所以无法update 2、试着把mongoDB的gpg删除，用apt-key del 91FA4AD5，再次apt-get update，还是报错 3、这时候重新导入一个新的MongoDB public GPG Keyapt-key adv –keyserver hkp://keyserver.ubuntu.com:80 –recv 2930ADAE8CAF5059EE73BB4B58712A2291FA4AD5然后再执行apt-get update,这是update终于不会报错了这时候就可以安装docker了：$sudo apt-get install docker-ce","categories":[{"name":"QA","slug":"QA","permalink":"http://yoursite.com/categories/QA/"}],"tags":[]},{"title":"容器生态系统（容器支持技术）","slug":"容器生态系统（容器支持技术）","date":"2018-12-28T07:44:00.000Z","updated":"2018-12-28T07:52:46.504Z","comments":true,"path":"2018/12/28/容器生态系统（容器支持技术）/","link":"","permalink":"http://yoursite.com/2018/12/28/容器生态系统（容器支持技术）/","excerpt":"","text":"1、容器网络定义：容器的出现使网络拓扑变得更加动态和复杂。用户需要专门的解决方案来管理容器与容器，容器与其他实体之间的连通性和隔离性。分类：（1）docker原生：docker network（2）第三方开源：fannelweavecalico 2、服务发现定义：动态变化是微服务应用的一大特点。当负载增加时，集群会自动创建新的容器；负载减小，多余的容器会被销毁。容器也会根据 host 的资源使用情况在不同 host 中迁移，容器的 IP 和端口也会随之发生变化。因此需要提供服务发现这种机制，来保存容器集群中所有微服务最新的信息，比如 IP 和端口，并对外提供 API，提供服务查询功能。分类（典型方案）：（1）etcd（2）consul（3）zookeeper 3、监控定义：监控对于基础架构非常重要，而容器的动态特征对监控提出更多挑战。分类：（1）docker原生：docker ps/top/stats：docker ps/top/stats 是Docker 原生的命令行监控工具。docker stats API：用户可以通过 HTTP 请求获取容器的状态信息。（2）第三方开源：sysdigcAdvisor/HeapsterWeave Scope 4、数据管理定义：容器经常会在不同的 host 之间迁移，如何保证持久化数据也能够动态迁移，是数据管理的重要内容。分类：flocker（提供数据管理的相关能力） 5、日志管理定义：日志为问题排查和事件管理提供了重要依据。分类：（1）docker logs：docker logs是docker原生工具（2）logspout：logspout对日志提供了路由功能，它可以收集不同容器的日志并转发给其他工具进行后处理 6、安全性定义：对于年轻的容器，安全性一直是业界争论的焦点。分类：OpenSCAP（OpenSCAP能够对容器镜像进行扫描，发现潜在的漏洞。）","categories":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/categories/docker/"}],"tags":[]},{"title":"容器生态系统（容器平台技术）","slug":"容器生态系统（容器平台技术）","date":"2018-12-28T07:39:00.000Z","updated":"2018-12-28T07:43:01.371Z","comments":true,"path":"2018/12/28/容器生态系统（容器平台技术）/","link":"","permalink":"http://yoursite.com/2018/12/28/容器生态系统（容器平台技术）/","excerpt":"","text":"1、容器编排引擎定义：基于容器的应用一般会被划分为不同的组件，并以服务的形式运行在各自的容器中，通过 API 对外提供服务。为了保证应用的高可用，每个组件都可能会运行多个相同的容器。这些容器会组成集群，这时候我们就需要通过容器编排引擎来管理容器集群，包括容器管理、调度、集群定义和服务发现等。通过容器编排引擎，容器被有机的组合成微服务应用，实现业务需求。分类（当前主流）：（1）docker swarm：docker swarm 是 Docker 开发的容器编排引擎。（2）kubernetes：kubernetes 是 Google 领导开发的开源容器编排引擎，同时支持 Docker 和 CoreOS 容器。（3）mesos：mesos 是一个通用的集群资源调度平台，mesos 与 marathon 一起提供容器编排引擎功能。 2、容器管理平台定义：容器管理平台是架构在容器编排引擎之上的一个更为通用的平台。通常容器管理平台能够支持多种编排引擎，抽象了编排引擎的底层实现细节，为用户提供更方便的功能分类（典型代表）：（1）Rancher（2）ContainerShip 3、基于容器的PaaS定义：基于容器的 PaaS 为微服务应用开发人员和公司提供了开发、部署和管理应用的平台，使用户不必关心底层基础设施而专注于应用的开发。分类（典型代表）：（1）Deis（2）Flynn（3）Dokku","categories":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/categories/docker/"}],"tags":[]},{"title":"容器生态系统（容器核心技术）","slug":"容器生态系统（容器核心技术）","date":"2018-12-28T06:49:00.000Z","updated":"2018-12-28T07:25:18.320Z","comments":true,"path":"2018/12/28/容器生态系统（容器核心技术）/","link":"","permalink":"http://yoursite.com/2018/12/28/容器生态系统（容器核心技术）/","excerpt":"","text":"1、容器规范定义：容器不光是 Docker，还有其他容器，比如 CoreOS 的 rkt。为了保证容器生态的健康发展，保证不同容器之间能够兼容，包含 Docker、CoreOS、Google在内的若干公司共同成立了一个叫 Open Container Initiative（OCI） 的组织，其目是制定开放的容器规范。分类：目前 OCI 发布了两个规范：runtime spec 和 image format spec。有了这两个规范，不同组织和厂商开发的容器能够在不同的 runtime 上运行。这样就保证了容器的可移植性和互操作性。 2、容器runtime定义：runtime 是容器真正运行的地方。runtime 需要跟操作系统 kernel 紧密协作，为容器提供运行环境。类似于java与JVM的关系：Java 程序就好比是容器，JVM 则好比是 runtime。JVM 为 Java 程序提供运行环境。同样的道理，容器只有在 runtime 中才能运行。分类（目前主流）：（1）lxc：lxc 是 Linux 上老牌的容器 runtime。Docker 最初也是用 lxc 作为 runtime。（2）runc：runc 是 Docker 自己开发的容器 runtime，符合 oci 规范，也是现在 Docker 的默认 runtime。（3）rkt：rkt 是 CoreOS 开发的容器 runtime，符合 oci 规范，因而能够运行 Docker 的容器。 3、容器管理工具定义：容器管理工具对内与 runtime 交互，对外为用户提供 interface，比如 CLI。这就好比除了 JVM，还得提供 java 命令让用户能够启停应用分类：（1）lxd：lxc的管理工具lxd（2）docker engine：runc 的管理工具是 docker engine。可以理解为docker engine=docker daemon。docker engine 包含后台 deamon 和 cli 两个部分。我们通常提到 Docker，一般就是指的 docker engine（3）rkt cli：rkt 的管理工具是 rkt cli 4、容器定义工具定义：允许用户定义容器的内容和属性，这样容器就能够被保存，共享和重建。分类：（1）docker image：docker image 是 docker 容器的模板，runtime 依据 docker image 创建容器。（2）dockerfile：dockerfile是包含若干命令的文本文件，可以通过这些命令创建出 docker image。（3）ACI：ACI (App Container Image) 与 docker image 类似，只不过它是由 CoreOS 开发的 rkt 容器的 image 格式。 5、registries定义：容器是通过 image 创建的，需要有一个仓库来统一存放 image，这个仓库就叫做 Registry。分类：（1）docker registry：企业可以用 Docker Registry 构建私有的 Registry。（2）docker hub：Docker Hub（https://hub.docker.com） 是 Docker 为公众提供的托管 Registry，上面有很多现成的 image，为 Docker 用户提供了极大的便利。（3）Quay.io：Quay.io（https://quay.io/）是另一个公共托管 Registry，提供与 Docker Hub 类似的服务。 6、容器OS定义：容器 OS 是专门运行容器的操作系统。与常规 OS 相比，容器 OS 通常体积更小，启动更快。因为是为容器定制的 OS，通常它们运行容器的效率会更高。分类（杰出代表）：（1）CoreOS（2）atomic（3）ubuntu core","categories":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/categories/docker/"}],"tags":[]},{"title":"路由技术（动态路由之OSPF）","slug":"路由技术（动态路由之OSPF）","date":"2018-12-28T02:06:00.000Z","updated":"2018-12-28T02:20:15.382Z","comments":true,"path":"2018/12/28/路由技术（动态路由之OSPF）/","link":"","permalink":"http://yoursite.com/2018/12/28/路由技术（动态路由之OSPF）/","excerpt":"","text":"1、基本概述定义：开放性最短路径优先（用于替代有缺陷的RIP）2、基本特征（1）OSI层次：传输层，基于协议号89（2）协议类型：链路状态路由协议（3）有类/无类：无类（4）IGP/EGP：IGP（5）管理距离：110（6）度量值：cost=100/带宽（M）（7）路由更新：组播如果是Dother，组播地址224.0.0.5如果是DR/BDR，组播地址224.0.0.63、基本运行 4、路由表更新 5、运行环境决定因素：网络类型默认由介质类型决定环境分类：（1）广播多路访问（BMA）（2）非广播多路访问（NBMA）（3）点到点（P2P）（4）点到多点（P2MP）（5）点到多点非广播多路访问（P2MP-NBMA）–思科私有相关命令： 6、特殊概念（1）router-id定义：路由器的身份id，唯一代表一台ospf路由器（默认以最大物理接口ip作为router-id）功能：防止路由抖动选举规则：a、手动指定；b、最大环回接口IP；c、最大物理接口IP清除router-id： （2）DR/BDR定义：指定路由器/备份指定路由器，类似于班集体当中的班长/副班长的位置功能：设定DR和BDR可以避免报文重复发送而导致的链路资源浪费选举规则：a、最大ospf接口优先级，默认为1（优先级为0代表不参与DR/BDR的选举）b、最大物理接口IP（3）邻居/邻接邻居关系：Dother–Dother邻接关系：Dother–DR/BDR两者区别：邻接关系建立在邻居关系基础之上，就好像男女朋友关系是建立在男女性朋友关系之上（4）区域骨干区域：骨干区域是area 0非骨干区域：所有不是area 0的都是非骨干区域两者关系：a、流量中转：非骨干区域间数据通信，必须要经过骨干区域 area 0 中转b、拓扑规划：所有非骨干区域要挂载在骨干区域 area 0 上","categories":[{"name":"网络基础","slug":"网络基础","permalink":"http://yoursite.com/categories/网络基础/"}],"tags":[]},{"title":"路由技术（动态路由之EIGRP）","slug":"路由技术（动态路由之EIGRP）","date":"2018-12-28T01:53:00.000Z","updated":"2018-12-28T02:22:52.082Z","comments":true,"path":"2018/12/28/路由技术（动态路由之EIGRP）/","link":"","permalink":"http://yoursite.com/2018/12/28/路由技术（动态路由之EIGRP）/","excerpt":"","text":"1、基本概述定义：增强型内部网关路由协议（号称”收敛之王”），属于混合型路由协议（距离矢量+链路状态）2、基本特征（1）OSI层次：传输层，基于协议号88（2）协议类型：混合型（3）有类/无类：无类（4）IGP/EGP：IGP（5）管理距离：内部90，外部170（6）度量值：复合型度量值a、5个标准：带宽、负载、延迟、可靠性、MTUb、度量值计算：针对路由条目接收端口（7）路由更新：224.0.0.103、基本运行 4、路由表同步 5、特殊术语（1）通告距离（AD）：邻居告诉你他自己到达目的地的距离 （2）可行距离（FD）：本地到达目的地的距离 （3）可行条件（FC）：AD&lt;FD，用于防环（4）后继路由：最优路由（5）可行后继路由：次优路由（6）后继站：最优路由的下一跳（7）可行后继站：次优路由的下一跳","categories":[{"name":"网络基础","slug":"网络基础","permalink":"http://yoursite.com/categories/网络基础/"}],"tags":[]},{"title":"路由技术（动态路由之RIP）","slug":"路由技术（动态路由之RIP）","date":"2018-12-28T01:31:00.000Z","updated":"2019-01-25T07:32:50.636Z","comments":true,"path":"2018/12/28/路由技术（动态路由之RIP）/","link":"","permalink":"http://yoursite.com/2018/12/28/路由技术（动态路由之RIP）/","excerpt":"","text":"1、基本概述定义：路由信息协议版本：（1）RIPv1：有类，传递路由条目时，不携带掩码，默认开启主类汇总，不能关闭主类汇总（不能关闭主要是为了减少链路带宽消耗）（2）RIPv2：无类，传递路由条目时，携带掩码，默认开启主类汇总，可以关闭主类汇总（到目前带宽已经不是问题，而更加追求网络的真实性）2、基本特征（1）OSI层次：应用层，基于UDP520（2）协议类型：距离矢量路由协议（3）有类/无类：RIPv1–有类，RIPv2–无类（4）IGP/EGP：IGP（5）管理距离：120（6）度量值：最大跳数15跳，16跳为不可达（7）路由更新：RIPv1–广播RIPv2–组播224.0.0.93、基本运行 4、路由表同步 5、时间机制 （1）更新计时器–30s在RIP启动之后,平均每30秒（实际上为25.5~30秒间的随机数时间，之所以这样也是为了错峰发送更新，以防止所有路由器同时发送路由更新造成太大流量） 启用了RIP的接口会发送自己的除了被水平分割（split horizon）抑制的路由选择表的完整副本给所有相邻路由器的时间间隔，并且update的目标地址为255.255.255.255。（2）失效计时器–180s如果 180 秒（默认值）后还未收到可刷新现有路由的更新，则将该路由的度量设置为 16，路由表项将被标记为“x.x.x.x is possibly down”。在清除计时器超时以前，该路由仍将保留在路由表中。（此时RIP路由仍然用来转发数据包）（3）刷新计时器–240s默认情况下，清除计时器设置为 240 秒，比无效计时器长 60 秒。当清除计时器超时后，该路由将从路由表中删除。（4）抑制计时器–180s该计时器用于稳定路由信息，并有助于在拓扑结构根据新信息收敛的过程中防止路由环路。在某条路由被标记为不可达后，它处于抑制状态的时间必须足够长，以便拓扑结构中所有路由器能在此期间获知该不可达网络。默认情况下，抑制计时器设置为180 秒。失效计时器到时，立马进入180s的抑制计时器。6、防环机制（1）最大条数：最大跳数15跳，16跳为不可达（2）水平分割：我发给你的，不要发给我（3）路由毒化：故障点设备主动发送16跳路由，主动干掉故障路由（4）毒性逆转：转发16跳毒化路由（违背水平分割原则）（5）抑制计时器：防止路由表频繁翻动，增加了网络的稳定性（6）触发更新：一旦检测到路由崩溃，立即广播路由刷新报文，而不等到下一个刷新周期","categories":[{"name":"网络基础","slug":"网络基础","permalink":"http://yoursite.com/categories/网络基础/"}],"tags":[]},{"title":"路由技术（静态路由）","slug":"路由技术（静态路由）","date":"2018-12-27T08:44:00.000Z","updated":"2018-12-28T01:27:56.902Z","comments":true,"path":"2018/12/27/路由技术（静态路由）/","link":"","permalink":"http://yoursite.com/2018/12/27/路由技术（静态路由）/","excerpt":"","text":"1、定义管理员手动静态写入路由表2、配置：Config# ip route 目标网络号 目标网络掩码 下一跳/逃出接口3、特殊的静态路由（1）默认路由定义：路由器网关配置：ip route 0.0.0.0 0.0.0.0 下一跳/逃出接口（2）浮动默认路由定义：主备冗余配置：","categories":[{"name":"网络基础","slug":"网络基础","permalink":"http://yoursite.com/categories/网络基础/"}],"tags":[]},{"title":"路由基础","slug":"路由基础","date":"2018-12-27T08:36:00.000Z","updated":"2018-12-27T08:43:32.801Z","comments":true,"path":"2018/12/27/路由基础/","link":"","permalink":"http://yoursite.com/2018/12/27/路由基础/","excerpt":"","text":"1、路由功能依据路由表进行数据转发的功能2、路由最优选举原则：（1）最小管理距离（管理距离越小越可靠、安全）（2）最小度量值（度量值越小，本地到达目的网络的花销就越小）3、路由查询查询原则：（1）最长匹配原则（最长是指网络位最长）（2）递归查询 4、路由分类（1）静态路由定义：管理员手工静态写入路由表优点：安全性高，度量值为0缺点：配置繁琐，不能动态适应拓扑变化（2）动态路由定义：通过路由协议协商交互路由条目优点：配置相对简单，能动态适应拓扑变化缺点：相对静态路由不安全分类：按距离矢量和链路状态来划分，分为以下三种：距离矢量路由协议：RIP 链路状态路由协议：OSPF 混合型路由协议：EIGRP 按有类和无类来划分，分为以下两种：有类路由协议：传递路由条目时，不携带掩码（不支持VLSM和CIDR）无类路由协议：传递路由条目时，携带掩码（支持VLSM和CIDR）","categories":[{"name":"网络基础","slug":"网络基础","permalink":"http://yoursite.com/categories/网络基础/"}],"tags":[]},{"title":"zabbix问题","slug":"zabbix","date":"2018-12-26T09:42:00.000Z","updated":"2018-12-28T07:30:25.124Z","comments":true,"path":"2018/12/26/zabbix/","link":"","permalink":"http://yoursite.com/2018/12/26/zabbix/","excerpt":"","text":"Assuming that agent dropped connection because of access permissions. 解决方法：修改客户端的配置文件zabbix_agentd.conf1、给serverActive和Hostname加注释 2、因为是采用C/S架构，客户端和服务器端不是同一台机器，所以还要在配置文件中加上两行： serverActive表示zabbix主动监控server的ip地址（默认server是主动来agent拿数据，serverActive表示agent主动推送数据给服务器端）","categories":[{"name":"QA","slug":"QA","permalink":"http://yoursite.com/categories/QA/"}],"tags":[]},{"title":"-bash: netstat: command not found","slug":"bash-netstat-command-not-found","date":"2018-12-26T07:54:00.000Z","updated":"2018-12-26T07:55:19.937Z","comments":true,"path":"2018/12/26/bash-netstat-command-not-found/","link":"","permalink":"http://yoursite.com/2018/12/26/bash-netstat-command-not-found/","excerpt":"","text":"yum install net-tools -y","categories":[{"name":"QA","slug":"QA","permalink":"http://yoursite.com/categories/QA/"}],"tags":[]},{"title":"交换技术（交换防环技术）","slug":"交换技术（交换防环技术）","date":"2018-12-26T01:26:00.000Z","updated":"2018-12-26T01:51:24.785Z","comments":true,"path":"2018/12/26/交换技术（交换防环技术）/","link":"","permalink":"http://yoursite.com/2018/12/26/交换技术（交换防环技术）/","excerpt":"","text":"1、STP基本概述（1）STP定义spanning-tree，生成树协议–通过选举机制选举出阻塞端口进而阻塞活动链路，直至剩下一条活动链路（2）STP功能用于防止环路备注：环路定义：首尾相连，无始无终环路危害：广播风暴（广播、组播、未知单播）；桥接表损坏，也叫CAM表（广播风暴+交换机学习功能）；重复帧环路本质：有多条活动链路 2、STP角色选举（1）设备角色根桥交换机（根桥选举原则：最小BID，BID=优先级+MAC地址）非根桥交换机（非根桥交换机收到TC包，会把MAC地址清空；TC包只有根桥才能发送）（2）端口角色a、根端口，简写RP根端口选举原则：最小cost值（cost=BPDU包内的cost值+接收端口的cost值）最小发送者BID（BID=优先级+MAC地址）最小发送者PID（PID=端口优先级+端口编号）备注：每一非根桥交换机上有且只有一个根端口b、指定端口，简写DP备注：根桥上所有端口都是指定端口每一条链路有且只有一个指定端口c、阻塞端口，简写block 3、STP参数修改通过修改STP选举参数，阻塞指定端口 4、STP端口状态机 5、STP链路收敛（1）直接链路失效–30s （2）间接链路失效–50s 6、STP数据分组 正常BPDU 次级BPDU TCN TCA TC TCA/TC","categories":[{"name":"网络基础","slug":"网络基础","permalink":"http://yoursite.com/categories/网络基础/"}],"tags":[]},{"title":"交换技术（交换安全技术）","slug":"交换技术（交换安全技术）","date":"2018-12-25T09:22:00.000Z","updated":"2018-12-26T01:24:51.829Z","comments":true,"path":"2018/12/25/交换技术（交换安全技术）/","link":"","permalink":"http://yoursite.com/2018/12/25/交换技术（交换安全技术）/","excerpt":"","text":"1、MAC地址绑定（1）MAC地址表MAC地址组成 查看MAC地址表 查看MAC地址 一对多关系 （2）需求用于限定PC只能通过特定接口上网（3）配置 2、port-security（1）需求：此F0/1接口只支持PCA数据通过 （2）配置","categories":[{"name":"网络基础","slug":"网络基础","permalink":"http://yoursite.com/categories/网络基础/"}],"tags":[]},{"title":"交换技术（交换冗余技术）","slug":"交换技术（交换冗余技术）","date":"2018-12-25T08:46:00.000Z","updated":"2018-12-25T08:58:18.682Z","comments":true,"path":"2018/12/25/交换技术（交换冗余技术）/","link":"","permalink":"http://yoursite.com/2018/12/25/交换技术（交换冗余技术）/","excerpt":"","text":"以太通道1、定义通过捆绑多条链路逻辑增加链路带宽（链路冗余）2、命令（1）配置： （2）查看： 3、限制条件（1）物理限制：接口物理参数必须匹配（2）逻辑限制：协议必须匹配协议种类： 协议分类：a、链路聚合控制协议（行业里的） b、端口汇聚协议（思科私有） 4、增强技术 （1）配置 （2）查看","categories":[{"name":"网络基础","slug":"网络基础","permalink":"http://yoursite.com/categories/网络基础/"}],"tags":[]},{"title":"交换技术（交换通信技术）","slug":"交换技术（交换通信技术）","date":"2018-12-25T06:13:00.000Z","updated":"2018-12-25T06:24:12.433Z","comments":true,"path":"2018/12/25/交换技术（交换通信技术）/","link":"","permalink":"http://yoursite.com/2018/12/25/交换技术（交换通信技术）/","excerpt":"","text":"1、单臂路由（1）why网关配置接口不够用；路由器识别不了vlan tag（2）what功能：实现不同vlan间的数据通信（3）how 2、三层交换通信（1）why单臂路由拓展性差，带宽限制严重，由此又引入了三层交换技术（2）what三层交换接口，简称SVI（switch virtual interface）（3）how 3、DHCP（1）why动态分配IP、掩码、网关、DNS（2）whatdynamic host configuration protocol，动态主机配置协议（3）how部署方式：a、内置部署结构图 配置命令（服务器端） 配置命令（客户端） b、旁路部署结构图 配置命令（服务器端） 配置命令（客户端）","categories":[{"name":"网络基础","slug":"网络基础","permalink":"http://yoursite.com/categories/网络基础/"}],"tags":[]},{"title":"交换技术（交换基础技术）","slug":"交换技术（交换基础技术）","date":"2018-12-25T03:23:00.000Z","updated":"2018-12-25T03:44:07.659Z","comments":true,"path":"2018/12/25/交换技术（交换基础技术）/","link":"","permalink":"http://yoursite.com/2018/12/25/交换技术（交换基础技术）/","excerpt":"","text":"1、vlan技术（1）why （2）what （3）how 2、trunk技术（1）why （2）what （3）how 3、DTP技术（1）why （2）whatDTP定义：dynamic trunking protocol，动态中继协议（思科私有） 端口模式：access：不能发送和接收协商信息trunk：能发送和接收协商信息desirable：能发送和接收协商信息auto：不能发送但能接收协商信息 链路模式：OFF模式 ON模式 DD模式 DA模式 链路规则：至少一端能发送协商信息，另一端能接收协商信息封装协议：802.1Q（3）how 4、VTP技术（1）why （2）whatVTP定义：vlan trunking protocol，vlan中继协议（思科私有）VTP角色：server：创建、删除、修改、发送、学习和传递vlan信息，修改所有VTP参数备注：当出现多个server时，配置版本号低的向高的学习；创建、删除、修改vlan，配置版本号都会加1；domain和password一致才能学习vlan信息client：学习和传递vlan信息transparent：创建、删除、修改和传递vlan信息，修改部分VTP参数VTP过程： （3）how创建VTP： VTP修剪：适用场景：假如AB两交换机，A有VLAN2 VLAN3 VLAN 4。B只有VLAN2，则VLAN3和VLAN4的信息无需转发到B交换机。VTP修剪可以节约链路资源","categories":[{"name":"网络基础","slug":"网络基础","permalink":"http://yoursite.com/categories/网络基础/"}],"tags":[]},{"title":"交换基础","slug":"交换基础","date":"2018-12-25T03:17:00.000Z","updated":"2018-12-25T03:20:13.943Z","comments":true,"path":"2018/12/25/交换基础/","link":"","permalink":"http://yoursite.com/2018/12/25/交换基础/","excerpt":"","text":"1、局域网概述 2、局域网术语 3、以太网标准 4、交换机原理","categories":[{"name":"网络基础","slug":"网络基础","permalink":"http://yoursite.com/categories/网络基础/"}],"tags":[]},{"title":"思科设备基本管理之三（文件管理）","slug":"思科设备基本管理之三（配置文件管理）","date":"2018-12-20T09:19:00.000Z","updated":"2018-12-20T09:22:01.770Z","comments":true,"path":"2018/12/20/思科设备基本管理之三（配置文件管理）/","link":"","permalink":"http://yoursite.com/2018/12/20/思科设备基本管理之三（配置文件管理）/","excerpt":"","text":"配置文件管理1、保存 2、删除 3、备份 IOS文件管理1、升级 2、删除 3、重灌（1）路由器IOS （2）交换机IOS","categories":[{"name":"网络基础","slug":"网络基础","permalink":"http://yoursite.com/categories/网络基础/"}],"tags":[]},{"title":"思科设备基本管理之二（密码管理）","slug":"思科设备基本管理之二","date":"2018-12-20T09:06:00.000Z","updated":"2018-12-20T09:13:20.244Z","comments":true,"path":"2018/12/20/思科设备基本管理之二/","link":"","permalink":"http://yoursite.com/2018/12/20/思科设备基本管理之二/","excerpt":"","text":"密码管理1、密码配置（1）enable密码 （2）console密码只需要密码： 需要用户名和密码： （3）telnet密码只需要密码： 需要用户名和密码： 2、密码破解（1）路由器破解原理： 破解过程： （2）交换机破解原理： 破解过程：","categories":[{"name":"网络基础","slug":"网络基础","permalink":"http://yoursite.com/categories/网络基础/"}],"tags":[]},{"title":"思科设备基本管理之一","slug":"思科设备基本管理","date":"2018-12-20T08:51:00.000Z","updated":"2018-12-20T09:17:16.285Z","comments":true,"path":"2018/12/20/思科设备基本管理/","link":"","permalink":"http://yoursite.com/2018/12/20/思科设备基本管理/","excerpt":"","text":"1、启动流程（1）交换机加电自检；bootstrap引导程序；从FLASH里寻找并加载IOS；从FLASH寻找并加载config.txt （2）路由器加电自检；bootstrap引导程序；从FLASH寻找并加载IOS；从NVRAM里寻找并加载startup-config 2、管理方式（1）带外管理：通过console线连接管理（2）带内管理：通过网线互联设备，telnet管理 3、配置模式用户模式：&gt;特权模式：#全局配置模式：（config）#exit：从当前模式返回到上一级模式end：从当前模式返回至特权模式 4、设备端口（1）端口类型 （2）端口命名 （3）端口配置 5、常用命令（1）标配命令 （2）常用show命令","categories":[{"name":"网络基础","slug":"网络基础","permalink":"http://yoursite.com/categories/网络基础/"}],"tags":[]},{"title":"进制转换","slug":"进制转换","date":"2018-12-19T08:34:00.000Z","updated":"2018-12-19T08:36:11.985Z","comments":true,"path":"2018/12/19/进制转换/","link":"","permalink":"http://yoursite.com/2018/12/19/进制转换/","excerpt":"","text":"二进制位权 二进制转十进制 二进制转十六进制 十进制转十六进制","categories":[{"name":"网络基础","slug":"网络基础","permalink":"http://yoursite.com/categories/网络基础/"}],"tags":[{"name":"进制转换","slug":"进制转换","permalink":"http://yoursite.com/tags/进制转换/"}]},{"title":"nmap","slug":"nmap","date":"2018-12-19T08:01:00.000Z","updated":"2018-12-19T08:01:21.931Z","comments":true,"path":"2018/12/19/nmap/","link":"","permalink":"http://yoursite.com/2018/12/19/nmap/","excerpt":"","text":"nmap:扫描器之王主要概念:探测主机是否在线、扫描主机开放端口和嗅探网络服务，用于网络探测和安全扫描扫描类型:(1)-sT:tcp扫描，用来建立一个tcp连接。如果成功则认为目标端口正在监听，否则认为端口没有监听程序。这种扫描很容易被检测到，在目标主机的日志中会记录大批的连接请求和错误信息(2)-sU:udp扫描，如果返回icmp不可达的错误信息说明端口是关闭的(3)-sS:tcp同步扫描(tcp syn)，只向目标发出syn数据包，如果收到syn/ack响应就认为目标端口正在监听，并立即断开连接，否则认为端口没有监听程序。这种扫描称为半开扫描，最大的好处是很少有系统会把这个记入系统日志(4)-sA:这种高级的扫描方法通常可以穿过防火墙(5)-sW:滑动窗口扫描，非常类似于ack的扫描(6)-sV:version版本扫描(7)-sL:显示扫描的所有主机列表(8)-sP:找出主机是否存在于网络中 nmap基本操作:(1)nmap 192.168.1.1(2)nmap 192.168.1.1 192.168.1.2(3)nmap 192.168.0-25.1-254(4)nmap magedu.com(5)nmap -vv 192.168.1.1(6)nmap -vv -p 3389 192.168..1(7)扫描除了某ip之外的所有子网主机:nmap 192.168.1.1/24 -exclude 192.168.1.10(8)扫描除了某文件中的ip之外的所有子网主机:nmap 192.168.1.1/24 -excludefile gov.txt(9)显示扫描的所有主机列表:nmap -sL 192.168.1.1/24(10)ping扫描，只用于找出主机是否存在于网络中:nmap -sP 192.168.1.1-255","categories":[{"name":"linux抓包管理","slug":"linux抓包管理","permalink":"http://yoursite.com/categories/linux抓包管理/"}],"tags":[{"name":"nmap","slug":"nmap","permalink":"http://yoursite.com/tags/nmap/"}]},{"title":"nc","slug":"nc","date":"2018-12-19T07:59:00.000Z","updated":"2018-12-19T08:00:01.003Z","comments":true,"path":"2018/12/19/nc/","link":"","permalink":"http://yoursite.com/2018/12/19/nc/","excerpt":"","text":"nc(由nc包提供，包名叫nc) #另外一个实现:ncat(由nmap提供,包名叫nmap)(1)传输文件文件传输:监听者为接收方nc -l PORT &gt; /file (监听端口，-l表示监听)nc IP PORT &lt; /file 文件传输:监听者为传输方nc -l PORT &lt; /filenc IP PORT &gt; /file (2)传输目录:需要先归档 (3)web客户端nc作为web客户端来访问web服务器nc WEBSERVER PORTGET /index.html HTTP/1.1Host:172.16.10.1 (4)扫描器nc -v -w 1 172.16.10.1 -z 1-1023-v:详细显示-w:超时时间-z:只扫描，不做其他任何动作 (5)聊天器nc -l PORTnc IP PORT例如:在一台主机上监听某个端口:nc -l 2333在另外一台主机上，nc 172.16.10.1 2333 -p 2333通过这样的方式，就可以在两台主机上相互传送信息了 (6)其他选项-s SOURCE_IP","categories":[{"name":"linux抓包管理","slug":"linux抓包管理","permalink":"http://yoursite.com/categories/linux抓包管理/"}],"tags":[{"name":"nc","slug":"nc","permalink":"http://yoursite.com/tags/nc/"}]},{"title":"tcpdump","slug":"tcpdump-1","date":"2018-12-19T07:57:00.000Z","updated":"2018-12-19T07:58:24.875Z","comments":true,"path":"2018/12/19/tcpdump-1/","link":"","permalink":"http://yoursite.com/2018/12/19/tcpdump-1/","excerpt":"","text":"tcpdump:网络嗅探器(需要将网卡设置为混杂模式，promisc)-i:interface-w:file(保存至文件)-r:file(读取文件)-nn:第一个n表示把地址显示为数字的形式，第二个n表示把协议显示为数字的形式-X:hex(16进制)以及ASCII格式显示-XX:除了有-X的作用之外，还会显示链路层首部相关信息-A:ASCII格式显示-v:显示详细的信息-vv:显示更加详细的信息expression:关键字:type:host、net、port、portrangedirection:src、dst、src or dst、src and dstprotocol:ether(以太网)、ip、arp、tcp、udp、icmp、wlan组合条件:andornot 举例子:(1)tcpdump -i eth0(2)tcpdump -i eth0 tcp dst port 80 (-n/-nn)(3)tcpdump -i eth0 -nn host 172.16.10.1(4)tcpdump -i eth0 -nn dst host 172.16.10.1(5)tcpdump -i eth0 -nn src and dst host 172.16.10.1(6)tcpdump -i eth0 -nn host 172.16.10.1 and 172.16.10.10(7)tcpdump -i eth0 -nn host 172.16.10.1 and (172.16.10.2 or 172.16.10.10)(8)tcpdump -i eth0 -A tcp port 80(9)tcpdump -i eth0 -X tcp port 80(10)tcpdump -i eth0 -XX tcp port 80(11)tcpdump -i eth0 -A -v tcp port 80(12)tcpdump -i eth0 -A -vv tcp port 80","categories":[{"name":"linux抓包管理","slug":"linux抓包管理","permalink":"http://yoursite.com/categories/linux抓包管理/"}],"tags":[{"name":"tcpdump","slug":"tcpdump","permalink":"http://yoursite.com/tags/tcpdump/"}]},{"title":"windows远程桌面（mstsc）无法复制粘贴","slug":"远程桌面（mstsc）无法复制","date":"2018-12-19T06:52:00.000Z","updated":"2018-12-19T06:55:01.381Z","comments":true,"path":"2018/12/19/远程桌面（mstsc）无法复制/","link":"","permalink":"http://yoursite.com/2018/12/19/远程桌面（mstsc）无法复制/","excerpt":"","text":"解决方法：在远程服务器上重启rdpclip.exe进程即可。 1、打开资源管理器，杀掉rdpclip.exe进程 2、开始——》运行，输入：rdpclip.exe，回车重启该进程。","categories":[{"name":"QA","slug":"QA","permalink":"http://yoursite.com/categories/QA/"}],"tags":[{"name":"mstsc","slug":"mstsc","permalink":"http://yoursite.com/tags/mstsc/"}]},{"title":"IP地址","slug":"IP地址","date":"2018-12-19T06:39:00.000Z","updated":"2018-12-19T06:48:18.688Z","comments":true,"path":"2018/12/19/IP地址/","link":"","permalink":"http://yoursite.com/2018/12/19/IP地址/","excerpt":"","text":"1、ip地址分类：（1）按ABCDE来分 （2）按公有、私有来分 2、私有ip地址分类： 3、ip地址中的网络位（通过子网掩码来区分） 4、ip地址中的主机位（通过子网掩码来区分） 5、子网划分 （1）掩码的1必须是连续的 （2）子网划分公式","categories":[{"name":"网络基础","slug":"网络基础","permalink":"http://yoursite.com/categories/网络基础/"}],"tags":[{"name":"ip地址","slug":"ip地址","permalink":"http://yoursite.com/tags/ip地址/"}]},{"title":"TCP/IP协议族","slug":"TCP-IP协议族","date":"2018-12-19T05:38:00.000Z","updated":"2018-12-19T05:56:26.888Z","comments":true,"path":"2018/12/19/TCP-IP协议族/","link":"","permalink":"http://yoursite.com/2018/12/19/TCP-IP协议族/","excerpt":"","text":"协议1、ARP （1）数据分用 （2）ARP过程 （3）APR报文 2、IP （1）IP报文 Identification用于标识数据包身份，数值不同则代表是不同的数据包 （2）数据分片 上图为数据分片和数据重组过程，与MTU密切相关 （3）MTU 上图为各层的MTU，决定各层限制的传输数据包大小 （4）进制转换 上图为进制转换 （5）TTL 上图为TTL在传递过程的变化，TTL值为0时不传递。TTL主要是用于防止环路的 3、ICMP traceroute &amp;&amp; tracert原理 4、TCP （1）面向连接服务（三次握手+四次关闭） （2）可靠传输（syn/ack+定时器+重传机制） （3）流控（滑动窗口） （4）多路复用（ip+port=套接字） 5、UDP TCP与UDP区别的通俗性理解：","categories":[{"name":"网络基础","slug":"网络基础","permalink":"http://yoursite.com/categories/网络基础/"}],"tags":[{"name":"TCP/IP","slug":"TCP-IP","permalink":"http://yoursite.com/tags/TCP-IP/"}]},{"title":"封装和解封装","slug":"封装和解封装","date":"2018-12-19T02:58:00.000Z","updated":"2018-12-19T03:00:19.703Z","comments":true,"path":"2018/12/19/封装和解封装/","link":"","permalink":"http://yoursite.com/2018/12/19/封装和解封装/","excerpt":"","text":"图解：图一 图二","categories":[{"name":"网络基础","slug":"网络基础","permalink":"http://yoursite.com/categories/网络基础/"}],"tags":[{"name":"封装","slug":"封装","permalink":"http://yoursite.com/tags/封装/"},{"name":"解封装","slug":"解封装","permalink":"http://yoursite.com/tags/解封装/"}]},{"title":"OSI七层模型","slug":"OSI七层模型-1","date":"2018-12-19T02:00:00.000Z","updated":"2018-12-19T02:03:12.015Z","comments":true,"path":"2018/12/19/OSI七层模型-1/","link":"","permalink":"http://yoursite.com/2018/12/19/OSI七层模型-1/","excerpt":"","text":"","categories":[{"name":"网络基础","slug":"网络基础","permalink":"http://yoursite.com/categories/网络基础/"}],"tags":[{"name":"七层模型","slug":"七层模型","permalink":"http://yoursite.com/tags/七层模型/"}]},{"title":"设备和网络发展史","slug":"OSI七层模型","date":"2018-12-19T02:00:00.000Z","updated":"2018-12-19T02:30:08.595Z","comments":true,"path":"2018/12/19/OSI七层模型/","link":"","permalink":"http://yoursite.com/2018/12/19/OSI七层模型/","excerpt":"","text":"","categories":[{"name":"网络基础","slug":"网络基础","permalink":"http://yoursite.com/categories/网络基础/"}],"tags":[{"name":"设备发展史","slug":"设备发展史","permalink":"http://yoursite.com/tags/设备发展史/"}]},{"title":"jenkins配置","slug":"jenkins配置","date":"2018-12-17T07:47:00.000Z","updated":"2018-12-17T07:47:53.415Z","comments":true,"path":"2018/12/17/jenkins配置/","link":"","permalink":"http://yoursite.com/2018/12/17/jenkins配置/","excerpt":"","text":"","categories":[{"name":"jenkins","slug":"jenkins","permalink":"http://yoursite.com/categories/jenkins/"}],"tags":[]},{"title":"jenkins（备份、主目录结构、默认路径）","slug":"jenkins（备份、主目录结构、默认路径）","date":"2018-12-17T07:46:00.000Z","updated":"2018-12-17T07:46:32.355Z","comments":true,"path":"2018/12/17/jenkins（备份、主目录结构、默认路径）/","link":"","permalink":"http://yoursite.com/2018/12/17/jenkins（备份、主目录结构、默认路径）/","excerpt":"","text":"","categories":[{"name":"jenkins","slug":"jenkins","permalink":"http://yoursite.com/categories/jenkins/"}],"tags":[]},{"title":"jenkins（CI、优势、版本）","slug":"jenkins（CI、优势、版本）","date":"2018-12-17T07:44:00.000Z","updated":"2018-12-17T07:44:16.395Z","comments":true,"path":"2018/12/17/jenkins（CI、优势、版本）/","link":"","permalink":"http://yoursite.com/2018/12/17/jenkins（CI、优势、版本）/","excerpt":"","text":"","categories":[{"name":"jenkins","slug":"jenkins","permalink":"http://yoursite.com/categories/jenkins/"}],"tags":[]},{"title":"jenkins安装","slug":"jenkins安装","date":"2018-12-17T06:37:00.000Z","updated":"2018-12-17T06:41:47.345Z","comments":true,"path":"2018/12/17/jenkins安装/","link":"","permalink":"http://yoursite.com/2018/12/17/jenkins安装/","excerpt":"","text":"6、进入选择插件安装界面，选择第一个（Install suggested plugins） 7、插件安装完成之后，需要创建第一个用户 8、创建完用户之后，就可以使用jenkins了","categories":[{"name":"jenkins","slug":"jenkins","permalink":"http://yoursite.com/categories/jenkins/"}],"tags":[]},{"title":"Git && Giuhub(Github部分)","slug":"Git-Giuhub-Github部分","date":"2018-12-14T06:27:00.000Z","updated":"2018-12-14T06:27:36.393Z","comments":true,"path":"2018/12/14/Git-Giuhub-Github部分/","link":"","permalink":"http://yoursite.com/2018/12/14/Git-Giuhub-Github部分/","excerpt":"","text":"","categories":[{"name":"Git && Github","slug":"Git-Github","permalink":"http://yoursite.com/categories/Git-Github/"}],"tags":[{"name":"Github","slug":"Github","permalink":"http://yoursite.com/tags/Github/"}]},{"title":"Git && Github(Git部分)","slug":"Git","date":"2018-12-14T06:20:00.000Z","updated":"2018-12-14T06:25:30.817Z","comments":true,"path":"2018/12/14/Git/","link":"","permalink":"http://yoursite.com/2018/12/14/Git/","excerpt":"","text":"","categories":[{"name":"Git && Github","slug":"Git-Github","permalink":"http://yoursite.com/categories/Git-Github/"}],"tags":[{"name":"Git","slug":"Git","permalink":"http://yoursite.com/tags/Git/"}]},{"title":"cloudwatch","slug":"cloudwatch","date":"2018-12-10T09:14:00.000Z","updated":"2018-12-19T07:30:47.422Z","comments":true,"path":"2018/12/10/cloudwatch/","link":"","permalink":"http://yoursite.com/2018/12/10/cloudwatch/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[{"name":"cloudwatch","slug":"cloudwatch","permalink":"http://yoursite.com/tags/cloudwatch/"}]},{"title":"keepalived安装与配置文件","slug":"keepalived安装与配置文件","date":"2018-12-07T06:45:00.000Z","updated":"2018-12-07T09:43:52.027Z","comments":true,"path":"2018/12/07/keepalived安装与配置文件/","link":"","permalink":"http://yoursite.com/2018/12/07/keepalived安装与配置文件/","excerpt":"","text":"keepalived目前已经被官方收录进linux版本当中，使用yum就可以下载安装keepalived yum info keepalived 查看系统中的keepalived版本yum install keepalived 安装keepalivedrpm -ql keepalived 查看安装keepalived生成了哪些文件在centos7中，cat /usr/lib/systemd/system/keepalived.service 查看keepalived的启动等配置信息cat /etc/sysconfig/keepalived 查看keepalived支持的参数帮助 keepalived的配置文件（三部分）：1、global configuration2、vrrpd configuration:分两段，第一段是vrrp instance，第二段是vrrp synchonization group3、lvs configuration:根据配置文件生成lvs规则备注：可以通过man keepalived.conf查看keepalived配置文件的配置帮助详细配置：1、global_defs:（1）notification_email（2）notification_email_from（3）smtp_server（4）smtp_connection_timeout（5）router_id hostname（6）vrrp_mcast_group 224.x.x.x #定义多播地址，224不变，后面三位可以变化 2、vrrp_instance:（1）state maste或backup（2）interface 在centos7中，int dev名字是eno16777736（3）virtual_router_id vrid是唯一的,跟虚拟mac相关，虚拟mac的格式为00-00-5E-00-01-{VRID} #虚拟mac的格式，前面是固定的，后面补上vrid；master和backup的virtual_router_id必须是一样的，因为id是一样说明master和backup是在同一个虚拟路由器中（4）priority 0到255之间的数字，数字越大，优先级越高，优先级高的是master（5）adver_init 发送心跳信息的时间间隔，默认是1（6）authentication {认证 auth_type PASS 这里是简单字符认证 auth_pass xxxx openssl rand -hex 4,生成十六进制的随机字符串}（7）virtual_ipaddress 定义虚拟ip地址，同一个虚拟路由器中的master和backup的vip的配置也是一样的（8）nopreempt:非抢占模式，默认为抢占模式 HA cluster配置前提：1、本机的主机名与host中定义的主机名保持一致，要与hostname(uname -n)获得名称保持一致，因为需要根据主机名进行彼此通信(各节点要能解析主机名，一般建议通过host文件进行解析，配置文件为/etc/hosts)2、各节点时间同步3、确保iptables和selinux不会成为服务的障碍iptables -L -n 查看iptables规则getenforce 查看linux状态","categories":[{"name":"keepalived","slug":"keepalived","permalink":"http://yoursite.com/categories/keepalived/"}],"tags":[{"name":"keepalived","slug":"keepalived","permalink":"http://yoursite.com/tags/keepalived/"}]},{"title":"linux进程管理","slug":"linux进程管理","date":"2018-12-07T03:43:00.000Z","updated":"2019-03-21T08:13:25.252Z","comments":true,"path":"2018/12/07/linux进程管理/","link":"","permalink":"http://yoursite.com/2018/12/07/linux进程管理/","excerpt":"","text":"1、进程的优先级：0到139,140个优先级，数字越小，表示优先级越高其中，0到99是内核决定的，100到139是可以由用户调整的用户可以通过调整nice值来进行调整，默认每个进程的nice值都是0nice值的取值范围是-20到19，对应100到139（普通用户只能调大nice值来降低优先级，管理员才有权限调大和调小nice值）调整nice值：（1）调整已经启动的进程的nice值：renice NI PID（2）在启动时指定nice值：nice -n NI COMMANDinit进程：第一个进程,是所有进程的父进程，进程号为1 2、每一个进程的相关属性信息在/proc目录下，其下的每一个目录对应一个进程，对应的数字就是进程号（可能是曾经存在过的进程） 3、进程的状态D:不可中断的睡眠S:可以中断的睡眠R:运行或就绪T:停止Z:僵死&lt;:高优先级进程N:低优先级进程+:前台进程组中的进程l:多线程进程s:会话进程首进程 4、进程相关命令：ps命令：有2种风格，system V风格和BSD风格sysV风格（需要加横杠-）：-o:显示指定字段的信息（默认只显示前台进程）要想显示所有，则使用ps -axo 字段1，字段2 BSD风格（不需要加横杠-）：a:显示所有跟终端有关的进程（跟终端有关：在终端中通过命令行运行启动的）x:显示所有跟终端无关的进程（跟终端无关：系统启动的时候自动启动的进程，用户还没登录就已经产生的进程）u:显示进程跟哪个用户相关 pstree命令:显示当前系统的进程树pgrep命令:根据进程名，查找进程的进程号用法:pgrep 进程，如果加上选项-u user可以指定以哪个用户的身份运行的进程pidof命令:根据程序名，查找其相关进程的ID号 top命令:默认根据CPU大小进行排序 （1）在top命令运行过程中按键：M:根据内存大小排序P:根据CPU大小排序T:根据占用CPU时间大小排序 l:是否显示平均负载和启动时间t:是否显示进程和CPU状态相关的信息m:是否显示内存相关信息c:是否显示完整的命令行信息k:是否终止某个进程q:退出top （2）运行top命令时指定选项参数:-d num:指定刷新时长，单位是s-b:批模式，一屏一屏向后翻-n num:在批模式下，显示多少屏，显示完成之后自动退出 前台作业送到后台:ctrl+z:把正在前台的作业送到后台并停止运行COMMAND &amp;:让命令在后台执行 jobs:查看后台的所有作业作业号:不同于进程号+:命令将默认操作的作业-:命令将第二个默认操作的作业 bg:让后台的停止作业继续运行bg [JOBID]fg:将后台的作业调回前台fg [JOBID] kill %JOBID:终止某作业 其他命令:vmstat 1 5:查看系统状态，每隔1秒刷新1次，显示5次就停止退出uptime:跟top显示内容的第一行是一样的 5、进程间通信（IPC）两种方式:（1）共享内存（2）信号:signal 6、重要的信号（通过数字表示）：1:SIGHUP，让一个进程不用重启，就可以重读其配置文件，并让新的配置信息生效2:SIGINT，相当于ctrl-c，中断一个进程9:SIGKILL，杀死一个进程15:SIGTERM，终止一个进程备注：kill默认发送就是15号信号 指定一个信号：信号号码:kill -9信号名称:kill -SIGKILL信号名称简写:kill -KILL备注：kill -l:查看各种信号名称以及对应的号码killall 进程名:但凡是这个进程名的进程都会被杀死","categories":[{"name":"linux进程管理","slug":"linux进程管理","permalink":"http://yoursite.com/categories/linux进程管理/"}],"tags":[{"name":"进程","slug":"进程","permalink":"http://yoursite.com/tags/进程/"}]},{"title":"网络负载均衡器","slug":"网络负载均衡器","date":"2018-12-07T03:37:00.000Z","updated":"2018-12-19T07:31:59.647Z","comments":true,"path":"2018/12/07/网络负载均衡器/","link":"","permalink":"http://yoursite.com/2018/12/07/网络负载均衡器/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[{"name":"网络负载均衡器","slug":"网络负载均衡器","permalink":"http://yoursite.com/tags/网络负载均衡器/"}]},{"title":"应用程序负载均衡器","slug":"应用程序负载均衡器","date":"2018-12-07T03:36:00.000Z","updated":"2018-12-19T07:32:43.439Z","comments":true,"path":"2018/12/07/应用程序负载均衡器/","link":"","permalink":"http://yoursite.com/2018/12/07/应用程序负载均衡器/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[{"name":"应用程序负载均衡器","slug":"应用程序负载均衡器","permalink":"http://yoursite.com/tags/应用程序负载均衡器/"}]},{"title":"传统负载均衡器（一些概念）","slug":"传统负载均衡器（一些概念）","date":"2018-12-07T03:35:00.000Z","updated":"2018-12-19T07:33:24.927Z","comments":true,"path":"2018/12/07/传统负载均衡器（一些概念）/","link":"","permalink":"http://yoursite.com/2018/12/07/传统负载均衡器（一些概念）/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[{"name":"ELB概念","slug":"ELB概念","permalink":"http://yoursite.com/tags/ELB概念/"}]},{"title":"传统负载均衡器（健康检查）","slug":"传统负载均衡器（健康检查）","date":"2018-12-07T03:33:00.000Z","updated":"2018-12-19T07:34:05.355Z","comments":true,"path":"2018/12/07/传统负载均衡器（健康检查）/","link":"","permalink":"http://yoursite.com/2018/12/07/传统负载均衡器（健康检查）/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[{"name":"健康检查","slug":"健康检查","permalink":"http://yoursite.com/tags/健康检查/"}]},{"title":"传统负载均衡器（特点）","slug":"传统负载均衡器（特点）","date":"2018-12-07T03:29:00.000Z","updated":"2018-12-19T07:35:20.815Z","comments":true,"path":"2018/12/07/传统负载均衡器（特点）/","link":"","permalink":"http://yoursite.com/2018/12/07/传统负载均衡器（特点）/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[{"name":"ELB","slug":"ELB","permalink":"http://yoursite.com/tags/ELB/"}]},{"title":"AMI和EBS快照的使用场景","slug":"AMI和EBS快照的使用场景","date":"2018-12-07T02:22:00.000Z","updated":"2018-12-19T07:36:27.291Z","comments":true,"path":"2018/12/07/AMI和EBS快照的使用场景/","link":"","permalink":"http://yoursite.com/2018/12/07/AMI和EBS快照的使用场景/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[{"name":"AMI","slug":"AMI","permalink":"http://yoursite.com/tags/AMI/"},{"name":"EBS快照","slug":"EBS快照","permalink":"http://yoursite.com/tags/EBS快照/"}]},{"title":"EBS快照","slug":"EBS快照","date":"2018-12-07T02:21:00.000Z","updated":"2018-12-19T07:39:04.464Z","comments":true,"path":"2018/12/07/EBS快照/","link":"","permalink":"http://yoursite.com/2018/12/07/EBS快照/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[{"name":"EBS快照","slug":"EBS快照","permalink":"http://yoursite.com/tags/EBS快照/"}]},{"title":"AMI","slug":"AMI系统镜像和EBS快照","date":"2018-12-07T02:20:00.000Z","updated":"2018-12-19T07:39:42.200Z","comments":true,"path":"2018/12/07/AMI系统镜像和EBS快照/","link":"","permalink":"http://yoursite.com/2018/12/07/AMI系统镜像和EBS快照/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[{"name":"AMI","slug":"AMI","permalink":"http://yoursite.com/tags/AMI/"}]},{"title":"EC2存储","slug":"EC2实例-1","date":"2018-12-07T01:46:00.000Z","updated":"2018-12-19T07:40:23.044Z","comments":true,"path":"2018/12/07/EC2实例-1/","link":"","permalink":"http://yoursite.com/2018/12/07/EC2实例-1/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[{"name":"EC2存储","slug":"EC2存储","permalink":"http://yoursite.com/tags/EC2存储/"}]},{"title":"安全组","slug":"全组-1","date":"2018-12-06T06:46:00.000Z","updated":"2018-12-19T07:46:42.253Z","comments":true,"path":"2018/12/06/全组-1/","link":"","permalink":"http://yoursite.com/2018/12/06/全组-1/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[{"name":"安全组","slug":"安全组","permalink":"http://yoursite.com/tags/安全组/"}]},{"title":"EC2实例（计费类型）","slug":"EC2","date":"2018-12-04T08:37:00.000Z","updated":"2019-01-11T08:08:31.973Z","comments":true,"path":"2018/12/04/EC2/","link":"","permalink":"http://yoursite.com/2018/12/04/EC2/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[{"name":"EC2","slug":"EC2","permalink":"http://yoursite.com/tags/EC2/"}]},{"title":"EC2实例（特性）","slug":"EC2实例2","date":"2018-12-04T08:34:00.000Z","updated":"2018-12-19T07:48:31.369Z","comments":true,"path":"2018/12/04/EC2实例2/","link":"","permalink":"http://yoursite.com/2018/12/04/EC2实例2/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[{"name":"EC2","slug":"EC2","permalink":"http://yoursite.com/tags/EC2/"}]},{"title":"EC2实例（简介、运行平台、访问方式）","slug":"EC2实例","date":"2018-12-04T08:22:00.000Z","updated":"2019-01-11T08:07:43.021Z","comments":true,"path":"2018/12/04/EC2实例/","link":"","permalink":"http://yoursite.com/2018/12/04/EC2实例/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[{"name":"EC2","slug":"EC2","permalink":"http://yoursite.com/tags/EC2/"}]},{"title":"IAM服务","slug":"IAM","date":"2018-11-30T06:48:00.000Z","updated":"2018-12-19T07:49:59.573Z","comments":true,"path":"2018/11/30/IAM/","link":"","permalink":"http://yoursite.com/2018/11/30/IAM/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[{"name":"IAM","slug":"IAM","permalink":"http://yoursite.com/tags/IAM/"}]},{"title":"申请AWS免费套餐","slug":"申请AWS免费套餐","date":"2018-11-30T03:23:00.000Z","updated":"2018-12-19T07:51:01.450Z","comments":true,"path":"2018/11/30/申请AWS免费套餐/","link":"","permalink":"http://yoursite.com/2018/11/30/申请AWS免费套餐/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[{"name":"AWS免费套餐","slug":"AWS免费套餐","permalink":"http://yoursite.com/tags/AWS免费套餐/"}]},{"title":"AWS分区","slug":"AWS分区","date":"2018-11-30T03:21:00.000Z","updated":"2018-12-19T07:53:20.050Z","comments":true,"path":"2018/11/30/AWS分区/","link":"","permalink":"http://yoursite.com/2018/11/30/AWS分区/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[{"name":"AWS分区","slug":"AWS分区","permalink":"http://yoursite.com/tags/AWS分区/"}]},{"title":"云计算技术","slug":"云计算","date":"2018-11-30T03:20:00.000Z","updated":"2018-12-19T07:54:17.274Z","comments":true,"path":"2018/11/30/云计算/","link":"","permalink":"http://yoursite.com/2018/11/30/云计算/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"http://yoursite.com/tags/云计算/"}]},{"title":"AWS服务","slug":"Untitled","date":"2018-11-30T03:17:00.000Z","updated":"2018-12-19T07:54:55.094Z","comments":true,"path":"2018/11/30/Untitled/","link":"","permalink":"http://yoursite.com/2018/11/30/Untitled/","excerpt":"","text":"","categories":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/categories/AWS/"}],"tags":[{"name":"AWS服务","slug":"AWS服务","permalink":"http://yoursite.com/tags/AWS服务/"}]},{"title":"源码安装puppet服务端","slug":"Untitled-1","date":"2018-11-22T03:11:00.000Z","updated":"2018-11-22T07:27:30.901Z","comments":true,"path":"2018/11/22/Untitled-1/","link":"","permalink":"http://yoursite.com/2018/11/22/Untitled-1/","excerpt":"","text":"1、安装ruby(版本：1.8.7)wget http://ftp.ruby-lang.org/pub/ruby/ruby-1.8.7-p358.zipunzip ruby-1.8.7cd ruby-1.8.7./configure –prefix=/usr/local/puppetmake &amp;&amp; make install因为安装ruby的位置不在系统环境变量中，所以需要手动导入系统环境变量export PATH=$PATH:/usr/local/puppet/bin/:/usr/local/puppet/sbin/ 2、安装ruby-shadowgit clone https://github.com/apalmblad/ruby-shadow.gitcd ruby-shadowruby extconf.rbmake &amp;&amp; make install 3、安装facter(版本：1.7.4)wget http://downloads.puppetlabs.com/facter/facter-1.7.4.tar.gztar zxvf facter-1.7.4.tar.gzcd facter-1.7.4ruby install.rb 4、安装puppet(版本：2.7.25)wget http://downloads.puppetlabs.com/puppet/puppet-2.7.25.tar.gzcd puppet-2.7.25ruby install.rb –full 有坑:到这一步，提示不能加载openssl，因此先安装openssl：apt-get install opensslapt-get install libssl-devel安装libssl-devel的时候，提示”apt-get install E: 无法定位软件包问题”尝试更新apt源，在/etc/apt的sources.list 添加镜像源deb http://archive.ubuntu.com/ubuntu/ trusty main universe restricted multiverse，然后apt-get update对apt-get进行更新，再次执行apt-get install libssl-devel，还是同样的报错。这时候尝试使用aptitude软件包管理器安装libssl-dev包:(1)安装aptitudeapt-get install aptitude(2)使用aptitude安装 libssl-dev包aptitude install libssl-dev安装完openssl之后，重新运行puppet安装命令”ruby install.rb –full”，依然提示无法load openssl，这时候需要进入到ruby的源码解压目录cd ruby-1.8.7-p358/ext/openssl,执行ruby extconf.rb可以生成编译openssl扩展的Makefile，然后make &amp;&amp; make install，这时候再运行puppet安装命令”ruby install.rb –full”就可以安装上puppet了。","categories":[{"name":"安装篇","slug":"安装篇","permalink":"http://yoursite.com/categories/安装篇/"}],"tags":[{"name":"puppet","slug":"puppet","permalink":"http://yoursite.com/tags/puppet/"}]},{"title":"挂载和卸载","slug":"挂载和卸载","date":"2018-11-13T01:39:00.000Z","updated":"2018-11-13T02:23:10.815Z","comments":true,"path":"2018/11/13/挂载和卸载/","link":"","permalink":"http://yoursite.com/2018/11/13/挂载和卸载/","excerpt":"","text":"挂载:将新的文件系统关联至当前根文件系统卸载:将某文件系统从当前根文件系统的关联关系移除 mount:挂载mount 设备 挂载点备注:1、设备可以是设备文件(/dev/sda5)、卷标(LABEL=”XXX”)、UUID(UUID=”XXX”)2、挂载点必须是目录，要求如下:(1)此目录没有被其他进程使用(2)此目录得事先存在(3)目录中的原有文件将会暂时隐藏3、挂载完成后，通过挂载点访问对应文件系统上的文件4、mount不带任何选项，会显示当前系统中已经挂载的设备以及挂载点可选参数:-a:表示/etc/fstab文件中定义的所有文件系统-n:挂载设备时，不把信息写入mtab文件(默认情况下，mount每挂载一个设备，会把挂载的设备信息保存至/etc/mtab文件)备注:mtab是mount table的简称，直接mount显示的信息就是mtab文件中的信息-t:指定挂载设备上的文件系统类型。不使用此选项时，mount会调用blkid获取对应文件系统类型-r:只读挂载，挂载光盘时常用此选项-w:读写挂载-o:指定额外的挂载选项，也即指定文件系统启用的属性额外的挂载选项有:remount:重新挂载当前文件系统(mount -o remount /dev/sda5 [/mnt/test] 备注:重新挂载的时候，可以省略挂载点)ro:只读挂载(等于-r)rw:读写挂载(等于-w) umount:卸载umount 设备 or umount 挂载点备注:卸载的时候，需要切换到跟挂载点无关的目录上去。如果你在挂载点上运行umount命令，会提示”device is busy”","categories":[{"name":"linux磁盘管理","slug":"linux磁盘管理","permalink":"http://yoursite.com/categories/linux磁盘管理/"}],"tags":[{"name":"挂载","slug":"挂载","permalink":"http://yoursite.com/tags/挂载/"},{"name":"卸载","slug":"卸载","permalink":"http://yoursite.com/tags/卸载/"}]},{"title":"设备文件管理","slug":"设备文件管理","date":"2018-11-12T09:12:00.000Z","updated":"2018-11-12T09:13:40.359Z","comments":true,"path":"2018/11/12/设备文件管理/","link":"","permalink":"http://yoursite.com/2018/11/12/设备文件管理/","excerpt":"","text":"设备文件:设备文件作为设备的访问入口，被内核识别，分两种1、b:块设备，以块为单位进行随机访问，例如硬盘2、c:字符设备，以字符为单位进行线性访问，例如键盘 创建设备文件:mknod -m 权限 文件名 文件类型(b或c) 主设备号 次设备号其中，1、设备文件名:IDE、ATA:hd开头的文件名SATA、SCSI、USB:sd开头的文件名(a、b、c…区分同一类型下的不同设备)2、设备号:/dev目录下的文件有两个数字属性:主设备号:major number，标识设备类型次设备号:minor number，标识同一类型下的不同设备(这种文件没有大小，有点类似于链接文件。因为大小指的是它真正占用磁盘块的大小，而设备文件只是作为设备的一个访问入口，因此没有大小)","categories":[{"name":"linux磁盘管理","slug":"linux磁盘管理","permalink":"http://yoursite.com/categories/linux磁盘管理/"}],"tags":[{"name":"设备文件","slug":"设备文件","permalink":"http://yoursite.com/tags/设备文件/"}]},{"title":"磁盘和分区管理","slug":"磁盘和分区管理","date":"2018-11-12T09:06:00.000Z","updated":"2018-11-13T03:15:52.888Z","comments":true,"path":"2018/11/12/磁盘和分区管理/","link":"","permalink":"http://yoursite.com/2018/11/12/磁盘和分区管理/","excerpt":"","text":"磁盘:真空的，需要防尘，磁盘主要分两种(1)机械硬盘:目前主流，比较遗憾(2)固态硬盘:性能相对好一点的磁盘 磁盘基本术语(硬件方面):(1)盘片(2)盘面:每一块盘片有两块盘面(3)磁头(4)磁道(5)扇区:512字节(6)机械臂(7)柱面:磁道组成的逻辑分区柱面具有以下特点:1、存储数据就是按照柱面来存储的，读取数据也是2、划分分区也是按照柱面来划分3、从外到内，柱面的编号从0开始4、同一个转轴，越靠外面的磁道，转速越快(这也是我们大多数操作系统安装在C盘的原因) 磁盘基本术语(软件方面):磁盘出厂前，需要低级格式化，划分磁道分区1、MBR:master boot record，主引导记录(0盘片0磁道0扇区的那一块地方就是MBR，属于磁盘，是全局的存储空间，独立于操作系统之外)MBR的大小为512字节，分为3个部分，446字节叫做BootLoader，叫做引导加载器，是一段程序代码，作用是引导操作系统正确启动起来；接下来的64字节，每16字节标识一个主分区，因此操作系统最多可以划分4个主分区；剩下的2个字节叫做魔数，标识MBR是否有效。2、分区:partition，划分分区的作用是创建文件系统，每一个分区就是一个文件系统。 要正常使用一块磁盘，需要经过:低级格式化（由硬盘厂商来完成）–做分区–高级格式化（创建文件系统）–挂载 磁盘分区命令:查看当前系统识别了多少块硬盘：fdisk -l查看当前系统某块硬盘的具体信息：fdisk -l /dev/sda管理磁盘分区：fdisk /dev/sda （启动一个交互式界面）m：for helpp：显示当前分区，包括没保存的改动n：创建新的分区e：创建新的扩展分区p：创建新的主分区d：删除一个分区w：保存退出q：不保存退出t：修改分区类型L：修改的时候查看分区类型（以确定某种类型对应的编号）创建完分区之后需要内核识别才能够格式化。查看内核已经识别的分区：cat /proc/partitions通知内核重读分区表：partprobe #Redhat6上使用了新命令:partx备注:partprobe是默认重读所有磁盘上的分区表，当然我们也可以指定内核重读哪一块磁盘，比如说partprobe /dev/sda 创建分区例子:1、创建3个逻辑分区(得先创建扩展分区，在扩展分区的基础上创建逻辑分区。主分区不能创建逻辑分区；扩展分区不能使用，只能使用在扩展分区上划分出来的逻辑分区)(1)fdisk /dev/sda #会进入一个交互界面，备注:进入交互界面后，如果在创建分区的过程中敲错命令，直接删除键是删不掉的，需要按住ctrl+删除键来删除(2)p #查看分区(3)n(4)e #创建扩展分区(5)n(6)+2G #创建第一个逻辑分区，大小为2G(7)n(8)+5G #创建第二个逻辑分区，大小为5G(9)n(10)+1G #创建第三个逻辑分区，大小为1G(11)p #查看分区(12)w #保存退出(13)cat /proc/partitions #查看内核是否识别新创建的分区(14)partprobe /dev/sda #指定内核重读/dev/sda分区表 2、创建SWAP分区(备注:SWAP分区是磁盘上的空间，允许内存过载使用。一旦内存耗尽，可以临时拿硬盘上的SWAP来应急，防止系统崩溃甚至宕机。SWAP分区必须是一个单独的分区)(1)首先新建一个新的分区:fdisk #准备新建分区p #查看已有分区n #新建分区+1G #新建1G的分区L #查看分区类型t #调整分区类型8 #对第几块磁盘调整类型L #查看分区类型82 #linux swap的分区编码p #查看是否已经建好swap分区w #保存退出partprobe /dev/sda #通知内核重读分区表(2)创建好分区之后，需要创建文件系统(swap分区也是有自己的文件系统的)mkswap /dev/sda8(3)启用和关闭交换分区的交换空间(类似于mount，但是有专门的命令，不用mount)启用:swapon /dev/sda8可选参数:-a:启用所有定义在/etc/fstab文件中的交换设备关闭:swapoff /dev/sda8 其他命令:1、blkid:block id，查看磁盘设备的相关属性UUID:用于唯一标识磁盘设备TYPE:用于标识文件系统类型LABEL:显示卷标 2、e2label:专门用于查看或者定义卷标e2label /dev/sda5 查看卷标e2label /dev/sda5 labelname 设定卷标 3、free:查看系统上物理内存和交换分区的使用情况(默认单位是字节)-m:以MB为单位显示内存使用情况buffer:缓冲，保存的是元数据cache:缓存，保存的是数据(这两段空间可以清除数据，不会影响到数据的完整性，对系统性能会有影响) 4、df:显示整个磁盘分区的使用情况(以磁盘块个数来显示大小)可选参数:-h:人性化显示-i:以inode个数显示大小-P:不换行显示备注:与du的区别:du显示目录或者目录的子目录所占用的大小可选参数:-h:人性化显示-s:显示目录所占据的整体的大小 5、dd:复制可选参数:if= #指定数据来源of= #指定数据存储目标bs=1 #以一个字节为单位count=2 #复制2次，跟bs=1结合使用就是复制2个字节的数据例子:1、创建1M的数据:dd if=/dev/zero of=/var/swapfile bs=1 count=10242、拿一个文件，哪怕你没有分区，没有多余的空间可以创建分区，我们照样可以找个文件来暂时性的当做交换分区来使用(性能差，但可以临时救急)(1)dd if=/dev/zero of=/var/swapfile bs=1M count=1024(2)mkswap /var/swapfile(3)swapon /var/swapfile与cp的区别:(1)cp是以文件为单位的，dd是以数据流为单位的(数据流就是01代码)(2)dd可以复制不完整的数据","categories":[{"name":"linux磁盘管理","slug":"linux磁盘管理","permalink":"http://yoursite.com/categories/linux磁盘管理/"}],"tags":[{"name":"磁盘","slug":"磁盘","permalink":"http://yoursite.com/tags/磁盘/"},{"name":"分区","slug":"分区","permalink":"http://yoursite.com/tags/分区/"}]},{"title":"文件系统管理","slug":"ntitled","date":"2018-11-12T09:01:00.000Z","updated":"2018-11-13T03:29:02.942Z","comments":true,"path":"2018/11/12/ntitled/","link":"","permalink":"http://yoursite.com/2018/11/12/ntitled/","excerpt":"","text":"文件系统:1、创建分区之后，要实现快速存储文件和查询文件，需要在这个分区上创建文件系统2、文件系统是一个管理软件，也是存储在磁盘的某个位置上的，但并不是在分区上，文件系统的数据在分区上3、文件系统把分区分为两部分，元数据区域(类似索引)和存储真正数据的区域新增、删除、复制、剪切文件的原理都跟文件系统的原理相关，比如说:(1)为什么剪切文件比复制文件的速度要快答:因为剪切的时候数据内容不变，变的是inode(2)为什么有些文件删除了还可以通过文件恢复器找回来？文件粉碎机的原理是什么？答:删除就是删除inode对应的磁盘块，原来的数据原封不动；粉碎就是用一堆随机数去覆盖原来的数据4、linux支持的文件系统:ext2、ext3、ext4、xfs、reiserfs、jfs、nfs…备注:(1)linux的vfs(虚拟文件系统)使得linux可以支持不同类型的文件系统(2)linux也支持fat32格式(windows平台)文件系统，但是本身不叫fat32，而叫做vfat；同样支持NTFS(windows平台)文件系统,但是支持不太好，写入速度慢，甚至严重的话会导致系统崩溃(3)要留意内核支持哪些文件系统，比如ext2，ext3等。只有内核中具有某种文件系统的模块，它才能支持这种文件系统。cat /proc/filesystems:查看当前内核所支持的文件系统类型(4)ext3和ext2的区别:ext3:日志文件系统，分为3个区域，元数据区、数据区、日志区。对数据进行读写操作的时候，先把inode放到日志区进行操作，操作完成之后再放到元数据区。如果这时候断电或者系统崩溃，下次开机的时候直接查找日志区有哪些inode文件就可以知道有哪些文件是损坏的，而不用从头到尾扫描所有的文件。ext3最大的功能在于能够加快文件系统修复的速度。ext2:就是采取从头到尾的扫描方式，如果存储数据很大的话这样扫描查找会导致机器崩溃，修复速度很慢。ext2是linux上唯一的非日志文件系统。有些情况下，对于安全性、完整性要求不高并且会频繁的大量读写小文件的时候，使用ext2尤佳。 创建完分区，下面就可以创建文件系统commands:1、mkfs:make file system，创建文件系统-t 指定文件系统类型mkfs -t ext2 = mkfs.ext2mkfs -t ext3 = mkfs.ext3mkfs -t vfat = mkfs.vfat2、mke2fs:专门创建或者管理ext系列文件系统:-j journal，直接创建ext3系列的文件系统(默认是创建ext2系列的文件系统)-b 指定block size(块大小)，默认是4096，可以取值为1024,2048-L 指定分区label(卷标)-m # 指定预留给超级用户的块数百分比(直接指定数字即可，不用加%。防止空间填满管理员也无法进入，因此预留一些空间出来，默认应该是20%)-i # 指定为多少字节的空间创建一个inode(默认是8192，这里给出的数值应该是块大小的2^n倍。块大小默认是4096字节)-F #强制创建文件系统(少用)-E #用户指定额外的文件系统属性(少用) 3、tune2fs:调整文件系统相关属性(例如:tune2fs -j /dev/sda2)可选参数:-j:不损坏原有数据，将ext2升级为ext3-L labelname:设定或修改卷标-m #:调整预留百分比-r #:指定预留块数-c #:指定挂载次数达到#次之后进行自检，0或者-1表示关闭此功能-i #:每挂载使用多少天之后进行自检，0或者-1表示关闭此功能(因为系统默认是挂载达到多少次或者多少天之后进行自检，如果文件很大而自检次数hen频繁的话，系统的IO会很高，有时会影响到系统的性能。所以通过设定-c和-i来修改默认的自检次数或者天数)-l /dev/sda5:显示超级块的信息(所有块组的信息都存储在超级块中)-o:设定默认挂载选项 4、dumpe2fs:显示文件系统属性信息可选参数:-h:只显示超级块中的信息 5、fsck:filesystem check，检查并修复linux文件系统可选参数:-t:指定文件系统类型(不指定也没关系，fsck会自动调用blkid来查看类型)-a:自动修复(不与用户交互) 6、e2fsck:专门用于检查并修复ext2、ext的文件系统可选参数:-f:强制检查-p:自动修复(也可以使用-a) 文件系统配置文件:/etc/fstabOS在初始化时，会自动挂载此文件中定义的每个文件系统配置文件格式:第一列:要挂载的设备，/dev/sda5第二列:挂载点，/mnt/test第三列:文件系列类型，ext3第四列:挂载选项，默认是defaults第五列:转储频率，跟文件系统备份相关，每多少天做一次完全备份第六列:文件系统检测次序，只有根文件系统为1，可以多个文件系统为2。0标识不检测注意事项:(1)以上设置可以让/dev/sda5在开机之后自动挂载到/mnt/test上(2)如果挂载设备时一个swap分区的话，它的挂载点也是swap(3)伪文件系统:tmpfs、devpts、sysfs、proc，用来实现特定功能的，不得不挂载(2)转储频率:0表示不备份，1表示每天都要备份，2表示每2天备份一次等等","categories":[{"name":"linux磁盘管理","slug":"linux磁盘管理","permalink":"http://yoursite.com/categories/linux磁盘管理/"}],"tags":[{"name":"文件系统","slug":"文件系统","permalink":"http://yoursite.com/tags/文件系统/"}]},{"title":"IP、TCP、UDP","slug":"IP报文和TCP报文","date":"2018-10-31T01:47:00.000Z","updated":"2018-10-31T02:42:22.783Z","comments":true,"path":"2018/10/31/IP报文和TCP报文/","link":"","permalink":"http://yoursite.com/2018/10/31/IP报文和TCP报文/","excerpt":"","text":"1、IP报文(1)IP VERSION:IP版本号(2)HEAD LEN:报文首部长度(3)TYPE OF SERVICE(TOS):服务类型(在现实生活中比如快递中的加急快件等)(4)TOTAL LEN:整个数据报文的长度(5)FRAGMENT ID:标识分片之后的报文;FRAGMENT OFFSET:标识分片之后的报文组合 #其中MF(MORE FRAGMENT)值为1表示报文分片;DF值为1表示报文没有分片(6)TTL:定义最大跳数(7)PROTOCOL:定义IP网络层上一层的协议(8)HEADER CHECKSUM:校验和，判断数据前后是否一致(9)源IP(10)目的IP(11)OPTION:可选选项(12)要传输的数据 2、TCP报文(1)TCP HEADER:TCP首部(2)SOURCE PORT:源端口(3)DESTINATION PORT:目标端口(4)SEQUENCE NUMBER:序列号(5)ACKNOWLEDGEMENT NUMBER:确认号(6)HEADER LENGTH:首部长度(7)URG:紧急位(8)URGENT POINTER:紧急指针(URG值为1表示指针有效，否则指针无效)(9)ACK:确认位(确认位为1，确认号有效；确认位为0，确认号无效)(10)PUSH值为1表示有优先传输的特权(因为数据传输都是通过网卡来传输的，不同的进程数据，在发送之前，会放置发送缓冲区当中再逐个的往外发送；同样的接收数据也会先保存到接收缓冲区当中。PUSH为1表示不再先保存至缓冲区当中，而是直接往外发送或者接收)(11)RST:重置位(12)SYN:三次握手发的包(13)FIN:四次关闭发的包(14)WINDOW SIZE:窗口大小(当发送方发送数据的速率和接收方接收数据的速率不一致的时候需要用到，其实发送速率和接收速率取决于发送缓冲区和接收缓冲区可容纳的数据)(15)TCP CHECKSUM:TCP校验和(16)OPTION:可选选项(17)DATA:数据 3、TCP与UDP的区别:TCP，transmission control protocol，传输控制协议(相当于打电话，特点是可靠，但是效率低)UDP，user datagram protocol，用户数据报协议(相当于发短信，特点是不靠谱，但是速度快)备注:对于即时通讯都是采用UDP协议，比如QQ，它是在应用层来保证通讯的可靠性 4、三次握手和四次关闭:(1)三次握手A:SYN=1,sn=100(sn即seq num，序列号，随机生成)B:SYN=1,ACK=1,an=101(an即ack num，确认号，序列号加1)，sn=300(随机生成)A:ACK=1,an=301(2)四次关闭A:FIN=1B:ACK=1B:FIN=1A:ACK=1","categories":[{"name":"linux网络管理","slug":"linux网络管理","permalink":"http://yoursite.com/categories/linux网络管理/"}],"tags":[{"name":"IP","slug":"IP","permalink":"http://yoursite.com/tags/IP/"},{"name":"TCP","slug":"TCP","permalink":"http://yoursite.com/tags/TCP/"},{"name":"UDP","slug":"UDP","permalink":"http://yoursite.com/tags/UDP/"}]},{"title":"linux软件编译安装","slug":"inux软件编译安装","date":"2018-10-30T06:09:00.000Z","updated":"2018-10-30T06:37:31.958Z","comments":true,"path":"2018/10/30/inux软件编译安装/","link":"","permalink":"http://yoursite.com/2018/10/30/inux软件编译安装/","excerpt":"","text":"首先，程序运行过程：源程序–&gt;编译–&gt;链接–&gt;运行c语言是将源代码编译成二进制格式，编译需要编译环境(开发环境)、编译工具等(跟C语言相比，脚本语言是解释器直接解释成二进制格式，不需要编译) 编译环境:因为linux的内核是使用c语言开发的，有部分跟平台相关的代码是用汇编语言写的。linux上运行的众多gnu软件，大多数也是用c开发的。因此最流行的的开发环境：C、C++、PERL、JAVA、PYTHON等。 编译工具:gcc:C的编译工具，全称是GNU complier cg++:C++的编译工具make:C或者C++的项目管理工具makefile:定义了make按什么顺序去编译这些源程序文件中的源程序automake:–&gt;makefile.in–&gt;makefileautoconf:–&gt;configure 编译安装三步骤:(注意要在源程序的目录下操作)前提:准备开发环境(编译环境)，最简单的就是安装两个组”Development tools”和”Development libraries”1、configure–help #获取帮助–prefix= #指定软件安装路径(会自动生成/bin和/sbin目录)–sysconfdir= #指定配置文件安装目录(如果不指定的话，默认安装在软件安装路径下的conf目录或者etc目录)–conf-path= #指定配置文件安装文件configure功能:(1)让用户选择编译特性(通过参数赋值)(2)检查编译环境2、make3、make install 编译安装之后的一些环境变量的问题:1、修改PATH环境变量，以能够识别此程序的二进制文件路径(提示找不到命令，大多是原因是命令的路径没有包含在$PATH中)在/etc/profile.d/目录下建立一个以.sh为名称后缀的文件，在里面定义export PATH=$PATH:/path/to/somewhere然后重新登录一下终端，比如克隆一个终端，配置即可生效 2、默认情况下，系统搜索库文件的路径是/lib，/usr/lib，要增加额外的搜索路径在/etc/ld.so.conf.d/目录下创建以.conf为后缀名的文件，然后把要增添的路径写到此文件中(例如apache的库文件路径/usr/local/apache/lib)然后运行ldconfig，通知系统重新搜索库文件-v则显示重新搜索库文件的过程 3、增加头文件的搜索路径，默认是/usr/include增加搜索路径的方式有两种:(使用链接)ln -s /usr/local/apache/include/* /usr/include(这会创建一堆链接，对将来管理这些链接的时候不方便)ln -s /usr/local/apache/include /usr/include/apache(推荐使用这种方式) 4、man文件路径默认安装在–prefix指定的目录下的man目录","categories":[{"name":"linux软件管理","slug":"linux软件管理","permalink":"http://yoursite.com/categories/linux软件管理/"}],"tags":[{"name":"编译安装","slug":"编译安装","permalink":"http://yoursite.com/tags/编译安装/"}]},{"title":"rpm包的前端工具--yum","slug":"rpm包的前端工具-yum","date":"2018-10-30T03:45:00.000Z","updated":"2018-10-30T06:04:32.012Z","comments":true,"path":"2018/10/30/rpm包的前端工具-yum/","link":"","permalink":"http://yoursite.com/2018/10/30/rpm包的前端工具-yum/","excerpt":"","text":"why–为什么是yumyum依赖于rpm，功能比rpm强大因为rpm有一个很大的缺陷就是依赖关系，yum的出现就是用来解决依赖关系的 what–什么是yum(1)yum架构:C/S架构(2)yum仓库:yum的工作依赖于server端的yum仓库(yum repository)yum仓库中的元数据文件(位于repodata目录下):primary.xml.gz:所有rpm包的列表、各种包的依赖关系、每个rpm包安装生成的文件列表(局部概念)filelists.xml.gz:当前仓库中所有rpm包的文件列表(全局概念)other.xml.gz:额外信息，rpm包的修改日志(单个软件包各个发行版的发行时间、作者等)repomd.xml:记录的是上面三个文件的时间戳和校验和comps*-.xml:rpm分组信息(3)yum配置:/etc/yum.confyum仓库的配置文件:/etc/yum.repos.d/目录下面的各个文件就是各个仓库文件(文件名格式:file.repo，必须是以repo结尾)定义repo文件:(for example)[Repo_ID]name=Descriptionbaseurl= #有三种路径，ftp、http、file(本地)ftp://http://file:///(第3个/表示根路径)enable={1|0} #1表示启用gpgcheck={1|0} #1表示校验gpgkey= #如果设置gpgcheck=1必须有此项，否则不需要此项 how–怎么使用yum备注:要注意跟rpm命令对比下，很多命令的功能是差不多的(1)yum clean:清缓存(2)yum list [all|available|installed]:查看所有的安装包，包括安装的和未安装的(已安装的最后一个字段显示install，未安装的显示[Repo_ID]，也就是仓库文件里面的第一行定义的那个ID)yum list all:显示所有的软件包(直接yum list默认也是显示所有的软件包)yum list available:可用的，仓库中有但是未安装的yum list installed:已经安装的yum list updates:可用的升级yum list all +通配符的包名:查看匹配的软件包(3)yum repolist [all|enabled|disabled]:查看库的信息yum repolist all:显示所有repo列表及其简要信息yun repolist enabled:显示可用的repo列表及其简要信息(直接yum repolist默认就是显示enabled的repo表)yum repolist disabled:显示不可用的repo列表及其简要信息(4)yum install:安装软件包(5)yum update:默认升级到最新版本yum update-to:指定升级到特定版本(6)yum remove/rease:卸载(7)yum info:查看软件包的简要信息(8)yum provide/whatprovides:查看指定的文件或特性是由哪个包生成的(9)软件包组groupyum groupinfoyum grouplistyum groupremoveyum groupupdateyum groupinstallyum grouplocalinstall备注:groupinstall和grouplocalinstall的区别在于，install只需要指定包名，localinstall则必须指定包文件，也就是以rpm包结尾的文件。用yum相比用rpm安装的好处在于，如果仓库中刚好包有依赖包，yumlocalinstall可以解决依赖关系 创建yum仓库:createrepo命令","categories":[{"name":"linux软件管理","slug":"linux软件管理","permalink":"http://yoursite.com/categories/linux软件管理/"}],"tags":[{"name":"yum","slug":"yum","permalink":"http://yoursite.com/tags/yum/"}]},{"title":"ubuntu16.04安装MongoDB","slug":"MongoDB","date":"2018-10-24T07:30:00.000Z","updated":"2018-10-24T08:05:13.425Z","comments":true,"path":"2018/10/24/MongoDB/","link":"","permalink":"http://yoursite.com/2018/10/24/MongoDB/","excerpt":"","text":"1、通过tgz压缩包安装:(1)wget https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-ubuntu1604-4.0.3.tgz(2)tar zxvf mongodb-linux-x86_64-ubuntu1604-4.0.3.tgz(3)cp -pr mongodb-linux-x86_64-ubuntu1604-4.0.3 /usr/local/mongodb #-p表示保留源文件的属性，-r表示递归复制(4)bin/mongod &amp; #会报错，因为不指定数据目录的时候，默认会以/data/db目录作为数据目录，因此不存在/data/db目录时会报错，可以创建一个/data/db目录，也可以在启动mongod的时候指定dbpath为自定义的数据目录，像这样:bin/mongod –dbpath= ~/db(5)可以通过bin/mongod –help来查看mongod的帮助选项备注:通过这样的方式安装的mongod，默认没有配置文件，需要自己创建配置文件。一般不建议通过这种方式安装mongod 2、通过apt-get安装:(1)导入软件源公钥sudo apt-key adv –keyserver hkp://keyserver.ubuntu.com:80 –recv EA312927(2)为mongodb创建软件源list文件ubuntu16.04:echo “deb http://repo.mongodb.org/apt/ubuntu xenial/mongodb-org/3.4 multiverse” | sudo tee /etc/apt/sources.list.d/mongodb-org-3.4.list #mongodb-org/3.4 的3.4 为版本号，可更换为你想要安装的版本(3)更新软件源sudo apt-get update #更新的时候可能会报错，提示由于没有公钥，无法验证下列签名： NO_PUBKEY 3EE66BD3F599ACE3这时候，只需要重新运行第一步，软件源公钥替换成错误提示中的key，然后重新运行sudo apt-get update(4)安装mongodbapt-get install -y mongodb-org #如果想要安装指定的版本，使用下面的命令:sudo apt-get install -y mongodb-org=3.2.9 mongodb-org-server=3.2.9 mongodb-org-shell=3.2.9 mongodb-org-mongos=3.2.9 mongodb-org-tools=3.2.9(上面的命令需要把3.4改为3.2)(5)开机启动systemctl enable mongod(6)启动、停止mongod和查看mongod服务状态systemctl start mongod.servicesystemctl stop mongod.servicesystemctl status mongod.service备注:mongodb启动报错，其中大量提到WiredTiger error，主要报错提示如下txn-recover: unsupported WiredTiger file version WiredTiger error这时候，把/data/db目录下的文件清空，再重新启动就可以了(亲测有效)，但是如果数据库中有重要数据, 不建议采取此方法。安装参考链接:https://github.com/cgDeepLearn/LinuxSetups/blob/master/docs/databases/mongodb.md 补充mongodb图形化工具:NoSQLBooster for MongoDB(windows)下载链接:https://nosqlbooster.com/downloads工具截图:","categories":[{"name":"安装篇","slug":"安装篇","permalink":"http://yoursite.com/categories/安装篇/"}],"tags":[{"name":"mongodb","slug":"mongodb","permalink":"http://yoursite.com/tags/mongodb/"}]},{"title":"QA","slug":"QA","date":"2018-10-22T03:29:00.000Z","updated":"2018-10-29T04:07:10.034Z","comments":true,"path":"2018/10/22/QA/","link":"","permalink":"http://yoursite.com/2018/10/22/QA/","excerpt":"","text":"1、mysql max_allowed_packet自动重置为1024 最后发现是被人搞了。发现过程:打开general.log记录日志，查找日志(1)grep “SET GLOBAL” ubuntu.log，日志截图，发现有改动痕迹 (2)选择某一个query ID，例如188592 (3)把这个链接的文件下载下来，360马上就提示这是一个病毒文件 因此，被人搞是确定无疑了。。 然后，赶紧把mysql的密码改了(原密码是mysql…因为这个服务器还没上线，所以密码也设置得很简单…)","categories":[{"name":"QA","slug":"QA","permalink":"http://yoursite.com/categories/QA/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/tags/mysql/"}]},{"title":"NFS入门","slug":"NFS","date":"2018-10-19T05:39:00.000Z","updated":"2018-10-19T07:57:16.806Z","comments":true,"path":"2018/10/19/NFS/","link":"","permalink":"http://yoursite.com/2018/10/19/NFS/","excerpt":"","text":"1、NFS介绍NFS是”Network File system”的缩写，即网络文件系统网络文件系统是应用层的一种应用服务，它主要应用于linux与linux系统，linux与unix系统之间的文件或目录的共享。当用户想要使用远程文件的时候，只要用mount命令就可以把远程文件系统挂载到本地的文件系统上，操作远程文件就跟操作自己本地操作系统的文件一样。采用NFS之后省去了登录的过程，方便了用户访问系统资源。一言以蔽之，NFS的主要功能就是通过网络让不同的主机系统之间可以彼此共享文件或目录。 2、NFS原理对于linux而言，文件系统是在内核空间实现的，即文件系统比如ext3、ext4等是在kernel启动时，以内核模块的身份加载运行的。类似的，NFS(网络文件系统)也是工作在内核空间。NFS本身的服务没有提供数据传递的协议，而是通过使用RPC(Remote Procedure Call)来实现。具体实现过程如下:(1)本地用户要使用NFS服务器中的文件，先向内核发起请求，内核调用NFS模块以及rpc client(2)rpc client向rpc server发起连接(3)在连接之前，NFS服务除了启动nfsd本身监听的端口2049/tcp和2049/udp，还会启动其他进程(如mount，statd,rquotad等)已完成文件共享，这些进程的端口是不固定的，是每次NFS服务启动时向RPC服务注册的，RPC服务会随机分配未使用的端口(4)完成连接，接受访问请求(5)NFS应用程序向内核发起请求(6)内核调用文件系统然后client端通过获取的NFS端口来建立和server端的NFS连接并进行数据的传输简单来说，NFS客户端与服务端的通信过程:(1)先与rpc服务通信(tcp和udp的111端口)(2)再根据rpc提供的mounted监听端口，与mounted通信；mounted进程会对用户进行验证，验证通过返回用户一个通行证(3)最后客户端与nfsd进程建立联系进行通信 3、NFS服务器端组件:nfs-utilsrpm -ql nfs-utils #查看nfs-utils程序所生成的文件NFS服务端将启动3个主进程:(1)nfsd，跟NFS文件传输相关，工作在tcp和udp的2049端口(2)mounted，跟客户端挂载相关，随机端口(3)quotad，跟磁盘配额相关，随机端口备注:mounted和quotad的端口是随机产生的，不是固定的，每次重启nfs端口会发生变化。由此我们最好自定义端口。定义mounted和quotad进程监听固定端口:编辑/etc/sysconfig/nfs文件 #MOUNTED_PORT= #QUOTAD_PORT= #LOCKED_TCPPORT= #LOCKED_UDPPORT= 4、rpc介绍(1)rpc，远程过程调用，是一种编程技术，主要是用于简化分布式应用程序的开发。因为如果需要在两台主机上的进程进行通信，那么客户端、服务器端必须要处理网络传输中的网络请求、网络响应等等。这时候就大大增加了程序员开发的难度。因此就出现了rpc的框架。由此，程序员在开发客户端和服务端的时候，不需要再下功夫去处理网络协议报文的封装，因为rpc在底层就完成了这种观功能。(2)NFS是基于rpc来进行网络传输的，使得本地主机访问远程主机的时候，就好像本地主机访问本地一样。网络通讯过程对于本地主机来说是透明的。(3)在linux提供rpc服务的程序，叫做portmap，自身监听在tcp和udp的111端口。rpc与portmap的关系是，rpc是协议，portmap是实现，相当于http协议和apache、nginx、lightted的关系(4)rpc实现数据交换，可以基于二进制格式，也可以基于文本格式，基于文本格式比较常见的叫做XLRPC，后来又发展为SOAP 5、NFS介绍NFS是由SUN公司开发的，NFS版本有:NFSV1(SUN公司内部使用)NFSV2(早期公开版)NFSV3(在RHEL5上使用)NFSV4(在RHEL6上使用)NFS的缺点:(1)NFS可以基于认证，但是在认证这一块的功能是非常弱的，只认ID号，不认用户名举例子:假如在一台主机上有一个用户名叫做tom，通过NFS在另外一台主机上创建了一个目录，那么a.如果另外一台主机上没有tom这个用户，那么创建的目录的属主和属组是tom对应的uid和gidb.如果另外一台主机上有一个叫做jerry的用户，他的uid跟tom的uid一样，那么在另外一台主机上创建的这个目录的属主和属组就是jerry正是因为NFS不支持用户名认证，所以NFS一般不支持在互联网上使用，多用于在内网中各主机之间实现文件共享服务(2)NFS只支持在linux/unix上进行通信，不支持在windows主机上通信(linux上的NFS其实就相当于windows上的网上邻居，所以windows网上邻居的功能也是基于类似于rpc的协议来实现的) 6、NFS配置文件:/etc/exports只需要在这个文件中定义共享哪个目录出去，并且能够让客户端挂载，就能够让客户端像使用本地目录那样来使用这个共享出去的目录查看NFS的exports配置帮助的相关文档:man export 7、export文件格式:共享目录 客户端列表备注:(1)如果有多个客户端，客户端之间用空白字符分隔；而且每个客户端必须跟上一个小括号，里面定义了此客户端的访问特性，比如访问权限等(2)编辑保存之后需要重启nfs服务(3)文件系统访问特性有:ro:只读rw:只写sync:同步async:异步root_squash:将root用户映射为来宾用户，默认开启此功能no_root_squash:一台主机上的root用户访问另外一台主机的文件系统，是以另外一台主机的文件系统的root用户身份来访问的all_squash:将所有访问的用户映射为来宾用户anonuid,anongid:指定映射的来宾用户的uid和gid 8、命令相关(1)showmount命令:这个命令在客户端和服务端都可以使用-a:列出所有的客户端地址以及挂载的目录 #showmount -a 服务端IP，这条命令在客户端和服务端都可以实现-e:显示服务器共享了哪些目录 #showmount -e 服务端IP-d:显示NFS服务器共享出来的目录有哪些是被客户端挂载了的 #showmount -d 服务端IP (2)exportfs命令:-a:一般是跟-r或者-u选项同时使用，表示重新挂载(或者说导出，export)所有目录(或者说文件系统)或者取消挂载(导出)所有目录(文件系统)-r:重新导出-u:取消导出(这时候export下的所有文件系统或者目录都不能被客户端访问) #exportfs -uav-v:显示详细信息备注:当我们修改export文件的时候，需要重启nfs服务配置才会生效。使用exportfs就可以不用重启nfs服务，相当于reload (3)rpcinfo命令rpcinfo -p IP #查看mount或者quotad监听的端口号rpcinfo -p localhost #查看本机上rpc程序所监听的端口 (4)mount命令客户端使用mount命令挂载:mount -t nfs NFS_SERVER:/PATH /PATH #需要指定类型为nfsmount -t nfs 172.16.100.7:/shared /mnt/nfs #把172.16.100.7的shared目录共享出去，客户端挂载该目录即可使用 9、NFS开机自启动chkconfig nfs on 10、客户端开机自动挂载nfs目录编辑/etc/fstab文件，格式如下:172.16.100.1:/shared /mnt/nfs nfs defaults 0 0172.16.100.1:/shared /mnt/nfs nfs defaults,_rnetdev 0 0备注:man mount有一个挂载选项需要关注，_rnetdev:如果文件系统挂不上，就自动忽略掉 参考链接:https://www.cnblogs.com/whych/p/9196537.html","categories":[{"name":"linux共享服务","slug":"linux共享服务","permalink":"http://yoursite.com/categories/linux共享服务/"}],"tags":[{"name":"NFS","slug":"NFS","permalink":"http://yoursite.com/tags/NFS/"}]},{"title":"HTML基础","slug":"Untitled-3","date":"2018-10-17T07:14:00.000Z","updated":"2018-12-19T08:02:50.231Z","comments":true,"path":"2018/10/17/Untitled-3/","link":"","permalink":"http://yoursite.com/2018/10/17/Untitled-3/","excerpt":"","text":"HTML:HyperText Markup Language,超文本标记语言 1、HTML特点(1)HTML不需要编译，直接由浏览器执行(2)HTML文件是一个文本文件(3)HTML文件必须使用html或者xml为文件名后缀(4)HTML大小写不敏感 2、HTML基本结构 3、HTML标签(1)&lt;&gt;括起来(2)一般成对出现，分开始标签和结束标签。结束标签比开始标签多一个/(3)单标签:没有结束标签(4)标签属性 4、HTML标签类型(1)标题标签:h1到h6 (2)段落标签 段落标签align属性left:多对齐right:右对齐center:居中对齐justify:对行进行伸展，这样每行都可以有相等的长度(3)文字标签 (4)换行标签 (5)水平线标签 水平线标签属性width:设置水平线宽度，可以是像素或者是百分比color:设置水平线颜色align:设置水平线对齐方式noshade:设置水平线无阴影(6)列表标签之无序列表 无序列表标签type属性disc:圆点square:正方形circle:空心圆(7)列表标签之有序列表 有序列表标签type属性1:数字1,2…a:小写字母a,b..A:大写字母A,B..i:小写罗马数字iI:大写罗马数字I(8)列表标签之定义列表 (9)图像标签 图像标签属性 (10)超链接标签 超链接标签属性 5、HTML元素在开始标签和结束标签中的所有代码，称为HTML元素 6、HTML注释 7、DOCTYPE文档类型声明 8、网页编码设置","categories":[{"name":"HTML","slug":"HTML","permalink":"http://yoursite.com/categories/HTML/"}],"tags":[{"name":"html","slug":"html","permalink":"http://yoursite.com/tags/html/"}]},{"title":"grep入门","slug":"grep","date":"2018-10-17T06:08:00.000Z","updated":"2018-10-17T06:23:13.109Z","comments":true,"path":"2018/10/17/grep/","link":"","permalink":"http://yoursite.com/2018/10/17/grep/","excerpt":"","text":"grep:根据模式搜索文本，并将符合模式的文本行显示出来 模式(pattern)的概念:文本字符和正则表达式的元字符组合而成的匹配条件 grep版本:(1)grep(2)egrep(3)fgrep grep用法:grep [option] pattern [file…]备注:(1)模式(pattern)要用引号引起来。在shell中，单引号是强引用，双引号是弱引用。(2)强引用指的是单引号里面的内容会原封不动(3)弱引用指的是引用变量，变量会被赋值为对应的值(4)在模式引用中，只要不涉及到变量的引用，单引号和双引号都可以；如果模式中没有包含正则表达式的元字符的时候，实际上不加引号也可以 option:-i 忽略大小写–color 匹配的字符高亮显示(可以通过别名，用alias grep=’grep –color’将grep的高亮显示作为默认显示)-v 反向grep-o 只显示被模式匹配到的字符串(默认会显示包含模式匹配到的整行文本)-E 支持扩展的正则表达式(相当于egrep)-A n 显示匹配到的字符串所在行及向下的n行-B n 显示匹配到的字符串所在行及向上的n行-C n 显示匹配到的字符串所在行及其上和其下的n行","categories":[{"name":"linux文本处理","slug":"linux文本处理","permalink":"http://yoursite.com/categories/linux文本处理/"}],"tags":[{"name":"grep","slug":"grep","permalink":"http://yoursite.com/tags/grep/"}]},{"title":"正则表达式","slug":"正则表达式","date":"2018-10-17T03:45:00.000Z","updated":"2018-12-10T09:36:46.354Z","comments":true,"path":"2018/10/17/正则表达式/","link":"","permalink":"http://yoursite.com/2018/10/17/正则表达式/","excerpt":"","text":"regular expression，简写REGEXP主要关注正则表达式里面的一些元字符，这些字符不表示本身的意义，而表示一些通配的意义(正则表达式默认工作在贪婪模式下，即尽可能长的匹配) 模式的概念:字符和正则表达式的元字符组合起来过滤文本的过滤条件 正则表达式分两类:basic regexp:基本正则表达式extended regexp:扩展正则表达式 基本正则表达式:(1)字符匹配. 匹配任意单个字符[] 匹配指定范围之内的任意单个字符[^] 匹配指定范围之外的任意单个字符也可以字符集合的方法来表示匹配字符集合里面的任意单个字符[:digit:] 数字[:alpha:] 所有字母[:alnum:] 数字和字母[:lower:] 小写字母[:upper:] 大写字母[:punct:] 标点符号[:space:] 空白字符注意:使用字符集合的时候，还要使用一个方括号括起来，就是要用到两个方括号 (2)次数匹配:* 匹配其前面的字符任意次.* 匹配任意长度的任意字符(跟通配符中的*表示的一样)\\? 匹配其前面的字符0次或1次\\{m,n\\} 匹配其前面的字符最少m次，最多n次(反斜线是用来转义的，因为在bash shell中，花括号会被理解成命令行展开)\\{m\\} 匹配其前面的字符最少m次举栗子:a.*b 表示a开头，b结尾，中间是任意长度的任意字符\\{1,\\} 最少1次\\{0,3\\} 最多3次 (3)位置锚定^ 锚定行首，此字符后面的任意内容必须出现在行首$ 锚定行尾，此字符前面的任意内容必须出现在行尾^$ 表示空白行\\&lt;或者\\b:锚定词首，其后面的任意字符必须作为单词的首部出现>或者\\b:锚定词尾，其前面的任意字符必须作为单词的尾部出现举栗子:\\&lt;root\\&gt; 匹配单词root(root既是词首，也是词尾) (4)分组\\(..\\)\\(ab\\) ab作为一个整体，ab可以出现0次、1次或者多次分组的主要目的是:后向引用，在后面引用前面括号括起来的内容\\1 引用第一个小括号分组中的内容\\2 引用第二个小括号分组中的内容\\3 引用第三个小括号分组中的内容举栗子:grep ‘\\(l..e\\).\\1’ test.txt可以匹配到以下两行:He love his lover.He like his liker. 扩展正则表达式:(1)字符匹配. 匹配任意单个字符[] 匹配指定范围之内的任意单个字符[^] 匹配指定范围之外的任意单个字符 (2)次数匹配* 匹配其前面的字符任意次.* 匹配任意长度的任意字符(跟通配符中的*表示的一样)?:匹配其前面的字符0次或1次+:匹配其前面的字符至少1次，相当于{1,}{m,n} 匹配其前面的字符最少m次，最多n次(在扩展正则表达式中，不需要加反斜线){m} 匹配其前面的字符最少m次 (3)位置锚定^ 锚定行首，此字符后面的任意内容必须出现在行首$ 锚定行尾，此字符前面的任意内容必须出现在行尾\\&lt;或者\\b:锚定词首，其后面的任意字符必须作为单词的首部出现>或者\\b:锚定词尾，其前面的任意字符必须作为单词的尾部出现 (4)分组() #不需要加反斜线\\1 引用第一个小括号分组中的内容\\2 引用第二个小括号分组中的内容\\3… (5)竖线| 表示或者的意思C|cat 匹配C或者cat(C|c)at 匹配Cat或者cat 总结:1、基本正则表达式和扩展正则表达式的区别:(1)扩展正则表达式中，表示分组的括号和表示次数匹配的花括号和问号，前面都不需要加反斜线(2)扩展正则表达式中，次数匹配多了一个”+”号，表示匹配一次或者多次(3)扩展正则表达式中，多了一个竖线的符号，表示或者的意思 2、正则表达式和通配符的区别:在文本过滤工具里面，都是用正则表达式，比如像awk、sed、grep等，都是针对文件内容的；而通配符是linux系统本身就支持的，多用在文件名上，比如像find、ls、cp，等等 通配符:* 任意长度的任意字符? 任意单个字符[] 指定范围内[^] 指定范围外","categories":[{"name":"linux文本处理","slug":"linux文本处理","permalink":"http://yoursite.com/categories/linux文本处理/"}],"tags":[{"name":"正则","slug":"正则","permalink":"http://yoursite.com/tags/正则/"}]},{"title":"awk入门","slug":"awk入门","date":"2018-10-17T03:37:00.000Z","updated":"2019-02-25T03:52:03.895Z","comments":true,"path":"2018/10/17/awk入门/","link":"","permalink":"http://yoursite.com/2018/10/17/awk入门/","excerpt":"","text":"awk:报告生成器，根据输入信息，将输入信息格式化之后再显示出来 awk版本:(1)awk(2)new awk,简称nawk(3)gnome awk,简称gwak awk使用格式:awk [options] ‘PATTERN { action }’ file1,file2… options:-F 指定分隔符BEGIN{OFS=””} 指定输出分隔符 在options中使用的内置变量(1)awk内置变量之记录变量:FS:读取文本时所使用的字段分隔符，默认是空白字符RS:读取文本时所使用的换行符OFS:输出分隔符ORS:输出换行符 (2)awk内置变量之数据变量:NR:awk命令所处理的记录数。如果有多个文件，这个数目会把处理的多个文件中的行统一计数FNR:记录正处理的行是当前这一文件中被总共处理的行中是第几行NF:用于统计正在处理的行中的字段总数($NF:正在被处理的行中的最后一个字段) 常见的PATTERN类型:1.regexp，正则表达式，格式为/reglar expression/示例：awk -F: ‘/^r/{print $1}’ /etc/passwd #显示passwd文件中以r开头的用户名2.expression，表达式，比如$1 ~ /foo/ 或$1 == “magedu”等示例：awk -F: ‘$3&gt;=500{print $1,$3}’ /etc/passwd #显示passwd文件中uid大于300的用户及其uidawk -F: ‘$7~”bash$”{print $1,$7}’ /etc/passwd #显示passwd文件中以bash shell为shell的用户名及其对应的shell3.BEGIN/END,特殊模式，在awk命令执行之前运行一次或结束之前运行一次BEGIN:在awk处理文本第一行之前执行END:在awk处理文本最后一行之前执行实例：awk -F: ‘BEGIN{print “Username ID Shell”}{printf “%-10s%-10s%-20s\\n”,$1,$3,$7}END{print “end of report”}’ /etc/passwd #在第一行打印”Username ID Shell”，在最后一行打印”end of report” 常见的actions类型:控制语句：1.if-else实例：awk -F: ‘{if ($1==”root”) print $1,”admin”;else print $1,”common user”}’ /etc/passwd2.while实例：awk -F: ‘{i=1;while (i&lt;=3) {print $i;i++}}’ /etc/passwd3.do-whileawk -F: ‘{i=1;do {print $i;i++}while(i&lt;=3)}’ /etc/passwd4.forawk -F: ‘{for(i=1;i&lt;=3;i++)print $i}’ /etc/passwd5.case6.break,continue(跳过本字段)7.next(跳过本行) awk使用数组：示例：awk -F: ‘{shell[$NF]++}END{for(A in shell){print A,shell[A]}}’ /etc/passwd #生成一个shell数组，并统计passwd文件中各种shell的个数，A指的是下标netstat -tan | awk ‘/^tcp/{STATE{$NF}++}END{for (S IN STATE){print S,STATE[S]}}’ #生成一个STATE数组，并统计各种程序状态的个数，S指的是下标awk ‘{counts[$1]++}END{for(ip in counts){printf “%-20s:%d\\n”,ip,count[ip]}}’ /var/log/httpd/access.log #统计web日志文件中IP地址的访问量备注：awk中的下标很独特，可以是任意字符串","categories":[{"name":"linux文本处理","slug":"linux文本处理","permalink":"http://yoursite.com/categories/linux文本处理/"}],"tags":[{"name":"awk","slug":"awk","permalink":"http://yoursite.com/tags/awk/"}]},{"title":"初步认识docker","slug":"docker入门","date":"2018-10-12T01:26:00.000Z","updated":"2018-12-19T07:24:19.329Z","comments":true,"path":"2018/10/12/docker入门/","link":"","permalink":"http://yoursite.com/2018/10/12/docker入门/","excerpt":"","text":"什么是dockerdocker是一个开源的应用容器引擎，让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的linux机器中，也可以实现虚拟化。docker的目标是实现轻量级操作系统虚拟化的解决方案。(基于Go语言开发) docker简单原理docker的基础是linux容器(LXC)、Cgroup技术。docker是在LXC的基础上进行了进一步的封装，让用户不再需要去关心容器的管理，使得操作更加简便。用户操作docker的容器就像操作一个快速轻量级的虚拟机一样简单。与传统虚拟户(KVM、XEN等)相比较：(1)docker是在操作系统层面上实现虚拟化，直接复用本地主机的操作系统(由下往上:硬件-&gt;host操作系统-&gt;docker engine-&gt;应用库-&gt;应用app) (2)传统的虚拟化方式是在硬件的基础上，虚拟出自己的系统，再在系统上部署相关的APP应用(由下往上:硬件-&gt;host操作系统-&gt;hypervisor-&gt;guest操作系统-&gt;应用库-&gt;应用app) docker组件(1)镜像:其实就是模板，跟我们常见的ISO镜像类似，是一个样板(2)容器:使用镜像常见的应用或系统，我们称之为一个容器(容器相当于启动之后的镜像)(3)仓库:仓库就是存放镜像的地方，分为公开仓库(public)和私有仓库(private)两种形式 docker技术组件linux内核的命名空间(namespace)，用于隔离文件系统、进程和网络(1)文件系统隔离:每个容器都有自己的root文件系统(2)进程隔离:每个容器都运行在自己的进程环境中(3)网络隔离:容器间的虚拟网络接口和IP地址都是分开的(4)资源隔离和分组:使用Cgroups(即control group，linux内核特性之一)将cpu和内存之类的资源独立分配给每个docker容器(5)写时复制:文件系统都是通过写时复制创建的(6)日志:容器产生的STDOUT、STDIN和STDERR这些IO流都会被收集并记入日志(7)交互式shell:用户可以创建一个伪tty终端，为容器提供一个交互式shell docker虚拟化特点(1)操作启动快运行时的性能获得极大的提升，管理操作(开始、停止、重启等)都是以秒或者毫秒为单位的(2)轻量级虚拟化你会拥有足够的”操作系统”，仅需添加或减少镜像即可。在一台服务器上可以部署100~1000个container容器，但是传统虚拟化虚拟出10~20个虚拟机就已经很好了(3)开源免费(4)前景及云支持 使用docker的优势(1)提供一个简单、轻量的建模方式用户上手docker非常快，只需要几分钟就可以将自己的程序”docker化”,docker依赖于”写时复制”(copy-on-write)模型，使得修改应用程序也非常迅速。(2)职责的逻辑分离使用docker，开发人员只需要关心容器中运行的应用程序，运维人员只需要关心如何管理容器，从而降低”开发时一切正常，肯定是运维问题”的风险。(3)快速、高效的开发生命周期docker的目标之一就是缩短代码从开发、测试到部署、上线运行的周期，让你的应用程序具备可移植性、易于构建、易于协作。(4)鼓励使用面向服务的架构docker推荐单个容器只运行一个应用程序，这样就形成了一个分布式的应用程序模型。在这种模型下，应用程序或服务都可以表示为一系列内部互联的容器，从而使分布式部署应用程序或者扩展应用程序变得简单。 docker安装先决条件(1)运行64位CPU架构的计算机，不支持32位的CPU(2)运行linux3.8或更高版本的内核查看内核版本:uname -a目前3.8内核已经可以通过apt-get来安装，内核更新步骤:apt-get updateapt-get install linux-headers-3.8.0-27-genericupdate-grubreboot(3)内核必须支持一种适合的存储驱动，默认是Device Mapper检查主机是否安装Device-mapper:grep device-mapper /proc/devices如果没有出现device-mapper的相关信息，可以尝试加载dm_mod模块:modprobe dm_mod(4)内核必须支持并开启cgroup和namespace(命名空间)的功能cgroup和namespace自2.6版本就已经集成到linux内核中，目前为止功能非常稳定 docker安装默认docker只能在centos6.5以上机器才能使用yum直接安装，如果是其他版本的话需要安装centos扩展源epel。docker官方要求linux kernel至少要3.8以上。在centos6.5系统上安装docker:(1)关闭selinux(2)安装epel源wget http://ftp.riken.jp/Linux/fedora/epel/6/x86_64/epel-release-6-8.noarch.rpmrpm -ivh epel-release-6-8.noarch.rpm(3)安装依赖yum install lxc libcgroup device-mapper-event-libsdevice-mapper* -y(4)安装dockeryum install docker-io(5)docker启动/etc/init.d/docker start在ubuntu 16.04安装docker:(1)安装wget -qO- https://get.docker.com/ | sh(2)启动/etc/init.d/docker start备注:在ubuntu中，如果使用UFW，需要在UFW中启用数据报文转发，才能让docker正常工作。因为UFW默认情况下会丢弃所有转发的数据包。修改/etc/default/ufw，将DEFAULT_FORWARD_POLICY=”DROP”修改为DEFAULT_FORWARD_POLICY=”ACCEPT”，保存修改内容并通过ufw reload重启UFW即可 docker常用命令docker version #查看docker版本docker images #查看当前的docker所有镜像docker info #检查docker是否已经正确安装并运行docker search centos #搜索可用的docker镜像docker pull centos #从公有仓库中下载镜像cat centos.tar | docker import - centos6 #导入镜像，导入centos.tar镜像并重命名为centos6docker export id &gt; centos6.tar #导出镜像，根据id导出镜像并重命名为centos6.tardocker ps -l #查看最后一个容器的iddocker ps -a #查看所有容器docker run centos echo “hello world” #在容器中运行”hello world”docker run centos yum install ntpdate #在容器中安装ntpdate程序docker run -i -t centos /bin/bash #在容器中启动一个/bin/bash shell环境，可以登入操作，-t表示打开一个终端，-i表示交互式输入docker run -d centos:v1 /bin/bash #在后台启动一个/bin/bash shell环境，-d表示在后台以daemon方式启动docker run -d -p 80:80 -p 8022:22 centos:v2 #-p指定容器启动后docker上运行的端口映射为容器里运行的端口，80:80中第一个80表示docker系统(本机)的80端口，第二个80表示docker虚拟机(docker容器)里面的端口。用户默认访问本机80端口，自动映射到容器里面的80端口docker commit 2313132 centos:v1 #提交刚修改的容器docker stop id #关闭容器docker start id #启动容器docker rm id #删除容器","categories":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/categories/docker/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/tags/docker/"}]},{"title":"初识java","slug":"初识java","date":"2018-10-10T08:33:00.000Z","updated":"2018-12-07T06:34:55.897Z","comments":true,"path":"2018/10/10/初识java/","link":"","permalink":"http://yoursite.com/2018/10/10/初识java/","excerpt":"","text":"1、先了解一下PHP(1)PHP是开发语言，也是运行环境作为开发语言，PHP属于脚本语言，也属于动态语言 (2)PHP编译过程:为简化编译过程，引入Zend Engine，编译成opcode，第一次编译第二次就不用编译；但是像Apache，每一个进程都使用一个独立的进程空间，因此第一个进程编译的结果第二个进程无法使用，因此又引入了缓存，像Xcache、APC、eAccelerator。 (3)PHP与C(面向过程)、C++(面向对象)相比较:PHP具有动态语言和脚本语言的灵活性、便捷性、移植性好C和C++移植困难、维护成本高，但是高速、性能好，一般用来开发驱动和底层程序等 插入介绍一些linux系统知识:(1)最底层:System call，系统调用上一层:API(application programming interface)，应用编程接口，有windows api和linux api再上一层:POSIX(POS全称portable operation system)，可移植操作系统，后面的IX是为了兼容linux操作系统的叫法。POSIX可以实现跨平台编译，POSIX是一种规范。(2)程序可以跨平台编译，但是不能跨平台运行(因为windows和linux的动态库不一样，windows系统是.so文件，linux系统是.dll文件)。因此，又出现一种叫做ABI的接口，ABI全称是application binary interface，可以拟合不同操作系统的二进制格式。在linux中，二进制格式是ELF；在windows中，二进制格式是EXE 最后引入java，java的出现就是为了能够在不同的操作系统上运行应用程序java包含四个独立又彼此相关的技术:(1)java程序设计语言(2)jvm(java virtual machine)，又叫java虚拟机(3)java class文件格式(4)java api彼此相关:java编程语言结合java api，编译成java class文件格式(字节码)，在jvm上运行(name.java–&gt;name.class,还有各种公有类和私有类跑在jvm上) 2、java apijava ee包含多个独立的api，servlet(硬编码)和jsp(.jsp-&gt;.java-&gt;.class)就是其中的两个，而java ee中著名的api还还包含以下几个:java ee api:(1)ehj(enterprise javabeans):java相关的诸多高级功能的实现，如rmi(remote method invocation)，对象/关系映射，跨越多个数据源的分布式事务等(2)jms(java message service):高性能异步消息服务，实现java ee应用程序与非java程序的透明通信(3)jmx(java management extensions):在程序运行时对其进行交互式监控和管理的机制(4)jta(java transaction api):允许应用程序在自身的一个或多个组件中平滑的处理错误的机制(5)javamail:通过工业标准的POP/SMTP/IMAP协议发送和接收邮件的机制 java se api:jndi(java naming and directory interface):用于与ldap服务交互的apijaxp(java api for xml processing):用于分析和转换xml 3、介绍jvmjvm最大的特点:一次编译，到处运行(once for all)jvm实现方式:(1)一次性解释器，解释字节码并执行(2)即时编译器(just-in-time complier)，依赖于更多内存缓存解释后的结果(3)自适应编译器，监控执行频率较高的代码，并将结果缓存下来(二八法则，缓存20%左右的代码，提高80%左右的速度) jvm分类:(1)hotspot，sum公司自己的jvm，hotspot又分为两类:jre:java运行环境，运行(编译)所需；jre=java语言+java se apijdk:java开发环境(包含jre，是jre的超集)，运行(编译)+开发所需；jdk=java语言+java api+jvm，jdk是实现java程序开发的最小环境(2)openjdk，开源界的jvm开发+运行的开源实现 java分类(根据java应用领域的不同):(1)java se:standard edition，标准版本，早期也叫做J2SE(2)java ee:enterprise edition，企业版本，早期也叫做J2EE(3)java me:mobile edition，移动版本，早期也叫做J2ME(用的很少) #2指的是第二版 4、介绍jdk:(1)jdk包格式jdk 1.6 update 32(jdk1.6的第32次升级，软件包名称是jdk-1.6.32)jdk 1.7 update 9(jdk1.7的第9次升级，软件包名称是jdk-1.7.9)(2)jdk安装方式rmp包通用二进制格式源码编译(3)命令yum list all|grep java #查看操作系统自身提供的jdk软件包java -version #查看java版本 5、介绍jsp(1)早期的时候，出现了applet这种小程序，用于开发动态网站；applet是开发在客户端运行的应用程序，基于web技术(2)接着，出现一种叫做CGI(common gateway interface)规范，能够让用户访问某种资源的时候，触发web服务器，调用额外的程序执行。除了CGI规范，java还提供了一种叫做servlet的规范，用来兼容applet和CGI；servlet是开发运行在服务器端的应用程序，基于CGI技术(3)在servlet的基础上进行升级改造，又引入了jsp(java server page)，用来嵌入java语言；jsp将servlet简化，开发者只需要将java程序嵌入到html代码中 #虽然说jsp拜托了servlet的束缚，但是jsp还是要通过Jasper先转换成servlet；jsp框架能够让java以嵌入式代码的方式嵌入到html代码中，从而实现基于java的动态网站开发 6、介绍java类(类库)有三类:(1)applet(2)servlet(3)jsp.jsp通过Jasper转换为.java.java通过jvm转换为.class 7、垃圾回收机制java程序可以实现自动内存回收，通过GC(gabbage collect)来完成(1)垃圾回收器:cms(Concurrent Mark-Sweep)，cms是以牺牲吞吐量为代价来获得最短回收停顿时间的垃圾回收器。对于要求服务器响应速度的应用上，这种垃圾回收器非常适合。在启动JVM参数加上-XX:+UseConcMarkSweepGC ，这个参数表示对于老年代的回收采用CMS。CMS采用的基础算法是：标记—清除。(2)cms过程:初始标记、并发标记、并发预处理、重新标记、并发清理、并发重置(3)cms优缺点:优点:并发收集、低停顿缺点:无法收集浮动垃圾，由于基于标记-清除算法，可能会产生碎片 8、java配置参数-XX:+ #开启此参数指定的功能-XX:- #关闭此参数指定的功能-XX:= #给option指定的选项赋值示例:java -XX:+PrintFlagsFinal #查看java配置所支持的参数 9、java工具sun jdk免费提供给用户监控和故障处理工具:(在jdk安装目录的bin目录下有很多java工具和命令)(1)jps:java process status tool，显示指定系统内的所有hotspot虚拟机进程的列表信息(2)jstat:jvm staticstics monitoring tool，收集并显示hotspot虚拟机各方面的运行数据(3)jinfo:显示正在运行的某hotspot虚拟机配置信息(4)jmap:生成某hotspot虚拟机的内存转储快照 可视化工具:(1)jconsole:java的监控和管理控制台(2)jvisualvm:java虚拟机控制台 #java工具除了sun开源的工具，还有很多商业的工具","categories":[{"name":"tomcat","slug":"tomcat","permalink":"http://yoursite.com/categories/tomcat/"}],"tags":[{"name":"java","slug":"java","permalink":"http://yoursite.com/tags/java/"}]},{"title":"redis高级功能","slug":"redis高级功能","date":"2018-10-08T09:20:00.000Z","updated":"2018-12-19T07:21:52.861Z","comments":true,"path":"2018/10/08/redis高级功能/","link":"","permalink":"http://yoursite.com/2018/10/08/redis高级功能/","excerpt":"","text":"1、redis认证实现方法:(1)通过配置文件redis.conf修改requirepass PASSWORD #定义连接redis时的密码(2)通过客户端redis-cli修改auth PASSWORD #验证密码，PASSWORD为配置文件中requirepass定义的密码 2、redis事务(1)通过MULTI、EXEC、WATCH等命令实现事务功能:将一个命令或多个命令归并为一个操作提请服务器按顺序执行的机制举栗子:multi #启动(开始)一个事务……exec #执行(结束)一个事务 (2)watch:乐观锁在exec命令执行之前，用于监视指定键；如果监视中的某任意键数据被修改，则服务器拒绝执行事务(因为watch是监视数据是否被修改，一旦确认数据被修改，则放弃使用数据，而不是拒绝对方使用数据，所以叫乐观锁) (3)redis事务与传统关系型数据库的事务最大区别在于:redis不支持回滚 3、redis持久化:本质上是内存数据库redis持久化有两种机制:(1)RDB:快照机制，按事先制定的策略，周期性的将数据保存至磁盘，数据文件默认为dunp.rdb客户端也可以显式使用save或bgsave命令启动快照保存机制save:同步，在主线中保存快照，此时会阻塞所有客户端请求bgsave:异步，bg表示back-ground，后台运行，不会阻塞客户端请求 与rdb相关的配置文件参数:stop-write-on-bgsave-error yes #出错时停止写入rdbcompression yes #rdb文件是否执行压缩来节省磁盘空间rdbchecksum yes #是否对rdb的镜像文件做校验码检测dbfilename dump.rdb #指明文件名dir /var/lib/redis #指明rdb文件保存的目录 (2)AOF：append only file的缩写，把redis的每一个操作命令以附加的形式，附加到指定文件的尾部，会导致文件很大。记录每一次写操作至指定的文件尾部实现持久化，当redis重启时，可以通过重新执行文件中的命令在内存中重建数据库。通过bgrewriteaof来实现aof文件重写，不会读取正在使用的aof文件，而是通过将内存中的数据以命令的方式保存到临时文件中，完成之后替换原来的aof文件 与aof相关的配置文件参数:appendonly no #没有开启aof功能appendfilename “appendonly.aof” #文件名appendfsync always #每次收到写命令就立即写到aof文件appendfsync everysec #每秒钟写一次(折中的方式)appendfsync no #不通知内核，内核爱怎么写就怎么写no-appendfsync-on-write no #重写的时候对新写的操作不做sync操作，而是暂存在内存当中auto-aof-rewrite-percentage 100auto-aof-rewrite-min-size 64m aof重写过程:a.redis主进程通过fork创建子进程b.子进程根据redis内存中的数据创建数据库重建命令序列于临时文件中c.父进程继承client的请求，并会把这些请求中的写操作继续追加至原来的aof文件中；额外的，这些新的写请求还会被放置于一个缓冲队列中d.子进程重写完成，会通知父进程；父进程把缓冲中的命令写到临时文件中e.父进程用临时文件替换老的aof文件 使用子进程进行AOF重写的问题：子进程在进行AOF重写期间，服务器进程还要继续处理命令请求，而新的命令可能对现有的数据进行修改，这会让当前数据库的数据和重写后的AOF文件中的数据不一致如何修正:为了解决这种数据不一致的问题，Redis增加了一个AOF重写缓存，这个缓存在fork出子进程之后开始启用，Redis服务器主进程在执行完写命令之后，会同时将这个写命令追加到AOF缓冲区和AOF重写缓冲区即子进程在执行AOF重写时，主进程需要执行以下三个工作：执行client发来的命令请求；将写命令追加到现有的AOF文件中；将写命令追加到AOF重写缓存中。参考链接:https://blog.csdn.net/hezhiqiang1314/article/details/69396887 备注:重写本身不能取代备份，还应该指定备份策略，对redis数据库进行定期备份rdb与aof同时启用的时候:a.bgsave和bgrewriteaof不会同时执行b.在redis服务器启动数据恢复时，会优先使用aof 4、复制功能(1)特点:a.一个master可以有多个slaveb.支持链式复制c.master以非阻塞的方式同步数据至salve(2)主从(配置):slave slaveof master_ip master_port(3)认证如果master使用requirepass开启了认证功能，从服务器要使用masterauth 来连入服务请求来使用此密码进行验证 5、HA高可用通过sentinel来管理多个redis服务器实现HAsentinel作用:(1)用于监视主服务器(2)实现通知功能(notification)(3)实现自动故障转移 sentinel协议:(1)流言协议:接收主服务器是否下线的通知(2)投票协议:决定哪个服务器成为新的主服务器 sentinel启动:(1)redis-sentinel /path/to/file.conf(2)redis-server /path/to/file.conf –sentinel启动过程:(1)服务器自身初始化，运行redis-server中专用于sentinel功能的代码(2)初始化sentinel状态，根据给定的配置文件，初始化监控的master服务器列表(3)创建指向master的连接 sentinel下线:(1)主观下线:一个sentinel实例判断出某节点下线(2)客观下线:多个sentinel节点协商好判断出某节点下线 sentinel专用配置文件:/etc/redis-sentinel.conf(1)sentinel monitor mymaster 127.0.0.1 6379 2(2代表投票数) #多个sentinel的情况下，有2票投票从服务器成为主服务器的话，从服务器就会成为新的主服务器(2)sentinel down-after-milliseconds mymaster 30000 #30秒找不到主服务器就判断离线(3)sentinel parallel-syncs mymaster 2 #允许多少个从服务器向主服务器发起同步请求(4)sentinel failover-timeout mymaster 20 #主服务器发生故障，故障转移超时时间(故障转移超过这个时间，判断故障转移失败) sentinel专用命令(都以sentinel开头):sentinel masters:列出所有监视的主服务器sentinel slaves master_name:获取指定主服务器的从节点sentinel get-master-addr-by-name master_name:根据name获取master地址sentinel reset:重置操作sentinel failover &lt;master_name&gt;:手动执行故障转移操作 sentinel连接:(1)客户端连接sentinel示例redis-cli -h ipaddr -p 26379(sentinel默认端口)(2)客户端连接从节点示例redis-cli -h ipaddr -p 6380(自定义redis端口) 6、集群clustering:redis3.0以后支持分布式数据库，通过分片机制进行数据分析，clustering内的每个节点仅存数据库的一部分数据，也被称作去中心化(每一个节点都可以接入客户请求)。这样，每个节点都持有全局元数据，但仅持有一部分数据优点:(1)无中心化，gossip分散式模式(2)更少的来回次数并降低延迟(3)自动于多个redis节点进行分片(4)不需要第三方软件支持协调机制缺点:(1)依赖于redis3.0或更高版本(2)需要时间验证其稳定性(3)没有后台界面(4)需要智能客户端(5)redis客户端必须支持redis cluster架构","categories":[{"name":"redis","slug":"redis","permalink":"http://yoursite.com/categories/redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://yoursite.com/tags/redis/"}]},{"title":"redis安装、配置及基本命令操作","slug":"redis配置及基本命令操作","date":"2018-10-08T08:19:00.000Z","updated":"2018-12-19T07:19:56.057Z","comments":true,"path":"2018/10/08/redis配置及基本命令操作/","link":"","permalink":"http://yoursite.com/2018/10/08/redis配置及基本命令操作/","excerpt":"","text":"1、redis特点:(1)原子性:要么全部执行，要么全部不执行(2)一致性:支持事务(3)隔离性:单线程(4)持久性:异步写入磁盘，避免雪崩效应 2、首先介绍一下redis3.0特性:(1)支持redis cluster(2)支持新的”embedded string”(3)LRU算法的改进改进如下:a.预设随机抽取5个样本，插入并排序至一个pool，移除最佳者，如此反复，直到内存用量小于maxmemory的设定b.样本5比先前的3多c.从局部最优趋向全局最优 3、redis组件:(1)redis-server(服务端)(2)redis-cli(客户端)(3)redis-benchmark(压测工具)(4)redis-check-dump &amp; redis-check-aof(检查持久化文件是否完整，分别对应rdb和aof格式) 4、redis官方站点:www.redis.ioyum info redis #查看epel源是否含有redis的安装包yum localinstall redis-3.0.2-1.el6.reml.x86_64.rpm #本地安装redisrpm -ql redis #查看安装redis时安装了哪些文件redis-server –help #查看帮助 5、redis配置文件(常用配置):(1)tcp-backlog #指等待队列。当并发量大的时候，redis可能会忙不过来。这时候需要额外找一个地方，将新的请求缓存下来，这个位置就叫backlog(2)redis.sock #服务端和客户端在同一台机器的时候，建议以sock文件的方式进行通信。好处是在内存当中直接交换，而不需要经过tcp/ip协议栈进行封装和解封装(3)timeout 0 #0表示连接不会超时(4)snapshotting配置:save 900 1 表示在900秒内有一个键发生变化，就做一次快照(5)replication配置:主从(6)daemonize yes #启动程序时，程序在后台运行 6、redis基本命令:(1)通过redis-cli客户端连接redis之后，可以通过help命令查看帮助help +tab键 #查看redis支持哪些类型help @STRING #查看字符串帮助help append #查看append命令的用法 (2)连接(connection)命令:help @connection #查看连接相关命令AUTH #验证PING #测试服务器是否在线，在线的话会返回PONGECHO #显示命令，例如ECHO ‘hello’QUIT #退出命令SELECT #选择数据库 (3)服务器(server)命令:help @server #查看服务器相关命令CLIENT SETNAME connection-name #设定连接名CLIENT GETNAME #查看连接名CLIENT KILL ip:port kill #关闭client (4)配置(config)命令:INFO #查看redis信息，信息包含很多段，例如INFO memory可以查看内存段的信息CONFIG RESETSTAT #重置INFO中所统计的数据CONFIG SET #运行中修改，也就是在内存中修改，不会同步到硬盘中CONFIG REWRITE #将配置写到硬盘当中CONFIG GET (如dir) #查看配置 7、redis支持的数据结构:(1)string #help @string，查看string支持的命令string支持的命令:set #help set，查看set帮助getappendstrlen (2)integer #help @integer，查看integer支持的命令integer支持的命令:incr #help incr，查看incr帮助decr (3)list [a,b,c,d] #help @list，查看list支持的命令list支持的命令:rpush #help rpush，查看rpush帮助lpushrpoplpoplindexlsetllen (4)set {a,b,c,d} #help @set，查看set支持的命令set支持的命令:sadd #help sadd，查看sadd帮助sinter #求交集sunion #求并集spop #随机弹出，set无序sismember #成员运算符 (5)sorted set {a:1,b:2,c:3} #help @sorten_set，查看sorten_set支持的命令sorten_set支持的命令:zadd #help zadd，查看zadd帮助zrangezcardzrank (6)hash {field1:”a”,field2:”b”}，说白了就是映射，也称为关联数组 #help @hash，查看hash支持的命令hash支持的命令:hset #help hset，查看set帮助hsetnxhgethkeyshvalshlenhdel (7)bitmaps #help @bitmaps，查看bitmaps支持的命令(8)hyperloglog #help @hyperloglog，查看hyperloglog支持的命令 …. 8、清空数据库:FLUSHDB:清空当前库FLUSHALL:清空所有库","categories":[{"name":"redis","slug":"redis","permalink":"http://yoursite.com/categories/redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://yoursite.com/tags/redis/"}]},{"title":"开始认识redis","slug":"初识redis","date":"2018-10-08T06:59:00.000Z","updated":"2018-12-19T07:18:59.620Z","comments":true,"path":"2018/10/08/初识redis/","link":"","permalink":"http://yoursite.com/2018/10/08/初识redis/","excerpt":"","text":"redis属于nosql的一种。首先介绍一下nosql的分类:1、key-value nosql，比如redis，memcached2、column family nosql(列式存储)，比如hbase3、documentation nosql(文档存储)，比如mongodb4、graph nosql(图形存储) redis特性:1、key-value cache and store2、in-memory3、single threaded(单线程，因为redis占用cpu的消耗很低，因此cpu一般不会成为瓶颈)4、支持持久化(snapshotting，快照方式，异步写入到磁盘:AOF，append only file)5、支持主从(借助于sentinel实现一定意义上的HA:高可用)6、支持分布式集群(clustering)7、支持string、list、hash(关联数组)、set、sorted set(有序集合)、bitmap、hyperloglog redis与memcached比较:redis优势:1、支持的数据类型丰富，包括hash、lists、sets、sorted set、hyperloglog2、内建replication及cluster3、就地更新操作(in-place update)4、支持持久化(异步写入磁盘，避免雪崩效应)memcached优势:1、多线程(善用多核CPU，更少的阻塞操作)2、更少的内存开销3、更少的内存分配压力4、可能有更少的内存碎片","categories":[{"name":"redis","slug":"redis","permalink":"http://yoursite.com/categories/redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://yoursite.com/tags/redis/"}]},{"title":"解决rabbitmq的web管理界面无法使用guest用户登录的问题","slug":"解决rabbitmq的web管理界面无法使用guest用户登录的问题","date":"2018-09-29T09:26:00.000Z","updated":"2018-09-29T09:27:15.108Z","comments":true,"path":"2018/09/29/解决rabbitmq的web管理界面无法使用guest用户登录的问题/","link":"","permalink":"http://yoursite.com/2018/09/29/解决rabbitmq的web管理界面无法使用guest用户登录的问题/","excerpt":"","text":"为了解决这个问题，需要在rabbitmq的配置文件中将loopback_users配置设置为空，如编写配置文件:/etc/rabbitmq/rabbitmq.config，并在其中添加以下内容： [{rabbit, [{loopback_users, []}]}]. 保存后重启rabbitmq-server即可随意使用guest用户名和密码来登录了(当然这个做法非常不安全)。","categories":[],"tags":[{"name":"rabbitmq","slug":"rabbitmq","permalink":"http://yoursite.com/tags/rabbitmq/"}]},{"title":"iptables删除已有的规则","slug":"iptables删除已有的规则","date":"2018-09-29T09:21:00.000Z","updated":"2018-12-10T09:31:44.817Z","comments":true,"path":"2018/09/29/iptables删除已有的规则/","link":"","permalink":"http://yoursite.com/2018/09/29/iptables删除已有的规则/","excerpt":"","text":"比如要删除input链上的某条规则，先要查询input链的所有规则iptables -L INPUT –line-numbers 查看你所要删除的规则是第几条，比如要删除第3条iptables -D INPUT 3","categories":[{"name":"iptables","slug":"iptables","permalink":"http://yoursite.com/categories/iptables/"}],"tags":[{"name":"iptables","slug":"iptables","permalink":"http://yoursite.com/tags/iptables/"}]},{"title":"mysql启动报错:\"[ERROR] Table 'mysql.user' doesn't exist\"","slug":"mysql启动报错","date":"2018-09-29T09:16:00.000Z","updated":"2018-12-19T07:29:31.466Z","comments":true,"path":"2018/09/29/mysql启动报错/","link":"","permalink":"http://yoursite.com/2018/09/29/mysql启动报错/","excerpt":"","text":"这是因为编译安装mysql时指定了”–datadir=/usr/local/mysql/data”,所以在新增加一个/etc/my.cnf文件的时候，需要在my.cnf里面指定datadir=/usr/local/mysql/data 然后重启mysql就可以正常启动了","categories":[{"name":"QA","slug":"QA","permalink":"http://yoursite.com/categories/QA/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/tags/mysql/"}]},{"title":"ubuntu安装ansible","slug":"ubuntu安装ansible","date":"2018-09-26T08:13:00.000Z","updated":"2018-10-08T05:50:39.916Z","comments":true,"path":"2018/09/26/ubuntu安装ansible/","link":"","permalink":"http://yoursite.com/2018/09/26/ubuntu安装ansible/","excerpt":"","text":"1、安装add-apt-repository必要套件apt-get install -y python-software-properties software-properties-common 2、使用ansible官方的PPA套件来源add-apt-repository -y ppa:ansible/ansible 3、升级apt-getapt-get update 4、安装ansibleapt-get install -y ansible","categories":[{"name":"安装篇","slug":"安装篇","permalink":"http://yoursite.com/categories/安装篇/"}],"tags":[{"name":"ansible","slug":"ansible","permalink":"http://yoursite.com/tags/ansible/"}]},{"title":"集群的概念","slug":"集群的概念","date":"2018-09-23T10:31:00.000Z","updated":"2018-09-23T10:42:13.270Z","comments":true,"path":"2018/09/23/集群的概念/","link":"","permalink":"http://yoursite.com/2018/09/23/集群的概念/","excerpt":"","text":"1、LB集群:lvs,nginx(lvs,nginx也可以实现高可用，但是相对来说在高可用中keepalived比较常见)2、HA集群:keepalived,heartbeat,corosync3、HP集群:高性能集群、超算集群，在互联网公司中很少见，一般在国家级实验室或者超算实验室中比较常见(HP集群一般可以用分布式计算来替换) 延伸:分布式计算中的一些概念分布式存储:HDFS分布式计算:YARNbatch:mapreducein-memory:sparkstream:storm HA cluster配置前提:1、本机的主机名与host中定义的主机名保持一致，要与hostname(uname -n)获得的名称保持一致 #根据主机名彼此通信配置主机名:在centos6中,/etc/sysconfig/networks在centos7中，hostnamectl set-hostname HOSTNAME #各节点要能相互解析主机名:一般建议通过host文件进行解析(配置文件/etc/hosts)2、各节点时间同步3、确保iptables及selinux不会成为服务的阻碍iptables -L -n #查看iptables规则getenforce #查看selinux状态","categories":[{"name":"高可用web","slug":"高可用web","permalink":"http://yoursite.com/categories/高可用web/"}],"tags":[{"name":"集群","slug":"集群","permalink":"http://yoursite.com/tags/集群/"}]},{"title":"keepalived配置实例","slug":"keepalived配置实例","date":"2018-09-23T09:53:00.000Z","updated":"2018-12-07T06:39:29.278Z","comments":true,"path":"2018/09/23/keepalived配置实例/","link":"","permalink":"http://yoursite.com/2018/09/23/keepalived配置实例/","excerpt":"","text":"实例一启动keepalived之后找不到配置文件:1、编辑/etc/rsyslog.conf #指明各类日志文件中的信息加上一句，local3.* /var/log/keepalived.log 2、编辑/etc/sysconfig/keepalived,加上一句，KEEPALIVED_OPTIONS=”-D -S 3” #指明keepalived日志文件的facility(等级)为3 3、重启rsyslog,keepalived服务在centos7中，systemctl restart rsyslog.servicesystemctl restart keepalived.service 实例二手动调度vip在两台主机中转移在配置文件中，1、vrrp实例之外加上一个函数vrrp_script chk_maintainnance{ script “[[ -f /etc/keepalived/down]] &amp;&amp; exit 1 || exit 0” interval 1 weight -2} 2、vrrp实例之内调用这个函数track_script{ chk_maintainnance}用法:只需要touch /etc/keepalived/down,vip就会转移；删除down文件又会转移到另一台主机 实例三配置虚拟路由器组vrrp_sync_group VG_1{ group { VI_1 VI_2 }} vrrp_instance VI_1{ eth0 vip #对外部客户} vrrp_instance VI_2{ eth1 dip #对内部主机} 实例四主机状态发生改变时发送通知:在vrrp实例中定义 #notify scripts,alert as above –自定义脚本 notify_master | #当前节点转换为master时，发送相应消息 notify_backup | #当前节点转换为backup时，发送相应消息 notify_fault |&lt;QUOTED_STRING&gt; #当前节点转换为fault(发生故障)时，发送相应消息 notify | smtp_alert实例:””括起来的内容就是表示QUOTED_STRINGnotify_master “/etc/keepalived/notify.sh master”notify_backup “/etc/keepalived/notify.sh backup”notify_fault “/etc/keepalived/notify.sh fault” 下面是一个notify脚本的简单示例: #!/bin/bashvip=172.16.100.1contact=‘root@localhost’ notify(){ mailsubject=”hostname to be $1:$vip floating” mailbody=”date &#39;+%F %H:%M:%S&#39;:vrrp transtion,hostname change to be $1” echo $mailbody|mail -s “$mailsubject” $contact} case “$1” in master) notify master #/etc/rc.d/init.d/haproxy start exit 0 ;; backup) notify backup #/etc/rc.d/init.d/haproxy stop exit 0 ;; fault) notify fault #/etc/rc.d/init.d/haproxy stop exit 0 ;; *) echo “Usage:basename $0 {master|backup|fault}” exit 1 ;;esac","categories":[{"name":"keepalived","slug":"keepalived","permalink":"http://yoursite.com/categories/keepalived/"}],"tags":[{"name":"keepalived","slug":"keepalived","permalink":"http://yoursite.com/tags/keepalived/"}]},{"title":"初步认识Keepalived","slug":"eepalived简介、组件及配置文件","date":"2018-09-22T08:16:00.000Z","updated":"2018-12-19T07:27:54.750Z","comments":true,"path":"2018/09/22/eepalived简介、组件及配置文件/","link":"","permalink":"http://yoursite.com/2018/09/22/eepalived简介、组件及配置文件/","excerpt":"","text":"keepalived是vrrp协议在linux主机上的实现，能够根据配置文件自动生成ipvs规则，对各RS做健康状态检查。1、特点(1)轻量级(2)以守护进程的形式(3)节点类型分为active/passive 2、组件(1)vrrp stack(2)checkers(3)ipvs wrapper 3、keepalived涉及的协议(1)组播:主服务器发送hello信息给从服务器，证明”I am alive”配置同进退vrrp实例时，要注意多播地址，每一组实例默认会分配一个组播地址。如果是在配置文件中指定一个组播地址，则只能配置一组实例；如果需要配置多组实例(不让其中一台主机有空闲)，则需要在各组实例的配置中配置上组播地址 (2)ntp:network time protocol格式:ntpdate timeserver_ip，以这个时间服务器的时间为准，同步自己的时间date命令调整时间的格式:”date 月日时分年.秒” (3)vrrp:virtual routing redundent protocol，虚拟路由冗余协议(vrrp是路由交换协议，keepalived是vrrp在linux上的实现)vrrp是一种容错协议，保证当主机的下一跳路由出现故障时，由另一台路由器来代替出故障的路由器进行工作，从而保障网络通信的连续性和可靠性。在vrrp协议中，分为master和backup两种角色。 vrrp中的一些概念: vrid:虚拟路由器标识，有相同vrid的一组路由器构成一个虚拟路由器 虚拟Mac:一个虚拟路由器拥有一个虚拟Mac，通常情况下虚拟路由器回应arp请求使用的是虚拟Mac 优先级:vrrp根据优先级来确定虚拟路由器中每台路由器的地位 非抢占模式:即使backup路由器的优先级比master高，也不会抢占master的地位 抢占模式:根据优先级的大小来确定谁是master vrrp工作原理: a.虚拟路由器中的路由器根据优先级选举出master，master路由器通过发送免费arp报文，将自己的虚拟Mac地址通知给其他与其连接的设备或主机，从而承担报文转发任务 b.master路由器周期性发送vrrp报文，以公布其配置信息(优先级)和工作状况 c.如果master路由器出现故障，虚拟路由器中的backup路由器将根据优先级重新选举新的master d.虚拟路由器切换时，master路由器由一台设备切换成另外一台设备，新的master路由器只是简单的发送一个携带虚拟路由器的Mac地址和虚拟ip地址信息的免费arp报文，这样就可以更新与之连接的设备或主机的arp信息 e.backup路由器优先级高于master的时候，由backup路由器的工作方式(抢占或非抢占)来决定是否重新选举master vrrp认证方式: a.无认证 b.简单字符认证(将认证字符插入到vrrp报文中) c.md5认证(利用认证字符和MD5算法对vrrp报文进行加密)","categories":[{"name":"keepalived","slug":"keepalived","permalink":"http://yoursite.com/categories/keepalived/"}],"tags":[{"name":"keepalived","slug":"keepalived","permalink":"http://yoursite.com/tags/keepalived/"}]},{"title":"ubuntu 16.04搭建Hexo博客后台管理系统","slug":"ubuntu-16-04搭建Hexo博客后台管理系统","date":"2018-09-20T06:40:00.000Z","updated":"2018-09-20T07:00:40.481Z","comments":true,"path":"2018/09/20/ubuntu-16-04搭建Hexo博客后台管理系统/","link":"","permalink":"http://yoursite.com/2018/09/20/ubuntu-16-04搭建Hexo博客后台管理系统/","excerpt":"","text":"1、安装Hexo-adminnpm install –save hexo-admin #之前已经介绍安装Hexo,参考链接:https://leungzj.github.io/2018/09/19/ubuntu16-04-%E6%90%AD%E5%BB%BAHexo%E5%8D%9A%E5%AE%A2/ 2、启动服务hexo s &amp; 3、访问后台http://你的ip地址:4000/admin 4、后台启用密码登录(默认无密码)点击”Setup authentification here” 弹出设置窗口，按要求填入登录用户名和密码，然后将”admin config section”下面那一段代码复制到Hexo的配置文件_config.yml即可 5、重启Hexokillall hexohexo s &amp; 6、更换Hexo主题先切换到Hexo所在安装目录，通过git下载主题文件到本地文件夹git clone https://github.com/BosenY/Lap.git theme/lap #Hexo主题汇总链接:https://hexo.io/themes/ 7、修改Hexo配置文件_config.yml 8、保存配置文件，重新生成并重启Hexo服务hexo ghexo dkillall hexohexo s &amp;","categories":[{"name":"搭建篇","slug":"搭建篇","permalink":"http://yoursite.com/categories/搭建篇/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://yoursite.com/tags/Hexo/"}]},{"title":"secureCRT连接ubuntu显示中文乱码的解决方法","slug":"secureCRT显示中文乱码","date":"2018-09-20T05:33:00.000Z","updated":"2018-09-20T05:52:17.443Z","comments":true,"path":"2018/09/20/secureCRT显示中文乱码/","link":"","permalink":"http://yoursite.com/2018/09/20/secureCRT显示中文乱码/","excerpt":"","text":"一、ubuntu设置1、在/var/lib/locales/supported.d/local文件中添加一行:zh_CN.UTF-8 UTF-8 执行sudo locale-gen下载文件 2、在/etc/environment文件中添加两行:LANG=”zh_CN.UTF-8”LC_ALL=”zh_CN.UTF-8” 3、在~/.profile文件中添加两行:export LANG=”zh_CN.UTF-8”export LC_ALL=”zh_CN.UTF-8 执行source ~/.profile 二、secureCRT设置1、选择options – session options，弹出设置窗口2、选择terminal – emulation，terminal下拉表选择linux，并在”ansi color”前面方框打上勾 3、选择terminal – appearance，”current color scheme”选择traditional font字体选择fangsong，script选择”Chinese GB2312” character encoding下拉表选择utf-8 退出当前crt窗口，重新登录试试！","categories":[{"name":"工具篇","slug":"工具篇","permalink":"http://yoursite.com/categories/工具篇/"}],"tags":[{"name":"secureCRT","slug":"secureCRT","permalink":"http://yoursite.com/tags/secureCRT/"}]},{"title":"ubuntu16.04 源码编译安装boost1_59_0","slug":"ubuntu16-04-源码编译安装boost1-59-0","date":"2018-09-19T08:31:00.000Z","updated":"2018-09-19T08:38:34.285Z","comments":true,"path":"2018/09/19/ubuntu16-04-源码编译安装boost1-59-0/","link":"","permalink":"http://yoursite.com/2018/09/19/ubuntu16-04-源码编译安装boost1-59-0/","excerpt":"","text":"1、下载源码包wget https://iweb.dl.sourceforge.net/project/boost/boost/1.59.0/boost_1_59_0.tar.gz 2、解压缩tar zxvf boost_1_59_0.tar.gz 3、进入解压缩目录cd boost_1_59_0/ 4、运行bootstrap.sh脚本./bootstrap.sh –with-libraries=all –with-toolset=gcc参数解释:–with-libraries指定编译哪些boost库，all的话就是全部编译，只想编译部分库的话就把库的名称写上，用逗号分隔即可–with-toolset指定编译时使用哪种编译器，Linux下使用gcc即可，如果系统中安装了多个版本的gcc，在这里可以指定gcc的版本，比如–with-toolset=gcc-4.4 5、编译boost./b2 toolset=gcc 6、安装boost./b2 install可以加–prefix参数:用来指定boost的安装目录，不加此参数的话默认的头文件在/usr/local/include/boost目录下，库文件在/usr/local/lib/目录下 7、更新系统的动态链接库ldconfig","categories":[{"name":"安装篇","slug":"安装篇","permalink":"http://yoursite.com/categories/安装篇/"}],"tags":[{"name":"boost","slug":"boost","permalink":"http://yoursite.com/tags/boost/"}]},{"title":"ubuntu16.04 搭建Hexo博客","slug":"ubuntu16-04-搭建Hexo博客","date":"2018-09-19T06:56:00.000Z","updated":"2018-09-19T09:09:42.422Z","comments":true,"path":"2018/09/19/ubuntu16-04-搭建Hexo博客/","link":"","permalink":"http://yoursite.com/2018/09/19/ubuntu16-04-搭建Hexo博客/","excerpt":"","text":"一、安装Node.js1、安装curlapt install curl 2、安装node.jscurl -sL https://deb.nodesource.com/setup_8.x | sudo -E bash -apt install -y nodejs 3、检查版本(有版本号输出表示安装完成)node -vnpm -v 二、安装Hexo1、npm install -g hexo-cli 2、进入你希望建站的文件夹(必须是一个空的文件夹)，执行初始化命令:hexo init 3、安装依赖包:npm install 至此，Hexo本地博客搭建完成。 三、Hexo常用命令hexo help:查看帮助hexo init:初始化一个目录hexo generate:生成网页，在public目录查看整个网站的文件，简写为hexo ghexo server:用来启动本地站点，执行后即可在浏览器中输localhost:4000查看，简写为hexo shexo deploy:部署.deploy目录，可以简化为hexo dhexo clean:清除缓存，强烈建议每次部署deploy之前先清理缓存 四、使用github pages服务部署hexoGiuhub Page介绍:我们用来托管博客的服务叫做 Github Pages，它是 Github 用来提供给个人/组织或者项目的网页服务，只需要部署到你的 Github Repository，推送代码，便可以实时呈现。 1、首先要使用邮箱注册Github账号 2、设置gitgit config –global user.email “you@example.com“git config –global user.name “Your Name” 3、安装插件npm install hexo-deployer-git –save #为了部署到Github上，需要安装hexo-deployer-git插件 4、生成ssh秘钥ssh-keygen -t rsa -C you@example.com #-C后面跟住你在github的用户名邮箱，这样公钥才会被github认可 5、查看你的公钥，添加到Github账户的sshkey中less ~/.ssh/id_rsa.pub 6、Github上新建项目，项目名称为”用户名.github.io”，例如我的用户名是leungzj，则创建的项目名为leungzj.github.io 7、在setting–SSH and GPG keys中，添加生成的公钥，也就是将~/.ssh/id_rsa.pub的内容添加到这里 8、修改Hexo配置文件 9、编译并上传部署到Githubhexo generate #编译hexo deploy #将hexo部署到Github io上 10、访问Hexo博客通过用户名.github.io就可以Hexo博客啦！例如我的博客:https://leungzj.github.io/","categories":[{"name":"搭建篇","slug":"搭建篇","permalink":"http://yoursite.com/categories/搭建篇/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://yoursite.com/tags/Hexo/"}]},{"title":"ubuntu16.04 源码编译安装mysql5.7","slug":"安装篇-ubuntu16-04-安装mysql5-7","date":"2018-09-19T05:36:00.000Z","updated":"2019-03-20T14:46:50.490Z","comments":true,"path":"2018/09/19/安装篇-ubuntu16-04-安装mysql5-7/","link":"","permalink":"http://yoursite.com/2018/09/19/安装篇-ubuntu16-04-安装mysql5-7/","excerpt":"","text":"1、安装依赖sudo apt-get install make cmake gcc g++ bison libncurses5-dev build-essential 2、下载mysql 5.7源码包下载地址：https://dev.mysql.com/downloads/mysql/在”select operating system”中选择”source code”，我下载的版本是mysql-5.7.23 3、解压缩tar zxvf mysql-5.7.23.tar.gz -C /usr/localcd /usr/local/mysql-5.7.23/ 4、编译安装cmake . -DCMAKE_INSTALL_PREFIX=/usr/local/mysql -DMYSQL_DATADIR=/usr/local/mysql/data -DSYSCONFDIR=/etc -DWITH_INNOBASE_STORAGE_ENGINE=1 -DWITH_ARCHIVE_STORAGE_ENGINE=1 -DWITH_BLACKHOLE_STORAGE_ENGINE=1 -DWITH_PARTITION_STORAGE_ENGINE=1 -DWITH_PERFSCHEMA_STORAGE_ENGINE=1 -DWITHOUT_EXAMPLE_STORAGE_ENGINE=1 -DWITHOUT_FEDERATED_STORAGE_ENGINE=1 -DDEFAULT_CHARSET=utf8 -DDEFAULT_COLLATION=utf8_general_ci -DWITH_EXTRA_CHARSETS=all -DENABLED_LOCAL_INFILE=1 -DWITH_READLINE=1 -DMYSQL_UNIX_ADDR=/usr/local/mysql/mysql.sock -DMYSQL_TCP_PORT=3306 -DMYSQL_USER=mysql -DCOMPILATION_COMMENT=”lq-edition” -DENABLE_DTRACE=0 -DOPTIMIZER_TRACE=1 -DWITH_DEBUG=1 运行到这一步，出现报错信息:“CMake Error at cmake/boost.cmake:81 (MESSAGE): You can download it with -DDOWNLOAD_BOOST=1 -DWITH_BOOST=“提示需要安装boost库，安装参考链接:https://leungzj.github.io/2018/09/19/ubuntu16-04-%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85boost1-59-0/ makemake install 5、配置mysql(1)创建用户和用户组groupadd mysqluseradd -g mysql mysql (2)设置mysql安装目录的权限cd /usr/local/mysqlchown -R mysql:mysql ./ (3)mysql初始化 #这里会生成一个mysql临时登录密码，需要记下来，稍后登录mysql会用到bin/mysqld –initialize –user=mysql (4)启动mysqlsupport-files/mysql.server start (5)修改mysql登录密码bin/mysql -u root -pSET PASSWORD FOR ‘root‘@’localhost’ = PASSWORD(‘newpassword’); 6、远程连接mysql用类似navicat的客户端连接mysql，如果出现提示”is not allowed to connect”，需要在mysql命令行上设置远程连接权限，检查iptables是否开放3306端口(1)GRANT ALL PRIVILEGES ON *.* TO ‘root‘@’%’ IDENTIFIED BY ‘password’ WITH GRANT OPTION;#with grant option表示它具有grant权限，这是一个超级用户权限(2)iptables -A INPUT -P tcp –dport 3306 -j ACCEPT","categories":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/categories/mysql/"}],"tags":[]}]}