{"meta":{"title":"Jim's Blog","subtitle":null,"description":null,"author":"Jim","url":"http://yoursite.com"},"pages":[{"title":"","date":"2018-10-17T02:15:56.847Z","updated":"2018-10-17T02:15:56.843Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":"关于运维工程师，熟悉网络、运维、数据库、自学前端、python，志向于全栈认证：CCNA,SAA,PMP,中级网络工程师，目前在考高级项目管理师 { name: ‘jim’ age: ‘28’ gender: ‘男’ profession: ‘Operation’ experience: ‘3年’ address: ‘广东省广州市’ education: ‘本科’ github: ‘https://github.com/leungzj&#39; email: &#39;18826400669@163.com‘ blog: ‘leungzj.github.io’ description: ‘技术改变世界’ skills: [ 网络、运维、SQL、python...(持续更新中) ] }"},{"title":"","date":"2018-10-17T01:48:40.795Z","updated":"2018-10-17T01:48:40.795Z","comments":true,"path":"books/index.html","permalink":"http://yoursite.com/books/index.html","excerpt":"","text":"docker:《第一本docker书》 python:《python编程:从入门到实践》"},{"title":"categories","date":"2018-09-19T09:02:45.000Z","updated":"2018-09-19T09:06:58.378Z","comments":true,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2018-10-17T01:52:18.715Z","updated":"2018-10-17T01:52:18.715Z","comments":true,"path":"links/index.html","permalink":"http://yoursite.com/links/index.html","excerpt":"","text":""},{"title":"标签","date":"2018-10-17T02:54:58.153Z","updated":"2018-10-17T02:54:58.153Z","comments":false,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"给你的情书","slug":"给你的情书","date":"2018-10-16T03:00:00.000Z","updated":"2018-10-16T03:03:37.299Z","comments":true,"path":"2018/10/16/给你的情书/","link":"","permalink":"http://yoursite.com/2018/10/16/给你的情书/","excerpt":"","text":"想起你的时候就想起夜半的野百合一支晃摇着节奏的野百合想起远方嫁给岩石的海鸟想起河神有几只鞋跑丢在太长的大陆跑丢在人群中想起丝绸仅仅成为东方母亲的蒙面我便是诗人 –海子《想起你的时候》","categories":[{"name":"一言","slug":"一言","permalink":"http://yoursite.com/categories/一言/"}],"tags":[]},{"title":"awk入门","slug":"Untitled","date":"2018-10-15T08:01:00.000Z","updated":"2018-10-15T09:24:05.011Z","comments":true,"path":"2018/10/15/Untitled/","link":"","permalink":"http://yoursite.com/2018/10/15/Untitled/","excerpt":"","text":"文本处理工具三剑客:grep、sed、awk(1)grep:文本过滤器，匹配模式，过滤文本(2)sed:流编辑器，能够编辑文本，默认将编辑之后的文本输出到屏幕(3)awk:报告生成器，根据输入信息，将输入信息格式化之后再显示出来(awk是以awk三个作者名字的首字母命名) awk版本:(1)awk(2)new awk，简称nawk(3)gnome awk，简称gawk(linux上的版本都是gawk，可以通过ls -l /bin/awk来查看awk指向的链接就是gawk) awk使用格式:awk [options] ‘PATTERN {action}’ file1,file2… options:-F 指定分隔符BEGIN {OFS=””} 指定输出分隔符 awk内置变量:(1)记录变量FS:读取文本时所使用的字段分隔符，默认是空白字符RS:输入文本信息时所使用的换行符OFS:输出分隔符ORS:输出行分隔符(2)数据变量NR:awk命令所处理的记录数。如果有多个文件，这个数目会把处理的多个文件中的行统一计数FNR:记录所处理的行是当前这一文件中被总共处理的行中是第几行NF:用于统计正在处理的行中的字段总数($NF:正在被处理的行中的最后一个字段) 常见的PATTERN类型:1、regexp，正则表达式，格式为/regular expression/用法示例:awk -F: ‘/^r/{print $1}’ /etc/passwd #显示passwd文件中以r开头的用户名2、expression，表达式，比如$1 ~ /foo/或$1 == “magedu”等用法示例:awk -F: ‘$3&gt;=500{print $1,$3}’ /etc/passwd #显示passwd文件中uid大于300的用户及其uidawk -F: ‘$7~”bash$”{print $1,$7}’ /etc/passwd #显示passwd文件中以bash shell为shell的用户名及其对应的shell3、range，指定匹配范围用法示例:awk -F: ‘/^r/^m/{print $1,$3}’ /etc/passwd #显示passwd文件中第一次以r开头开始到第一次以m开头的行结束的之间的所有行4、BEGIN/END，特殊模式，在awk命令执行之前运行一次或结束之前运行一次BEGIN:在awk处理文本第一行之前执行END:在awk处理文本最后一行之前执行用法示例:awk -F: ‘BEGIN{print “Username ID SHELL”}{printf “%-10s%-10s%-20s\\n”,$1,$3,$7}END{print “end of report”}’ /etc/passwd #在第一行打印”Username ID SHELL”，在最后一行打印”end of report” 常见的action:控制语句:(1)if-else用法示例:awk -F: ‘{if ($1==”root”) print $1,”admin”;else print $1,”common user”}’ /etc/passwd(2)while用法示例:awk -F: ‘{i=1;while(i&lt;=3) {print $i;i++}}’ /etc/passwd(3)do-while用法示例:awk -F: ‘{i=1;do {print $i;i++}while(i&lt;=3)}’ /etc/passwd(4)for用法示例:awk -F: ‘{for(i=1;i&lt;=3;i++)print $i}’ /etc/passwd(5)case(6)break、continue(跳过本字段)(7)next(跳过本行) awk使用数组:用法示例:(1)awk -F: ‘{shell[$NF]++}END{for(A in shell){print A,shell[A]}}’ /etc/passwd #生成一个shell数组，并统计passwd文件中各种shell的个数，A指的是下标(2)netstat -tan | awk ‘/^tcp/{STATE{$NF}++}END{for (S IN STATE){print S,STATE[S]}}’ #生成一个STATE数组，并统计各种程序状态的个数，S指的是下标(3)awk ‘{counts[$1]++}END{for(ip in counts){printf “%-20s:%d\\n”,ip,count[ip]}}’ /var/log/httpd/access.log #统计web日志文件中IP地址的访问量备注：awk中的下标很独特，可以是任意字符串","categories":[{"name":"linux文本处理","slug":"linux文本处理","permalink":"http://yoursite.com/categories/linux文本处理/"}],"tags":[{"name":"awk","slug":"awk","permalink":"http://yoursite.com/tags/awk/"}]},{"title":"docker","slug":"docker入门","date":"2018-10-12T01:26:00.000Z","updated":"2018-10-12T09:38:38.748Z","comments":true,"path":"2018/10/12/docker入门/","link":"","permalink":"http://yoursite.com/2018/10/12/docker入门/","excerpt":"","text":"什么是dockerdocker是一个开源的应用容器引擎，让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的linux机器中，也可以实现虚拟化。docker的目标是实现轻量级操作系统虚拟化的解决方案。(基于Go语言开发) docker简单原理docker的基础是linux容器(LXC)、Cgroup技术。docker是在LXC的基础上进行了进一步的封装，让用户不再需要去关心容器的管理，使得操作更加简便。用户操作docker的容器就像操作一个快速轻量级的虚拟机一样简单。与传统虚拟户(KVM、XEN等)相比较：(1)docker是在操作系统层面上实现虚拟化，直接复用本地主机的操作系统(由下往上:硬件-&gt;host操作系统-&gt;docker engine-&gt;应用库-&gt;应用app) (2)传统的虚拟化方式是在硬件的基础上，虚拟出自己的系统，再在系统上部署相关的APP应用(由下往上:硬件-&gt;host操作系统-&gt;hypervisor-&gt;guest操作系统-&gt;应用库-&gt;应用app) docker组件(1)镜像:其实就是模板，跟我们常见的ISO镜像类似，是一个样板(2)容器:使用镜像常见的应用或系统，我们称之为一个容器(容器相当于启动之后的镜像)(3)仓库:仓库就是存放镜像的地方，分为公开仓库(public)和私有仓库(private)两种形式 docker技术组件linux内核的命名空间(namespace)，用于隔离文件系统、进程和网络(1)文件系统隔离:每个容器都有自己的root文件系统(2)进程隔离:每个容器都运行在自己的进程环境中(3)网络隔离:容器间的虚拟网络接口和IP地址都是分开的(4)资源隔离和分组:使用Cgroups(即control group，linux内核特性之一)将cpu和内存之类的资源独立分配给每个docker容器(5)写时复制:文件系统都是通过写时复制创建的(6)日志:容器产生的STDOUT、STDIN和STDERR这些IO流都会被收集并记入日志(7)交互式shell:用户可以创建一个伪tty终端，为容器提供一个交互式shell docker虚拟化特点(1)操作启动快运行时的性能获得极大的提升，管理操作(开始、停止、重启等)都是以秒或者毫秒为单位的(2)轻量级虚拟化你会拥有足够的”操作系统”，仅需添加或减少镜像即可。在一台服务器上可以部署100~1000个container容器，但是传统虚拟化虚拟出10~20个虚拟机就已经很好了(3)开源免费(4)前景及云支持 使用docker的优势(1)提供一个简单、轻量的建模方式用户上手docker非常快，只需要几分钟就可以将自己的程序”docker化”,docker依赖于”写时复制”(copy-on-write)模型，使得修改应用程序也非常迅速。(2)职责的逻辑分离使用docker，开发人员只需要关心容器中运行的应用程序，运维人员只需要关心如何管理容器，从而降低”开发时一切正常，肯定是运维问题”的风险。(3)快速、高效的开发生命周期docker的目标之一就是缩短代码从开发、测试到部署、上线运行的周期，让你的应用程序具备可移植性、易于构建、易于协作。(4)鼓励使用面向服务的架构docker推荐单个容器只运行一个应用程序，这样就形成了一个分布式的应用程序模型。在这种模型下，应用程序或服务都可以表示为一系列内部互联的容器，从而使分布式部署应用程序或者扩展应用程序变得简单。 docker安装先决条件(1)运行64位CPU架构的计算机，不支持32位的CPU(2)运行linux3.8或更高版本的内核查看内核版本:uname -a目前3.8内核已经可以通过apt-get来安装，内核更新步骤:apt-get updateapt-get install linux-headers-3.8.0-27-genericupdate-grubreboot(3)内核必须支持一种适合的存储驱动，默认是Device Mapper检查主机是否安装Device-mapper:grep device-mapper /proc/devices如果没有出现device-mapper的相关信息，可以尝试加载dm_mod模块:modprobe dm_mod(4)内核必须支持并开启cgroup和namespace(命名空间)的功能cgroup和namespace自2.6版本就已经集成到linux内核中，目前为止功能非常稳定 docker安装默认docker只能在centos6.5以上机器才能使用yum直接安装，如果是其他版本的话需要安装centos扩展源epel。docker官方要求linux kernel至少要3.8以上。在centos6.5系统上安装docker:(1)关闭selinux(2)安装epel源wget http://ftp.riken.jp/Linux/fedora/epel/6/x86_64/epel-release-6-8.noarch.rpmrpm -ivh epel-release-6-8.noarch.rpm(3)安装依赖yum install lxc libcgroup device-mapper-event-libsdevice-mapper* -y(4)安装dockeryum install docker-io(5)docker启动/etc/init.d/docker start在ubuntu 16.04安装docker:(1)安装wget -qO- https://get.docker.com/ | sh(2)启动/etc/init.d/docker start备注:在ubuntu中，如果使用UFW，需要在UFW中启用数据报文转发，才能让docker正常工作。因为UFW默认情况下会丢弃所有转发的数据包。修改/etc/default/ufw，将DEFAULT_FORWARD_POLICY=”DROP”修改为DEFAULT_FORWARD_POLICY=”ACCEPT”，保存修改内容并通过ufw reload重启UFW即可 docker常用命令docker version #查看docker版本docker images #查看当前的docker所有镜像docker info #检查docker是否已经正确安装并运行docker search centos #搜索可用的docker镜像docker pull centos #从公有仓库中下载镜像cat centos.tar | docker import - centos6 #导入镜像，导入centos.tar镜像并重命名为centos6docker export id &gt; centos6.tar #导出镜像，根据id导出镜像并重命名为centos6.tardocker ps -l #查看最后一个容器的iddocker ps -a #查看所有容器docker run centos echo “hello world” #在容器中运行”hello world”docker run centos yum install ntpdate #在容器中安装ntpdate程序docker run -i -t centos /bin/bash #在容器中启动一个/bin/bash shell环境，可以登入操作，-t表示打开一个终端，-i表示交互式输入docker run -d centos:v1 /bin/bash #在后台启动一个/bin/bash shell环境，-d表示在后台以daemon方式启动docker run -d -p 80:80 -p 8022:22 centos:v2 #-p指定容器启动后docker上运行的端口映射为容器里运行的端口，80:80中第一个80表示docker系统(本机)的80端口，第二个80表示docker虚拟机(docker容器)里面的端口。用户默认访问本机80端口，自动映射到容器里面的80端口docker commit 2313132 centos:v1 #提交刚修改的容器docker stop id #关闭容器docker start id #启动容器docker rm id #删除容器","categories":[{"name":"容器技术","slug":"容器技术","permalink":"http://yoursite.com/categories/容器技术/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/tags/docker/"}]},{"title":"初识java","slug":"初识java","date":"2018-10-10T08:33:00.000Z","updated":"2018-10-15T03:40:52.015Z","comments":true,"path":"2018/10/10/初识java/","link":"","permalink":"http://yoursite.com/2018/10/10/初识java/","excerpt":"","text":"1、先了解一下PHP(1)PHP是开发语言，也是运行环境作为开发语言，PHP属于脚本语言，也属于动态语言 (2)PHP编译过程:为简化编译过程，引入Zend Engine，编译成opcode，第一次编译第二次就不用编译；但是像Apache，每一个进程都使用一个独立的进程空间，因此第一个进程编译的结果第二个进程无法使用，因此又引入了缓存，像Xcache、APC、eAccelerator。 (3)PHP与C(面向过程)、C++(面向对象)相比较:PHP具有动态语言和脚本语言的灵活性、便捷性、移植性好C和C++移植困难、维护成本高，但是高速、性能好，一般用来开发驱动和底层程序等 插入介绍一些linux系统知识:(1)最底层:System call，系统调用上一层:API(application programming interface)，应用编程接口，有windows api和linux api再上一层:POSIX(POS全称portable operation system)，可移植操作系统，后面的IX是为了兼容linux操作系统的叫法。POSIX可以实现跨平台编译，POSIX是一种规范。(2)程序可以跨平台编译，但是不能跨平台运行(因为windows和linux的动态库不一样，windows系统是.so文件，linux系统是.dll文件)。因此，又出现一种叫做ABI的接口，ABI全称是application binary interface，可以拟合不同操作系统的二进制格式。在linux中，二进制格式是ELF；在windows中，二进制格式是EXE 最后引入java，java的出现就是为了能够在不同的操作系统上运行应用程序java包含四个独立又彼此相关的技术:(1)java程序设计语言(2)jvm(java virtual machine)，又叫java虚拟机(3)java class文件格式(4)java api彼此相关:java编程语言结合java api，编译成java class文件格式(字节码)，在jvm上运行(name.java–&gt;name.class,还有各种公有类和私有类跑在jvm上) 2、java apijava ee包含多个独立的api，servlet(硬编码)和jsp(.jsp-&gt;.java-&gt;.class)就是其中的两个，而java ee中著名的api还还包含以下几个:java ee api:(1)ehj(enterprise javabeans):java相关的诸多高级功能的实现，如rmi(remote method invocation)，对象/关系映射，跨越多个数据源的分布式事务等(2)jms(java message service):高性能异步消息服务，实现java ee应用程序与非java程序的透明通信(3)jmx(java management extensions):在程序运行时对其进行交互式监控和管理的机制(4)jta(java transaction api):允许应用程序在自身的一个或多个组件中平滑的处理错误的机制(5)javamail:通过工业标准的POP/SMTP/IMAP协议发送和接收邮件的机制 java se api:jndi(java naming and directory interface):用于与ldap服务交互的apijaxp(java api for xml processing):用于分析和转换xml 3、介绍jvmjvm最大的特点:一次编译，到处运行(once for all)jvm实现方式:(1)一次性解释器，解释字节码并执行(2)即时编译器(just-in-time complier)，依赖于更多内存缓存解释后的结果(3)自适应编译器，监控执行频率较高的代码，并将结果缓存下来(二八法则，缓存20%左右的代码，提高80%左右的速度) jvm分类:(1)hotspot，sum公司自己的jvm，hotspot又分为两类:jre:java运行环境，运行(编译)所需；jre=java语言+java se apijdk:java开发环境(包含jre，是jre的超集)，运行(编译)+开发所需；jdk=java语言+java api+jvm，jdk是实现java程序开发的最小环境(2)openjdk，开源界的jvm开发+运行的开源实现 java分类(根据java应用领域的不同):(1)java se:standard edition，标准版本，早期也叫做J2SE(2)java ee:enterprise edition，企业版本，早期也叫做J2EE(3)java me:mobile edition，移动版本，早期也叫做J2ME(用的很少) #2指的是第二版 4、介绍jdk:(1)jdk包格式jdk 1.6 update 32(jdk1.6的第32次升级，软件包名称是jdk-1.6.32)jdk 1.7 update 9(jdk1.7的第9次升级，软件包名称是jdk-1.7.9)(2)jdk安装方式rmp包通用二进制格式源码编译(3)命令yum list all|grep java #查看操作系统自身提供的jdk软件包java -version #查看java版本 5、介绍jsp(1)早期的时候，出现了applet这种小程序，用于开发动态网站；applet是开发在客户端运行的应用程序，基于web技术(2)接着，出现一种叫做CGI(common gateway interface)规范，能够让用户访问某种资源的时候，触发web服务器，调用额外的程序执行。除了CGI规范，java还提供了一种叫做servlet的规范，用来兼容applet和CGI；servlet是开发运行在服务器端的应用程序，基于CGI技术(3)在servlet的基础上进行升级改造，又引入了jsp(java server page)，用来嵌入java语言；jsp将servlet简化，开发者只需要将java程序嵌入到html代码中 #虽然说jsp拜托了servlet的束缚，但是jsp还是要通过Jasper先转换成servlet；jsp框架能够让java以嵌入式代码的方式嵌入到html代码中，从而实现基于java的动态网站开发 6、介绍java类(类库)有三类:(1)applet(2)servlet(3)jsp.jsp通过Jasper转换为.java.java通过jvm转换为.class 7、垃圾回收机制java程序可以实现自动内存回收，通过GC(gabbage collect)来完成(1)垃圾回收器:cms(Concurrent Mark-Sweep)，cms是以牺牲吞吐量为代价来获得最短回收停顿时间的垃圾回收器。对于要求服务器响应速度的应用上，这种垃圾回收器非常适合。在启动JVM参数加上-XX:+UseConcMarkSweepGC ，这个参数表示对于老年代的回收采用CMS。CMS采用的基础算法是：标记—清除。(2)cms过程:初始标记、并发标记、并发预处理、重新标记、并发清理、并发重置(3)cms优缺点:优点:并发收集、低停顿缺点:无法收集浮动垃圾，由于基于标记-清除算法，可能会产生碎片 8、java配置参数-XX:+ #开启此参数指定的功能-XX:- #关闭此参数指定的功能-XX:= #给option指定的选项赋值示例:java -XX:+PrintFlagsFinal #查看java配置所支持的参数 9、java工具sun jdk免费提供给用户监控和故障处理工具:(在jdk安装目录的bin目录下有很多java工具和命令)(1)jps:java process status tool，显示指定系统内的所有hotspot虚拟机进程的列表信息(2)jstat:jvm staticstics monitoring tool，收集并显示hotspot虚拟机各方面的运行数据(3)jinfo:显示正在运行的某hotspot虚拟机配置信息(4)jmap:生成某hotspot虚拟机的内存转储快照 可视化工具:(1)jconsole:java的监控和管理控制台(2)jvisualvm:java虚拟机控制台 #java工具除了sun开源的工具，还有很多商业的工具","categories":[{"name":"高可用web","slug":"高可用web","permalink":"http://yoursite.com/categories/高可用web/"}],"tags":[{"name":"tomcat","slug":"tomcat","permalink":"http://yoursite.com/tags/tomcat/"}]},{"title":"redis高级功能","slug":"redis高级功能","date":"2018-10-08T09:20:00.000Z","updated":"2018-10-10T06:18:55.021Z","comments":true,"path":"2018/10/08/redis高级功能/","link":"","permalink":"http://yoursite.com/2018/10/08/redis高级功能/","excerpt":"","text":"1、redis认证实现方法:(1)通过配置文件redis.conf修改requirepass PASSWORD #定义连接redis时的密码(2)通过客户端redis-cli修改auth PASSWORD #验证密码，PASSWORD为配置文件中requirepass定义的密码 2、redis事务(1)通过MULTI、EXEC、WATCH等命令实现事务功能:将一个命令或多个命令归并为一个操作提请服务器按顺序执行的机制举栗子:multi #启动(开始)一个事务……exec #执行(结束)一个事务 (2)watch:乐观锁在exec命令执行之前，用于监视指定键；如果监视中的某任意键数据被修改，则服务器拒绝执行事务(因为watch是监视数据是否被修改，一旦确认数据被修改，则放弃使用数据，而不是拒绝对方使用数据，所以叫乐观锁) (3)redis事务与传统关系型数据库的事务最大区别在于:redis不支持回滚 3、redis持久化:本质上是内存数据库redis持久化有两种机制:(1)RDB:快照机制，按事先制定的策略，周期性的将数据保存至磁盘，数据文件默认为dunp.rdb客户端也可以显式使用save或bgsave命令启动快照保存机制save:同步，在主线中保存快照，此时会阻塞所有客户端请求bgsave:异步，bg表示back-ground，后台运行，不会阻塞客户端请求 与rdb相关的配置文件参数:stop-write-on-bgsave-error yes #出错时停止写入rdbcompression yes #rdb文件是否执行压缩来节省磁盘空间rdbchecksum yes #是否对rdb的镜像文件做校验码检测dbfilename dump.rdb #指明文件名dir /var/lib/redis #指明rdb文件保存的目录 (2)AOF：append only file的缩写，把redis的每一个操作命令以附加的形式，附加到指定文件的尾部，会导致文件很大。记录每一次写操作至指定的文件尾部实现持久化，当redis重启时，可以通过重新执行文件中的命令在内存中重建数据库。通过bgrewriteaof来实现aof文件重写，不会读取正在使用的aof文件，而是通过将内存中的数据以命令的方式保存到临时文件中，完成之后替换原来的aof文件 与aof相关的配置文件参数:appendonly no #没有开启aof功能appendfilename “appendonly.aof” #文件名appendfsync always #每次收到写命令就立即写到aof文件appendfsync everysec #每秒钟写一次(折中的方式)appendfsync no #不通知内核，内核爱怎么写就怎么写no-appendfsync-on-write no #重写的时候对新写的操作不做sync操作，而是暂存在内存当中auto-aof-rewrite-percentage 100auto-aof-rewrite-min-size 64m aof重写过程:a.redis主进程通过fork创建子进程b.子进程根据redis内存中的数据创建数据库重建命令序列于临时文件中c.父进程继承client的请求，并会把这些请求中的写操作继续追加至原来的aof文件中；额外的，这些新的写请求还会被放置于一个缓冲队列中d.子进程重写完成，会通知父进程；父进程把缓冲中的命令写到临时文件中e.父进程用临时文件替换老的aof文件 使用子进程进行AOF重写的问题：子进程在进行AOF重写期间，服务器进程还要继续处理命令请求，而新的命令可能对现有的数据进行修改，这会让当前数据库的数据和重写后的AOF文件中的数据不一致如何修正:为了解决这种数据不一致的问题，Redis增加了一个AOF重写缓存，这个缓存在fork出子进程之后开始启用，Redis服务器主进程在执行完写命令之后，会同时将这个写命令追加到AOF缓冲区和AOF重写缓冲区即子进程在执行AOF重写时，主进程需要执行以下三个工作：执行client发来的命令请求；将写命令追加到现有的AOF文件中；将写命令追加到AOF重写缓存中。参考链接:https://blog.csdn.net/hezhiqiang1314/article/details/69396887 备注:重写本身不能取代备份，还应该指定备份策略，对redis数据库进行定期备份rdb与aof同时启用的时候:a.bgsave和bgrewriteaof不会同时执行b.在redis服务器启动数据恢复时，会优先使用aof 4、复制功能(1)特点:a.一个master可以有多个slaveb.支持链式复制c.master以非阻塞的方式同步数据至salve(2)主从(配置):slave slaveof master_ip master_port(3)认证如果master使用requirepass开启了认证功能，从服务器要使用masterauth 来连入服务请求来使用此密码进行验证 5、HA高可用通过sentinel来管理多个redis服务器实现HAsentinel作用:(1)用于监视主服务器(2)实现通知功能(notification)(3)实现自动故障转移 sentinel协议:(1)流言协议:接收主服务器是否下线的通知(2)投票协议:决定哪个服务器成为新的主服务器 sentinel启动:(1)redis-sentinel /path/to/file.conf(2)redis-server /path/to/file.conf –sentinel启动过程:(1)服务器自身初始化，运行redis-server中专用于sentinel功能的代码(2)初始化sentinel状态，根据给定的配置文件，初始化监控的master服务器列表(3)创建指向master的连接 sentinel下线:(1)主观下线:一个sentinel实例判断出某节点下线(2)客观下线:多个sentinel节点协商好判断出某节点下线 sentinel专用配置文件:/etc/redis-sentinel.conf(1)sentinel monitor mymaster 127.0.0.1 6379 2(2代表投票数) #多个sentinel的情况下，有2票投票从服务器成为主服务器的话，从服务器就会成为新的主服务器(2)sentinel down-after-milliseconds mymaster 30000 #30秒找不到主服务器就判断离线(3)sentinel parallel-syncs mymaster 2 #允许多少个从服务器向主服务器发起同步请求(4)sentinel failover-timeout mymaster 20 #主服务器发生故障，故障转移超时时间(故障转移超过这个时间，判断故障转移失败) sentinel专用命令(都以sentinel开头):sentinel masters:列出所有监视的主服务器sentinel slaves master_name:获取指定主服务器的从节点sentinel get-master-addr-by-name master_name:根据name获取master地址sentinel reset:重置操作sentinel failover &lt;master_name&gt;:手动执行故障转移操作 sentinel连接:(1)客户端连接sentinel示例redis-cli -h ipaddr -p 26379(sentinel默认端口)(2)客户端连接从节点示例redis-cli -h ipaddr -p 6380(自定义redis端口) 6、集群clustering:redis3.0以后支持分布式数据库，通过分片机制进行数据分析，clustering内的每个节点仅存数据库的一部分数据，也被称作去中心化(每一个节点都可以接入客户请求)。这样，每个节点都持有全局元数据，但仅持有一部分数据优点:(1)无中心化，gossip分散式模式(2)更少的来回次数并降低延迟(3)自动于多个redis节点进行分片(4)不需要第三方软件支持协调机制缺点:(1)依赖于redis3.0或更高版本(2)需要时间验证其稳定性(3)没有后台界面(4)需要智能客户端(5)redis客户端必须支持redis cluster架构","categories":[{"name":"数据库","slug":"数据库","permalink":"http://yoursite.com/categories/数据库/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://yoursite.com/tags/redis/"}]},{"title":"redis安装、配置及基本命令操作","slug":"redis配置及基本命令操作","date":"2018-10-08T08:19:00.000Z","updated":"2018-10-10T06:22:00.185Z","comments":true,"path":"2018/10/08/redis配置及基本命令操作/","link":"","permalink":"http://yoursite.com/2018/10/08/redis配置及基本命令操作/","excerpt":"","text":"1、redis特点:(1)原子性:要么全部执行，要么全部不执行(2)一致性:支持事务(3)隔离性:单线程(4)持久性:异步写入磁盘，避免雪崩效应 2、首先介绍一下redis3.0特性:(1)支持redis cluster(2)支持新的”embedded string”(3)LRU算法的改进改进如下:a.预设随机抽取5个样本，插入并排序至一个pool，移除最佳者，如此反复，直到内存用量小于maxmemory的设定b.样本5比先前的3多c.从局部最优趋向全局最优 3、redis组件:(1)redis-server(服务端)(2)redis-cli(客户端)(3)redis-benchmark(压测工具)(4)redis-check-dump &amp; redis-check-aof(检查持久化文件是否完整，分别对应rdb和aof格式) 4、redis官方站点:www.redis.ioyum info redis #查看epel源是否含有redis的安装包yum localinstall redis-3.0.2-1.el6.reml.x86_64.rpm #本地安装redisrpm -ql redis #查看安装redis时安装了哪些文件redis-server –help #查看帮助 5、redis配置文件(常用配置):(1)tcp-backlog #指等待队列。当并发量大的时候，redis可能会忙不过来。这时候需要额外找一个地方，将新的请求缓存下来，这个位置就叫backlog(2)redis.sock #服务端和客户端在同一台机器的时候，建议以sock文件的方式进行通信。好处是在内存当中直接交换，而不需要经过tcp/ip协议栈进行封装和解封装(3)timeout 0 #0表示连接不会超时(4)snapshotting配置:save 900 1 表示在900秒内有一个键发生变化，就做一次快照(5)replication配置:主从(6)daemonize yes #启动程序时，程序在后台运行 6、redis基本命令:(1)通过redis-cli客户端连接redis之后，可以通过help命令查看帮助help +tab键 #查看redis支持哪些类型help @STRING #查看字符串帮助help append #查看append命令的用法 (2)连接(connection)命令:help @connection #查看连接相关命令AUTH #验证PING #测试服务器是否在线，在线的话会返回PONGECHO #显示命令，例如ECHO ‘hello’QUIT #退出命令SELECT #选择数据库 (3)服务器(server)命令:help @server #查看服务器相关命令CLIENT SETNAME connection-name #设定连接名CLIENT GETNAME #查看连接名CLIENT KILL ip:port kill #关闭client (4)配置(config)命令:INFO #查看redis信息，信息包含很多段，例如INFO memory可以查看内存段的信息CONFIG RESETSTAT #重置INFO中所统计的数据CONFIG SET #运行中修改，也就是在内存中修改，不会同步到硬盘中CONFIG REWRITE #将配置写到硬盘当中CONFIG GET (如dir) #查看配置 7、redis支持的数据结构:(1)string #help @string，查看string支持的命令string支持的命令:set #help set，查看set帮助getappendstrlen (2)integer #help @integer，查看integer支持的命令integer支持的命令:incr #help incr，查看incr帮助decr (3)list [a,b,c,d] #help @list，查看list支持的命令list支持的命令:rpush #help rpush，查看rpush帮助lpushrpoplpoplindexlsetllen (4)set {a,b,c,d} #help @set，查看set支持的命令set支持的命令:sadd #help sadd，查看sadd帮助sinter #求交集sunion #求并集spop #随机弹出，set无序sismember #成员运算符 (5)sorted set {a:1,b:2,c:3} #help @sorten_set，查看sorten_set支持的命令sorten_set支持的命令:zadd #help zadd，查看zadd帮助zrangezcardzrank (6)hash {field1:”a”,field2:”b”}，说白了就是映射，也称为关联数组 #help @hash，查看hash支持的命令hash支持的命令:hset #help hset，查看set帮助hsetnxhgethkeyshvalshlenhdel (7)bitmaps #help @bitmaps，查看bitmaps支持的命令(8)hyperloglog #help @hyperloglog，查看hyperloglog支持的命令 …. 8、清空数据库:FLUSHDB:清空当前库FLUSHALL:清空所有库","categories":[{"name":"数据库","slug":"数据库","permalink":"http://yoursite.com/categories/数据库/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://yoursite.com/tags/redis/"}]},{"title":"初识redis","slug":"初识redis","date":"2018-10-08T06:59:00.000Z","updated":"2018-10-08T08:18:01.950Z","comments":true,"path":"2018/10/08/初识redis/","link":"","permalink":"http://yoursite.com/2018/10/08/初识redis/","excerpt":"","text":"redis属于nosql的一种。首先介绍一下nosql的分类:1、key-value nosql，比如redis，memcached2、column family nosql(列式存储)，比如hbase3、documentation nosql(文档存储)，比如mongodb4、graph nosql(图形存储) redis特性:1、key-value cache and store2、in-memory3、single threaded(单线程，因为redis占用cpu的消耗很低，因此cpu一般不会成为瓶颈)4、支持持久化(snapshotting，快照方式，异步写入到磁盘:AOF，append only file)5、支持主从(借助于sentinel实现一定意义上的HA:高可用)6、支持分布式集群(clustering)7、支持string、list、hash(关联数组)、set、sorted set(有序集合)、bitmap、hyperloglog redis与memcached比较:redis优势:1、支持的数据类型丰富，包括hash、lists、sets、sorted set、hyperloglog2、内建replication及cluster3、就地更新操作(in-place update)4、支持持久化(异步写入磁盘，避免雪崩效应)memcached优势:1、多线程(善用多核CPU，更少的阻塞操作)2、更少的内存开销3、更少的内存分配压力4、可能有更少的内存碎片","categories":[{"name":"数据库","slug":"数据库","permalink":"http://yoursite.com/categories/数据库/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://yoursite.com/tags/redis/"}]},{"title":"解决rabbitmq的web管理界面无法使用guest用户登录的问题","slug":"解决rabbitmq的web管理界面无法使用guest用户登录的问题","date":"2018-09-29T09:26:00.000Z","updated":"2018-09-29T09:27:15.108Z","comments":true,"path":"2018/09/29/解决rabbitmq的web管理界面无法使用guest用户登录的问题/","link":"","permalink":"http://yoursite.com/2018/09/29/解决rabbitmq的web管理界面无法使用guest用户登录的问题/","excerpt":"","text":"为了解决这个问题，需要在rabbitmq的配置文件中将loopback_users配置设置为空，如编写配置文件:/etc/rabbitmq/rabbitmq.config，并在其中添加以下内容： [{rabbit, [{loopback_users, []}]}]. 保存后重启rabbitmq-server即可随意使用guest用户名和密码来登录了(当然这个做法非常不安全)。","categories":[],"tags":[{"name":"rabbitmq","slug":"rabbitmq","permalink":"http://yoursite.com/tags/rabbitmq/"}]},{"title":"iptables删除已有的规则","slug":"iptables删除已有的规则","date":"2018-09-29T09:21:00.000Z","updated":"2018-09-29T09:24:02.852Z","comments":true,"path":"2018/09/29/iptables删除已有的规则/","link":"","permalink":"http://yoursite.com/2018/09/29/iptables删除已有的规则/","excerpt":"","text":"比如要删除input链上的某条规则，先要查询input链的所有规则iptables -L INPUT –line-numbers 查看你所要删除的规则是第几条，比如要删除第3条iptables -D INPUT 3","categories":[{"name":"linux简单应用","slug":"linux简单应用","permalink":"http://yoursite.com/categories/linux简单应用/"}],"tags":[{"name":"iptables","slug":"iptables","permalink":"http://yoursite.com/tags/iptables/"}]},{"title":"mysql启动报错:\"[ERROR] Table 'mysql.user' doesn't exist\"","slug":"mysql启动报错","date":"2018-09-29T09:16:00.000Z","updated":"2018-10-08T05:52:09.396Z","comments":true,"path":"2018/09/29/mysql启动报错/","link":"","permalink":"http://yoursite.com/2018/09/29/mysql启动报错/","excerpt":"","text":"这是因为编译安装mysql时指定了”–datadir=/usr/local/mysql/data”,所以在新增加一个/etc/my.cnf文件的时候，需要在my.cnf里面指定datadir=/usr/local/mysql/data 然后重启mysql就可以正常启动了","categories":[{"name":"数据库","slug":"数据库","permalink":"http://yoursite.com/categories/数据库/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/tags/mysql/"}]},{"title":"ubuntu安装ansible","slug":"ubuntu安装ansible","date":"2018-09-26T08:13:00.000Z","updated":"2018-10-08T05:50:39.916Z","comments":true,"path":"2018/09/26/ubuntu安装ansible/","link":"","permalink":"http://yoursite.com/2018/09/26/ubuntu安装ansible/","excerpt":"","text":"1、安装add-apt-repository必要套件apt-get install -y python-software-properties software-properties-common 2、使用ansible官方的PPA套件来源add-apt-repository -y ppa:ansible/ansible 3、升级apt-getapt-get update 4、安装ansibleapt-get install -y ansible","categories":[{"name":"安装篇","slug":"安装篇","permalink":"http://yoursite.com/categories/安装篇/"}],"tags":[{"name":"ansible","slug":"ansible","permalink":"http://yoursite.com/tags/ansible/"}]},{"title":"集群的概念","slug":"集群的概念","date":"2018-09-23T10:31:00.000Z","updated":"2018-09-23T10:42:13.270Z","comments":true,"path":"2018/09/23/集群的概念/","link":"","permalink":"http://yoursite.com/2018/09/23/集群的概念/","excerpt":"","text":"1、LB集群:lvs,nginx(lvs,nginx也可以实现高可用，但是相对来说在高可用中keepalived比较常见)2、HA集群:keepalived,heartbeat,corosync3、HP集群:高性能集群、超算集群，在互联网公司中很少见，一般在国家级实验室或者超算实验室中比较常见(HP集群一般可以用分布式计算来替换) 延伸:分布式计算中的一些概念分布式存储:HDFS分布式计算:YARNbatch:mapreducein-memory:sparkstream:storm HA cluster配置前提:1、本机的主机名与host中定义的主机名保持一致，要与hostname(uname -n)获得的名称保持一致 #根据主机名彼此通信配置主机名:在centos6中,/etc/sysconfig/networks在centos7中，hostnamectl set-hostname HOSTNAME #各节点要能相互解析主机名:一般建议通过host文件进行解析(配置文件/etc/hosts)2、各节点时间同步3、确保iptables及selinux不会成为服务的阻碍iptables -L -n #查看iptables规则getenforce #查看selinux状态","categories":[{"name":"高可用web","slug":"高可用web","permalink":"http://yoursite.com/categories/高可用web/"}],"tags":[{"name":"集群","slug":"集群","permalink":"http://yoursite.com/tags/集群/"}]},{"title":"keepalived配置实例","slug":"keepalived配置实例","date":"2018-09-23T09:53:00.000Z","updated":"2018-10-08T05:58:15.385Z","comments":true,"path":"2018/09/23/keepalived配置实例/","link":"","permalink":"http://yoursite.com/2018/09/23/keepalived配置实例/","excerpt":"","text":"实例一启动keepalived之后找不到配置文件:1、编辑/etc/rsyslog.conf #指明各类日志文件中的信息加上一句，local3.* /var/log/keepalived.log 2、编辑/etc/sysconfig/keepalived,加上一句，KEEPALIVED_OPTIONS=”-D -S 3” #指明keepalived日志文件的facility(等级)为3 3、重启rsyslog,keepalived服务在centos7中，systemctl restart rsyslog.servicesystemctl restart keepalived.service 实例二手动调度vip在两台主机中转移在配置文件中，1、vrrp实例之外加上一个函数vrrp_script chk_maintainnance{ script “[[ -f /etc/keepalived/down]] &amp;&amp; exit 1 || exit 0” interval 1 weight -2} 2、vrrp实例之内调用这个函数track_script{ chk_maintainnance}用法:只需要touch /etc/keepalived/down,vip就会转移；删除down文件又会转移到另一台主机 实例三配置虚拟路由器组vrrp_sync_group VG_1{ group { VI_1 VI_2 }} vrrp_instance VI_1{ eth0 vip #对外部客户} vrrp_instance VI_2{ eth1 dip #对内部主机} 实例四主机状态发生改变时发送通知:在vrrp实例中定义 #notify scripts,alert as above –自定义脚本 notify_master | #当前节点转换为master时，发送相应消息 notify_backup | #当前节点转换为backup时，发送相应消息 notify_fault |&lt;QUOTED_STRING&gt; #当前节点转换为fault(发生故障)时，发送相应消息 notify | smtp_alert实例:””括起来的内容就是表示QUOTED_STRINGnotify_master “/etc/keepalived/notify.sh master”notify_backup “/etc/keepalived/notify.sh backup”notify_fault “/etc/keepalived/notify.sh fault” 下面是一个notify脚本的简单示例: #!/bin/bashvip=172.16.100.1contact=‘root@localhost’ notify(){ mailsubject=”hostname to be $1:$vip floating” mailbody=”date &#39;+%F %H:%M:%S&#39;:vrrp transtion,hostname change to be $1” echo $mailbody|mail -s “$mailsubject” $contact} case “$1” in master) notify master #/etc/rc.d/init.d/haproxy start exit 0 ;; backup) notify backup #/etc/rc.d/init.d/haproxy stop exit 0 ;; fault) notify fault #/etc/rc.d/init.d/haproxy stop exit 0 ;; *) echo “Usage:basename $0 {master|backup|fault}” exit 1 ;;esac","categories":[{"name":"高可用web","slug":"高可用web","permalink":"http://yoursite.com/categories/高可用web/"}],"tags":[{"name":"keepalived","slug":"keepalived","permalink":"http://yoursite.com/tags/keepalived/"}]},{"title":"keepalived在centos7中的安装和配置文件","slug":"keepalived在centos7中的安装及配置","date":"2018-09-23T09:37:00.000Z","updated":"2018-10-08T05:58:39.041Z","comments":true,"path":"2018/09/23/keepalived在centos7中的安装及配置/","link":"","permalink":"http://yoursite.com/2018/09/23/keepalived在centos7中的安装及配置/","excerpt":"","text":"keepalived目前已经被官方收录进linux版本当中，在centos中使用yum就可以下载安装keepalivedyum info keepalived #查看系统中的keepalived版本yun install keepalived #安装keepalivedrpm -ql keepalived #查看安装keepalived生成了哪些文件cat /usr/lib/systemd/system/keepalived.service #查看keepalived的启动等配置信息cat /etc/sysconfig/keepalived #查看keepalived支持的参数帮助 keepalived配置文件:分为三部分1、global configuration2、vrrp configuration #分两段，第一段vrrp instance，第二段vrrp synchonization group3、lvs configuration #根据配置文件生成lvs规则 man keepalived.conf #查看keepalived配置文件的配置帮助详细配置:1、global_defs:notification_emailnotification_email_fromsmtp_serversmtp_connection_timeoutrouter_id #即hostanmevrrp_mcast_group 224.x.x.x #定义多播地址，224固定不变，后面三位可以变化 2、vrrp_instance:state #master或backupinterface #在centos7中，int dev的名字是eno16777736virtual_router_id #vrid是唯一的，跟虚拟Mac相关，虚拟Mac的格式是00-00-5E-00-01-{vrid} #根据Mac格式，前面是固定的，后面补上vrid。温馨提示，master和backup的virtual_router_id必须是一样的，因为id一样说明master和backup是在同一个虚拟路由器中priority #0到255的数字，数字越大，优先级越高，优先级高的是masteradver_init #发送心跳信息的时间间隔，默认是1authentication { auth_type PASS #这里是简单字符认证 auth_pass xxxx #}virtual_ipaddress #定义虚拟ip地址，同一个虚拟路由器中的master和backup的vip的配置是一样的nopreempt #非抢占模式，默认为抢占模式","categories":[{"name":"高可用web","slug":"高可用web","permalink":"http://yoursite.com/categories/高可用web/"}],"tags":[{"name":"keepalived","slug":"keepalived","permalink":"http://yoursite.com/tags/keepalived/"}]},{"title":"初识Keepalived","slug":"eepalived简介、组件及配置文件","date":"2018-09-22T08:16:00.000Z","updated":"2018-10-08T05:59:06.233Z","comments":true,"path":"2018/09/22/eepalived简介、组件及配置文件/","link":"","permalink":"http://yoursite.com/2018/09/22/eepalived简介、组件及配置文件/","excerpt":"","text":"keepalived是vrrp协议在linux主机上的实现，能够根据配置文件自动生成ipvs规则，对各RS做健康状态检查。1、特点(1)轻量级(2)以守护进程的形式(3)节点类型分为active/passive 2、组件(1)vrrp stack(2)checkers(3)ipvs wrapper 3、keepalived涉及的协议(1)组播:主服务器发送hello信息给从服务器，证明”I am alive”配置同进退vrrp实例时，要注意多播地址，每一组实例默认会分配一个组播地址。如果是在配置文件中指定一个组播地址，则只能配置一组实例；如果需要配置多组实例(不让其中一台主机有空闲)，则需要在各组实例的配置中配置上组播地址 (2)ntp:network time protocol格式:ntpdate timeserver_ip，以这个时间服务器的时间为准，同步自己的时间date命令调整时间的格式:”date 月日时分年.秒” (3)vrrp:virtual routing redundent protocol，虚拟路由冗余协议(vrrp是路由交换协议，keepalived是vrrp在linux上的实现)vrrp是一种容错协议，保证当主机的下一跳路由出现故障时，由另一台路由器来代替出故障的路由器进行工作，从而保障网络通信的连续性和可靠性。在vrrp协议中，分为master和backup两种角色。 vrrp中的一些概念: vrid:虚拟路由器标识，有相同vrid的一组路由器构成一个虚拟路由器 虚拟Mac:一个虚拟路由器拥有一个虚拟Mac，通常情况下虚拟路由器回应arp请求使用的是虚拟Mac 优先级:vrrp根据优先级来确定虚拟路由器中每台路由器的地位 非抢占模式:即使backup路由器的优先级比master高，也不会抢占master的地位 抢占模式:根据优先级的大小来确定谁是master vrrp工作原理: a.虚拟路由器中的路由器根据优先级选举出master，master路由器通过发送免费arp报文，将自己的虚拟Mac地址通知给其他与其连接的设备或主机，从而承担报文转发任务 b.master路由器周期性发送vrrp报文，以公布其配置信息(优先级)和工作状况 c.如果master路由器出现故障，虚拟路由器中的backup路由器将根据优先级重新选举新的master d.虚拟路由器切换时，master路由器由一台设备切换成另外一台设备，新的master路由器只是简单的发送一个携带虚拟路由器的Mac地址和虚拟ip地址信息的免费arp报文，这样就可以更新与之连接的设备或主机的arp信息 e.backup路由器优先级高于master的时候，由backup路由器的工作方式(抢占或非抢占)来决定是否重新选举master vrrp认证方式: a.无认证 b.简单字符认证(将认证字符插入到vrrp报文中) c.md5认证(利用认证字符和MD5算法对vrrp报文进行加密)","categories":[{"name":"高可用web","slug":"高可用web","permalink":"http://yoursite.com/categories/高可用web/"}],"tags":[{"name":"keepalived","slug":"keepalived","permalink":"http://yoursite.com/tags/keepalived/"}]},{"title":"小麦","slug":"小麦","date":"2018-09-20T09:34:11.000Z","updated":"2018-09-20T09:34:16.584Z","comments":true,"path":"2018/09/20/小麦/","link":"","permalink":"http://yoursite.com/2018/09/20/小麦/","excerpt":"","text":"有一个姑娘叫小麦","categories":[],"tags":[]},{"title":"ubuntu 16.04搭建Hexo博客后台管理系统","slug":"ubuntu-16-04搭建Hexo博客后台管理系统","date":"2018-09-20T06:40:00.000Z","updated":"2018-09-20T07:00:40.481Z","comments":true,"path":"2018/09/20/ubuntu-16-04搭建Hexo博客后台管理系统/","link":"","permalink":"http://yoursite.com/2018/09/20/ubuntu-16-04搭建Hexo博客后台管理系统/","excerpt":"","text":"1、安装Hexo-adminnpm install –save hexo-admin #之前已经介绍安装Hexo,参考链接:https://leungzj.github.io/2018/09/19/ubuntu16-04-%E6%90%AD%E5%BB%BAHexo%E5%8D%9A%E5%AE%A2/ 2、启动服务hexo s &amp; 3、访问后台http://你的ip地址:4000/admin 4、后台启用密码登录(默认无密码)点击”Setup authentification here” 弹出设置窗口，按要求填入登录用户名和密码，然后将”admin config section”下面那一段代码复制到Hexo的配置文件_config.yml即可 5、重启Hexokillall hexohexo s &amp; 6、更换Hexo主题先切换到Hexo所在安装目录，通过git下载主题文件到本地文件夹git clone https://github.com/BosenY/Lap.git theme/lap #Hexo主题汇总链接:https://hexo.io/themes/ 7、修改Hexo配置文件_config.yml 8、保存配置文件，重新生成并重启Hexo服务hexo ghexo dkillall hexohexo s &amp;","categories":[{"name":"搭建篇","slug":"搭建篇","permalink":"http://yoursite.com/categories/搭建篇/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://yoursite.com/tags/Hexo/"}]},{"title":"secureCRT连接ubuntu显示中文乱码的解决方法","slug":"secureCRT显示中文乱码","date":"2018-09-20T05:33:00.000Z","updated":"2018-09-20T05:52:17.443Z","comments":true,"path":"2018/09/20/secureCRT显示中文乱码/","link":"","permalink":"http://yoursite.com/2018/09/20/secureCRT显示中文乱码/","excerpt":"","text":"一、ubuntu设置1、在/var/lib/locales/supported.d/local文件中添加一行:zh_CN.UTF-8 UTF-8 执行sudo locale-gen下载文件 2、在/etc/environment文件中添加两行:LANG=”zh_CN.UTF-8”LC_ALL=”zh_CN.UTF-8” 3、在~/.profile文件中添加两行:export LANG=”zh_CN.UTF-8”export LC_ALL=”zh_CN.UTF-8 执行source ~/.profile 二、secureCRT设置1、选择options – session options，弹出设置窗口2、选择terminal – emulation，terminal下拉表选择linux，并在”ansi color”前面方框打上勾 3、选择terminal – appearance，”current color scheme”选择traditional font字体选择fangsong，script选择”Chinese GB2312” character encoding下拉表选择utf-8 退出当前crt窗口，重新登录试试！","categories":[{"name":"工具篇","slug":"工具篇","permalink":"http://yoursite.com/categories/工具篇/"}],"tags":[{"name":"secureCRT","slug":"secureCRT","permalink":"http://yoursite.com/tags/secureCRT/"}]},{"title":"ubuntu16.04 源码编译安装boost1_59_0","slug":"ubuntu16-04-源码编译安装boost1-59-0","date":"2018-09-19T08:31:00.000Z","updated":"2018-09-19T08:38:34.285Z","comments":true,"path":"2018/09/19/ubuntu16-04-源码编译安装boost1-59-0/","link":"","permalink":"http://yoursite.com/2018/09/19/ubuntu16-04-源码编译安装boost1-59-0/","excerpt":"","text":"1、下载源码包wget https://iweb.dl.sourceforge.net/project/boost/boost/1.59.0/boost_1_59_0.tar.gz 2、解压缩tar zxvf boost_1_59_0.tar.gz 3、进入解压缩目录cd boost_1_59_0/ 4、运行bootstrap.sh脚本./bootstrap.sh –with-libraries=all –with-toolset=gcc参数解释:–with-libraries指定编译哪些boost库，all的话就是全部编译，只想编译部分库的话就把库的名称写上，用逗号分隔即可–with-toolset指定编译时使用哪种编译器，Linux下使用gcc即可，如果系统中安装了多个版本的gcc，在这里可以指定gcc的版本，比如–with-toolset=gcc-4.4 5、编译boost./b2 toolset=gcc 6、安装boost./b2 install可以加–prefix参数:用来指定boost的安装目录，不加此参数的话默认的头文件在/usr/local/include/boost目录下，库文件在/usr/local/lib/目录下 7、更新系统的动态链接库ldconfig","categories":[{"name":"安装篇","slug":"安装篇","permalink":"http://yoursite.com/categories/安装篇/"}],"tags":[{"name":"boost","slug":"boost","permalink":"http://yoursite.com/tags/boost/"}]},{"title":"ubuntu16.04 搭建Hexo博客","slug":"ubuntu16-04-搭建Hexo博客","date":"2018-09-19T06:56:00.000Z","updated":"2018-09-19T09:09:42.422Z","comments":true,"path":"2018/09/19/ubuntu16-04-搭建Hexo博客/","link":"","permalink":"http://yoursite.com/2018/09/19/ubuntu16-04-搭建Hexo博客/","excerpt":"","text":"一、安装Node.js1、安装curlapt install curl 2、安装node.jscurl -sL https://deb.nodesource.com/setup_8.x | sudo -E bash -apt install -y nodejs 3、检查版本(有版本号输出表示安装完成)node -vnpm -v 二、安装Hexo1、npm install -g hexo-cli 2、进入你希望建站的文件夹(必须是一个空的文件夹)，执行初始化命令:hexo init 3、安装依赖包:npm install 至此，Hexo本地博客搭建完成。 三、Hexo常用命令hexo help:查看帮助hexo init:初始化一个目录hexo generate:生成网页，在public目录查看整个网站的文件，简写为hexo ghexo server:用来启动本地站点，执行后即可在浏览器中输localhost:4000查看，简写为hexo shexo deploy:部署.deploy目录，可以简化为hexo dhexo clean:清除缓存，强烈建议每次部署deploy之前先清理缓存 四、使用github pages服务部署hexoGiuhub Page介绍:我们用来托管博客的服务叫做 Github Pages，它是 Github 用来提供给个人/组织或者项目的网页服务，只需要部署到你的 Github Repository，推送代码，便可以实时呈现。 1、首先要使用邮箱注册Github账号 2、设置gitgit config –global user.email “you@example.com“git config –global user.name “Your Name” 3、安装插件npm install hexo-deployer-git –save #为了部署到Github上，需要安装hexo-deployer-git插件 4、生成ssh秘钥ssh-keygen -t rsa -C you@example.com #-C后面跟住你在github的用户名邮箱，这样公钥才会被github认可 5、查看你的公钥，添加到Github账户的sshkey中less ~/.ssh/id_rsa.pub 6、Github上新建项目，项目名称为”用户名.github.io”，例如我的用户名是leungzj，则创建的项目名为leungzj.github.io 7、在setting–SSH and GPG keys中，添加生成的公钥，也就是将~/.ssh/id_rsa.pub的内容添加到这里 8、修改Hexo配置文件 9、编译并上传部署到Githubhexo generate #编译hexo deploy #将hexo部署到Github io上 10、访问Hexo博客通过用户名.github.io就可以Hexo博客啦！例如我的博客:https://leungzj.github.io/","categories":[{"name":"搭建篇","slug":"搭建篇","permalink":"http://yoursite.com/categories/搭建篇/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://yoursite.com/tags/Hexo/"}]},{"title":"ubuntu16.04 源码编译安装mysql5.7","slug":"安装篇-ubuntu16-04-安装mysql5-7","date":"2018-09-19T05:36:00.000Z","updated":"2018-09-20T02:42:02.370Z","comments":true,"path":"2018/09/19/安装篇-ubuntu16-04-安装mysql5-7/","link":"","permalink":"http://yoursite.com/2018/09/19/安装篇-ubuntu16-04-安装mysql5-7/","excerpt":"","text":"1、安装依赖sudo apt-get install make cmake gcc g++ bison libncurses5-dev build-essential 2、下载mysql 5.7源码包下载地址：https://dev.mysql.com/downloads/mysql/在”select operating system”中选择”source code”，我下载的版本是mysql-5.7.23 3、解压缩tar zxvf mysql-5.7.23.tar.gz -C /usr/localcd /usr/local/mysql-5.7.23/ 4、编译安装cmake . -DCMAKE_INSTALL_PREFIX=/usr/local/mysql -DMYSQL_DATADIR=/usr/local/mysql/data -DSYSCONFDIR=/etc -DWITH_INNOBASE_STORAGE_ENGINE=1 -DWITH_ARCHIVE_STORAGE_ENGINE=1 -DWITH_BLACKHOLE_STORAGE_ENGINE=1 -DWITH_PARTITION_STORAGE_ENGINE=1 -DWITH_PERFSCHEMA_STORAGE_ENGINE=1 -DWITHOUT_EXAMPLE_STORAGE_ENGINE=1 -DWITHOUT_FEDERATED_STORAGE_ENGINE=1 -DDEFAULT_CHARSET=utf8 -DDEFAULT_COLLATION=utf8_general_ci -DWITH_EXTRA_CHARSETS=all -DENABLED_LOCAL_INFILE=1 -DWITH_READLINE=1 -DMYSQL_UNIX_ADDR=/usr/local/mysql/mysql.sock -DMYSQL_TCP_PORT=3306 -DMYSQL_USER=mysql -DCOMPILATION_COMMENT=”lq-edition” -DENABLE_DTRACE=0 -DOPTIMIZER_TRACE=1 -DWITH_DEBUG=1 运行到这一步，出现报错信息:“CMake Error at cmake/boost.cmake:81 (MESSAGE): You can download it with -DDOWNLOAD_BOOST=1 -DWITH_BOOST=“提示需要安装boost库，安装参考链接:https://leungzj.github.io/2018/09/19/ubuntu16-04-%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85boost1-59-0/ makemake install 5、配置mysql(1)创建用户和用户组groupadd mysqluseradd -g mysql mysql (2)设置mysql安装目录的权限cd /usr/local/mysqlchown -R mysql:mysql ./ (3)mysql初始化 #这里会生成一个mysql临时登录密码，需要记下来，稍后登录mysql会用到bin/mysqld –initialize –user=mysql (4)启动mysqlsupport-files/mysql.server start (5)修改mysql登录密码bin/mysql -u root -pSET PASSWORD FOR ‘root‘@’localhost’ = PASSWORD(‘newpassword’); 6、远程连接mysql用类似navicat的客户端连接mysql，如果出现提示”is not allowed to connect”，需要在mysql命令行上设置远程连接权限，检查iptables是否开放3306端口(1)GRANT ALL ON . TO ‘root‘@’%’ IDENTIFIED BY ‘password’ WITH GRANT OPTION;(2)iptables -A INPUT -P tcp –dport 3306 -j ACCEPT","categories":[{"name":"安装篇","slug":"安装篇","permalink":"http://yoursite.com/categories/安装篇/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/tags/mysql/"}]}]}